{"id": "sha256:af1159a553dc17f382a4f30b6d821c0d68ae52ed52bddc1511e78e1869023d60", "content": "include::{commons}@data-commons::page$upgrade.adoc[]\n\nOnce you’ve decided to upgrade your application, you can find detailed information regarding specific features in the rest of the document.\nYou can find xref:upgrading.adoc#redis.upgrading[migration guides] specific to major version migrations at the end of this document.\n\nSpring Data's documentation is specific to that version, so any information that you find in here will contain the most up-to-date changes that are in that version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/commons/upgrade.adoc", "title": "upgrade", "heading": "upgrade", "heading_level": 1, "file_order": 0, "section_index": 0, "content_hash": "af1159a553dc17f382a4f30b6d821c0d68ae52ed52bddc1511e78e1869023d60", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/commons/upgrade.adoc"}}
{"id": "sha256:7452b69bf98436334b83ea4ca9a57467cfd6ebcf5a5143d325f78272444f5552", "content": "[[redis.repositories.anatomy]]\n\nRedis as a store itself offers a very narrow low-level API leaving higher level functions, such as secondary indexes and query operations, up to the user.\n\nThis section provides a more detailed view of commands issued by the repository abstraction for a better understanding of potential performance implications.\n\nConsider the following entity class as the starting point for all operations:\n\n.Example entity\n====\n[source,java]\n----\n@RedisHash(\"people\")\npublic class Person {\n\n @Id String id;\n @Indexed String firstname;\n String lastname;\n Address hometown;\n}\n\npublic class Address {\n\n @GeoIndexed Point location;\n}\n----\n====\n\n[[redis.repositories.anatomy.insert]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "anatomy", "heading_level": 1, "file_order": 1, "section_index": 0, "content_hash": "7452b69bf98436334b83ea4ca9a57467cfd6ebcf5a5143d325f78272444f5552", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:851a18cded34f7c6a065b0d3fe35bd19662bd5d799bdf2f9c91ba305b7e31f66", "content": "====\n[source,java]\n----\nrepository.save(new Person(\"rand\", \"al'thor\"));\n----\n\n[source,text]\n----\nHMSET \"people:19315449-cda2-4f5c-b696-9cb8018fa1f9\" \"_class\" \"Person\" \"id\" \"19315449-cda2-4f5c-b696-9cb8018fa1f9\" \"firstname\" \"rand\" \"lastname\" \"al'thor\" <1>\nSADD \"people\" \"19315449-cda2-4f5c-b696-9cb8018fa1f9\" <2>\nSADD \"people:firstname:rand\" \"19315449-cda2-4f5c-b696-9cb8018fa1f9\" <3>\nSADD \"people:19315449-cda2-4f5c-b696-9cb8018fa1f9:idx\" \"people:firstname:rand\" <4>\n----\n\n<1> Save the flattened entry as hash.\n<2> Add the key of the hash written in <1> to the helper index of entities in the same keyspace.\n<3> Add the key of the hash written in <2> to the secondary index of firstnames with the properties value.\n<4> Add the index of <3> to the set of helper structures for entry to keep track of indexes to clean on delete/update.\n====\n\n[[redis.repositories.anatomy.replace]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "Insert new", "heading_level": 2, "file_order": 1, "section_index": 1, "content_hash": "851a18cded34f7c6a065b0d3fe35bd19662bd5d799bdf2f9c91ba305b7e31f66", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:c94e613cf83a1a460790757f1f2b6755cb21a01dc9e5cddff7de16a212e39ec2", "content": "====\n[source,java]\n----\nrepository.save(new Person(\"e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\", \"Dragon Reborn\", \"al'thor\"));\n----\n\n[source,text]\n----\nDEL \"people:e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" <1>\nHMSET \"people:e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" \"_class\" \"Person\" \"id\" \"e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" \"firstname\" \"Dragon Reborn\" \"lastname\" \"al'thor\" <2>\nSADD \"people\" \"e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" <3>\nSMEMBERS \"people:e82908cf-e7d3-47c2-9eec-b4e0967ad0c9:idx\" <4>\nTYPE \"people:firstname:rand\" <5>\nSREM \"people:firstname:rand\" \"e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" <6>\nDEL \"people:e82908cf-e7d3-47c2-9eec-b4e0967ad0c9:idx\" <7>\nSADD \"people:firstname:Dragon Reborn\" \"e82908cf-e7d3-47c2-9eec-b4e0967ad0c9\" <8>\nSADD \"people:e82908cf-e7d3-47c2-9eec-b4e0967ad0c9:idx\" \"people:firstname:Dragon Reborn\" <9>\n----\n\n<1> Remove the existing hash to avoid leftovers of hash keys potentially no longer present.\n<2> Save the flattened entry as hash.\n<3> Add the key of the hash written in <1> to the helper index of entities in the same keyspace.\n<4> Get existing index structures that might need to be updated.\n<5> Check if the index exists and what type it is (text, geo, …).\n<6> Remove a potentially existing key from the index.\n<7> Remove the helper holding index information.\n<8> Add the key of the hash added in <2> to the secondary index of firstnames with the properties value.\n<9> Add the index of <6> to the set of helper structures for entry to keep track of indexes to clean on delete/update.\n====\n\n[[redis.repositories.anatomy.geo]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "Replace existing", "heading_level": 2, "file_order": 1, "section_index": 2, "content_hash": "c94e613cf83a1a460790757f1f2b6755cb21a01dc9e5cddff7de16a212e39ec2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:9c3e4c08991041b3bf4985d3967b7fcce8d4279cc35c5e54da866182eea6d8f6", "content": "Geo indexes follow the same rules as normal text based ones but use geo structure to store values.\nSaving an entity that uses a Geo-indexed property results in the following commands:\n\n====\n[source,text]\n----\nGEOADD \"people:hometown:location\" \"13.361389\" \"38.115556\" \"76900e94-b057-44bc-abcf-8126d51a621b\" <1>\nSADD \"people:76900e94-b057-44bc-abcf-8126d51a621b:idx\" \"people:hometown:location\" <2>\n----\n\n<1> Add the key of the saved entry to the the geo index.\n<2> Keep track of the index structure.\n====\n\n[[redis.repositories.anatomy.index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "Save Geo Data", "heading_level": 2, "file_order": 1, "section_index": 3, "content_hash": "9c3e4c08991041b3bf4985d3967b7fcce8d4279cc35c5e54da866182eea6d8f6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:47ade804ee5c7009724e6db3d3c752c136c97d17ec55d2858d68517ac956e5ed", "content": "====\n[source,java]\n----\nrepository.findByFirstname(\"egwene\");\n----\n\n[source,text]\n----\nSINTER \"people:firstname:egwene\" <1>\nHGETALL \"people:d70091b5-0b9a-4c0a-9551-519e61bc9ef3\" <2>\nHGETALL ...\n----\n\n<1> Fetch keys contained in the secondary index.\n<2> Fetch each key returned by <1> individually.\n====\n\n[[redis.repositories.anatomy.geo-index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "Find using simple index", "heading_level": 2, "file_order": 1, "section_index": 4, "content_hash": "47ade804ee5c7009724e6db3d3c752c136c97d17ec55d2858d68517ac956e5ed", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:3bd1fed662f546aa6ef080b89c1c241237f84ff5351d478dbcb86c7a6d091e9a", "content": "====\n[source,java]\n----\nrepository.findByHometownLocationNear(new Point(15, 37), new Distance(200, KILOMETERS));\n----\n\n[source,text]\n----\nGEORADIUS \"people:hometown:location\" \"15.0\" \"37.0\" \"200.0\" \"km\" <1>\nHGETALL \"people:76900e94-b057-44bc-abcf-8126d51a621b\" <2>\nHGETALL ...\n----\n\n<1> Fetch keys contained in the secondary index.\n<2> Fetch each key returned by <1> individually.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc", "title": "anatomy", "heading": "Find using Geo Index", "heading_level": 2, "file_order": 1, "section_index": 5, "content_hash": "3bd1fed662f546aa6ef080b89c1c241237f84ff5351d478dbcb86c7a6d091e9a", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/anatomy.adoc"}}
{"id": "sha256:1e376c17c481e3f82b6cd90655556203c8607dca6f38ea670952cea690dfe317", "content": "[[redis.repositories.cdi-integration]]\n\nInstances of the repository interfaces are usually created by a container, for which Spring is the most natural choice when working with Spring Data.\nSpring offers sophisticated for creating bean instances.\nSpring Data Redis ships with a custom CDI extension that lets you use the repository abstraction in CDI environments.\nThe extension is part of the JAR, so, to activate it, drop the Spring Data Redis JAR into your classpath.\n\nYou can then set up the infrastructure by implementing a CDI Producer for the javadoc:org.springframework.data.redis.connection.RedisConnectionFactory[] and javadoc:org.springframework.data.redis.core.RedisOperations[], as shown in the following example:\n\n[source,java]\n----\nclass RedisOperationsProducer {\n\n @Produces\n RedisConnectionFactory redisConnectionFactory() {\n\n LettuceConnectionFactory connectionFactory = new LettuceConnectionFactory(new RedisStandaloneConfiguration());\n connectionFactory.afterPropertiesSet();\n\tconnectionFactory.start();\n\n return connectionFactory;\n }\n\n void disposeRedisConnectionFactory(@Disposes RedisConnectionFactory redisConnectionFactory) throws Exception {\n\n if (redisConnectionFactory instanceof DisposableBean) {\n ((DisposableBean) redisConnectionFactory).destroy();\n }\n }\n\n @Produces\n @ApplicationScoped\n RedisOperations<byte[], byte[]> redisOperationsProducer(RedisConnectionFactory redisConnectionFactory) {\n\n RedisTemplate<byte[], byte[]> template = new RedisTemplate<byte[], byte[]>();\n template.setConnectionFactory(redisConnectionFactory);\n template.afterPropertiesSet();\n\n return template;\n }\n\n}\n----\n\nThe necessary setup can vary, depending on your JavaEE environment.\n\nThe Spring Data Redis CDI extension picks up all available repositories as CDI beans and creates a proxy for a Spring Data repository whenever a bean of a repository type is requested by the container.\nThus, obtaining an instance of a Spring Data repository is a matter of declaring an `@Injected` property, as shown in the following example:\n\n[source,java]\n----\nclass RepositoryClient {\n\n @Inject\n PersonRepository repository;\n\n public void businessMethod() {\n List<Person> people = repository.findAll();\n }\n}\n----\n\nA Redis Repository requires javadoc:org.springframework.data.redis.core.RedisKeyValueAdapter[] and javadoc:org.springframework.data.redis.core.RedisKeyValueTemplate[] instances.\nThese beans are created and managed by the Spring Data CDI extension if no provided beans are found.\nYou can, however, supply your own beans to configure the specific properties of javadoc:org.springframework.data.redis.core.RedisKeyValueAdapter[] and javadoc:org.springframework.data.redis.core.RedisKeyValueTemplate[].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/cdi-integration.adoc", "title": "cdi-integration", "heading": "cdi-integration", "heading_level": 1, "file_order": 2, "section_index": 0, "content_hash": "1e376c17c481e3f82b6cd90655556203c8607dca6f38ea670952cea690dfe317", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/cdi-integration.adoc"}}
{"id": "sha256:c9acd23cdcf0b741c5ad9588cf6ba0c495a45bf8a393b96cafa9b122f74a37e4", "content": "[[redis.repositories.cluster]]\n\nYou can use the Redis repository support in a clustered Redis environment.\nSee the \"`xref:redis/cluster.adoc[Redis Cluster]`\" section for `ConnectionFactory` configuration details.\nStill, some additional configuration must be done, because the default key distribution spreads entities and secondary indexes through out the whole cluster and its slots.\n\nThe following table shows the details of data on a cluster (based on previous examples):\n\n[options = \"header, autowidth\"]\n|===============\n|Key|Type|Slot|Node\n|people:e2c7dcee-b8cd-4424-883e-736ce564363e|id for hash|15171|127.0.0.1:7381\n|people:a9d4b3a0-50d3-4538-a2fc-f7fc2581ee56|id for hash|7373|127.0.0.1:7380\n|people:firstname:rand|index|1700|127.0.0.1:7379\n|===============\n\n====\n\nSome commands (such as `SINTER` and `SUNION`) can only be processed on the server side when all involved keys map to the same slot.\nOtherwise, computation has to be done on client side.\nTherefore, it is useful to pin keyspaces to a single slot, which lets make use of Redis server side computation right away.\nThe following table shows what happens when you do (note the change in the slot column and the port value in the node column):\n\n[options = \"header, autowidth\"]\n|===============\n|Key|Type|Slot|Node\n|\\{people}:e2c7dcee-b8cd-4424-883e-736ce564363e|id for hash|2399|127.0.0.1:7379\n|\\{people}:a9d4b3a0-50d3-4538-a2fc-f7fc2581ee56|id for hash|2399|127.0.0.1:7379\n|\\{people}:firstname:rand|index|2399|127.0.0.1:7379\n|===============\n====\n\nTIP: Define and pin keyspaces by using `@RedisHash(\"\\{yourkeyspace}\")` to specific slots when you use Redis cluster.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/cluster.adoc", "title": "cluster", "heading": "cluster", "heading_level": 1, "file_order": 3, "section_index": 0, "content_hash": "c9acd23cdcf0b741c5ad9588cf6ba0c495a45bf8a393b96cafa9b122f74a37e4", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/cluster.adoc"}}
{"id": "sha256:d40588e87d0b94fffef2a7d7e561516a31e77356d413d1e086e6eb82fabfda6e", "content": "[[redis.repositories.expirations]]\n\nObjects stored in Redis may be valid only for a certain amount of time.\nThis is especially useful for persisting short-lived objects in Redis without having to remove them manually when they reach their end of life.\nThe expiration time in seconds can be set with `@RedisHash(timeToLive=...)` as well as by using javadoc:org.springframework.data.redis.core.convert.KeyspaceConfiguration$KeyspaceSettings[] (see xref:redis/redis-repositories/keyspaces.adoc[Keyspaces]).\n\nMore flexible expiration times can be set by using the `@TimeToLive` annotation on either a numeric property or a method.\nHowever, do not apply `@TimeToLive` on both a method and a property within the same class.\nThe following example shows the `@TimeToLive` annotation on a property and on a method:\n\n.Expirations\n====\n[source,java]\n----\npublic class TimeToLiveOnProperty {\n\n @Id\n private String id;\n\n @TimeToLive\n private Long expiration;\n}\n\npublic class TimeToLiveOnMethod {\n\n @Id\n private String id;\n\n @TimeToLive\n public long getTimeToLive() {\n return new Random().nextLong();\n }\n}\n----\n====\n\nNOTE: Annotating a property explicitly with `@TimeToLive` reads back the actual `TTL` or `PTTL` value from Redis. `-1` indicates that the object has no associated expiration.\n\nThe repository implementation ensures subscription to https://redis.io/topics/notifications[Redis keyspace notifications] via javadoc:org.springframework.data.redis.listener.RedisMessageListenerContainer[].\n\nWhen the expiration is set to a positive value, the corresponding `EXPIRE` command is run.\nIn addition to persisting the original, a phantom copy is persisted in Redis and set to expire five minutes after the original one.\nThis is done to enable the Repository support to publish javadoc:org.springframework.data.redis.core.RedisKeyExpiredEvent[], holding the expired value in Spring's `ApplicationEventPublisher` whenever a key expires, even though the original values have already been removed.\nExpiry events are received on all connected applications that use Spring Data Redis repositories.\n\nBy default, the key expiry listener is disabled when initializing the application.\nThe startup mode can be adjusted in `@EnableRedisRepositories` or `RedisKeyValueAdapter` to start the listener with the application or upon the first insert of an entity with a TTL.\nSee javadoc:org.springframework.data.redis.core.RedisKeyValueAdapter$EnableKeyspaceEvents[] for possible values.\n\nThe `RedisKeyExpiredEvent` holds a copy of the expired domain object as well as the key.\n\nNOTE: Delaying or disabling the expiry event listener startup impacts `RedisKeyExpiredEvent` publishing.\nA disabled event listener does not publish expiry events.\nA delayed startup can cause loss of events because of the delayed listener initialization.\n\nNOTE: The keyspace notification message listener alters `notify-keyspace-events` settings in Redis, if those are not already set.\nExisting settings are not overridden, so you must set up those settings correctly (or leave them empty).\nNote that `CONFIG` is disabled on AWS ElastiCache, and enabling the listener leads to an error.\nTo work around this behavior, set the `keyspaceNotificationsConfigParameter` parameter to an empty string.\nThis prevents `CONFIG` command usage.\n\nNOTE: Redis repositories rely on Pub/Sub messages for residual index cleanup.\nRedis Pub/Sub messages are not persistent.\nIf a key expires while the application is down, the expiry event is not processed, which may lead to secondary indexes containing references to the expired object.\nRedis does not allow for expiration of individual entries of a set that is used as secondary index.\n\nNOTE: `@EnableKeyspaceEvents(shadowCopy = OFF)` disable storage of phantom copies and reduces data size within Redis. `RedisKeyExpiredEvent` will only contain the `id` of the expired key.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/expirations.adoc", "title": "expirations", "heading": "expirations", "heading_level": 1, "file_order": 4, "section_index": 0, "content_hash": "d40588e87d0b94fffef2a7d7e561516a31e77356d413d1e086e6eb82fabfda6e", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/expirations.adoc"}}
{"id": "sha256:9d5357eb9666d88d2de8a4737cc919e63f855030780dfa327ee7cd0f9d52b609", "content": "[[redis.repositories.indexes]]\n\nhttps://redis.io/topics/indexes[Secondary indexes] are used to enable lookup operations based on native Redis structures.\nValues are written to the according indexes on every save and are removed when objects are deleted or xref:redis/redis-repositories/expirations.adoc[expire].\n\n[[redis.repositories.indexes.simple]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc", "title": "indexes", "heading": "indexes", "heading_level": 1, "file_order": 5, "section_index": 0, "content_hash": "9d5357eb9666d88d2de8a4737cc919e63f855030780dfa327ee7cd0f9d52b609", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc"}}
{"id": "sha256:155330aabcfb92ecb340f3768f014c02ea57ffd68ecb6e183af8fa99942c6f88", "content": "Given the sample `Person` entity shown earlier, we can create an index for `firstname` by annotating the property with `@Indexed`, as shown in the following example:\n\n.Annotation driven indexing\n====\n[source,java]\n----\n@RedisHash(\"people\")\npublic class Person {\n\n @Id String id;\n @Indexed String firstname;\n String lastname;\n Address address;\n}\n----\n====\n\nIndexes are built up for actual property values.\nSaving two Persons (for example, \"rand\" and \"aviendha\") results in setting up indexes similar to the following:\n\n====\n[source,text]\n----\nSADD people:firstname:rand e2c7dcee-b8cd-4424-883e-736ce564363e\nSADD people:firstname:aviendha a9d4b3a0-50d3-4538-a2fc-f7fc2581ee56\n----\n====\n\nIt is also possible to have indexes on nested elements.\nAssume `Address` has a `city` property that is annotated with `@Indexed`.\nIn that case, once `person.address.city` is not `null`, we have Sets for each city, as shown in the following example:\n\n====\n[source,text]\n----\nSADD people:address.city:tear e2c7dcee-b8cd-4424-883e-736ce564363e\n----\n====\n\nFurthermore, the programmatic setup lets you define indexes on map keys and list properties, as shown in the following example:\n\n====\n[source,java]\n----\n@RedisHash(\"people\")\npublic class Person {\n\n // ... other properties omitted\n\n Map<String, String> attributes; <1>\n Map<String, Person> relatives; <2>\n List<Address> addresses; <3>\n}\n----\n\n<1> `SADD people:attributes.map-key:map-value e2c7dcee-b8cd-4424-883e-736ce564363e`\n<2> `SADD people:relatives.map-key.firstname:tam e2c7dcee-b8cd-4424-883e-736ce564363e`\n<3> `SADD people:addresses.city:tear e2c7dcee-b8cd-4424-883e-736ce564363e`\n====\n\nCAUTION: Indexes cannot be resolved on xref:redis/redis-repositories/usage.adoc#redis.repositories.references[References].\n\nAs with keyspaces, you can configure indexes without needing to annotate the actual domain type, as shown in the following example:\n\n.Index Setup with @EnableRedisRepositories\n====\n[source,java]\n----\n@Configuration\n@EnableRedisRepositories(indexConfiguration = MyIndexConfiguration.class)\npublic class ApplicationConfig {\n\n //... RedisConnectionFactory and RedisTemplate Bean definitions omitted\n\n public static class MyIndexConfiguration extends IndexConfiguration {\n\n @Override\n protected Iterable<IndexDefinition> initialConfiguration() {\n return Collections.singleton(new SimpleIndexDefinition(\"people\", \"firstname\"));\n }\n }\n}\n----\n====\n\nAgain, as with keyspaces, you can programmatically configure indexes, as shown in the following example:\n\n.Programmatic Index setup\n====\n[source,java]\n----\n@Configuration\n@EnableRedisRepositories\npublic class ApplicationConfig {\n\n //... RedisConnectionFactory and RedisTemplate Bean definitions omitted\n\n @Bean\n public RedisMappingContext keyValueMappingContext() {\n return new RedisMappingContext(\n new MappingConfiguration(\n new KeyspaceConfiguration(), new MyIndexConfiguration()));\n }\n\n public static class MyIndexConfiguration extends IndexConfiguration {\n\n @Override\n protected Iterable<IndexDefinition> initialConfiguration() {\n return Collections.singleton(new SimpleIndexDefinition(\"people\", \"firstname\"));\n }\n }\n}\n----\n====\n\n[[redis.repositories.indexes.geospatial]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc", "title": "indexes", "heading": "Simple Property Index", "heading_level": 2, "file_order": 5, "section_index": 1, "content_hash": "155330aabcfb92ecb340f3768f014c02ea57ffd68ecb6e183af8fa99942c6f88", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc"}}
{"id": "sha256:345099d2c6ba6fc2b933c32d82cf21c1a35bfa074edfb1f996647da977fcf2d9", "content": "Assume the `Address` type contains a `location` property of type `Point` that holds the geo coordinates of the particular address.\nBy annotating the property with `@GeoIndexed`, Spring Data Redis adds those values by using Redis `GEO` commands, as shown in the following example:\n\n====\n[source,java]\n----\n@RedisHash(\"people\")\npublic class Person {\n\n Address address;\n\n // ... other properties omitted\n}\n\npublic class Address {\n\n @GeoIndexed Point location;\n\n // ... other properties omitted\n}\n\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n List<Person> findByAddressLocationNear(Point point, Distance distance); <1>\n List<Person> findByAddressLocationWithin(Circle circle); <2>\n}\n\nPerson rand = new Person(\"rand\", \"al'thor\");\nrand.setAddress(new Address(new Point(13.361389D, 38.115556D)));\n\nrepository.save(rand); <3>\n\nrepository.findByAddressLocationNear(new Point(15D, 37D), new Distance(200, Metrics.KILOMETERS)); <4>\n----\n\n<1> Query method declaration on a nested property, using `Point` and `Distance`.\n<2> Query method declaration on a nested property, using `Circle` to search within.\n<3> `GEOADD people:address:location 13.361389 38.115556 e2c7dcee-b8cd-4424-883e-736ce564363e`\n<4> `GEORADIUS people:address:location 15.0 37.0 200.0 km`\n====\n\nIn the preceding example the, longitude and latitude values are stored by using `GEOADD` that use the object's `id` as the member's name.\nThe finder methods allow usage of `Circle` or `Point, Distance` combinations for querying those values.\n\nNOTE: It is **not** possible to combine `near` and `within` with other criteria.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc", "title": "indexes", "heading": "Geospatial Index", "heading_level": 2, "file_order": 5, "section_index": 2, "content_hash": "345099d2c6ba6fc2b933c32d82cf21c1a35bfa074edfb1f996647da977fcf2d9", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/indexes.adoc"}}
{"id": "sha256:ef3a80e4fab6eecd8578bc521c5912b1ee0ec68ab19191d78c1f149cf48709bc", "content": "[[redis.repositories.keyspaces]]\n\nKeyspaces define prefixes used to create the actual key for the Redis Hash.\nBy default, the prefix is set to `getClass().getName()`.\nYou can alter this default by setting `@RedisHash` on the aggregate root level or by setting up a programmatic configuration.\nHowever, the annotated keyspace supersedes any other configuration.\n\nThe following example shows how to set the keyspace configuration with the `@EnableRedisRepositories` annotation:\n\n.Keyspace Setup via `@EnableRedisRepositories`\n====\n[source,java]\n----\n@Configuration\n@EnableRedisRepositories(keyspaceConfiguration = MyKeyspaceConfiguration.class)\npublic class ApplicationConfig {\n\n //... RedisConnectionFactory and RedisTemplate Bean definitions omitted\n\n public static class MyKeyspaceConfiguration extends KeyspaceConfiguration {\n\n @Override\n protected Iterable<KeyspaceSettings> initialConfiguration() {\n return Collections.singleton(new KeyspaceSettings(Person.class, \"people\"));\n }\n }\n}\n----\n====\n\nThe following example shows how to programmatically set the keyspace:\n\n.Programmatic Keyspace setup\n====\n[source,java]\n----\n@Configuration\n@EnableRedisRepositories\npublic class ApplicationConfig {\n\n //... RedisConnectionFactory and RedisTemplate Bean definitions omitted\n\n @Bean\n public RedisMappingContext keyValueMappingContext() {\n return new RedisMappingContext(\n new MappingConfiguration(new IndexConfiguration(), new MyKeyspaceConfiguration()));\n }\n\n public static class MyKeyspaceConfiguration extends KeyspaceConfiguration {\n\n @Override\n protected Iterable<KeyspaceSettings> initialConfiguration() {\n return Collections.singleton(new KeyspaceSettings(Person.class, \"people\"));\n }\n }\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/keyspaces.adoc", "title": "keyspaces", "heading": "keyspaces", "heading_level": 1, "file_order": 6, "section_index": 0, "content_hash": "ef3a80e4fab6eecd8578bc521c5912b1ee0ec68ab19191d78c1f149cf48709bc", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/keyspaces.adoc"}}
{"id": "sha256:4ab8750bbc87e296eafea4cf1a08ff97ae44f6c2d8db538b849128e696ecf14d", "content": "[[redis.repositories.mapping]]\n\nThe Redis Repository support persists Objects to Hashes.\nThis requires an Object-to-Hash conversion which is done by a `RedisConverter`.\nThe default implementation uses `Converter` for mapping property values to and from Redis native `byte[]`.\n\nGiven the `Person` type from the previous sections, the default mapping looks like the following:\n\n====\n[source,text]\n----\n_class = org.example.Person <1>\nid = e2c7dcee-b8cd-4424-883e-736ce564363e\nfirstname = rand <2>\nlastname = al’thor\naddress.city = emond's field <3>\naddress.country = andor\n----\n\n<1> The `_class` attribute is included on the root level as well as on any nested interface or abstract types.\n<2> Simple property values are mapped by path.\n<3> Properties of complex types are mapped by their dot path.\n====\n\n[[mapping-conversion]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc", "title": "mapping", "heading": "mapping", "heading_level": 1, "file_order": 7, "section_index": 0, "content_hash": "4ab8750bbc87e296eafea4cf1a08ff97ae44f6c2d8db538b849128e696ecf14d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc"}}
{"id": "sha256:2d3c66b8496923b015c8a3a325e9b52589e99292a75a3b403ea00c7e2426e38b", "content": "This section explains how types are mapped to and from a Hash representation:\n\n[cols=\"1,2,3\",options=\"header\"]\n.Default Mapping Rules\n|===\n| Type\n| Sample\n| Mapped Value\n\n| Simple Type +\n(for example, String)\n| String firstname = \"rand\";\n| firstname = \"rand\"\n\n| Byte array (`byte[]`)\n| byte[] image = \"rand\".getBytes();\n| image = \"rand\"\n\n| Complex Type +\n(for example, Address)\n| Address address = new Address(\"emond's field\");\n| address.city = \"emond's field\"\n\n| List +\nof Simple Type\n| List<String> nicknames = asList(\"dragon reborn\", \"lews therin\");\n| nicknames.[0] = \"dragon reborn\", +\nnicknames.[1] = \"lews therin\"\n\n| Map +\nof Simple Type\n| Map<String, String> atts = asMap({\"eye-color\", \"grey\"}, {\"...\n| atts.[eye-color] = \"grey\", +\natts.[hair-color] = \"...\n\n| List +\nof Complex Type\n| List<Address> addresses = asList(new Address(\"em...\n| addresses.[0].city = \"emond's field\", +\naddresses.[1].city = \"...\n\n| Map +\nof Complex Type\n| Map<String, Address> addresses = asMap({\"home\", new Address(\"em...\n| addresses.[home].city = \"emond's field\", +\naddresses.[work].city = \"...\n|===\n\nCAUTION: Due to the flat representation structure, Map keys need to be simple types, such as ``String`` or ``Number``.\n\nMapping behavior can be customized by registering the corresponding `Converter` in `RedisCustomConversions`.\nThose converters can take care of converting from and to a single `byte[]` as well as `Map<String, byte[]>`.\nThe first one is suitable for (for example) converting a complex type to (for example) a binary JSON representation that still uses the default mappings hash structure.\nThe second option offers full control over the resulting hash.\n\nWARNING: Writing objects to a Redis hash deletes the content from the hash and re-creates the whole hash, so data that has not been mapped is lost.\n\nThe following example shows two sample byte array converters:\n\n.Sample byte[] Converters\n====\n[source,java]\n----\n@WritingConverter\npublic class AddressToBytesConverter implements Converter<Address, byte[]> {\n\n private final JacksonJsonRedisSerializer<Address> serializer;\n\n public AddressToBytesConverter() {\n\n serializer = new JacksonJsonRedisSerializer<Address>(Address.class);\n serializer.setObjectMapper(new ObjectMapper());\n }\n\n @Override\n public byte[] convert(Address value) {\n return serializer.serialize(value);\n }\n}\n\n@ReadingConverter\npublic class BytesToAddressConverter implements Converter<byte[], Address> {\n\n private final JacksonJsonRedisSerializer<Address> serializer;\n\n public BytesToAddressConverter() {\n\n serializer = new JacksonJsonRedisSerializer<Address>(Address.class);\n serializer.setObjectMapper(new ObjectMapper());\n }\n\n @Override\n public Address convert(byte[] value) {\n return serializer.deserialize(value);\n }\n}\n----\n====\n\nUsing the preceding byte array `Converter` produces output similar to the following:\n\n====\n[source,text]\n----\n_class = org.example.Person\nid = e2c7dcee-b8cd-4424-883e-736ce564363e\nfirstname = rand\nlastname = al’thor\naddress = { city : \"emond's field\", country : \"andor\" }\n----\n====\n\nThe following example shows two examples of `Map` converters:\n\n.Sample Map<String, byte[]> Converters\n====\n[source,java]\n----\n@WritingConverter\npublic class AddressToMapConverter implements Converter<Address, Map<String, byte[]>> {\n\n @Override\n public Map<String, byte[]> convert(Address source) {\n return singletonMap(\"ciudad\", source.getCity().getBytes());\n }\n}\n\n@ReadingConverter\npublic class MapToAddressConverter implements Converter<Map<String, byte[]>, Address> {\n\n @Override\n public Address convert(Map<String, byte[]> source) {\n return new Address(new String(source.get(\"ciudad\")));\n }\n}\n----\n====\n\nUsing the preceding Map `Converter` produces output similar to the following:\n\n====\n[source,text]\n----\n_class = org.example.Person\nid = e2c7dcee-b8cd-4424-883e-736ce564363e\nfirstname = rand\nlastname = al’thor\nciudad = \"emond's field\"\n----\n====\n\nNOTE: Custom conversions have no effect on index resolution. xref:redis/redis-repositories/indexes.adoc[Secondary Indexes] are still created, even for custom converted types.\n\n[[customizing-type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc", "title": "mapping", "heading": "Data Mapping and Type Conversion", "heading_level": 2, "file_order": 7, "section_index": 1, "content_hash": "2d3c66b8496923b015c8a3a325e9b52589e99292a75a3b403ea00c7e2426e38b", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc"}}
{"id": "sha256:86a971dd493f50674aea2ea2f906b91a29b830aafc31cc93fc1ffb48e4128b61", "content": "If you want to avoid writing the entire Java class name as type information and would rather like to use a key, you can use the `@TypeAlias` annotation on the entity class being persisted.\nIf you need to customize the mapping even more, look at the {spring-data-commons-javadoc-base}/org/springframework/data/convert/TypeInformationMapper.html[`TypeInformationMapper`] interface.\nAn instance of that interface can be configured at the `DefaultRedisTypeMapper`, which can be configured on `MappingRedisConverter`.\n\nThe following example shows how to define a type alias for an entity:\n\n.Defining `@TypeAlias` for an entity\n====\n[source,java]\n----\n@TypeAlias(\"pers\")\nclass Person {\n\n}\n----\n====\n\nThe resulting document contains `pers` as the value in a `_class` field.\n\n[[configuring-custom-type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc", "title": "mapping", "heading": "Customizing Type Mapping", "heading_level": 2, "file_order": 7, "section_index": 2, "content_hash": "86a971dd493f50674aea2ea2f906b91a29b830aafc31cc93fc1ffb48e4128b61", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc"}}
{"id": "sha256:9d8cbaa1976ef1d0cbbdb70bc30e95e7814029c482a3d53fe59f519b630a1801", "content": "The following example demonstrates how to configure a custom `RedisTypeMapper` in `MappingRedisConverter`:\n\n.Configuring a custom `RedisTypeMapper` via Spring Java Config\n====\n[source,java]\n----\nclass CustomRedisTypeMapper extends DefaultRedisTypeMapper {\n //implement custom type mapping here\n}\n----\n\n[source,java]\n----\n@Configuration\nclass SampleRedisConfiguration {\n\n @Bean\n public MappingRedisConverter redisConverter(RedisMappingContext mappingContext,\n RedisCustomConversions customConversions, ReferenceResolver referenceResolver) {\n\n MappingRedisConverter mappingRedisConverter = new MappingRedisConverter(mappingContext, null, referenceResolver,\n customTypeMapper());\n\n mappingRedisConverter.setCustomConversions(customConversions);\n\n return mappingRedisConverter;\n }\n\n @Bean\n public RedisTypeMapper customTypeMapper() {\n return new CustomRedisTypeMapper();\n }\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc", "title": "mapping", "heading": "Configuring Custom Type Mapping", "heading_level": 3, "file_order": 7, "section_index": 3, "content_hash": "9d8cbaa1976ef1d0cbbdb70bc30e95e7814029c482a3d53fe59f519b630a1801", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/mapping.adoc"}}
{"id": "sha256:49e8d63d3e63df803c50e886938be49a1ca08c617ae1994526d6f104f2cb2ec2", "content": "[[redis.repositories.queries]]\n\nQuery methods allow automatic derivation of simple finder queries from the method name, as shown in the following example:\n\n.Sample Repository finder Method\n====\n[source,java]\n----\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n List<Person> findByFirstname(String firstname);\n}\n----\n====\n\nNOTE: Please make sure properties used in finder methods are set up for indexing.\n\nNOTE: Query methods for Redis repositories support only queries for entities and collections of entities with paging.\n\nUsing derived query methods might not always be sufficient to model the queries to run. `RedisCallback` offers more control over the actual matching of index structures or even custom indexes.\nTo do so, provide a `RedisCallback` that returns a single or `Iterable` set of `id` values, as shown in the following example:\n\n.Sample finder using RedisCallback\n====\n[source,java]\n----\nString user = //...\n\nList<RedisSession> sessionsByUser = template.find(new RedisCallback<Set<byte[]>>() {\n\n public Set<byte[]> doInRedis(RedisConnection connection) throws DataAccessException {\n return connection\n .sMembers(\"sessions:securityContext.authentication.principal.username:\" + user);\n }}, RedisSession.class);\n----\n====\n\nThe following table provides an overview of the keywords supported for Redis and what a method containing that keyword essentially translates to:\n\n====\n.Supported keywords inside method names\n[options = \"header, autowidth\"]\n|===============\n|Keyword|Sample|Redis snippet\n|`And`|`findByLastnameAndFirstname`|`SINTER …:firstname:rand …:lastname:al’thor`\n|`Or`|`findByLastnameOrFirstname`|`SUNION …:firstname:rand …:lastname:al’thor`\n|`Is, Equals`|`findByFirstname`, `findByFirstnameIs`, `findByFirstnameEquals`|`SINTER …:firstname:rand`\n|`IsTrue` | `FindByAliveIsTrue` | `SINTER …:alive:1`\n|`IsFalse` | `findByAliveIsFalse` | `SINTER …:alive:0`\n|`Top,First`|`findFirst10ByFirstname`,`findTop5ByFirstname`|\n|===============\n====\n\n[[redis.repositories.queries.sort]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/queries.adoc", "title": "queries", "heading": "queries", "heading_level": 1, "file_order": 8, "section_index": 0, "content_hash": "49e8d63d3e63df803c50e886938be49a1ca08c617ae1994526d6f104f2cb2ec2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/queries.adoc"}}
{"id": "sha256:2f94cc37d02183db008893c9fed7a31242d7662c76ff8ae8f22d6078a7a6fe75", "content": "Redis repositories allow various approaches to define sorting order.\nRedis itself does not support in-flight sorting when retrieving hashes or sets.\nTherefore, Redis repository query methods construct a `Comparator` that is applied to the result before returning results as `List`.\nLet's take a look at the following example:\n\n.Sorting Query Results\n====\n[source,java]\n----\ninterface PersonRepository extends RedisRepository<Person, String> {\n\n List<Person> findByFirstnameOrderByAgeDesc(String firstname); <1>\n\n List<Person> findByFirstname(String firstname, Sort sort); <2>\n}\n----\n\n<1> Static sorting derived from method name.\n<2> Dynamic sorting using a method argument.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/queries.adoc", "title": "queries", "heading": "Sorting Query Method results", "heading_level": 2, "file_order": 8, "section_index": 1, "content_hash": "2f94cc37d02183db008893c9fed7a31242d7662c76ff8ae8f22d6078a7a6fe75", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/queries.adoc"}}
{"id": "sha256:268f25ffa9938b1631f9b2214e82d575fe05965c297e5dc0553bfaf209a58c1d", "content": "include::{commons}@data-commons::page$query-by-example.adoc[]\n\n[[query-by-example.running]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/query-by-example.adoc", "title": "query-by-example", "heading": "query-by-example", "heading_level": 1, "file_order": 9, "section_index": 0, "content_hash": "268f25ffa9938b1631f9b2214e82d575fe05965c297e5dc0553bfaf209a58c1d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/query-by-example.adoc"}}
{"id": "sha256:a2be132fd38d7bf5adc617595a1ea6a1d2e2f260274f2539620c43eb853336c9", "content": "The following example uses Query by Example against a repository:\n\n.Query by Example using a Repository\n====\n[source, java]\n----\ninterface PersonRepository extends ListQueryByExampleExecutor<Person> {\n}\n\nclass PersonService {\n\n @Autowired PersonRepository personRepository;\n\n List<Person> findPeople(Person probe) {\n return personRepository.findAll(Example.of(probe));\n }\n}\n----\n====\n\nRedis Repositories support, with their secondary indexes, a subset of Spring Data's Query by Example features.\nIn particular, only exact, case-sensitive, and non-null values are used to construct a query.\n\nSecondary indexes use set-based operations (Set intersection, Set union) to determine matching keys. Adding a property to the query that is not indexed returns no result, because no index exists. Query by Example support inspects indexing configuration to include only properties in the query that are covered by an index. This is to prevent accidental inclusion of non-indexed properties.\n\nCase-insensitive queries and unsupported `StringMatcher` instances are rejected at runtime.\n\nThe following list shows the supported Query by Example options:\n\n* Case-sensitive, exact matching of simple and nested properties\n* Any/All match modes\n* Value transformation of the criteria value\n* Exclusion of `null` values from the criteria\n\nThe following list shows properties not supported by Query by Example:\n\n* Case-insensitive matching\n* Regex, prefix/contains/suffix String-matching\n* Querying of Associations, Collection, and Map-like properties\n* Inclusion of `null` values from the criteria\n* `findAll` with sorting", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/query-by-example.adoc", "title": "query-by-example", "heading": "Running an Example", "heading_level": 2, "file_order": 9, "section_index": 1, "content_hash": "a2be132fd38d7bf5adc617595a1ea6a1d2e2f260274f2539620c43eb853336c9", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/query-by-example.adoc"}}
{"id": "sha256:ca6d0352de797cba50bbc6a0486cb7e8697fa567937b8d634eff34527b4195c9", "content": "[[redis.repositories.usage]]\n\nSpring Data Redis lets you easily implement domain entities, as shown in the following example:\n\n.Sample Person Entity\n====\n[source,java]\n----\n@RedisHash(\"people\")\npublic class Person {\n\n @Id String id;\n String firstname;\n String lastname;\n Address address;\n}\n----\n====\n\nWe have a pretty simple domain object here.\nNote that it has a `@RedisHash` annotation on its type and a property named `id` that is annotated with `org.springframework.data.annotation.Id`.\nThose two items are responsible for creating the actual key used to persist the hash.\n\nNOTE: Properties annotated with `@Id` as well as those named `id` are considered as the identifier properties.\nThose with the annotation are favored over others.\n\nTo now actually have a component responsible for storage and retrieval, we need to define a repository interface, as shown in the following example:\n\n.Basic Repository Interface To Persist Person Entities\n====\n[source,java]\n----\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n}\n----\n====\n\nAs our repository extends `CrudRepository`, it provides basic CRUD and finder operations.\nThe thing we need in between to glue things together is the corresponding Spring configuration, shown in the following example:\n\n.JavaConfig for Redis Repositories\n====\n[source,java]\n----\n@Configuration\n@EnableRedisRepositories\npublic class ApplicationConfig {\n\n @Bean\n public RedisConnectionFactory connectionFactory() {\n return new LettuceConnectionFactory();\n }\n\n @Bean\n public RedisTemplate<?, ?> redisTemplate(RedisConnectionFactory redisConnectionFactory) {\n\n RedisTemplate<byte[], byte[]> template = new RedisTemplate<byte[], byte[]>();\n template.setConnectionFactory(redisConnectionFactory);\n return template;\n }\n}\n----\n====\n\nGiven the preceding setup, we can inject `PersonRepository` into our components, as shown in the following example:\n\n.Access to Person Entities\n====\n[source,java]\n----\n@Autowired PersonRepository repo;\n\npublic void basicCrudOperations() {\n\n Person rand = new Person(\"rand\", \"al'thor\");\n rand.setAddress(new Address(\"emond's field\", \"andor\"));\n\n repo.save(rand); <1>\n\n repo.findOne(rand.getId()); <2>\n\n repo.count(); <3>\n\n repo.delete(rand); <4>\n}\n----\n\n<1> Generates a new `id` if the current value is `null` or reuses an already set `id` value and stores properties of type `Person` inside the Redis Hash with a key that has a pattern of `keyspace:id` -- in this case, it might be `people:5d67b7e1-8640-present-beeb-c666fab4c0e5`.\n<2> Uses the provided `id` to retrieve the object stored at `keyspace:id`.\n<3> Counts the total number of entities available within the keyspace, `people`, defined by `@RedisHash` on `Person`.\n<4> Removes the key for the given object from Redis.\n====\n\n[[redis.repositories.references]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc", "title": "usage", "heading": "usage", "heading_level": 1, "file_order": 10, "section_index": 0, "content_hash": "ca6d0352de797cba50bbc6a0486cb7e8697fa567937b8d634eff34527b4195c9", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc"}}
{"id": "sha256:2f7cfb745d59fc988cdec11d6b88d735fac5b00bd830897264448e1459181199", "content": "Marking properties with `@Reference` allows storing a simple key reference instead of copying values into the hash itself.\nOn loading from Redis, references are resolved automatically and mapped back into the object, as shown in the following example:\n\n.Sample Property Reference\n====\n[source,text]\n----\n_class = org.example.Person\nid = e2c7dcee-b8cd-4424-883e-736ce564363e\nfirstname = rand\nlastname = al’thor\nmother = people:a9d4b3a0-50d3-4538-a2fc-f7fc2581ee56 <1>\n----\n\n<1> Reference stores the whole key (`keyspace:id`) of the referenced object.\n====\n\nWARNING: Referenced Objects are not persisted when the referencing object is saved.\nYou must persist changes on referenced objects separately, since only the reference is stored.\nIndexes set on properties of referenced types are not resolved.\n\n[[redis.repositories.partial-updates]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc", "title": "usage", "heading": "Persisting References", "heading_level": 2, "file_order": 10, "section_index": 1, "content_hash": "2f7cfb745d59fc988cdec11d6b88d735fac5b00bd830897264448e1459181199", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc"}}
{"id": "sha256:26d62f133d3c8026a624098b4b015e2cf10300385e30fd2de0332c8397bac8e1", "content": "In some cases, you need not load and rewrite the entire entity just to set a new value within it.\nA session timestamp for the last active time might be such a scenario where you want to alter one property.\n`PartialUpdate` lets you define `set` and `delete` actions on existing objects while taking care of updating potential expiration times of both the entity itself and index structures.\nThe following example shows a partial update:\n\n.Sample Partial Update\n====\n[source,java]\n----\nPartialUpdate<Person> update = new PartialUpdate<Person>(\"e2c7dcee\", Person.class)\n .set(\"firstname\", \"mat\") <1>\n .set(\"address.city\", \"emond's field\") <2>\n .del(\"age\"); <3>\n\ntemplate.update(update);\n\nupdate = new PartialUpdate<Person>(\"e2c7dcee\", Person.class)\n .set(\"address\", new Address(\"caemlyn\", \"andor\")) <4>\n .set(\"attributes\", singletonMap(\"eye-color\", \"grey\")); <5>\n\ntemplate.update(update);\n\nupdate = new PartialUpdate<Person>(\"e2c7dcee\", Person.class)\n .refreshTtl(true); <6>\n .set(\"expiration\", 1000);\n\ntemplate.update(update);\n----\n\n<1> Set the simple `firstname` property to `mat`.\n<2> Set the simple 'address.city' property to 'emond's field' without having to pass in the entire object.\nThis does not work when a custom conversion is registered.\n<3> Remove the `age` property.\n<4> Set complex `address` property.\n<5> Set a map of values, which removes the previously existing map and replaces the values with the given ones.\n<6> Automatically update the server expiration time when altering xref:redis/redis-repositories/expirations.adoc[Time To Live].\n====\n\nNOTE: Updating complex objects as well as map (or other collection) structures requires further interaction with Redis to determine existing values, which means that rewriting the entire entity might be faster.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc", "title": "usage", "heading": "Persisting Partial Updates", "heading_level": 2, "file_order": 10, "section_index": 2, "content_hash": "26d62f133d3c8026a624098b4b015e2cf10300385e30fd2de0332c8397bac8e1", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-repositories/usage.adoc"}}
{"id": "sha256:ce1ef33896f71e4198b37c23d9ca5a933f57ba42899e886c01b48404ee1d8ae0", "content": "[[cluster]]\n\nWorking with https://redis.io/topics/cluster-spec[Redis Cluster] requires Redis Server version 3.0+.\nSee the https://redis.io/topics/cluster-tutorial[Cluster Tutorial] for more information.\n\nNOTE: When using xref:repositories.adoc[Redis Repositories] with Redis Cluster, make yourself familiar with how to xref:redis/redis-repositories/cluster.adoc[run Redis Repositories on a Cluster].\n\nCAUTION: Do not rely on keyspace events when using Redis Cluster as keyspace events are not replicated across shards.\nPub/Sub https://github.com/spring-projects/spring-data-redis/issues/1111[subscribes to a random cluster node] which only receives keyspace events from a single shard.\nUse single-node Redis to avoid keyspace event loss.\n\n[[cluster.working.with.cluster]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/cluster.adoc", "title": "cluster", "heading": "cluster", "heading_level": 1, "file_order": 11, "section_index": 0, "content_hash": "ce1ef33896f71e4198b37c23d9ca5a933f57ba42899e886c01b48404ee1d8ae0", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/cluster.adoc"}}
{"id": "sha256:9999e6ab458c8b23079c27c905d8c3643ea6f4500e215d742431cbf11e11ed73", "content": "Redis Cluster behaves differently from single-node Redis or even a Sentinel-monitored master-replica environment.\nThis is because the automatic sharding maps a key to one of `16384` slots, which are distributed across the nodes.\nTherefore, commands that involve more than one key must assert all keys map to the exact same slot to avoid cross-slot errors.\nA single cluster node serves only a dedicated set of keys.\nCommands issued against one particular server return results only for those keys served by that server.\nAs a simple example, consider the `KEYS` command.\nWhen issued to a server in a cluster environment, it returns only the keys served by the node the request is sent to and not necessarily all keys within the cluster.\nSo, to get all keys in a cluster environment, you must read the keys from all the known master nodes.\n\nWhile redirects for specific keys to the corresponding slot-serving node are handled by the driver libraries, higher-level functions, such as collecting information across nodes or sending commands to all nodes in the cluster, are covered by `RedisClusterConnection`.\nPicking up the keys example from earlier, this means that the `keys(pattern)` method picks up every master node in the cluster and simultaneously runs the `KEYS` command on every master node while picking up the results and returning the cumulated set of keys.\nTo just request the keys of a single node `RedisClusterConnection` provides overloads for those methods (for example, `keys(node, pattern)`).\n\nA `RedisClusterNode` can be obtained from `RedisClusterConnection.clusterGetNodes` or it can be constructed by using either the host and the port or the node Id.\n\nThe following example shows a set of commands being run across the cluster:\n\n.Sample of Running Commands Across the Cluster\n====\n[source,text]\n----\nredis-cli@127.0.0.1:7379 > cluster nodes\n\n6b38bb... 127.0.0.1:7379 master - 0 0 25 connected 0-5460 <1>\n7bb78c... 127.0.0.1:7380 master - 0 1449730618304 2 connected 5461-present2 <2>\n164888... 127.0.0.1:7381 master - 0 1449730618304 3 connected 10923-present3 <3>\nb8b5ee... 127.0.0.1:7382 slave 6b38bb... 0 1449730618304 25 connected <4>\n----\n\n[source,java]\n----\nRedisClusterConnection connection = connectionFactory.getClusterConnection();\n\nconnection.set(\"thing1\", value); <5>\nconnection.set(\"thing2\", value); <6>\n\nconnection.keys(\"*\"); <7>\n\nconnection.keys(NODE_7379, \"*\"); <8>\nconnection.keys(NODE_7380, \"*\"); <9>\nconnection.keys(NODE_7381, \"*\"); <10>\nconnection.keys(NODE_7382, \"*\"); <11>\n----\n\n<1> Master node serving slots 0 to 5460 replicated to replica at 7382\n<2> Master node serving slots 5461 to 10922\n<3> Master node serving slots 10923 to 16383\n<4> Replica node holding replicants of the master at 7379\n<5> Request routed to node at 7381 serving slot 12182\n<6> Request routed to node at 7379 serving slot 5061\n<7> Request routed to nodes at 7379, 7380, 7381 -> [thing1, thing2]\n<8> Request routed to node at 7379 -> [thing2]\n<9> Request routed to node at 7380 -> []\n<10> Request routed to node at 7381 -> [thing1]\n<11> Request routed to node at 7382 -> [thing2]\n====\n\nWhen all keys map to the same slot, the native driver library automatically serves cross-slot requests, such as `MGET`.\nHowever, once this is not the case, `RedisClusterConnection` runs multiple parallel `GET` commands against the slot-serving nodes and again returns an accumulated result.\nThis is less performant than the single-slot approach and, therefore, should be used with care.\nIf in doubt, consider pinning keys to the same slot by providing a prefix in curly brackets, such as `\\{my-prefix}.thing1` and `\\{my-prefix}.thing2`, which will both map to the same slot number.\nThe following example shows cross-slot request handling:\n\n.Sample of Cross-Slot Request Handling\n====\n[source,text]\n----\nredis-cli@127.0.0.1:7379 > cluster nodes\n\n6b38bb... 127.0.0.1:7379 master - 0 0 25 connected 0-5460 <1>\n7bb...\n----\n\n[source,java]\n----\nRedisClusterConnection connection = connectionFactory.getClusterConnection();\n\nconnection.set(\"thing1\", value); // slot: 12182\nconnection.set(\"{thing1}.thing2\", value); // slot: 12182\nconnection.set(\"thing2\", value); // slot: 5461\n\nconnection.mGet(\"thing1\", \"{thing1}.thing2\"); <2>\n\nconnection.mGet(\"thing1\", \"thing2\"); <3>\n----\n\n<1> Same Configuration as in the sample before.\n<2> Keys map to same slot -> 127.0.0.1:7381 MGET thing1 \\{thing1}.thing2\n<3> Keys map to different slots and get split up into single slot ones routed to the according nodes +\n-> 127.0.0.1:7379 GET thing2 +\n-> 127.0.0.1:7381 GET thing1\n====\n\nTIP: The preceding examples demonstrate the general strategy followed by Spring Data Redis.\nBe aware that some operations might require loading huge amounts of data into memory to compute the desired command.\nAdditionally, not all cross-slot requests can safely be ported to multiple single slot requests and error if misused (for example, `PFCOUNT`).\n\n[[cluster.redistemplate]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/cluster.adoc", "title": "cluster", "heading": "Working With Redis Cluster Connection", "heading_level": 2, "file_order": 11, "section_index": 1, "content_hash": "9999e6ab458c8b23079c27c905d8c3643ea6f4500e215d742431cbf11e11ed73", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/cluster.adoc"}}
{"id": "sha256:382dd919f80b4d671274a19bc701535178b47d86c8743a4cdf94bfe002156c00", "content": "See the xref:redis/template.adoc[Working with Objects through RedisTemplate] section for information about the general purpose, configuration, and usage of `RedisTemplate`.\n\nCAUTION: Be careful when setting up `RedisTemplate#keySerializer` using any of the JSON `RedisSerializers`, as changing JSON structure has immediate influence on hash slot calculation.\n\n`RedisTemplate` provides access to cluster-specific operations through the `ClusterOperations` interface, which can be obtained from `RedisTemplate.opsForCluster()`.\nThis lets you explicitly run commands on a single node within the cluster while retaining the serialization and deserialization features configured for the template.\nIt also provides administrative commands (such as `CLUSTER MEET`) or more high-level operations (for example, resharding).\n\nThe following example shows how to access `RedisClusterConnection` with `RedisTemplate`:\n\n.Accessing `RedisClusterConnection` with `RedisTemplate`\n====\n[source,java]\n----\nClusterOperations clusterOps = redisTemplate.opsForCluster();\nclusterOps.shutdown(NODE_7379); <1>\n----\n\n<1> Shut down node at 7379 and cross fingers there is a replica in place that can take over.\n====\n\nNOTE: Redis Cluster pipelining is currently only supported through the Lettuce driver except for the following commands when using cross-slot keys: `rename`, `renameNX`, `sort`, `bLPop`, `bRPop`, `rPopLPush`, `bRPopLPush`, `info`, `sMove`, `sInter`, `sInterStore`, `sUnion`, `sUnionStore`, `sDiff`, `sDiffStore`.\nSame-slot keys are fully supported.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/cluster.adoc", "title": "cluster", "heading": "Working with `RedisTemplate` and `ClusterOperations`", "heading_level": 2, "file_order": 11, "section_index": 2, "content_hash": "382dd919f80b4d671274a19bc701535178b47d86c8743a4cdf94bfe002156c00", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/cluster.adoc"}}
{"id": "sha256:8cb5094f4f28bde7a548df945216a10997746a9f25cd1a15c86be7a31806f2a4", "content": "[[configuration]]\n\nRedis can be operated in various setups.\nEach mode of operation requires specific configuration that is explained in the following sections.\n\n[[redis:standalone]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/connection-modes.adoc", "title": "connection-modes", "heading": "connection-modes", "heading_level": 1, "file_order": 12, "section_index": 0, "content_hash": "8cb5094f4f28bde7a548df945216a10997746a9f25cd1a15c86be7a31806f2a4", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/connection-modes.adoc"}}
{"id": "sha256:6178e05169d6e6ccf0da801f6fa9afbd5c71cc081e9aa94d4ace1695d3154cba", "content": "The easiest way to get started is by using Redis Standalone with a single Redis server,\n\nConfigure javadoc:org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory[] or javadoc:org.springframework.data.redis.connection.jedis.JedisConnectionFactory[], as shown in the following example:\n\n[source,java]\n----\n@Configuration\nclass RedisStandaloneConfiguration {\n\n /**\n * Lettuce\n */\n @Bean\n public RedisConnectionFactory lettuceConnectionFactory() {\n return new LettuceConnectionFactory(new RedisStandaloneConfiguration(\"server\", 6379));\n }\n\n /**\n * Jedis\n */\n @Bean\n public RedisConnectionFactory jedisConnectionFactory() {\n return new JedisConnectionFactory(new RedisStandaloneConfiguration(\"server\", 6379));\n }\n}\n----\n\n[[redis:write-to-master-read-from-replica]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/connection-modes.adoc", "title": "connection-modes", "heading": "Redis Standalone", "heading_level": 2, "file_order": 12, "section_index": 1, "content_hash": "6178e05169d6e6ccf0da801f6fa9afbd5c71cc081e9aa94d4ace1695d3154cba", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/connection-modes.adoc"}}
{"id": "sha256:09395147ed4dd06562c8660e227376a678390e2e6ed40db7eb68c9d83ae9133e", "content": "The Redis Master/Replica setup -- without automatic failover (for automatic failover see: <<redis:sentinel, Sentinel>>) -- not only allows data to be safely stored at more nodes.\nIt also allows, by using xref:redis/drivers.adoc#redis:connectors:lettuce[Lettuce], reading data from replicas while pushing writes to the master.\nYou can set the read/write strategy to be used by using `LettuceClientConfiguration`, as shown in the following example:\n\n[source,java]\n----\n@Configuration\nclass WriteToMasterReadFromReplicaConfiguration {\n\n @Bean\n public LettuceConnectionFactory redisConnectionFactory() {\n\n LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()\n .readFrom(REPLICA_PREFERRED)\n .build();\n\n RedisStandaloneConfiguration serverConfig = new RedisStandaloneConfiguration(\"server\", 6379);\n\n return new LettuceConnectionFactory(serverConfig, clientConfig);\n }\n}\n----\n\nTIP: For environments reporting non-public addresses through the `INFO` command (for example, when using AWS), use javadoc:org.springframework.data.redis.connection.RedisStaticMasterReplicaConfiguration[] instead of javadoc:org.springframework.data.redis.connection.RedisStandaloneConfiguration[]. Please note that `RedisStaticMasterReplicaConfiguration` does not support Pub/Sub because of missing Pub/Sub message propagation across individual servers.\n\n[[redis:sentinel]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/connection-modes.adoc", "title": "connection-modes", "heading": "Write to Master, Read from Replica", "heading_level": 2, "file_order": 12, "section_index": 2, "content_hash": "09395147ed4dd06562c8660e227376a678390e2e6ed40db7eb68c9d83ae9133e", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/connection-modes.adoc"}}
{"id": "sha256:235a8828d00d54ce11200ade9e83c71e54d62546c357609deb4c65458408d25d", "content": "For dealing with high-availability Redis, Spring Data Redis has support for https://redis.io/topics/sentinel[Redis Sentinel], using javadoc:org.springframework.data.redis.connection.RedisSentinelConfiguration[], as shown in the following example:\n\n[source,java]\n----\n/**\n * Lettuce\n */\n@Bean\npublic RedisConnectionFactory lettuceConnectionFactory() {\n RedisSentinelConfiguration sentinelConfig = new RedisSentinelConfiguration()\n .master(\"mymaster\")\n .sentinel(\"127.0.0.1\", 26379)\n .sentinel(\"127.0.0.1\", 26380);\n return new LettuceConnectionFactory(sentinelConfig);\n}\n\n/**\n * Jedis\n */\n@Bean\npublic RedisConnectionFactory jedisConnectionFactory() {\n RedisSentinelConfiguration sentinelConfig = new RedisSentinelConfiguration()\n .master(\"mymaster\")\n .sentinel(\"127.0.0.1\", 26379)\n .sentinel(\"127.0.0.1\", 26380);\n return new JedisConnectionFactory(sentinelConfig);\n}\n----\n\n[TIP]\n====\n`RedisSentinelConfiguration` can also be defined through `RedisSentinelConfiguration.of(PropertySource)`, which lets you pick up the following properties:\n\n.Configuration Properties\n* `spring.redis.sentinel.master`: name of the master node.\n* `spring.redis.sentinel.nodes`: Comma delimited list of host:port pairs.\n* `spring.redis.sentinel.username`: The username to apply when authenticating with Redis Sentinel (requires Redis 6)\n* `spring.redis.sentinel.password`: The password to apply when authenticating with Redis Sentinel\n* `spring.redis.sentinel.dataNode.username`: The username to apply when authenticating with Redis Data Node\n* `spring.redis.sentinel.dataNode.password`: The password to apply when authenticating with Redis Data Node\n* `spring.redis.sentinel.dataNode.database`: The database index to apply when authenticating with Redis Data Node\n====\n\nSometimes, direct interaction with one of the Sentinels is required. Using `RedisConnectionFactory.getSentinelConnection()` or `RedisConnection.getSentinelCommands()` gives you access to the first active Sentinel configured.\n\n[[cluster.enable]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/connection-modes.adoc", "title": "connection-modes", "heading": "Redis Sentinel", "heading_level": 2, "file_order": 12, "section_index": 3, "content_hash": "235a8828d00d54ce11200ade9e83c71e54d62546c357609deb4c65458408d25d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/connection-modes.adoc"}}
{"id": "sha256:eab60dc4bcc906da68095b93698983554643ade28e64fe2e7dbf1946dc1f8006", "content": "xref:redis/cluster.adoc[Cluster support] is based on the same building blocks as non-clustered communication. javadoc:org.springframework.data.redis.connection.RedisClusterConnection[], an extension to `RedisConnection`, handles the communication with the Redis Cluster and translates errors into the Spring DAO exception hierarchy.\n`RedisClusterConnection` instances are created with the `RedisConnectionFactory`, which has to be set up with the associated javadoc:org.springframework.data.redis.connection.RedisClusterConfiguration[], as shown in the following example:\n\n.Sample RedisConnectionFactory Configuration for Redis Cluster\n====\n[source,java]\n----\n@Component\n@ConfigurationProperties(prefix = \"spring.redis.cluster\")\npublic class ClusterConfigurationProperties {\n\n /*\n * spring.redis.cluster.nodes[0] = 127.0.0.1:7379\n * spring.redis.cluster.nodes[1] = 127.0.0.1:7380\n * ...\n */\n List<String> nodes;\n\n /**\n * Get initial collection of known cluster nodes in format {@code host:port}.\n *\n * @return\n */\n public List<String> getNodes() {\n return nodes;\n }\n\n public void setNodes(List<String> nodes) {\n this.nodes = nodes;\n }\n}\n\n@Configuration\npublic class AppConfig {\n\n /**\n * Type safe representation of application.properties\n */\n @Autowired ClusterConfigurationProperties clusterProperties;\n\n public @Bean RedisConnectionFactory connectionFactory() {\n\n return new LettuceConnectionFactory(\n new RedisClusterConfiguration(clusterProperties.getNodes()));\n }\n}\n----\n====\n\n[TIP]\n====\n`RedisClusterConfiguration` can also be defined through `RedisClusterConfiguration.of(PropertySource)`, which lets you pick up the following properties:\n\n.Configuration Properties\n- `spring.redis.cluster.nodes`: Comma-delimited list of host:port pairs.\n- `spring.redis.cluster.max-redirects`: Number of allowed cluster redirections.\n====\n\nNOTE: The initial configuration points driver libraries to an initial set of cluster nodes. Changes resulting from live cluster reconfiguration are kept only in the native driver and are not written back to the configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/connection-modes.adoc", "title": "connection-modes", "heading": "Redis Cluster", "heading_level": 2, "file_order": 12, "section_index": 4, "content_hash": "eab60dc4bcc906da68095b93698983554643ade28e64fe2e7dbf1946dc1f8006", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/connection-modes.adoc"}}
{"id": "sha256:bd67e07beafe69ef528c48fecf6cfc0c97d618ef759b4dacc779b361565b8691", "content": "[[redis:connectors]]\n\nOne of the first tasks when using Redis and Spring is to connect to the store through the IoC container.\nTo do that, a Java connector (or binding) is required.\nNo matter the library you choose, you need to use only one set of Spring Data Redis APIs (which behaves consistently across all connectors).\nThe `org.springframework.data.redis.connection` package and its `RedisConnection` and `RedisConnectionFactory` interfaces for working with and retrieving active connections to Redis.\n\n[[redis:connectors:connection]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/drivers.adoc", "title": "drivers", "heading": "drivers", "heading_level": 1, "file_order": 13, "section_index": 0, "content_hash": "bd67e07beafe69ef528c48fecf6cfc0c97d618ef759b4dacc779b361565b8691", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/drivers.adoc"}}
{"id": "sha256:ede18e05bb1e367ed6f429b2ea972de39cb50c29f51fa673a243bc3e803bbb70", "content": "`RedisConnection` provides the core building block for Redis communication, as it handles the communication with the Redis backend.\nIt also automatically translates underlying connecting library exceptions to Spring's consistent {spring-framework-docs}/data-access.html#dao-exceptions[DAO exception hierarchy] so that you can switch connectors without any code changes, as the operation semantics remain the same.\n\nNOTE: For the corner cases where the native library API is required, `RedisConnection` provides a dedicated method (`getNativeConnection`) that returns the raw, underlying object used for communication.\n\nActive `RedisConnection` objects are created through `RedisConnectionFactory`.\nIn addition, the factory acts as `PersistenceExceptionTranslator` objects, meaning that, once declared, they let you do transparent exception translation.\nFor example, you can do exception translation through the use of the `@Repository` annotation and AOP.\nFor more information, see the dedicated {spring-framework-docs}/data-access.html#orm-exception-translation[section] in the Spring Framework documentation.\n\nNOTE: `RedisConnection` classes are **not** Thread-safe.\nWhile the underlying native connection, such as Lettuce's `StatefulRedisConnection`, may be Thread-safe, Spring Data Redis's `LettuceConnection` class itself is not.\nTherefore, you should **not** share instances of a `RedisConnection` across multiple Threads.\nThis is especially true for transactional, or blocking Redis operations and commands, such as `BLPOP`.\nIn transactional and pipelining operations, for instance, `RedisConnection` holds onto unguarded mutable state to complete the operation correctly, thereby making it unsafe to use with multiple Threads.\nThis is by design.\n\nTIP: If you need to share (stateful) Redis resources, like connections, across multiple Threads, for performance reasons or otherwise, then you should acquire the native connection and use the Redis client library (driver) API directly.\nAlternatively, you can use the `RedisTemplate`, which acquires and manages connections for operations (and Redis commands) in a Thread-safe manner.\nSee xref:redis/template.adoc[documentation] on `RedisTemplate` for more details.\n\nNOTE: Depending on the underlying configuration, the factory can return a new connection or an existing connection (when a pool or shared native connection is used).\n\nThe easiest way to work with a `RedisConnectionFactory` is to configure the appropriate connector through the IoC container and inject it into the using class.\n\nUnfortunately, currently, not all connectors support all Redis features.\nWhen invoking a method on the Connection API that is unsupported by the underlying library, an `UnsupportedOperationException` is thrown.\nThe following overview explains features that are supported by the individual Redis connectors:\n\n[[redis:connectors:overview]]\n.Feature Availability across Redis Connectors\n|===\n| Supported Feature | Lettuce | Jedis\n\n| Standalone Connections\n| X\n| X\n\n| xref:redis.adoc#redis:write-to-master-read-from-replica[Master/Replica Connections]\n| X\n|\n\n| xref:redis.adoc#redis:sentinel[Redis Sentinel]\n| Master Lookup, Sentinel Authentication, Replica Reads\n| Master Lookup\n\n| xref:redis/cluster.adoc[Redis Cluster]\n| Cluster Connections, Cluster Node Connections, Replica Reads\n| Cluster Connections, Cluster Node Connections\n\n| Transport Channels\n| TCP, OS-native TCP (epoll, kqueue), Unix Domain Sockets\n| TCP\n\n| Connection Pooling\n| X (using `commons-pool2`)\n| X (using `commons-pool2`)\n\n| Other Connection Features\n| Singleton-connection sharing for non-blocking commands\n| Pipelining and Transactions mutually exclusive. Cannot use server/connection commands in pipeline/transactions.\n\n| SSL Support\n| X\n| X\n\n| xref:redis/pubsub.adoc[Pub/Sub]\n| X\n| X\n\n| xref:redis/pipelining.adoc[Pipelining]\n| X\n| X (Pipelining and Transactions mutually exclusive)\n\n| xref:redis/transactions.adoc[Transactions]\n| X\n| X (Pipelining and Transactions mutually exclusive)\n\n| Datatype support\n| Key, String, List, Set, Sorted Set, Hash, Server, Stream, Scripting, Geo, HyperLogLog\n| Key, String, List, Set, Sorted Set, Hash, Server, Stream, Scripting, Geo, HyperLogLog\n\n| Reactive (non-blocking) API\n| X\n|\n\n|===\n\n[[redis:connectors:lettuce]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/drivers.adoc", "title": "drivers", "heading": "RedisConnection and RedisConnectionFactory", "heading_level": 2, "file_order": 13, "section_index": 1, "content_hash": "ede18e05bb1e367ed6f429b2ea972de39cb50c29f51fa673a243bc3e803bbb70", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/drivers.adoc"}}
{"id": "sha256:60835f7ca06d01b097297c8955248829cf5ddcbcb524c733c452142f4bf68dca", "content": "https://github.com/lettuce-io/lettuce-core[Lettuce] is a https://netty.io/[Netty]-based open-source connector supported by Spring Data Redis through the `org.springframework.data.redis.connection.lettuce` package.\n\n.Add the following to the pom.xml files `dependencies` element:\n[source,xml,subs=\"+attributes\"]\n----\n<dependencies>\n\n <!-- other dependency elements omitted -->\n\n <dependency>\n <groupId>io.lettuce</groupId>\n <artifactId>lettuce-core</artifactId>\n <version>{lettuce}</version>\n </dependency>\n\n</dependencies>\n----\n\nThe following example shows how to create a new Lettuce connection factory:\n\n[source,java]\n----\n@Configuration\nclass AppConfig {\n\n @Bean\n public LettuceConnectionFactory redisConnectionFactory() {\n\n return new LettuceConnectionFactory(new RedisStandaloneConfiguration(\"server\", 6379));\n }\n}\n----\n\nThere are also a few Lettuce-specific connection parameters that can be tweaked.\nBy default, all `LettuceConnection` instances created by the `LettuceConnectionFactory` share the same thread-safe native connection for all non-blocking and non-transactional operations.\nTo use a dedicated connection each time, set `shareNativeConnection` to `false`. `LettuceConnectionFactory` can also be configured to use a `LettucePool` for pooling blocking and transactional connections or all connections if `shareNativeConnection` is set to `false`.\n\nThe following example shows a more sophisticated configuration, including SSL and timeouts, that uses `LettuceClientConfigurationBuilder`:\n\n[source,java]\n----\n@Bean\npublic LettuceConnectionFactory lettuceConnectionFactory() {\n\n LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()\n .useSsl().and()\n .commandTimeout(Duration.ofSeconds(2))\n .shutdownTimeout(Duration.ZERO)\n .build();\n\n return new LettuceConnectionFactory(new RedisStandaloneConfiguration(\"localhost\", 6379), clientConfig);\n}\n----\n\nFor more detailed client configuration tweaks, see javadoc:org.springframework.data.redis.connection.lettuce.LettuceClientConfiguration[].\n\nLettuce integrates with Netty's https://netty.io/wiki/native-transports.html[native transports], letting you use Unix domain sockets to communicate with Redis.\nMake sure to include the appropriate native transport dependencies that match your runtime environment.\nThe following example shows how to create a Lettuce Connection factory for a Unix domain socket at `/var/run/redis.sock`:\n\n[source,java]\n----\n@Configuration\nclass AppConfig {\n\n @Bean\n public LettuceConnectionFactory redisConnectionFactory() {\n\n return new LettuceConnectionFactory(new RedisSocketConfiguration(\"/var/run/redis.sock\"));\n }\n}\n----\n\nNOTE: Netty currently supports the epoll (Linux) and kqueue (BSD/macOS) interfaces for OS-native transport.\n\n[[redis:connectors:jedis]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/drivers.adoc", "title": "drivers", "heading": "Configuring the Lettuce Connector", "heading_level": 2, "file_order": 13, "section_index": 2, "content_hash": "60835f7ca06d01b097297c8955248829cf5ddcbcb524c733c452142f4bf68dca", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/drivers.adoc"}}
{"id": "sha256:9906aae2e6d72fb55a11d2146703715ad29e0f439307ac327c91b87539dd87b4", "content": "https://github.com/redis/jedis[Jedis] is a community-driven connector supported by the Spring Data Redis module through the `org.springframework.data.redis.connection.jedis` package.\n\n.Add the following to the pom.xml files `dependencies` element:\n[source,xml,subs=\"+attributes\"]\n----\n<dependencies>\n\n <!-- other dependency elements omitted -->\n\n <dependency>\n <groupId>redis.clients</groupId>\n <artifactId>jedis</artifactId>\n <version>{jedis}</version>\n </dependency>\n\n</dependencies>\n----\n\nIn its simplest form, the Jedis configuration looks as follow:\n\n[source,java]\n----\n@Configuration\nclass AppConfig {\n\n @Bean\n public JedisConnectionFactory redisConnectionFactory() {\n return new JedisConnectionFactory();\n }\n}\n----\n\nFor production use, however, you might want to tweak settings such as the host or password, as shown in the following example:\n\n[source,java]\n----\n@Configuration\nclass RedisConfiguration {\n\n @Bean\n public JedisConnectionFactory redisConnectionFactory() {\n\n RedisStandaloneConfiguration config = new RedisStandaloneConfiguration(\"server\", 6379);\n return new JedisConnectionFactory(config);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/drivers.adoc", "title": "drivers", "heading": "Configuring the Jedis Connector", "heading_level": 2, "file_order": 13, "section_index": 3, "content_hash": "9906aae2e6d72fb55a11d2146703715ad29e0f439307ac327c91b87539dd87b4", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/drivers.adoc"}}
{"id": "sha256:245500e356952af2e6e50c818e6c8fa6601854ad1f740d4060ad5b7626e86a64", "content": "[[redis.getting-started]]\n\nAn easy way to bootstrap setting up a working environment is to create a Spring-based project via https://start.spring.io/#!type=maven-project&dependencies=data-redis[start.spring.io] or create a Spring project in https://spring.io/tools[Spring Tools].\n\n[[redis.examples-repo]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/getting-started.adoc", "title": "getting-started", "heading": "getting-started", "heading_level": 1, "file_order": 14, "section_index": 0, "content_hash": "245500e356952af2e6e50c818e6c8fa6601854ad1f740d4060ad5b7626e86a64", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/getting-started.adoc"}}
{"id": "sha256:20e77e92fed6674f64a028341daf7b24f0b74bf919d2ebb8b70a3514c0949f93", "content": "The GitHub https://github.com/spring-projects/spring-data-examples[spring-data-examples repository] hosts several examples that you can download and play around with to get a feel for how the library works.\n\n[[redis.hello-world]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/getting-started.adoc", "title": "getting-started", "heading": "Examples Repository", "heading_level": 2, "file_order": 14, "section_index": 1, "content_hash": "20e77e92fed6674f64a028341daf7b24f0b74bf919d2ebb8b70a3514c0949f93", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/getting-started.adoc"}}
{"id": "sha256:19cbcc07dd2fb348a8ef8abb1f8a76a81b51a9eabad880294276acc819b14186", "content": "First, you need to set up a running Redis server.\nSpring Data Redis requires Redis 2.6 or above and Spring Data Redis integrates with https://github.com/lettuce-io/lettuce-core[Lettuce] and https://github.com/redis/jedis[Jedis], two popular open-source Java libraries for Redis.\n\nNow you can create a simple Java application that stores and reads a value to and from Redis.\n\nCreate the main application to run, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.serializer.StringRedisSerializer;\n\npublic class RedisApplication {\n\n\tprivate static final Log LOG = LogFactory.getLog(RedisApplication.class);\n\n\tpublic static void main(String[] args) {\n\n\t\tLettuceConnectionFactory connectionFactory = new LettuceConnectionFactory();\n\t\tconnectionFactory.afterPropertiesSet();\n\n\t\tRedisTemplate<String, String> template = new RedisTemplate<>();\n\t\ttemplate.setConnectionFactory(connectionFactory);\n\t\ttemplate.setDefaultSerializer(StringRedisSerializer.UTF_8);\n\t\ttemplate.afterPropertiesSet();\n\n\t\ttemplate.opsForValue().set(\"foo\", \"bar\");\n\n\t\tLOG.info(\"Value at foo:\" + template.opsForValue().get(\"foo\"));\n\n\t\tconnectionFactory.destroy();\n\t}\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nimport reactor.core.publisher.Mono;\n\nimport java.time.Duration;\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory;\nimport org.springframework.data.redis.core.ReactiveRedisTemplate;\nimport org.springframework.data.redis.serializer.RedisSerializationContext;\n\npublic class ReactiveRedisApplication {\n\n\tprivate static final Log LOG = LogFactory.getLog(ReactiveRedisApplication.class);\n\n\tpublic static void main(String[] args) {\n\n\t\tLettuceConnectionFactory connectionFactory = new LettuceConnectionFactory();\n\t\tconnectionFactory.afterPropertiesSet();\n\n\t\tReactiveRedisTemplate<String, String> template = new ReactiveRedisTemplate<>(connectionFactory,\n\t\t\t\tRedisSerializationContext.string());\n\n\t\tMono<Boolean> set = template.opsForValue().set(\"foo\", \"bar\");\n\t\tset.block(Duration.ofSeconds(10));\n\n\t\tLOG.info(\"Value at foo:\" + template.opsForValue().get(\"foo\").block(Duration.ofSeconds(10)));\n\n\t\tconnectionFactory.destroy();\n\t}\n}\n----\n======\n\nEven in this simple example, there are a few notable things to point out:\n\n* You can create an instance of javadoc:org.springframework.data.redis.core.RedisTemplate[] (or javadoc:org.springframework.data.redis.core.ReactiveRedisTemplate[]for reactive usage) with a javadoc:org.springframework.data.redis.connection.RedisConnectionFactory[]. Connection factories are an abstraction on top of the supported drivers.\n* There's no single way to use Redis as it comes with support for a wide range of data structures such as plain keys (\"strings\"), lists, sets, sorted sets, streams, hashes and so on.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/getting-started.adoc", "title": "getting-started", "heading": "Hello World", "heading_level": 2, "file_order": 14, "section_index": 2, "content_hash": "19cbcc07dd2fb348a8ef8abb1f8a76a81b51a9eabad880294276acc819b14186", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/getting-started.adoc"}}
{"id": "sha256:a79594c7d47a04b94251faf942e941f72f3c88dbaa6ad158e8450310b2ee98fb", "content": "[[redis.hashmappers.root]]\n\nData can be stored by using various data structures within Redis. javadoc:org.springframework.data.redis.serializer.JacksonJsonRedisSerializer[] can convert objects in https://en.wikipedia.org/wiki/JSON[JSON] format.\nIdeally, JSON can be stored as a value by using plain keys.\nYou can achieve a more sophisticated mapping of structured objects by using Redis hashes.\nSpring Data Redis offers various strategies for mapping data to hashes (depending on the use case):\n\n* Direct mapping, by using javadoc:org.springframework.data.redis.core.HashOperations[] and a xref:redis.adoc#redis:serializer[serializer]\n* Using xref:repositories.adoc[Redis Repositories]\n* Using javadoc:org.springframework.data.redis.hash.HashMapper[] and javadoc:org.springframework.data.redis.core.HashOperations[]\n\n[[redis.hashmappers.mappers]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/hash-mappers.adoc", "title": "hash-mappers", "heading": "hash-mappers", "heading_level": 1, "file_order": 15, "section_index": 0, "content_hash": "a79594c7d47a04b94251faf942e941f72f3c88dbaa6ad158e8450310b2ee98fb", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/hash-mappers.adoc"}}
{"id": "sha256:b9a74cd7f8f55028a86f393bddd6f1f83780880d03848ee87f49305822f95a8f", "content": "Hash mappers are converters of map objects to a `Map<K, V>` and back. javadoc:org.springframework.data.redis.hash.HashMapper[] is intended for using with Redis Hashes.\n\nMultiple implementations are available:\n\n* javadoc:org.springframework.data.redis.hash.BeanUtilsHashMapper[] using Spring's {spring-framework-javadoc}/org/springframework/beans/BeanUtils.html[BeanUtils].\n* javadoc:org.springframework.data.redis.hash.ObjectHashMapper[] using xref:redis/redis-repositories/mapping.adoc[Object-to-Hash Mapping].\n* <<redis.hashmappers.jackson3,`JacksonHashMapper`>> using https://github.com/FasterXML/jackson[FasterXML Jackson 3].\n* <<redis.hashmappers.jackson2,`Jackson2HashMapper`>> (deprecated) using https://github.com/FasterXML/jackson[FasterXML Jackson 2].\n\nThe following example shows one way to implement hash mapping:\n\n[source,java]\n----\npublic class Person {\n String firstname;\n String lastname;\n\n // …\n}\n\npublic class HashMapping {\n\n @Resource(name = \"redisTemplate\")\n HashOperations<String, byte[], byte[]> hashOperations;\n\n HashMapper<Object, byte[], byte[]> mapper = new ObjectHashMapper();\n\n public void writeHash(String key, Person person) {\n\n Map<byte[], byte[]> mappedHash = mapper.toHash(person);\n hashOperations.putAll(key, mappedHash);\n }\n\n public Person loadHash(String key) {\n\n Map<byte[], byte[]> loadedHash = hashOperations.entries(key);\n return (Person) mapper.fromHash(loadedHash);\n }\n}\n----\n\n[[redis.hashmappers.jackson3]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/hash-mappers.adoc", "title": "hash-mappers", "heading": "Hash Mappers", "heading_level": 2, "file_order": 15, "section_index": 1, "content_hash": "b9a74cd7f8f55028a86f393bddd6f1f83780880d03848ee87f49305822f95a8f", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/hash-mappers.adoc"}}
{"id": "sha256:d2622f38a57db0fee4849df5b548bd372a192841f94c008c30c78096cfec409c", "content": "javadoc:org.springframework.data.redis.hash.JacksonHashMapper[] provides Redis Hash mapping for domain objects by using https://github.com/FasterXML/jackson[FasterXML Jackson 3].\n`JacksonHashMapper` can map top-level properties as Hash field names and, optionally, flatten the structure.\nSimple types map to simple values. Complex types (nested objects, collections, maps, and so on) are represented as nested JSON.\n\nFlattening creates individual hash entries for all nested properties and resolves complex types into simple types, as far as possible.\n\nConsider the following class and the data structure it contains:\n\n[source,java]\n----\npublic class Person {\n String firstname;\n String lastname;\n Address address;\n Date date;\n LocalDateTime localDateTime;\n}\n\npublic class Address {\n String city;\n String country;\n}\n----\n\nThe following table shows how the data in the preceding class would appear in normal mapping:\n\n.Normal Mapping\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Hash Field\n|Value\n\n|firstname\n|`Jon`\n\n|lastname\n|`Snow`\n\n|address\n|`{ \"city\" : \"Castle Black\", \"country\" : \"The North\" }`\n\n|date\n|1561543964015\n\n|localDateTime\n|`2018-01-02T12:13:14`\n|====\n\nThe following table shows how the data in the preceding class would appear in flat mapping:\n\n.Flat Mapping\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Hash Field\n|Value\n\n|firstname\n|`Jon`\n\n|lastname\n|`Snow`\n\n|address.city\n|`Castle Black`\n\n|address.country\n|`The North`\n\n|date\n|1561543964015\n\n|localDateTime\n|`2018-01-02T12:13:14`\n|====\n\nNOTE: Flattening requires all property names to not interfere with the JSON path. Using dots or brackets in map keys or as property names is not supported when you use flattening. The resulting hash cannot be mapped back into an Object.\n\n[[redis.hashmappers.jackson2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/hash-mappers.adoc", "title": "hash-mappers", "heading": "JacksonHashMapper", "heading_level": 3, "file_order": 15, "section_index": 2, "content_hash": "d2622f38a57db0fee4849df5b548bd372a192841f94c008c30c78096cfec409c", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/hash-mappers.adoc"}}
{"id": "sha256:315f4db727a318cfb066c0569a95446b82d317e3317705d91d7052e469d7bdff", "content": "WARNING: Jackson 2 based implementations have been deprecated and are subject to removal in a subsequent release.\n\njavadoc:org.springframework.data.redis.hash.Jackson2HashMapper[] provides Redis Hash mapping for domain objects by using https://github.com/FasterXML/jackson[FasterXML Jackson].\n`Jackson2HashMapper` can map top-level properties as Hash field names and, optionally, flatten the structure.\nSimple types map to simple values. Complex types (nested objects, collections, maps, and so on) are represented as nested JSON.\n\nFlattening creates individual hash entries for all nested properties and resolves complex types into simple types, as far as possible.\n\nConsider the following class and the data structure it contains:\n\n[source,java]\n----\npublic class Person {\n String firstname;\n String lastname;\n Address address;\n Date date;\n LocalDateTime localDateTime;\n}\n\npublic class Address {\n String city;\n String country;\n}\n----\n\nThe following table shows how the data in the preceding class would appear in normal mapping:\n\n.Normal Mapping\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Hash Field\n|Value\n\n|firstname\n|`Jon`\n\n|lastname\n|`Snow`\n\n|address\n|`{ \"city\" : \"Castle Black\", \"country\" : \"The North\" }`\n\n|date\n|`1561543964015`\n\n|localDateTime\n|`2018-01-02T12:13:14`\n|====\n\nThe following table shows how the data in the preceding class would appear in flat mapping:\n\n.Flat Mapping\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Hash Field\n|Value\n\n|firstname\n|`Jon`\n\n|lastname\n|`Snow`\n\n|address.city\n|`Castle Black`\n\n|address.country\n|`The North`\n\n|date\n|`1561543964015`\n\n|localDateTime\n|`2018-01-02T12:13:14`\n|====\n\nNOTE: Flattening requires all property names to not interfere with the JSON path. Using dots or brackets in map keys or as property names is not supported when you use flattening. The resulting hash cannot be mapped back into an Object.\n\nNOTE: `java.util.Date` and `java.util.Calendar` are represented with milliseconds. JSR-310 Date/Time types are serialized to their `toString` form if `jackson-datatype-jsr310` is on the class path.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/hash-mappers.adoc", "title": "hash-mappers", "heading": "Jackson2HashMapper", "heading_level": 3, "file_order": 15, "section_index": 3, "content_hash": "315f4db727a318cfb066c0569a95446b82d317e3317705d91d7052e469d7bdff", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/hash-mappers.adoc"}}
{"id": "sha256:5c8539b3647938a8204a11f334df8053c60167ac4ebb6d26467c8eda2479fea6", "content": "[[pipeline]]\n\nRedis provides support for https://redis.io/topics/pipelining[pipelining], which involves sending multiple commands to the server without waiting for the replies and then reading the replies in a single step. Pipelining can improve performance when you need to send several commands in a row, such as adding many elements to the same List.\n\nSpring Data Redis provides several `RedisTemplate` methods for running commands in a pipeline. If you do not care about the results of the pipelined operations, you can use the standard `execute` method, passing `true` for the `pipeline` argument. The `executePipelined` methods run the provided `RedisCallback` or `SessionCallback` in a pipeline and return the results, as shown in the following example:\n\n[source,java]\n----\nList<Object> results = stringRedisTemplate.executePipelined(\n new RedisCallback<Object>() {\n public Object doInRedis(RedisConnection connection) throws DataAccessException {\n StringRedisConnection stringRedisConn = new DefaultStringRedisConnection(connection);\n for(int i=0; i< batchSize; i++) {\n stringRedisConn.rPop(\"myqueue\");\n }\n return null;\n }\n});\n----\n\nThe preceding example runs a bulk right pop of items from a queue in a pipeline.\nThe `results` `List` contains all the popped items. `RedisTemplate` uses its value, hash key, and hash value serializers to deserialize all results before returning, so the returned items in the preceding example are Strings.\nThere are additional `executePipelined` methods that let you pass a custom serializer for pipelined results.\n\nNote that the value returned from the `RedisCallback` is required to be `null`, as this value is discarded in favor of returning the results of the pipelined commands.\n\n[TIP]\n====\nThe Lettuce driver supports fine-grained flush control that allows to either flush commands as they appear, buffer or send them at connection close.\n\n[source,java]\n----\nLettuceConnectionFactory factory = // ...\nfactory.setPipeliningFlushPolicy(PipeliningFlushPolicy.buffered(3)); <1>\n----\n<1> Buffer locally and flush after every 3rd command.\n====\n\nNOTE: Pipelining is limited to Redis Standalone.\nRedis Cluster is currently only supported through the Lettuce driver except for the following commands when using cross-slot keys: `rename`, `renameNX`, `sort`, `bLPop`, `bRPop`, `rPopLPush`, `bRPopLPush`, `info`, `sMove`, `sInter`, `sInterStore`, `sUnion`, `sUnionStore`, `sDiff`, `sDiffStore`.\nSame-slot keys are fully supported.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pipelining.adoc", "title": "pipelining", "heading": "pipelining", "heading_level": 1, "file_order": 17, "section_index": 0, "content_hash": "5c8539b3647938a8204a11f334df8053c60167ac4ebb6d26467c8eda2479fea6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pipelining.adoc"}}
{"id": "sha256:32f87670b208fbfb330b27052fc2a92b55ace5e8fc418dad4ec2e2f8490885e7", "content": "[[pubsub]]\n\nSpring Data provides dedicated messaging integration for Redis, similar in functionality and naming to the JMS integration in Spring Framework.\n\nRedis messaging can be roughly divided into two areas of functionality:\n\n* Publication or production of messages\n* Subscription or consumption of messages\n\nThis is an example of the pattern often called Publish/Subscribe (Pub/Sub for short). The `RedisTemplate` class is used for message production. For asynchronous reception similar to Java EE's message-driven bean style, Spring Data provides a dedicated message listener container that is used to create Message-Driven POJOs (MDPs) and, for synchronous reception, the `RedisConnection` contract.\n\nThe `org.springframework.data.redis.connection` and `org.springframework.data.redis.listener` packages provide the core functionality for Redis messaging.\n\n[[redis:pubsub:publish]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "pubsub", "heading_level": 1, "file_order": 18, "section_index": 0, "content_hash": "32f87670b208fbfb330b27052fc2a92b55ace5e8fc418dad4ec2e2f8490885e7", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:8f9333eca7974eeedbb8c4155081f26d66197ec94b4a2fe457c4b3e7653cbf04", "content": "To publish a message, you can use, as with the other operations, either the low-level `[Reactive]RedisConnection` or the high-level `[Reactive]RedisOperations`. Both entities offer the `publish` method, which accepts the message and the destination channel as arguments. While `RedisConnection` requires raw data (array of bytes), the `[Reactive]RedisOperations` lets arbitrary objects be passed in as messages, as shown in the following example:\n\n[tabs]\n======\nImperative::\n+\n[source,java,role=\"primary\"]\n----\nRedisConnection con = …\nbyte[] msg = …\nbyte[] channel = …\ncon.pubSubCommands().publish(msg, channel);\n\nRedisOperations operations = …\nLong numberOfClients = operations.convertAndSend(\"hello!\", \"world\");\n----\n\nReactive::\n+\n[source,java,role=\"secondary\"]\n----\nReactiveRedisConnection con = …\nByteBuffer[] msg = …\nByteBuffer[] channel = …\ncon.pubSubCommands().publish(msg, channel);\n\nReactiveRedisOperations operations = …\nMono<Long> numberOfClients = operations.convertAndSend(\"hello!\", \"world\");\n----\n======\n\n[[redis:pubsub:subscribe]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "Publishing (Sending Messages)", "heading_level": 2, "file_order": 18, "section_index": 1, "content_hash": "8f9333eca7974eeedbb8c4155081f26d66197ec94b4a2fe457c4b3e7653cbf04", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:57b62f296c75c5a8c7ede09f591a41b8506d2b1903551707227b307a8345368d", "content": "On the receiving side, one can subscribe to one or multiple channels either by naming them directly or by using pattern matching. The latter approach is quite useful, as it not only lets multiple subscriptions be created with one command but can also listen on channels not yet created at subscription time (as long as they match the pattern).\n\nAt the low-level, `RedisConnection` offers the `subscribe` and `pSubscribe` methods that map the Redis commands for subscribing by channel or by pattern, respectively. Note that multiple channels or patterns can be used as arguments. To change the subscription of a connection or query whether it is listening, `RedisConnection` provides the `getSubscription` and `isSubscribed` methods.\n\nNOTE: Subscription commands in Spring Data Redis are blocking. That is, calling subscribe on a connection causes the current thread to block as it starts waiting for messages. The thread is released only if the subscription is canceled, which happens when another thread invokes `unsubscribe` or `pUnsubscribe` on the *same* connection. See \"`xref:redis/pubsub.adoc#redis:pubsub:subscribe:containers[Message Listener Containers]`\" (later in this document) for a solution to this problem.\n\nAs mentioned earlier, once subscribed, a connection starts waiting for messages. Only commands that add new subscriptions, modify existing subscriptions, and cancel existing subscriptions are allowed. Invoking anything other than `subscribe`, `pSubscribe`, `unsubscribe`, or `pUnsubscribe` throws an exception.\n\nIn order to subscribe to messages, one needs to implement the `MessageListener` callback. Each time a new message arrives, the callback gets invoked and the user code gets run by the `onMessage` method. The interface gives access not only to the actual message but also to the channel it has been received through and the pattern (if any) used by the subscription to match the channel. This information lets the callee differentiate between various messages not just by content but also examining additional details.\n\n[[redis:pubsub:subscribe:containers]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "Subscribing (Receiving Messages)", "heading_level": 2, "file_order": 18, "section_index": 2, "content_hash": "57b62f296c75c5a8c7ede09f591a41b8506d2b1903551707227b307a8345368d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:c863ebe37094a811a156d42df471333858cf0e837280101f9cca41a34e676909", "content": "Due to its blocking nature, low-level subscription is not attractive, as it requires connection and thread management for every single listener. To alleviate this problem, Spring Data offers javadoc:org.springframework.data.redis.listener.RedisMessageListenerContainer[], which does all the heavy lifting. If you are familiar with EJB and JMS, you should find the concepts familiar, as it is designed to be as close as possible to the support in Spring Framework and its message-driven POJOs (MDPs).\n\njavadoc:org.springframework.data.redis.listener.RedisMessageListenerContainer[] acts as a message listener container. It is used to receive messages from a Redis channel and drive the javadoc:org.springframework.data.redis.connection.MessageListener[] instances that are injected into it. The listener container is responsible for all threading of message reception and dispatches into the listener for processing. A message listener container is the intermediary between an MDP and a messaging provider and takes care of registering to receive messages, resource acquisition and release, exception conversion, and the like. This lets you as an application developer write the (possibly complex) business logic associated with receiving a message (and reacting to it) and delegates boilerplate Redis infrastructure concerns to the framework.\n\nA javadoc:org.springframework.data.redis.connection.MessageListener[] can additionally implement javadoc:org.springframework.data.redis.connection.SubscriptionListener[] to receive notifications upon subscription/unsubscribe confirmation. Listening to subscription notifications can be useful when synchronizing invocations.\n\nFurthermore, to minimize the application footprint, javadoc:org.springframework.data.redis.listener.RedisMessageListenerContainer[] lets one connection and one thread be shared by multiple listeners even though they do not share a subscription. Thus, no matter how many listeners or channels an application tracks, the runtime cost remains the same throughout its lifetime. Moreover, the container allows runtime configuration changes so that you can add or remove listeners while an application is running without the need for a restart. Additionally, the container uses a lazy subscription approach, using a `RedisConnection` only when needed. If all the listeners are unsubscribed, cleanup is automatically performed, and the thread is released.\n\nTo help with the asynchronous nature of messages, the container requires a `java.util.concurrent.Executor` (or Spring's `TaskExecutor`) for dispatching the messages. Depending on the load, the number of listeners, or the runtime environment, you should change or tweak the executor to better serve your needs. In particular, in managed environments (such as app servers), it is highly recommended to pick a proper `TaskExecutor` to take advantage of its runtime.\n\n[[redis:pubsub:subscribe:adapter]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "Message Listener Containers", "heading_level": 3, "file_order": 18, "section_index": 3, "content_hash": "c863ebe37094a811a156d42df471333858cf0e837280101f9cca41a34e676909", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:8a121d88913c5fad85fc34e3960d9b97eafa84d5efd84447262cc593cf46dcd0", "content": "The javadoc:org.springframework.data.redis.listener.adapter.MessageListenerAdapter[] class is the final component in Spring's asynchronous messaging support. In a nutshell, it lets you expose almost *any* class as a MDP (though there are some constraints).\n\nConsider the following interface definition:\n\n[source,java]\n----\npublic interface MessageDelegate {\n void handleMessage(String message);\n void handleMessage(Map message);\n void handleMessage(byte[] message);\n void handleMessage(Serializable message);\n // pass the channel/pattern as well\n void handleMessage(Serializable message, String channel);\n }\n----\n\nNotice that, although the interface does not extend the `MessageListener` interface, it can still be used as a MDP by using the javadoc:org.springframework.data.redis.listener.adapter.MessageListenerAdapter[] class. Notice also how the various message handling methods are strongly typed according to the *contents* of the various `Message` types that they can receive and handle. In addition, the channel or pattern to which a message is sent can be passed in to the method as the second argument of type `String`:\n\n[source,java]\n----\npublic class DefaultMessageDelegate implements MessageDelegate {\n // implementation elided for clarity...\n}\n----\n\n Notice how the above implementation of the `MessageDelegate` interface (the above `DefaultMessageDelegate` class) has *no* Redis dependencies at all. It truly is a POJO that we make into an MDP with the following configuration:\n\n[tabs]\n======\nJava::\n+\n[source,java,role=\"primary\"]\n----\n@Configuration\nclass MyConfig {\n\n // …\n\n @Bean\n DefaultMessageDelegate listener() {\n return new DefaultMessageDelegate();\n }\n\n @Bean\n MessageListenerAdapter messageListenerAdapter(DefaultMessageDelegate listener) {\n return new MessageListenerAdapter(listener, \"handleMessage\");\n }\n\n @Bean\n RedisMessageListenerContainer redisMessageListenerContainer(RedisConnectionFactory connectionFactory, MessageListenerAdapter listener) {\n\n RedisMessageListenerContainer container = new RedisMessageListenerContainer();\n container.setConnectionFactory(connectionFactory);\n container.addMessageListener(listener, ChannelTopic.of(\"chatroom\"));\n return container;\n }\n}\n----\n\nXML::\n+\n[source,xml,role=\"secondary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:redis=\"http://www.springframework.org/schema/redis\"\n xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\n http://www.springframework.org/schema/redis https://www.springframework.org/schema/redis/spring-redis.xsd\">\n\n<!-- the default ConnectionFactory -->\n<redis:listener-container>\n <!-- the method attribute can be skipped as the default method name is \"handleMessage\" -->\n <redis:listener ref=\"listener\" method=\"handleMessage\" topic=\"chatroom\" />\n</redis:listener-container>\n\n<bean id=\"listener\" class=\"redisexample.DefaultMessageDelegate\"/>\n ...\n</beans>\n----\n======\n\nNOTE: The listener topic can be either a channel (for example, `topic=\"chatroom\"` respective `Topic.channel(\"chatroom\")`) or a pattern (for example, `topic=\"*room\"` respective `Topic.pattern(\"*room\")`).\n\nThe preceding example uses the Redis namespace to declare the message listener container and automatically register the POJOs as listeners. The full-blown beans definition follows:\n\n[source,xml]\n----\n<bean id=\"messageListener\" class=\"org.springframework.data.redis.listener.adapter.MessageListenerAdapter\">\n <constructor-arg>\n <bean class=\"redisexample.DefaultMessageDelegate\"/>\n </constructor-arg>\n</bean>\n\n<bean id=\"redisContainer\" class=\"org.springframework.data.redis.listener.RedisMessageListenerContainer\">\n <property name=\"connectionFactory\" ref=\"connectionFactory\"/>\n <property name=\"messageListeners\">\n <map>\n <entry key-ref=\"messageListener\">\n <bean class=\"org.springframework.data.redis.listener.ChannelTopic\">\n <constructor-arg value=\"chatroom\"/>\n </bean>\n </entry>\n </map>\n </property>\n</bean>\n----\n\nEach time a message is received, the adapter automatically and transparently performs translation (using the configured `RedisSerializer`) between the low-level format and the required object type. Any exception caused by the method invocation is caught and handled by the container (by default, exceptions get logged).\n\n[[redis:reactive:pubsub:subscribe:containers]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "The MessageListenerAdapter", "heading_level": 3, "file_order": 18, "section_index": 4, "content_hash": "8a121d88913c5fad85fc34e3960d9b97eafa84d5efd84447262cc593cf46dcd0", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:c1da019499c068eacfe3e43884e82d7ab3a36165bffaa7c7ade3e828f9e99cc2", "content": "Spring Data offers javadoc:org.springframework.data.redis.listener.ReactiveRedisMessageListenerContainer[] which does all the heavy lifting of conversion and subscription state management on behalf of the user.\n\nThe message listener container itself does not require external threading resources. It uses the driver threads to publish messages.\n\n[source,java]\n----\nReactiveRedisConnectionFactory factory = …\nReactiveRedisMessageListenerContainer container = new ReactiveRedisMessageListenerContainer(factory);\n\nFlux<ChannelMessage<String, String>> stream = container.receive(ChannelTopic.of(\"my-channel\"));\n----\n\nTo await and ensure proper subscription, you can use the `receiveLater` method that returns a `Mono<Flux<ChannelMessage>>`.\nThe resulting `Mono` completes with an inner publisher as a result of completing the subscription to the given topics. By intercepting `onNext` signals, you can synchronize server-side subscriptions.\n\n[source,java]\n----\nReactiveRedisConnectionFactory factory = …\nReactiveRedisMessageListenerContainer container = new ReactiveRedisMessageListenerContainer(factory);\n\nMono<Flux<ChannelMessage<String, String>>> stream = container.receiveLater(ChannelTopic.of(\"my-channel\"));\n\nstream.doOnNext(inner -> // notification hook when Redis subscriptions are synchronized with the server)\n .flatMapMany(Function.identity())\n .…;\n----\n\n[[redis:reactive:pubsub:subscribe:template]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "Reactive Message Listener Container", "heading_level": 2, "file_order": 18, "section_index": 5, "content_hash": "c1da019499c068eacfe3e43884e82d7ab3a36165bffaa7c7ade3e828f9e99cc2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:be93185731244c4b97fd2aee9583341c3489f3ffdc58d8750786e2255ae986ef", "content": "As mentioned above you can directly use javadoc:org.springframework.data.redis.core.ReactiveRedisTemplate[] to subscribe to channels / patterns. This approach\noffers a straight forward, though limited solution as you lose the option to add subscriptions after the initial\nones. Nevertheless you still can control the message stream via the returned `Flux` using eg. `take(Duration)`. When\ndone reading, on error or cancellation all bound resources are freed again.\n\n[source,java]\n----\nredisTemplate.listenToChannel(\"channel1\", \"channel2\").doOnNext(msg -> {\n // message processing ...\n}).subscribe();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/pubsub.adoc", "title": "pubsub", "heading": "Subscribing via template API", "heading_level": 3, "file_order": 18, "section_index": 6, "content_hash": "be93185731244c4b97fd2aee9583341c3489f3ffdc58d8750786e2255ae986ef", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/pubsub.adoc"}}
{"id": "sha256:9c253cff0b6abc0b85cf67f4ace125fd8f8449d1b334c7a66d901173492c44df", "content": "[[redis:support:cache-abstraction]]\n\nSpring Data Redis provides an implementation of Spring Framework's {spring-framework-docs}/integration.html#cache[Cache Abstraction] in the `org.springframework.data.redis.cache` package.\nTo use Redis as a backing implementation, add javadoc:org.springframework.data.redis.cache.RedisCacheManager[] to your configuration, as follows:\n\n[source,java]\n----\n@Bean\npublic RedisCacheManager cacheManager(RedisConnectionFactory connectionFactory) {\n return RedisCacheManager.create(connectionFactory);\n}\n----\n\n`RedisCacheManager` behavior can be configured with javadoc:org.springframework.data.redis.cache.RedisCacheManager$RedisCacheManagerBuilder[], letting you set the default javadoc:org.springframework.data.redis.cache.RedisCacheManager[], transaction behavior, and predefined caches.\n\n[source,java]\n----\nRedisCacheManager cacheManager = RedisCacheManager.builder(connectionFactory)\n .cacheDefaults(RedisCacheConfiguration.defaultCacheConfig())\n .transactionAware()\n .withInitialCacheConfigurations(Collections.singletonMap(\"predefined\",\n RedisCacheConfiguration.defaultCacheConfig().disableCachingNullValues()))\n .build();\n----\n\nAs shown in the preceding example, `RedisCacheManager` allows custom configuration on a per-cache basis.\n\nThe behavior of javadoc:org.springframework.data.redis.cache.RedisCache[] created by javadoc:org.springframework.data.redis.cache.RedisCacheManager[] is defined with `RedisCacheConfiguration`.\nThe configuration lets you set key expiration times, prefixes, and `RedisSerializer` implementations for converting to and from the binary storage format, as shown in the following example:\n\n[source,java]\n----\nRedisCacheConfiguration cacheConfiguration = RedisCacheConfiguration.defaultCacheConfig()\n .entryTtl(Duration.ofSeconds(1))\n .disableCachingNullValues();\n----\n\njavadoc:org.springframework.data.redis.cache.RedisCacheManager[] defaults to a lock-free javadoc:org.springframework.data.redis.cache.RedisCacheWriter[] for reading and writing binary values.\nLock-free caching improves throughput.\nThe lack of entry locking can lead to overlapping, non-atomic commands for the `Cache` `putIfAbsent` and `clean` operations, as those require multiple commands to be sent to Redis.\nThe locking counterpart prevents command overlap by setting an explicit lock key and checking against presence of this key, which leads to additional requests and potential command wait times.\n\nLocking applies on the *cache level*, not per *cache entry*.\n\nIt is possible to opt in to the locking behavior as follows:\n\n[source,java]\n----\nRedisCacheManager cacheManager = RedisCacheManager\n .builder(RedisCacheWriter.lockingRedisCacheWriter(connectionFactory))\n .cacheDefaults(RedisCacheConfiguration.defaultCacheConfig())\n ...\n----\n\nBy default, any `key` for a cache entry gets prefixed with the actual cache name followed by two colons (`::`).\nThis behavior can be changed to a static as well as a computed prefix.\n\nThe following example shows how to set a static prefix:\n\n[source,java]\n----\nRedisCacheConfiguration.defaultCacheConfig().prefixCacheNameWith(\"(͡° ᴥ ͡°)\");\n\nThe following example shows how to set a computed prefix:\n\nRedisCacheConfiguration.defaultCacheConfig()\n .computePrefixWith(cacheName -> \"¯\\_(ツ)_/¯\" + cacheName);\n----\n\nThe cache implementation defaults to use `KEYS` and `DEL` to clear the cache. `KEYS` can cause performance issues with large keyspaces.\nTherefore, the default `RedisCacheWriter` can be created with a `BatchStrategy` to switch to a `SCAN`-based batch strategy.\nThe `SCAN` strategy requires a batch size to avoid excessive Redis command round trips:\n\n[source,java]\n----\nRedisCacheManager cacheManager = RedisCacheManager\n .builder(RedisCacheWriter.nonLockingRedisCacheWriter(connectionFactory, BatchStrategies.scan(1000)))\n .cacheDefaults(RedisCacheConfiguration.defaultCacheConfig())\n ...\n----\n\n[NOTE]\n====\nThe `KEYS` batch strategy is fully supported using any driver and Redis operation mode (Standalone, Clustered).\n`SCAN` is fully supported when using the Lettuce driver.\nJedis supports `SCAN` only in non-clustered modes.\n====\n\nThe following table lists the default settings for `RedisCacheManager`:\n\n.`RedisCacheManager` defaults\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Setting\n|Value\n\n|Cache Writer\n|Non-locking, `KEYS` batch strategy\n\n|Cache Configuration\n|`RedisCacheConfiguration#defaultConfiguration`\n\n|Initial Caches\n|None\n\n|Transaction Aware\n|No\n|====\n\nThe following table lists the default settings for `RedisCacheConfiguration`:\n\n.RedisCacheConfiguration defaults\n[width=\"80%\",cols=\"<1,<2\",options=\"header\"]\n|====\n|Key Expiration\n|None\n\n|Cache `null`\n|Yes\n\n|Prefix Keys\n|Yes\n\n|Default Prefix\n|The actual cache name\n\n|Key Serializer\n|`StringRedisSerializer`\n\n|Value Serializer\n|`JdkSerializationRedisSerializer`\n\n|Conversion Service\n|`DefaultFormattingConversionService` with default cache key converters\n|====\n\n[NOTE]\n====\nBy default `RedisCache`, statistics are disabled.\nUse `RedisCacheManagerBuilder.enableStatistics()` to collect local _hits_ and _misses_ through `RedisCache#getStatistics()`, returning a snapshot of the collected data.\n====\n\n[[redis:support:cache-abstraction:expiration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-cache.adoc", "title": "redis-cache", "heading": "redis-cache", "heading_level": 1, "file_order": 19, "section_index": 0, "content_hash": "9c253cff0b6abc0b85cf67f4ace125fd8f8449d1b334c7a66d901173492c44df", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-cache.adoc"}}
{"id": "sha256:d1a01be0afd2540576ab286b5cdf800c189ea29845aa21dff79911b896536b66", "content": "The implementation of time-to-idle (TTI) as well as time-to-live (TTL) varies in definition and behavior even across different data stores.\n\nIn general:\n\n* _time-to-live_ (TTL) _expiration_ - TTL is only set and reset by a create or update data access operation.\nAs long as the entry is written before the TTL expiration timeout, including on creation, an entry's timeout will reset to the configured duration of the TTL expiration timeout.\nFor example, if the TTL expiration timeout is set to 5 minutes, then the timeout will be set to 5 minutes on entry creation and reset to 5 minutes anytime the entry is updated thereafter and before the 5-minute interval expires.\nIf no update occurs within 5 minutes, even if the entry was read several times, or even just read once during the 5-minute interval, the entry will still expire.\nThe entry must be written to prevent the entry from expiring when declaring a TTL expiration policy.\n\n* _time-to-idle_ (TTI) _expiration_ - TTI is reset anytime the entry is also read as well as for entry updates, and is effectively and extension to the TTL expiration policy.\n\n[NOTE]\n====\nSome data stores expire an entry when TTL is configured no matter what type of data access operation occurs on the entry (reads, writes, or otherwise).\nAfter the set, configured TTL expiration timeout, the entry is evicted from the data store regardless.\nEviction actions (for example: destroy, invalidate, overflow-to-disk (for persistent stores), etc.) are data store specific.\n====\n\n[[redis:support:cache-abstraction:expiration:tti]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-cache.adoc", "title": "redis-cache", "heading": "Redis Cache Expiration", "heading_level": 2, "file_order": 19, "section_index": 1, "content_hash": "d1a01be0afd2540576ab286b5cdf800c189ea29845aa21dff79911b896536b66", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-cache.adoc"}}
{"id": "sha256:e6fff6650b460e826ed45302917e21b639fd0c646e08f8cc909bb6c15a34a6f6", "content": "Spring Data Redis's `Cache` implementation supports _time-to-live_ (TTL) expiration on cache entries.\nUsers can either configure the TTL expiration timeout with a fixed `Duration` or a dynamically computed `Duration` per cache entry by supplying an implementation of the new `RedisCacheWriter.TtlFunction` interface.\n\n[TIP]\n====\nThe `RedisCacheWriter.TtlFunction` interface was introduced in Spring Data Redis `3.2.0`.\n====\n\nIf all cache entries should expire after a set duration of time, then simply configure a TTL expiration timeout with a fixed `Duration`, as follows:\n\n[source,java]\n----\nRedisCacheConfiguration fiveMinuteTtlExpirationDefaults =\n RedisCacheConfiguration.defaultCacheConfig().enableTtl(Duration.ofMinutes(5));\n----\n\nHowever, if the TTL expiration timeout should vary by cache entry, then you must provide a custom implementation of the `RedisCacheWriter.TtlFunction` interface:\n\n[source,java]\n----\nenum MyCustomTtlFunction implements TtlFunction {\n\n INSTANCE;\n\n @Override\n public Duration getTimeToLive(Object key, @Nullable Object value) {\n // compute a TTL expiration timeout (Duration) based on the cache entry key and/or value\n }\n}\n----\n\n[NOTE]\n====\nUnder-the-hood, a fixed `Duration` TTL expiration is wrapped in a `TtlFunction` implementation returning the provided `Duration`.\n====\n\nThen, you can either configure the fixed `Duration` or the dynamic, per-cache entry `Duration` TTL expiration on a global basis using:\n\n.Global fixed Duration TTL expiration timeout\n[source,java]\n----\nRedisCacheManager cacheManager = RedisCacheManager.builder(redisConnectionFactory)\n .cacheDefaults(fiveMinuteTtlExpirationDefaults)\n .build();\n----\n\nOr, alternatively:\n\n.Global, dynamically computed per-cache entry Duration TTL expiration timeout\n[source,java]\n----\nRedisCacheConfiguration defaults = RedisCacheConfiguration.defaultCacheConfig()\n .entryTtl(MyCustomTtlFunction.INSTANCE);\n\nRedisCacheManager cacheManager = RedisCacheManager.builder(redisConnectionFactory)\n .cacheDefaults(defaults)\n .build();\n----\n\nOf course, you can combine both global and per-cache configuration using:\n\n.Global fixed Duration TTL expiration timeout\n[source,java]\n----\n\nRedisCacheConfiguration predefined = RedisCacheConfiguration.defaultCacheConfig()\n .entryTtl(MyCustomTtlFunction.INSTANCE);\n\nMap<String, RedisCacheConfiguration> initialCaches = Collections.singletonMap(\"predefined\", predefined);\n\nRedisCacheManager cacheManager = RedisCacheManager.builder(redisConnectionFactory)\n .cacheDefaults(fiveMinuteTtlExpirationDefaults)\n .withInitialCacheConfigurations(initialCaches)\n .build();\n----\n\n[[redis:support:cache-abstraction:expiration:tti2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-cache.adoc", "title": "redis-cache", "heading": "Time-To-Live (TTL) Expiration", "heading_level": 3, "file_order": 19, "section_index": 2, "content_hash": "e6fff6650b460e826ed45302917e21b639fd0c646e08f8cc909bb6c15a34a6f6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-cache.adoc"}}
{"id": "sha256:08d89bd4f96a627bffa2d73cb87566cbaf9ec32b09fc896cd56158734115896a", "content": "Redis itself does not support the concept of true, time-to-idle (TTI) expiration.\nStill, using Spring Data Redis's Cache implementation, it is possible to achieve time-to-idle (TTI) expiration-like behavior.\n\nThe configuration of TTI in Spring Data Redis's Cache implementation must be explicitly enabled, that is, is opt-in.\nAdditionally, you must also provide TTL configuration using either a fixed `Duration` or a custom implementation of the `TtlFunction` interface as described above in <<redis:support:cache-abstraction:expiration,Redis Cache Expiration>>.\n\nFor example:\n\n[source,java]\n----\n@Configuration\n@EnableCaching\nclass RedisConfiguration {\n\n @Bean\n RedisConnectionFactory redisConnectionFactory() {\n // ...\n }\n\n @Bean\n RedisCacheManager cacheManager(RedisConnectionFactory connectionFactory) {\n\n RedisCacheConfiguration defaults = RedisCacheConfiguration.defaultCacheConfig()\n .entryTtl(Duration.ofMinutes(5))\n .enableTimeToIdle();\n\n return RedisCacheManager.builder(connectionFactory)\n .cacheDefaults(defaults)\n .build();\n }\n}\n----\n\nBecause Redis servers do not implement a proper notion of TTI, then TTI can only be achieved with Redis commands accepting expiration options.\nIn Redis, the \"expiration\" is technically a time-to-live (TTL) policy.\nHowever, TTL expiration can be passed when reading the value of a key thereby effectively resetting the TTL expiration timeout, as is now the case in Spring Data Redis's `Cache.get(key)` operation.\n\n`RedisCache.get(key)` is implemented by calling the Redis `GETEX` command.\n\n[WARNING]\n====\nThe Redis https://redis.io/commands/getex[`GETEX`] command is only available in Redis version `6.2.0` and later.\nTherefore, if you are not using Redis `6.2.0` or later, then it is not possible to use Spring Data Redis's TTI expiration.\nA command execution exception will be thrown if you enable TTI against an incompatible Redis (server) version.\nNo attempt is made to determine if the Redis server version is correct and supports the `GETEX` command.\n====\n\n[WARNING]\n====\nIn order to achieve true time-to-idle (TTI) expiration-like behavior in your Spring Data Redis application, then an entry must be consistently accessed with (TTL) expiration on every read or write operation.\nThere are no exceptions to this rule.\nIf you are mixing and matching different data access patterns across your Spring Data Redis application (for example: caching, invoking operations using `RedisTemplate` and possibly, or especially when using Spring Data Repository CRUD operations), then accessing an entry may not necessarily prevent the entry from expiring if TTL expiration was set.\nFor example, an entry maybe \"put\" in (written to) the cache during a `@Cacheable` service method invocation with a TTL expiration (i.e. `SET <expiration options>`) and later read using a Spring Data Redis Repository before the expiration timeout (using `GET` without expiration options).\nA simple `GET` without specifying expiration options will not reset the TTL expiration timeout on an entry.\nTherefore, the entry may expire before the next data access operation, even though it was just read.\nSince this cannot be enforced in the Redis server, then it is the responsibility of your application to consistently access an entry when time-to-idle expiration is configured, in and outside of caching, where appropriate.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-cache.adoc", "title": "redis-cache", "heading": "Time-To-Idle (TTI) Expiration", "heading_level": 3, "file_order": 19, "section_index": 3, "content_hash": "08d89bd4f96a627bffa2d73cb87566cbaf9ec32b09fc896cd56158734115896a", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-cache.adoc"}}
{"id": "sha256:45187b3622a952b897e95228cd279a474226e292c762e22200238bfb8668ecb2", "content": "[[redis.streams]]\n\nRedis Streams model a log data structure in an abstract approach. Typically, logs are append-only data structures and are consumed from the beginning on, at a random position, or by streaming new messages.\n\nNOTE: Learn more about Redis Streams in the https://redis.io/topics/streams-intro[Redis reference documentation].\n\nRedis Streams can be roughly divided into two areas of functionality:\n\n* Appending records\n* Consuming records\n\nAlthough this pattern has similarities to xref:redis/pubsub.adoc[Pub/Sub], the main difference lies in the persistence of messages and how they are consumed.\n\nWhile Pub/Sub relies on the broadcasting of transient messages (i.e. if you don't listen, you miss a message), Redis Stream use a persistent, append-only data type that retains messages until the stream is trimmed. Another difference in consumption is that Pub/Sub registers a server-side subscription. Redis pushes arriving messages to the client while Redis Streams require active polling.\n\nThe `org.springframework.data.redis.connection` and `org.springframework.data.redis.stream` packages provide the core functionality for Redis Streams.\n\n[[redis.streams.send]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "redis-streams", "heading_level": 1, "file_order": 20, "section_index": 0, "content_hash": "45187b3622a952b897e95228cd279a474226e292c762e22200238bfb8668ecb2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:a5f668f339131e0e7cc5abf738846ae74c8fbd58ee748cee3cbbc421076e4d24", "content": "To send a record, you can use, as with the other operations, either the low-level `RedisConnection` or the high-level `StreamOperations`. Both entities offer the `add` (`xAdd`) method, which accepts the record and the destination stream as arguments. While `RedisConnection` requires raw data (array of bytes), the `StreamOperations` lets arbitrary objects be passed in as records, as shown in the following example:\n\n[source,java]\n----\nRedisConnection con = …\nbyte[] stream = …\nByteRecord record = StreamRecords.rawBytes(…).withStreamKey(stream);\ncon.xAdd(record);\n\nRedisTemplate template = …\nStringRecord record = StreamRecords.string(…).withStreamKey(\"my-stream\");\ntemplate.opsForStream().add(record);\n----\n\nStream records carry a `Map`, key-value tuples, as their payload. Appending a record to a stream returns the `RecordId` that can be used as further reference.\n\n[[redis.streams.receive]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Appending", "heading_level": 2, "file_order": 20, "section_index": 1, "content_hash": "a5f668f339131e0e7cc5abf738846ae74c8fbd58ee748cee3cbbc421076e4d24", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:e7ea2c572be373ae9c2f3f5410957c645419539f30e3ef92962b6d061bf858b1", "content": "On the consuming side, one can consume one or multiple streams. Redis Streams provide read commands that allow consumption of the stream from an arbitrary position (random access) within the known stream content and beyond the stream end to consume new stream record.\n\nAt the low-level, `RedisConnection` offers the `xRead` and `xReadGroup` methods that map the Redis commands for reading and reading within a consumer group, respectively. Note that multiple streams can be used as arguments.\n\nNOTE: Subscription commands in Redis can be blocking. That is, calling `xRead` on a connection causes the current thread to block as it starts waiting for messages. The thread is released only if the read command times out or receives a message.\n\nTo consume stream messages, one can either poll for messages in application code, or use one of the two xref:redis/redis-streams.adoc#redis.streams.receive.containers[Asynchronous reception through Message Listener Containers], the imperative or the reactive one. Each time a new records arrives, the container notifies the application code.\n\n[[redis.streams.receive.synchronous]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Consuming", "heading_level": 2, "file_order": 20, "section_index": 2, "content_hash": "e7ea2c572be373ae9c2f3f5410957c645419539f30e3ef92962b6d061bf858b1", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:0f2cf58c11a39ce6c1ac33b43d418fd09769133336bfd6bf672d7fb026d499ab", "content": "While stream consumption is typically associated with asynchronous processing, it is possible to consume messages synchronously. The overloaded `StreamOperations.read(…)` methods provide this functionality. During a synchronous receive, the calling thread potentially blocks until a message becomes available. The property `StreamReadOptions.block` specifies how long the receiver should wait before giving up waiting for a message.\n\n[source,java]\n----\nRedisTemplate template = …\n\nList<MapRecord<K, HK, HV>> messages = template.opsForStream().read(StreamReadOptions.empty().count(2),\n StreamOffset.latest(\"my-stream\"));\n\nList<MapRecord<K, HK, HV>> messages = template.opsForStream().read(Consumer.from(\"my-group\", \"my-consumer\"),\n StreamReadOptions.empty().count(2),\n StreamOffset.create(\"my-stream\", ReadOffset.lastConsumed()))\n----\n\n[[redis.streams.receive.containers]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Synchronous reception", "heading_level": 3, "file_order": 20, "section_index": 3, "content_hash": "0f2cf58c11a39ce6c1ac33b43d418fd09769133336bfd6bf672d7fb026d499ab", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:626ca61c49d8837fe252089e7f4b408248825a70ead789bed1d1867b3904cc4a", "content": "Due to its blocking nature, low-level polling is not attractive, as it requires connection and thread management for every single consumer. To alleviate this problem, Spring Data offers message listeners, which do all the heavy lifting. If you are familiar with EJB and JMS, you should find the concepts familiar, as it is designed to be as close as possible to the support in Spring Framework and its message-driven POJOs (MDPs).\n\nSpring Data ships with two implementations tailored to the used programming model:\n\n* javadoc:org.springframework.data.redis.stream.StreamMessageListenerContainer[] acts as message listener container for imperative programming models. It is used to consume records from a Redis Stream and drive the javadoc:org.springframework.data.redis.stream.StreamListener[] instances that are injected into it.\n* javadoc:org.springframework.data.redis.stream.StreamReceiver[] provides a reactive variant of a message listener. It is used to consume messages from a Redis Stream as potentially infinite stream and emit stream messages through a `Flux`.\n\n`StreamMessageListenerContainer` and `StreamReceiver` are responsible for all threading of message reception and dispatch into the listener for processing. A message listener container/receiver is the intermediary between an MDP and a messaging provider and takes care of registering to receive messages, resource acquisition and release, exception conversion, and the like. This lets you as an application developer write the (possibly complex) business logic associated with receiving a message (and reacting to it) and delegates boilerplate Redis infrastructure concerns to the framework.\n\nBoth containers allow runtime configuration changes so that you can add or remove subscriptions while an application is running without the need for a restart. Additionally, the container uses a lazy subscription approach, using a `RedisConnection` only when needed. If all the listeners are unsubscribed, it automatically performs a cleanup, and the thread is released.\n\n[[imperative-streammessagelistenercontainer]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Asynchronous reception through Message Listener Containers", "heading_level": 3, "file_order": 20, "section_index": 4, "content_hash": "626ca61c49d8837fe252089e7f4b408248825a70ead789bed1d1867b3904cc4a", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:26b7dc939c3d4304c867a4b92f8da69b89a798212875f56ba0bbba4071fdf9e2", "content": "In a fashion similar to a Message-Driven Bean (MDB) in the EJB world, the Stream-Driven POJO (SDP) acts as a receiver for Stream messages. The one restriction on an SDP is that it must implement the javadoc:org.springframework.data.redis.stream.StreamListener[] interface. Please also be aware that in the case where your POJO receives messages on multiple threads, it is important to ensure that your implementation is thread-safe.\n\n[source,java]\n----\nclass ExampleStreamListener implements StreamListener<String, MapRecord<String, String, String>> {\n\n\t@Override\n\tpublic void onMessage(MapRecord<String, String, String> message) {\n\n System.out.println(\"MessageId: \" + message.getId());\n System.out.println(\"Stream: \" + message.getStream());\n System.out.println(\"Body: \" + message.getValue());\n\t}\n}\n----\n\n`StreamListener` represents a functional interface so implementations can be rewritten using their Lambda form:\n\n[source,java]\n----\nmessage -> {\n\n System.out.println(\"MessageId: \" + message.getId());\n System.out.println(\"Stream: \" + message.getStream());\n System.out.println(\"Body: \" + message.getValue());\n};\n----\n\nOnce you’ve implemented your `StreamListener`, it’s time to create a message listener container and register a subscription:\n\n[source,java]\n----\nRedisConnectionFactory connectionFactory = …\nStreamListener<String, MapRecord<String, String, String>> streamListener = …\n\nStreamMessageListenerContainerOptions<String, MapRecord<String, String, String>> containerOptions = StreamMessageListenerContainerOptions\n .builder().pollTimeout(Duration.ofMillis(100)).build();\n\nStreamMessageListenerContainer<String, MapRecord<String, String, String>> container = StreamMessageListenerContainer.create(connectionFactory,\n containerOptions);\n\nSubscription subscription = container.receive(StreamOffset.fromStart(\"my-stream\"), streamListener);\n----\n\nPlease refer to the Javadoc of the various message listener containers for a full description of the features supported by each implementation.\n\n[[reactive-streamreceiver]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Imperative `StreamMessageListenerContainer`", "heading_level": 4, "file_order": 20, "section_index": 5, "content_hash": "26b7dc939c3d4304c867a4b92f8da69b89a798212875f56ba0bbba4071fdf9e2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:f0c2632d55fadaadf122912ce0936f18ccda050dcbe06bf94ce5afd242737235", "content": "Reactive consumption of streaming data sources typically happens through a `Flux` of events or messages. The reactive receiver implementation is provided with `StreamReceiver` and its overloaded `receive(…)` messages. The reactive approach requires fewer infrastructure resources such as threads in comparison to `StreamMessageListenerContainer` as it is leveraging threading resources provided by the driver. The receiving stream is a demand-driven publisher of ``StreamMessage``:\n\n[source,java]\n----\nFlux<MapRecord<String, String, String>> messages = …\n\nreturn messages.doOnNext(it -> {\n System.out.println(\"MessageId: \" + message.getId());\n System.out.println(\"Stream: \" + message.getStream());\n System.out.println(\"Body: \" + message.getValue());\n});\n----\n\nNow we need to create the `StreamReceiver` and register a subscription to consume stream messages:\n\n[source,java]\n----\nReactiveRedisConnectionFactory connectionFactory = …\n\nStreamReceiverOptions<String, MapRecord<String, String, String>> options = StreamReceiverOptions.builder().pollTimeout(Duration.ofMillis(100))\n .build();\nStreamReceiver<String, MapRecord<String, String, String>> receiver = StreamReceiver.create(connectionFactory, options);\n\nFlux<MapRecord<String, String, String>> messages = receiver.receive(StreamOffset.fromStart(\"my-stream\"));\n----\n\nPlease refer to the Javadoc of the various message listener containers for a full description of the features supported by each implementation.\n\nNOTE: Demand-driven consumption uses backpressure signals to activate and deactivate polling. `StreamReceiver` subscriptions pause polling if the demand is satisfied until subscribers signal further demand. Depending on the `ReadOffset` strategy, this can cause messages to be skipped.\n\n[[redis.streams.acknowledge]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Reactive `StreamReceiver`", "heading_level": 4, "file_order": 20, "section_index": 6, "content_hash": "f0c2632d55fadaadf122912ce0936f18ccda050dcbe06bf94ce5afd242737235", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:16d80a4a81c976d219f472b0d1c3b5ec4ddf6d2256690bc740c281d39f68e45b", "content": "When you read with messages via a `Consumer Group`, the server will remember that a given message was delivered and add it to the Pending Entries List (PEL). A list of messages delivered but not yet acknowledged. +\nMessages have to be acknowledged via `StreamOperations.acknowledge` in order to be removed from the Pending Entries List as shown in the snippet below.\n\n====\n[source,java]\n----\nStreamMessageListenerContainer<String, MapRecord<String, String, String>> container = ...\n\ncontainer.receive(Consumer.from(\"my-group\", \"my-consumer\"), <1>\n\tStreamOffset.create(\"my-stream\", ReadOffset.lastConsumed()),\n msg -> {\n\n // ...\n redisTemplate.opsForStream().acknowledge(\"my-group\", msg); <2>\n });\n----\n<1> Read as _my-consumer_ from group _my-group_. Received messages are not acknowledged.\n<2> Acknowledged the message after processing.\n====\n\nTIP: To auto acknowledge messages on receive use `receiveAutoAck` instead of `receive`.\n\n[[redis.streams.receive.readoffset]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "`Acknowledge` strategies", "heading_level": 3, "file_order": 20, "section_index": 7, "content_hash": "16d80a4a81c976d219f472b0d1c3b5ec4ddf6d2256690bc740c281d39f68e45b", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:2b04248af3a6e6a5990dd6695905a8c58b349229f3046bd318835b6eb9b65ed6", "content": "Stream read operations accept a read offset specification to consume messages from the given offset on. `ReadOffset` represents the read offset specification. Redis supports 3 variants of offsets, depending on whether you consume the stream standalone or within a consumer group:\n\n* `ReadOffset.latest()` – Read the latest message.\n* `ReadOffset.from(…)` – Read after a specific message Id.\n* `ReadOffset.lastConsumed()` – Read after the last consumed message Id (consumer-group only).\n\nIn the context of a message container-based consumption, we need to advance (or increment) the read offset when consuming a message. Advancing depends on the requested `ReadOffset` and consumption mode (with/without consumer groups). The following matrix explains how containers advance `ReadOffset`:\n\n.ReadOffset Advancing\n[options=\"header,footer,autowidth\"]\n|===\n| Read offset | Standalone | Consumer Group\n| Latest | Read latest message | Read latest message\n| Specific Message Id | Use last seen message as the next MessageId | Use last seen message as the next MessageId\n| Last Consumed | Use last seen message as the next MessageId | Last consumed message as per consumer group\n|===\n\nReading from a specific message id and the last consumed message can be considered safe operations that ensure consumption of all messages that were appended to the stream.\nUsing the latest message for read can skip messages that were added to the stream while the poll operation was in the state of dead time. Polling introduces a dead time in which messages can arrive between individual polling commands. Stream consumption is not a linear contiguous read but split into repeating `XREAD` calls.\n\n[[redis.streams.receive.serialization]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "`ReadOffset` strategies", "heading_level": 3, "file_order": 20, "section_index": 8, "content_hash": "2b04248af3a6e6a5990dd6695905a8c58b349229f3046bd318835b6eb9b65ed6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:27cd35709e59e48c2549f0f1d1ae0434d5d648de66a9ce5434e8c7d6845c2426", "content": "Any Record sent to the stream needs to be serialized to its binary format. Due to the streams closeness to the hash data structure the stream key, field names and values use the according serializers configured on the `RedisTemplate`.\n\n.Stream Serialization\n[options=\"header,footer,autowidth\"]\n|===\n| Stream Property | Serializer | Description\n| key | keySerializer | used for `Record#getStream()`\n| field | hashKeySerializer | used for each map key in the payload\n| value | hashValueSerializer | used for each map value in the payload\n|===\n\nPlease make sure to review ``RedisSerializer``s in use and note that if you decide to not use any serializer you need to make sure those values are binary already.\n\n[[redis.streams.hashing]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Serialization", "heading_level": 2, "file_order": 20, "section_index": 9, "content_hash": "27cd35709e59e48c2549f0f1d1ae0434d5d648de66a9ce5434e8c7d6845c2426", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:bea5ac29f1c88892090529e2e24591d79a9aa180edfb37aec343a29ac9a2dbbb", "content": "[[simple-values]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Object Mapping", "heading_level": 2, "file_order": 20, "section_index": 10, "content_hash": "bea5ac29f1c88892090529e2e24591d79a9aa180edfb37aec343a29ac9a2dbbb", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:cc5a000092d6c8caf94b4450195b710b109b4086da8ae5f740584bf17e2760a9", "content": "`StreamOperations` allows to append simple values, via `ObjectRecord`, directly to the stream without having to put those values into a `Map` structure.\nThe value will then be assigned to an _payload_ field and can be extracted when reading back the value.\n\n[source,java]\n----\nObjectRecord<String, String> record = StreamRecords.newRecord()\n .in(\"my-stream\")\n .ofObject(\"my-value\");\n\nredisTemplate()\n .opsForStream()\n .add(record); <1>\n\nList<ObjectRecord<String, String>> records = redisTemplate()\n .opsForStream()\n .read(String.class, StreamOffset.fromStart(\"my-stream\"));\n----\n<1> XADD my-stream * \"_class\" \"java.lang.String\" \"_raw\" \"my-value\"\n\n``ObjectRecord``s pass through the very same serialization process as the all other records, thus the Record can also obtained using the untyped read operation returning a `MapRecord`.\n\n[[complex-values]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Simple Values", "heading_level": 3, "file_order": 20, "section_index": 11, "content_hash": "cc5a000092d6c8caf94b4450195b710b109b4086da8ae5f740584bf17e2760a9", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:bcaa57e3d04e7bcbe1aeee773bf0440b32b6858e62b6720b5d3053b7dd9e3285", "content": "Adding a complex value to the stream can be done in 3 ways:\n\n* Convert to simple value using e. g. a String JSON representation.\n* Serialize the value with a suitable `RedisSerializer`.\n* Convert the value into a `Map` suitable for serialization using a xref:redis/hash-mappers.adoc[`HashMapper`].\n\nThe first variant is the most straight forward one but neglects the field value capabilities offered by the stream structure, still the values in the stream will be readable for other consumers.\nThe 2nd option holds the same benefits as the first one, but may lead to a very specific consumer limitations as the all consumers must implement the very same serialization mechanism.\nThe `HashMapper` approach is the a bit more complex one making use of the steams hash structure, but flattening the source. Still other consumers remain able to read the records as long as suitable serializer combinations are chosen.\n\nNOTE: xref:redis/hash-mappers.adoc[HashMappers] convert the payload to a `Map` with specific types. Make sure to use Hash-Key and Hash-Value serializers that are capable of (de-)serializing the hash.\n\n[source,java]\n----\nObjectRecord<String, User> record = StreamRecords.newRecord()\n .in(\"user-logon\")\n .ofObject(new User(\"night\", \"angel\"));\n\nredisTemplate()\n .opsForStream()\n .add(record); <1>\n\nList<ObjectRecord<String, User>> records = redisTemplate()\n .opsForStream()\n .read(User.class, StreamOffset.fromStart(\"user-logon\"));\n----\n<1> XADD user-logon * \"_class\" \"com.example.User\" \"firstname\" \"night\" \"lastname\" \"angel\"\n\n`StreamOperations` use by default xref:redis/redis-repositories/mapping.adoc[ObjectHashMapper].\nYou may provide a `HashMapper` suitable for your requirements when obtaining `StreamOperations`.\n\n[source,java]\n----\nredisTemplate()\n .opsForStream(new JacksonHashMapper(true))\n .add(record); <1>\n----\n<1> XADD user-logon * \"firstname\" \"night\" \"@class\" \"com.example.User\" \"lastname\" \"angel\"\n\n[NOTE]\n====\nA `StreamMessageListenerContainer` may not be aware of any `@TypeAlias` used on domain types as those need to be resolved through a `MappingContext`.\nMake sure to initialize `RedisMappingContext` with a `initialEntitySet`.\n\n[source,java]\n----\n@Bean\nRedisMappingContext redisMappingContext() {\n RedisMappingContext ctx = new RedisMappingContext();\n ctx.setInitialEntitySet(Collections.singleton(Person.class));\n return ctx;\n}\n\n@Bean\nRedisConverter redisConverter(RedisMappingContext mappingContext) {\n return new MappingRedisConverter(mappingContext);\n}\n\n@Bean\nObjectHashMapper hashMapper(RedisConverter converter) {\n return new ObjectHashMapper(converter);\n}\n\n@Bean\nStreamMessageListenerContainer streamMessageListenerContainer(RedisConnectionFactory connectionFactory, ObjectHashMapper hashMapper) {\n StreamMessageListenerContainerOptions<String, ObjectRecord<String, Object>> options = StreamMessageListenerContainerOptions.builder()\n .objectMapper(hashMapper)\n .build();\n\n return StreamMessageListenerContainer.create(connectionFactory, options);\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/redis-streams.adoc", "title": "redis-streams", "heading": "Complex Values", "heading_level": 3, "file_order": 20, "section_index": 12, "content_hash": "bcaa57e3d04e7bcbe1aeee773bf0440b32b6858e62b6720b5d3053b7dd9e3285", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/redis-streams.adoc"}}
{"id": "sha256:88d104931047a486b1fe1787039d4784b548513bc91f4bfaf1da723632fe0786", "content": "[[scripting]]\n\nRedis versions 2.6 and higher provide support for running Lua scripts through the https://redis.io/commands/eval[eval] and https://redis.io/commands/evalsha[evalsha] commands. Spring Data Redis provides a high-level abstraction for running scripts that handles serialization and automatically uses the Redis script cache.\n\nScripts can be run by calling the `execute` methods of `RedisTemplate` and `ReactiveRedisTemplate`. Both use a configurable javadoc:org.springframework.data.redis.core.script.ScriptExecutor[] (or javadoc:org.springframework.data.redis.core.script.ReactiveScriptExecutor[]) to run the provided script. By default, the javadoc:org.springframework.data.redis.core.script.ScriptExecutor[] (or javadoc:org.springframework.data.redis.core.script.ReactiveScriptExecutor[]) takes care of serializing the provided keys and arguments and deserializing the script result. This is done through the key and value serializers of the template. There is an additional overload that lets you pass custom serializers for the script arguments and the result.\n\nThe default javadoc:org.springframework.data.redis.core.script.ScriptExecutor[] optimizes performance by retrieving the SHA1 of the script and attempting first to run `evalsha`, falling back to `eval` if the script is not yet present in the Redis script cache.\n\nThe following example runs a common \"`check-and-set`\" scenario by using a Lua script. This is an ideal use case for a Redis script, as it requires that running a set of commands atomically, and the behavior of one command is influenced by the result of another.\n\n[source,java]\n----\n@Bean\npublic RedisScript<Boolean> script() {\n\n ScriptSource scriptSource = new ResourceScriptSource(new ClassPathResource(\"META-INF/scripts/checkandset.lua\"));\n return RedisScript.of(scriptSource, Boolean.class);\n}\n----\n\n[tabs]\n======\nImperative::\n+\n[source,java,role=\"primary\"]\n----\npublic class Example {\n\n @Autowired\n RedisOperations<String, String> redisOperations;\n\n @Autowired\n RedisScript<Boolean> script;\n\n public boolean checkAndSet(String expectedValue, String newValue) {\n return redisOperations.execute(script, List.of(\"key\"), expectedValue, newValue);\n }\n}\n----\n\nReactive::\n+\n[source,java,role=\"secondary\"]\n----\npublic class Example {\n\n @Autowired\n ReactiveRedisOperations<String, String> redisOperations;\n\n @Autowired\n RedisScript<Boolean> script;\n\n public Flux<Boolean> checkAndSet(String expectedValue, String newValue) {\n return redisOperations.execute(script, List.of(\"key\"), expectedValue, newValue);\n }\n}\n----\n======\n\n[source,lua]\n----\n-- checkandset.lua\nlocal current = redis.call('GET', KEYS[1])\nif current == ARGV[1]\n then redis.call('SET', KEYS[1], ARGV[2])\n return true\nend\nreturn false\n----\n\nThe preceding code configures a javadoc:org.springframework.data.redis.core.script.RedisScript[] pointing to a file called `checkandset.lua`, which is expected to return a boolean value. The script `resultType` should be one of `Long`, `Boolean`, `List`, or a deserialized value type. It can also be `null` if the script returns a throw-away status (specifically, `OK`).\n\nTIP: It is ideal to configure a single instance of `DefaultRedisScript` in your application context to avoid re-calculation of the script's SHA1 on every script run.\n\nThe `checkAndSet` method above then runs the scripts. Scripts can be run within a javadoc:org.springframework.data.redis.core.SessionCallback[] as part of a transaction or pipeline. See \"`xref:redis/transactions.adoc[Redis Transactions]`\" and \"`xref:redis/pipelining.adoc[Pipelining]`\" for more information.\n\nThe scripting support provided by Spring Data Redis also lets you schedule Redis scripts for periodic running by using the Spring Task and Scheduler abstractions. See the https://spring.io/projects/spring-framework/[Spring Framework] documentation for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/scripting.adoc", "title": "scripting", "heading": "scripting", "heading_level": 1, "file_order": 21, "section_index": 0, "content_hash": "88d104931047a486b1fe1787039d4784b548513bc91f4bfaf1da723632fe0786", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/scripting.adoc"}}
{"id": "sha256:37638dc70ed233d3c5b9cf39af39abfbb43929300b32b1d8fbf8e732228536d1", "content": "[[redis:support]]\n\nPackage `org.springframework.data.redis.support` offers various reusable components that rely on Redis as a backing store.\nCurrently, the package contains various JDK-based interface implementations on top of Redis, such as https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/atomic/package-summary.html[atomic] counters and JDK https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Collection.html[Collections].\n\nNOTE: javadoc:org.springframework.data.redis.support.collections.RedisList[] is forward-compatible with Java 21 `SequencedCollection`.\n\nThe atomic counters make it easy to wrap Redis key incrementation while the collections allow easy management of Redis keys with minimal storage exposure or API leakage.\nIn particular, the javadoc:org.springframework.data.redis.support.collections.RedisSet[] and javadoc:org.springframework.data.redis.support.collections.RedisZSet[] interfaces offer easy access to the set operations supported by Redis, such as `intersection` and `union`. javadoc:org.springframework.data.redis.support.collections.RedisList[] implements the `List`, `Queue`, and `Deque` contracts (and their equivalent blocking siblings) on top of Redis, exposing the storage as a FIFO (First-In-First-Out), LIFO (Last-In-First-Out) or capped collection with minimal configuration.\nThe following example shows the configuration for a bean that uses a javadoc:org.springframework.data.redis.support.collections.RedisList[]:\n\n[tabs]\n======\nJava::\n+\n[source,java,role=\"primary\"]\n----\n@Configuration\nclass MyConfig {\n\n // …\n\n @Bean\n RedisList<String> stringRedisTemplate(RedisTemplate<String, String> redisTemplate) {\n return new DefaultRedisList<>(template, \"queue-key\");\n }\n}\n----\n\nXML::\n+\n[source,xml,role=\"secondary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:p=\"http://www.springframework.org/schema/p\" xsi:schemaLocation=\"\n http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n <bean id=\"queue\" class=\"org.springframework.data.redis.support.collections.DefaultRedisList\">\n <constructor-arg ref=\"redisTemplate\"/>\n <constructor-arg value=\"queue-key\"/>\n </bean>\n\n</beans>\n----\n======\n\nThe following example shows a Java configuration example for a `Deque`:\n\n[source,java]\n----\npublic class AnotherExample {\n\n // injected\n private Deque<String> queue;\n\n public void addTag(String tag) {\n queue.push(tag);\n }\n}\n----\n\nAs shown in the preceding example, the consuming code is decoupled from the actual storage implementation.\nIn fact, there is no indication that Redis is used underneath.\nThis makes moving from development to production environments transparent and highly increases testability (the Redis implementation can be replaced with an in-memory one).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/support-classes.adoc", "title": "support-classes", "heading": "support-classes", "heading_level": 1, "file_order": 22, "section_index": 0, "content_hash": "37638dc70ed233d3c5b9cf39af39abfbb43929300b32b1d8fbf8e732228536d1", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/support-classes.adoc"}}
{"id": "sha256:00650249716eb56f7c00162916466b7eb7822d2dd2349742af772a4f01476987", "content": "[[redis:template]]\n\nMost users are likely to use javadoc:org.springframework.data.redis.core.RedisTemplate[] and its corresponding package, `org.springframework.data.redis.core` or its reactive variant javadoc:org.springframework.data.redis.core.ReactiveRedisTemplate[].\nThe template is, in fact, the central class of the Redis module, due to its rich feature set.\nThe template offers a high-level abstraction for Redis interactions.\nWhile `[Reactive]RedisConnection` offers low-level methods that accept and return binary values (`byte` arrays), the template takes care of serialization and connection management, freeing the user from dealing with such details.\n\nThe javadoc:org.springframework.data.redis.core.RedisTemplate[] class implements the javadoc:org.springframework.data.redis.core.RedisOperations[] interface and its reactive variant javadoc:org.springframework.data.redis.core.ReactiveRedisTemplate[] implements javadoc:org.springframework.data.redis.core.ReactiveRedisOperations[].\n\nNOTE: The preferred way to reference operations on a `[Reactive]RedisTemplate` instance is through the\n`[Reactive]RedisOperations` interface.\n\nMoreover, the template provides operations views (following the grouping from the Redis command https://redis.io/commands[reference]) that offer rich, generified interfaces for working against a certain type or certain key (through the `KeyBound` interfaces) as described in the following table:\n\n.Operational views\n[%collapsible]\n=======\n[tabs]\n======\nImperative::\n+\n[width=\"80%\",cols=\"<1,<2\",options=\"header\",role=\"primary\"]\n|====\n|Interface\n|Description\n\n2+^|_Key Type Operations_\n\n|javadoc:org.springframework.data.redis.core.GeoOperations[]\n|Redis geospatial operations, such as `GEOADD`, `GEORADIUS`,...\n\n|javadoc:org.springframework.data.redis.core.HashOperations[]\n|Redis hash operations\n\n|javadoc:org.springframework.data.redis.core.HyperLogLogOperations[]\n|Redis HyperLogLog operations, such as `PFADD`, `PFCOUNT`,...\n\n|javadoc:org.springframework.data.redis.core.ListOperations[]\n|Redis list operations\n\n|javadoc:org.springframework.data.redis.core.SetOperations[]\n|Redis set operations\n\n|javadoc:org.springframework.data.redis.core.ValueOperations[]\n|Redis string (or value) operations\n\n|javadoc:org.springframework.data.redis.core.ZSetOperations[]\n|Redis zset (or sorted set) operations\n\n2+^|_Key Bound Operations_\n\n|javadoc:org.springframework.data.redis.core.BoundGeoOperations[]\n|Redis key bound geospatial operations\n\n|javadoc:org.springframework.data.redis.core.BoundHashOperations[]\n|Redis hash key bound operations\n\n|javadoc:org.springframework.data.redis.core.BoundKeyOperations[]\n|Redis key bound operations\n\n|javadoc:org.springframework.data.redis.core.BoundListOperations[]\n|Redis list key bound operations\n\n|javadoc:org.springframework.data.redis.core.BoundSetOperations[]\n|Redis set key bound operations\n\n|javadoc:org.springframework.data.redis.core.BoundValueOperations[]\n|Redis string (or value) key bound operations\n\n|javadoc:org.springframework.data.redis.core.BoundZSetOperations[]\n|Redis zset (or sorted set) key bound operations\n\n|====\n\nReactive::\n+\n[width=\"80%\",cols=\"<1,<2\",options=\"header\",role=\"secondary\"]\n|====\n|Interface\n|Description\n\n2+^|_Key Type Operations_\n\n|javadoc:org.springframework.data.redis.core.ReactiveGeoOperations[]\n|Redis geospatial operations such as `GEOADD`, `GEORADIUS`, and others)\n\n|javadoc:org.springframework.data.redis.core.ReactiveHashOperations[]\n|Redis hash operations\n\n|javadoc:org.springframework.data.redis.core.ReactiveHyperLogLogOperations[]\n|Redis HyperLogLog operations such as (`PFADD`, `PFCOUNT`, and others)\n\n|javadoc:org.springframework.data.redis.core.ReactiveListOperations[]\n|Redis list operations\n\n|javadoc:org.springframework.data.redis.core.ReactiveSetOperations[]\n|Redis set operations\n\n|javadoc:org.springframework.data.redis.core.ReactiveValueOperations[]\n|Redis string (or value) operations\n\n|javadoc:org.springframework.data.redis.core.ReactiveZSetOperations[]\n|Redis zset (or sorted set) operations\n|====\n======\n=======\n\nOnce configured, the template is thread-safe and can be reused across multiple instances.\n\n`RedisTemplate` uses a Java-based serializer for most of its operations.\nThis means that any object written or read by the template is serialized and deserialized through Java.\n\nYou can change the serialization mechanism on the template, and the Redis module offers several implementations, which are available in the `org.springframework.data.redis.serializer` package.\nSee <<redis:serializer,Serializers>> for more information.\nYou can also set any of the serializers to null and use RedisTemplate with raw byte arrays by setting the `enableDefaultSerializer` property to `false`.\nNote that the template requires all keys to be non-null.\nHowever, values can be null as long as the underlying serializer accepts them.\nRead the Javadoc of each serializer for more information.\n\nFor cases where you need a certain template view, declare the view as a dependency and inject the template.\nThe container automatically performs the conversion, eliminating the `opsFor[X]` calls, as shown in the following example:\n\n.Configuring Template API\n[tabs]\n======\nJava Imperative::\n+\n[source,java,role=\"primary\"]\n----\n@Configuration\nclass MyConfig {\n\n @Bean\n LettuceConnectionFactory connectionFactory() {\n return new LettuceConnectionFactory();\n }\n\n @Bean\n RedisTemplate<String, String> redisTemplate(RedisConnectionFactory connectionFactory) {\n\n RedisTemplate<String, String> template = new RedisTemplate<>();\n template.setConnectionFactory(connectionFactory);\n return template;\n }\n}\n----\n\nJava Reactive::\n+\n[source,java,role=\"secondary\"]\n----\n@Configuration\nclass MyConfig {\n\n @Bean\n LettuceConnectionFactory connectionFactory() {\n return new LettuceConnectionFactory();\n }\n\n @Bean\n ReactiveRedisTemplate<String, String> ReactiveRedisTemplate(ReactiveRedisConnectionFactory connectionFactory) {\n return new ReactiveRedisTemplate<>(connectionFactory, RedisSerializationContext.string());\n }\n}\n----\n\nXML::\n+\n[source,xml,role=\"tertiary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:p=\"http://www.springframework.org/schema/p\"\n xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n <bean id=\"redisConnectionFactory\" class=\"org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory\"/>\n <!-- redis template definition -->\n <bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\" p:connection-factory-ref=\"redisConnectionFactory\"/>\n ...\n\n</beans>\n----\n======\n\n.Pushing an item to a List using `[Reactive]RedisTemplate`\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic class Example {\n\n // inject the actual operations\n @Autowired\n private RedisOperations<String, String> operations;\n\n // inject the template as ListOperations\n @Resource(name=\"redisTemplate\")\n private ListOperations<String, String> listOps;\n\n public void addLink(String userId, URL url) {\n listOps.leftPush(userId, url.toExternalForm());\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic class Example {\n\n // inject the actual template\n @Autowired\n private ReactiveRedisOperations<String, String> operations;\n\n public Mono<Long> addLink(String userId, URL url) {\n return operations.opsForList().leftPush(userId, url.toExternalForm());\n }\n}\n----\n======\n\n[[redis:string]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/template.adoc", "title": "template", "heading": "template", "heading_level": 1, "file_order": 23, "section_index": 0, "content_hash": "00650249716eb56f7c00162916466b7eb7822d2dd2349742af772a4f01476987", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/template.adoc"}}
{"id": "sha256:7c066223c4eb4d847d2562d008fdf28b37f935a9c6ba8178db30f3dfa0258ea2", "content": "Since it is quite common for the keys and values stored in Redis to be `java.lang.String`, the Redis modules provides two extensions to `RedisConnection` and `RedisTemplate`, respectively the `StringRedisConnection` (and its `DefaultStringRedisConnection` implementation) and `StringRedisTemplate` as a convenient one-stop solution for intensive String operations.\nIn addition to being bound to `String` keys, the template and the connection use the `StringRedisSerializer` underneath, which means the stored keys and values are human-readable (assuming the same encoding is used both in Redis and your code).\nThe following listings show an example:\n\n[tabs]\n======\nJava Imperative::\n+\n[source,java,role=\"primary\"]\n----\n@Configuration\nclass RedisConfiguration {\n\n @Bean\n LettuceConnectionFactory redisConnectionFactory() {\n return new LettuceConnectionFactory();\n }\n\n @Bean\n StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) {\n\n StringRedisTemplate template = new StringRedisTemplate();\n template.setConnectionFactory(redisConnectionFactory);\n return template;\n }\n}\n----\n\nJava Reactive::\n+\n[source,java,role=\"secondary\"]\n----\n@Configuration\nclass RedisConfiguration {\n\n @Bean\n LettuceConnectionFactory redisConnectionFactory() {\n return new LettuceConnectionFactory();\n }\n\n @Bean\n ReactiveStringRedisTemplate reactiveRedisTemplate(ReactiveRedisConnectionFactory factory) {\n return new ReactiveStringRedisTemplate<>(factory);\n }\n}\n----\n\nXML::\n+\n[source,xml,role=\"tertiary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:p=\"http://www.springframework.org/schema/p\"\n xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n <bean id=\"redisConnectionFactory\" class=\"org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory\"/>\n\n <bean id=\"stringRedisTemplate\" class=\"org.springframework.data.redis.core.StringRedisTemplate\" p:connection-factory-ref=\"redisConnectionFactory\"/>\n\n</beans>\n----\n======\n\n[tabs]\n======\nImperative::\n+\n[source,java,role=\"primary\"]\n----\npublic class Example {\n\n @Autowired\n private StringRedisTemplate redisTemplate;\n\n public void addLink(String userId, URL url) {\n redisTemplate.opsForList().leftPush(userId, url.toExternalForm());\n }\n}\n----\n\nReactive::\n+\n[source,java,role=\"secondary\"]\n----\npublic class Example {\n\n @Autowired\n private ReactiveStringRedisTemplate redisTemplate;\n\n public Mono<Long> addLink(String userId, URL url) {\n return redisTemplate.opsForList().leftPush(userId, url.toExternalForm());\n }\n}\n----\n======\n\nAs with the other Spring templates, `RedisTemplate` and `StringRedisTemplate` let you talk directly to Redis through the `RedisCallback` interface.\nThis feature gives complete control to you, as it talks directly to the `RedisConnection`.\nNote that the callback receives an instance of `StringRedisConnection` when a `StringRedisTemplate` is used.\nThe following example shows how to use the `RedisCallback` interface:\n\n[source,java]\n----\npublic void useCallback() {\n\n redisOperations.execute(new RedisCallback<Object>() {\n public Object doInRedis(RedisConnection connection) throws DataAccessException {\n Long size = connection.dbSize();\n // Can cast to StringRedisConnection if using a StringRedisTemplate\n ((StringRedisConnection)connection).set(\"key\", \"value\");\n }\n });\n}\n----\n\n[[redis:serializer]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/template.adoc", "title": "template", "heading": "String-focused Convenience Classes", "heading_level": 2, "file_order": 23, "section_index": 1, "content_hash": "7c066223c4eb4d847d2562d008fdf28b37f935a9c6ba8178db30f3dfa0258ea2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/template.adoc"}}
{"id": "sha256:6fcfa3d350302ccf1f584aacb62a1de665ce84d5a8215b89b192b3a02aba9459", "content": "From the framework perspective, the data stored in Redis is only bytes.\nWhile Redis itself supports various types, for the most part, these refer to the way the data is stored rather than what it represents.\nIt is up to the user to decide whether the information gets translated into strings or any other objects.\n\nIn Spring Data, the conversion between the user (custom) types and raw data (and vice-versa) is handled by Spring Data Redis in the `org.springframework.data.redis.serializer` package.\n\nThis package contains two types of serializers that, as the name implies, take care of the serialization process:\n\n* Two-way serializers based on javadoc:org.springframework.data.redis.serializer.RedisSerializer[].\n* Element readers and writers that use `RedisElementReader` and ``RedisElementWriter``.\n\nThe main difference between these variants is that `RedisSerializer` primarily serializes to `byte[]` while readers and writers use `ByteBuffer`.\n\nMultiple implementations are available (including two that have been already mentioned in this documentation):\n\n* javadoc:org.springframework.data.redis.serializer.JdkSerializationRedisSerializer[], which is used by default for javadoc:org.springframework.data.redis.cache.RedisCache[] and javadoc:org.springframework.data.redis.core.RedisTemplate[].\n* the `StringRedisSerializer`.\n\nHowever, one can use `OxmSerializer` for Object/XML mapping through Spring {spring-framework-docs}/data-access.html#oxm[OXM] support or javadoc:org.springframework.data.redis.serializer.JacksonJsonRedisSerializer[] or javadoc:org.springframework.data.redis.serializer.GenericJacksonJsonRedisSerializer[] for storing data in https://en.wikipedia.org/wiki/JSON[JSON] format.\n\nDo note that the storage format is not limited only to values.\nIt can be used for keys, values, or hashes without any restrictions.\n\n[WARNING]\n====\nBy default, javadoc:org.springframework.data.redis.cache.RedisCache[] and javadoc:org.springframework.data.redis.core.RedisTemplate[] are configured to use Java native serialization.\nJava native serialization is known for allowing the running of remote code caused by payloads that exploit vulnerable libraries and classes injecting unverified bytecode.\nManipulated input could lead to unwanted code being run in the application during the deserialization step.\nAs a consequence, do not use serialization in untrusted environments.\nIn general, we strongly recommend any other message format (such as JSON) instead.\n\nIf you are concerned about security vulnerabilities due to Java serialization, consider the general-purpose serialization filter mechanism at the core JVM level:\n\n* https://docs.oracle.com/en/java/javase/17/core/serialization-filtering1.html[Filter Incoming Serialization Data].\n* https://openjdk.org/jeps/290[JEP 290].\n* https://owasp.org/www-community/vulnerabilities/Deserialization_of_untrusted_data[OWASP: Deserialization of untrusted data].\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/template.adoc", "title": "template", "heading": "Serializers", "heading_level": 2, "file_order": 23, "section_index": 2, "content_hash": "6fcfa3d350302ccf1f584aacb62a1de665ce84d5a8215b89b192b3a02aba9459", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/template.adoc"}}
{"id": "sha256:9ea931c7f2b911285479412207cd48aa57a3c0ffde465b3b717b41074ca4eceb", "content": "[[tx]]\n\nRedis provides support for https://redis.io/topics/transactions[transactions] through the `multi`, `exec`, and `discard` commands.\nThese operations are available on javadoc:org.springframework.data.redis.core.RedisTemplate[].\nHowever, `RedisTemplate` is not guaranteed to run all the operations in the transaction with the same connection.\n\nSpring Data Redis provides the javadoc:org.springframework.data.redis.core.SessionCallback[] interface for use when multiple operations need to be performed with the same `connection`, such as when using Redis transactions.The following example uses the `multi` method:\n\n[source,java]\n----\nList<Object> txResults = redisOperations.execute(new SessionCallback<List<Object>>() {\n public List<Object> execute(RedisOperations operations) throws DataAccessException {\n operations.multi();\n operations.opsForSet().add(\"key\", \"value1\");\n\n // This will contain the results of all operations in the transaction\n return operations.exec();\n }\n});\nSystem.out.println(\"Number of items added to set: \" + txResults.get(0));\n----\n\n`RedisTemplate` uses its value, hash key, and hash value serializers to deserialize all results of `exec` before returning.\nThere is an additional `exec` method that lets you pass a custom serializer for transaction results.\n\nIt is worth mentioning that in case between `multi()` and `exec()` an exception happens (e.g. a timeout exception in case Redis does not respond within the timeout) then the connection may get stuck in a transactional state.\nTo prevent such a situation need have to discard the transactional state to clear the connection:\n\n[source,java]\n----\nList<Object> txResults = redisOperations.execute(new SessionCallback<List<Object>>() {\n public List<Object> execute(RedisOperations operations) throws DataAccessException {\n boolean transactionStateIsActive = true;\n\ttry {\n operations.multi();\n operations.opsForSet().add(\"key\", \"value1\");\n\n // This will contain the results of all operations in the transaction\n return operations.exec();\n } catch (RuntimeException e) {\n operations.discard();\n throw e;\n }\n }\n});\n----\n\n[[tx.spring]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/transactions.adoc", "title": "transactions", "heading": "transactions", "heading_level": 1, "file_order": 24, "section_index": 0, "content_hash": "9ea931c7f2b911285479412207cd48aa57a3c0ffde465b3b717b41074ca4eceb", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/transactions.adoc"}}
{"id": "sha256:691ad313b01fb28119e7924a3e9bfc7ae5af446483e79b8f8f023c70f89fda7d", "content": "By default, `RedisTemplate` does not participate in managed Spring transactions.\nIf you want `RedisTemplate` to make use of Redis transaction when using `@Transactional` or `TransactionTemplate`, you need to be explicitly enable transaction support for each `RedisTemplate` by setting `setEnableTransactionSupport(true)`.\nEnabling transaction support binds `RedisConnection` to the current transaction backed by a `ThreadLocal`.\nIf the transaction finishes without errors, the Redis transaction gets commited with `EXEC`, otherwise rolled back with `DISCARD`.\nRedis transactions are batch-oriented.\nCommands issued during an ongoing transaction are queued and only applied when committing the transaction.\n\nSpring Data Redis distinguishes between read-only and write commands in an ongoing transaction.\nRead-only commands, such as `KEYS`, are piped to a fresh (non-thread-bound) `RedisConnection` to allow reads.\nWrite commands are queued by `RedisTemplate` and applied upon commit.\n\nThe following example shows how to configure transaction management:\n\n.Configuration enabling Transaction Management\n====\n[source,java]\n----\n@Configuration\n@EnableTransactionManagement <1>\npublic class RedisTxContextConfiguration {\n\n @Bean\n public StringRedisTemplate redisTemplate() {\n StringRedisTemplate template = new StringRedisTemplate(redisConnectionFactory());\n // explicitly enable transaction support\n template.setEnableTransactionSupport(true); <2>\n return template;\n }\n\n @Bean\n public RedisConnectionFactory redisConnectionFactory() {\n // jedis || Lettuce\n }\n\n @Bean\n public PlatformTransactionManager transactionManager() throws SQLException {\n return new DataSourceTransactionManager(dataSource()); <3>\n }\n\n @Bean\n public DataSource dataSource() throws SQLException {\n // ...\n }\n}\n----\n<1> Configures a Spring Context to enable {spring-framework-docs}/data-access.html#transaction-declarative[declarative transaction management].\n<2> Configures `RedisTemplate` to participate in transactions by binding connections to the current thread.\n<3> Transaction management requires a `PlatformTransactionManager`.\nSpring Data Redis does not ship with a `PlatformTransactionManager` implementation.\nAssuming your application uses JDBC, Spring Data Redis can participate in transactions by using existing transaction managers.\n====\n\nThe following examples each demonstrate a usage constraint:\n\n.Usage Constraints\n====\n[source,java]\n----\ntemplate.opsForValue().set(\"thing1\", \"thing2\");\n\ntemplate.keys(\"*\");\n\ntemplate.opsForValue().get(\"thing1\");\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis/transactions.adoc", "title": "transactions", "heading": "`@Transactional` Support", "heading_level": 2, "file_order": 24, "section_index": 1, "content_hash": "691ad313b01fb28119e7924a3e9bfc7ae5af446483e79b8f8f023c70f89fda7d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis/transactions.adoc"}}
{"id": "sha256:60dafab8c1c44b49e46e766ceb2f5c6d9cb26fcba2af9f3d1db6ccca5142b177", "content": "include::{commons}@data-commons::page$repositories/core-concepts.adoc[]\n\n[[redis.entity-persistence.state-detection-strategies]]\ninclude::{commons}@data-commons::page$is-new-state-detection.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/core-concepts.adoc", "title": "core-concepts", "heading": "core-concepts", "heading_level": 1, "file_order": 25, "section_index": 0, "content_hash": "60dafab8c1c44b49e46e766ceb2f5c6d9cb26fcba2af9f3d1db6ccca5142b177", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/core-concepts.adoc"}}
{"id": "sha256:81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "content": "include::{commons}@data-commons::page$repositories/core-domain-events.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/core-domain-events.adoc", "title": "core-domain-events", "heading": "core-domain-events", "heading_level": 1, "file_order": 26, "section_index": 0, "content_hash": "81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/core-domain-events.adoc"}}
{"id": "sha256:aae50739c14d7eb32d6fefba868b01f71d3d0dbcb2e8366aa0364c6f840a2212", "content": "[[core.extensions.querydsl]]\n\nSpring Data Redis does not support Querydsl.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/core-extensions.adoc", "title": "core-extensions", "heading": "core-extensions", "heading_level": 1, "file_order": 27, "section_index": 0, "content_hash": "aae50739c14d7eb32d6fefba868b01f71d3d0dbcb2e8366aa0364c6f840a2212", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/core-extensions.adoc"}}
{"id": "sha256:bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "content": "include::{commons}@data-commons::page$repositories/create-instances.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/create-instances.adoc", "title": "create-instances", "heading": "create-instances", "heading_level": 1, "file_order": 28, "section_index": 0, "content_hash": "bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/create-instances.adoc"}}
{"id": "sha256:bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "content": "include::{commons}@data-commons::page$repositories/custom-implementations.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/custom-implementations.adoc", "title": "custom-implementations", "heading": "custom-implementations", "heading_level": 1, "file_order": 29, "section_index": 0, "content_hash": "bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/custom-implementations.adoc"}}
{"id": "sha256:661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "content": "include::{commons}@data-commons::page$repositories/definition.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/definition.adoc", "title": "definition", "heading": "definition", "heading_level": 1, "file_order": 30, "section_index": 0, "content_hash": "661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/definition.adoc"}}
{"id": "sha256:8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "content": "include::{commons}@data-commons::page$repositories/null-handling.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/null-handling.adoc", "title": "null-handling", "heading": "null-handling", "heading_level": 1, "file_order": 31, "section_index": 0, "content_hash": "8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/null-handling.adoc"}}
{"id": "sha256:695d91e03e4dbc15239cd09e578ee5ca2f3a144974a30554df0e3cbb7c9cc516", "content": "include::{commons}@data-commons::page$object-mapping.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/object-mapping.adoc", "title": "object-mapping", "heading": "object-mapping", "heading_level": 1, "file_order": 32, "section_index": 0, "content_hash": "695d91e03e4dbc15239cd09e578ee5ca2f3a144974a30554df0e3cbb7c9cc516", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/object-mapping.adoc"}}
{"id": "sha256:5fc43241139910ef2e7e59e2fd4d1deefd68506ee67abb368a6076354a04e189", "content": "[[redis.projections]]\n\ninclude::{commons}@data-commons::page$repositories/projections.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/projections.adoc", "title": "projections", "heading": "projections", "heading_level": 1, "file_order": 33, "section_index": 0, "content_hash": "5fc43241139910ef2e7e59e2fd4d1deefd68506ee67abb368a6076354a04e189", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/projections.adoc"}}
{"id": "sha256:7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "content": "include::{commons}@data-commons::page$repositories/query-keywords-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc", "title": "query-keywords-reference", "heading": "query-keywords-reference", "heading_level": 1, "file_order": 34, "section_index": 0, "content_hash": "7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc"}}
{"id": "sha256:2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "content": "include::{commons}@data-commons::page$repositories/query-methods-details.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/query-methods-details.adoc", "title": "query-methods-details", "heading": "query-methods-details", "heading_level": 1, "file_order": 35, "section_index": 0, "content_hash": "2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/query-methods-details.adoc"}}
{"id": "sha256:8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "content": "include::{commons}@data-commons::page$repositories/query-return-types-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc", "title": "query-return-types-reference", "heading": "query-return-types-reference", "heading_level": 1, "file_order": 36, "section_index": 0, "content_hash": "8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc"}}
{"id": "sha256:ea40bf5c2dfd0b15c92acb0649ad63922b250e16526d7e0e2895601b66a86f35", "content": "[[appendix]]\n\n[[schema]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/appendix.adoc", "title": "appendix", "heading": "appendix", "heading_level": 1, "file_order": 37, "section_index": 0, "content_hash": "ea40bf5c2dfd0b15c92acb0649ad63922b250e16526d7e0e2895601b66a86f35", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/appendix.adoc"}}
{"id": "sha256:9bfc23a75403b28aa72c61c4eafa16b8ae8ba7a4c5a17698b8b13c4e53db64c6", "content": "link:https://www.springframework.org/schema/redis/spring-redis-1.0.xsd[Spring Data Redis Schema (redis-namespace)]\n\n[[supported-commands]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/appendix.adoc", "title": "appendix", "heading": "Schema", "heading_level": 2, "file_order": 37, "section_index": 1, "content_hash": "9bfc23a75403b28aa72c61c4eafa16b8ae8ba7a4c5a17698b8b13c4e53db64c6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/appendix.adoc"}}
{"id": "sha256:a90c92d71c8f9ebc90eef59978c38a8ea4442015efe873bdc58eeb14e79bb67a", "content": ".Redis commands supported by `RedisTemplate`\n[width=\"50%\",cols=\"<2,^1\",options=\"header\"]\n|=========================================================\n|Command |Template Support\n\n|APPEND |X\n|AUTH |X\n|BGREWRITEAOF |X\n|BGSAVE |X\n|BITCOUNT |X\n|BITFIELD |X\n|BITOP |X\n|BLPOP |X\n|BRPOP |X\n|BRPOPLPUSH |X\n|CLIENT KILL |X\n|CLIENT GETNAME |X\n|CLIENT LIST |X\n|CLIENT SETNAME |X\n|CLUSTER SLOTS |-\n|COMMAND |-\n|COMMAND COUNT |-\n|COMMAND GETKEYS |-\n|COMMAND INFO |-\n|CONFIG GET |X\n|CONFIG RESETSTAT |X\n|CONFIG REWRITE |-\n|CONFIG SET |X\n|DBSIZE |X\n|DEBUG OBJECT |-\n|DEBUG SEGFAULT |-\n|DECR |X\n|DECRBY |X\n|DEL |X\n|DISCARD |X\n|DUMP |X\n|ECHO |X\n|EVAL |X\n|EVALSHA |X\n|EXEC |X\n|EXISTS |X\n|EXPIRE |X\n|EXPIREAT |X\n|FLUSHALL |X\n|FLUSHDB |X\n|GEOADD |X\n|GEODIST |X\n|GEOHASH |X\n|GEOPOS |X\n|GEORADIUS |X\n|GEORADIUSBYMEMBER |X\n|GEOSEARCH |X\n|GEOSEARCHSTORE |X\n|GET |X\n|GETBIT |X\n|GETRANGE |X\n|GETSET |X\n|HDEL |X\n|HEXISTS |X\n|HEXPIRE |X\n|HEXPIREAT |X\n|HPEXPIRE |X\n|HPEXPIREAT |X\n|HPERSIST |X\n|HTTL |X\n|HPTTL |X\n|HGET |X\n|HGETALL |X\n|HINCRBY |X\n|HINCRBYFLOAT |X\n|HKEYS |X\n|HLEN |X\n|HMGET |X\n|HMSET |X\n|HSCAN |X\n|HSET |X\n|HSETNX |X\n|HVALS |X\n|INCR |X\n|INCRBY |X\n|INCRBYFLOAT |X\n|INFO |X\n|KEYS |X\n|LASTSAVE |X\n|LINDEX |X\n|LINSERT |X\n|LLEN |X\n|LPOP |X\n|LPUSH |X\n|LPUSHX |X\n|LRANGE |X\n|LREM |X\n|LSET |X\n|LTRIM |X\n|MGET |X\n|MIGRATE |-\n|MONITOR |-\n|MOVE |X\n|MSET |X\n|MSETNX |X\n|MULTI |X\n|OBJECT |-\n|PERSIST |X\n|PEXIPRE |X\n|PEXPIREAT |X\n|PFADD |X\n|PFCOUNT |X\n|PFMERGE |X\n|PING |X\n|PSETEX |X\n|PSUBSCRIBE |X\n|PTTL |X\n|PUBLISH |X\n|PUBSUB |-\n|PUBSUBSCRIBE |-\n|QUIT |X\n|RANDOMKEY |X\n|RENAME |X\n|RENAMENX |X\n|REPLICAOF |X\n|RESTORE |X\n|ROLE |-\n|RPOP |X\n|RPOPLPUSH |X\n|RPUSH |X\n|RPUSHX |X\n|SADD |X\n|SAVE |X\n|SCAN |X\n|SCARD |X\n|SCRIPT EXITS |X\n|SCRIPT FLUSH |X\n|SCRIPT KILL |X\n|SCRIPT LOAD |X\n|SDIFF |X\n|SDIFFSTORE |X\n|SELECT |X\n|SENTINEL FAILOVER |X\n|SENTINEL GET-MASTER-ADD-BY-NAME |-\n|SENTINEL MASTER | -\n|SENTINEL MASTERS |X\n|SENTINEL MONITOR |X\n|SENTINEL REMOVE |X\n|SENTINEL RESET |-\n|SENTINEL SET |-\n|SENTINEL SLAVES |X\n|SET |X\n|SETBIT |X\n|SETEX |X\n|SETNX |X\n|SETRANGE |X\n|SHUTDOWN |X\n|SINTER |X\n|SINTERSTORE |X\n|SISMEMBER |X\n|SLAVEOF |X\n|SLOWLOG |-\n|SMEMBERS |X\n|SMOVE |X\n|SORT |X\n|SPOP |X\n|SRANDMEMBER |X\n|SREM |X\n|SSCAN |X\n|STRLEN |X\n|SUBSCRIBE |X\n|SUNION |X\n|SUNIONSTORE |X\n|SYNC |-\n|TIME |X\n|TTL |X\n|TYPE |X\n|UNSUBSCRIBE |X\n|UNWATCH |X\n|WATCH |X\n|XACK |X\n|XACKDEL |X\n|XADD |X\n|XAUTOCLAIM |X\n|XCLAIM |X\n|XDEL |X\n|XDELEX |X\n|XGROUP |X\n|XINFO |X\n|XLEN |X\n|XPENDING |X\n|XRANGE |X\n|XREAD |X\n|XREADGROUP |X\n|XREVRANGE |X\n|XTRIM |X\n|ZADD |X\n|ZCARD |X\n|ZCOUNT |X\n|ZINCRBY |X\n|ZINTERSTORE |X\n|ZLEXCOUNT |-\n|ZRANGE |X\n|ZRANGEBYLEX |-\n|ZREVRANGEBYLEX |-\n|ZRANGEBYSCORE |X\n|ZRANGESTORE |X\n|ZRANK |X\n|ZREM |X\n|ZREMRANGEBYLEX |-\n|ZREMRANGEBYRANK |X\n|ZREVRANGE |X\n|ZREVRANGEBYSCORE |X\n|ZREVRANK |X\n|ZSCAN |X\n|ZSCORE |X\n|ZUNINONSTORE |X\n|=========================================================", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/appendix.adoc", "title": "appendix", "heading": "Supported Commands", "heading_level": 2, "file_order": 37, "section_index": 2, "content_hash": "a90c92d71c8f9ebc90eef59978c38a8ea4442015efe873bdc58eeb14e79bb67a", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/appendix.adoc"}}
{"id": "sha256:47b069916e0c619e10dc6a59913cac6e9c407e9aef6d7e4f3702f8aa2a4c00ed", "content": "[[spring-data-redis-reference-documentation]]\n\n_Spring Data Redis provides Redis connectivity and repository support for the Redis database.\nIt eases development of applications with a consistent programming model that need to access Redis data sources._\n\n[horizontal]\nxref:redis.adoc[Redis] :: Redis support and connectivity\nxref:repositories.adoc[Repositories] :: Redis Repositories\nxref:observability.adoc[Observability] :: Observability Integration\nhttps://github.com/spring-projects/spring-data-commons/wiki[Wiki] :: What's New, Upgrade Notes, Supported Versions, additional cross-version information.\n\nCostin Leau, Jennifer Hickey, Christoph Strobl, Thomas Darimont, Mark Paluch, Jay Bryant\n\n(C) 2008-{copyright-year} VMware, Inc.\n\nCopies of this document may be made for your own use and for distribution to others, provided that you do not charge any fee for such copies and further provided that each copy contains this Copyright Notice, whether distributed in print or electronically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 38, "section_index": 0, "content_hash": "47b069916e0c619e10dc6a59913cac6e9c407e9aef6d7e4f3702f8aa2a4c00ed", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/index.adoc"}}
{"id": "sha256:04b5d163ac6f1ad413445d90ad28c4f70746651a12f33274e91e9fd94dd1a22c", "content": "[[redis.observability]]\n\nGetting insights from an application component about its operations, timing and relation to application code is crucial to understand latency.\nLettuce ships with a Micrometer integration to collect observations during Redis interaction.\nOnce the integration is set up, Micrometer will create meters and spans (for distributed tracing) for each Redis command.\n\nTo enable the integration, apply the following configuration to `LettuceClientConfiguration`:\n\n[source,java]\n----\n@Configuration\nclass ObservabilityConfiguration {\n\n @Bean\n public ClientResources clientResources(ObservationRegistry observationRegistry) {\n\n return ClientResources.builder()\n .tracing(new MicrometerTracing(observationRegistry, \"my-redis-cache\"))\n .build();\n }\n\n @Bean\n public LettuceConnectionFactory lettuceConnectionFactory(ClientResources clientResources) {\n\n LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()\n .clientResources(clientResources).build();\n RedisConfiguration redisConfiguration = …;\n return new LettuceConnectionFactory(redisConfiguration, clientConfig);\n }\n}\n----\n\nNOTE: When using Spring Boot, `LettuceMetricsAutoConfiguration` configures Lettuce's `MicrometerCommandLatencyRecorder`.\nDepending on whether you want only Metrics or Metrics and Tracing, you might want to exclude this auto-configuration class in your application.\n\nSee also for further reference:\n* https://redis.github.io/lettuce/advanced-usage/#micrometer[Lettuce Tracing]\n* https://opentelemetry.io/docs/reference/specification/trace/semantic_conventions/database/#redis[OpenTelemetry Semantic Conventions] .", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/observability.adoc", "title": "observability", "heading": "observability", "heading_level": 1, "file_order": 39, "section_index": 0, "content_hash": "04b5d163ac6f1ad413445d90ad28c4f70746651a12f33274e91e9fd94dd1a22c", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/observability.adoc"}}
{"id": "sha256:7b5f6630d4fbd91d05ef1761c3ef1b65feff325797b71dd745ed27c172ec7425", "content": "[[preface]]\n\nThe Spring Data Redis project applies core Spring concepts to the development of solutions by using a key-value style data store.\nWe provide a \"`template`\" as a high-level abstraction for sending and receiving messages.\nYou may notice similarities to the JDBC support in the Spring Framework.\n\nThis section provides an easy-to-follow guide for getting started with the Spring Data Redis module.\n\n[[get-started:first-steps:spring]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "preface", "heading_level": 1, "file_order": 40, "section_index": 0, "content_hash": "7b5f6630d4fbd91d05ef1761c3ef1b65feff325797b71dd745ed27c172ec7425", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:81113d35522d66947aa89898c55bffaa61efaeac5e4c7af6caf246b65ba7b5d4", "content": "Spring Data uses Spring framework's\n{spring-framework-docs}/core.html[core] functionality, including:\n\n* {spring-framework-docs}/core.html#beans[IoC] container\n* {spring-framework-docs}/core.html#validation[type conversion system]\n* {spring-framework-docs}/core.html#expressions[expression language]\n* {spring-framework-docs}/integration.html#jmx[JMX integration]\n* {spring-framework-docs}/data-access.html#dao-exceptions[DAO exception hierarchy].\n\nWhile you need not know the Spring APIs, understanding the concepts behind them is important.\nAt a minimum, the idea behind Inversion of Control (IoC) should be familiar, and you should be familiar with whatever IoC container you choose to use.\n\nThe core functionality of the Redis support can be used directly, with no need to invoke the IoC services of the Spring Container.\nThis is much like `JdbcTemplate`, which can be used \"'standalone'\" without any other services of the Spring container.\nTo leverage all the features of Spring Data Redis, such as the repository support, you need to configure some parts of the library to use Spring.\n\nTo learn more about Spring, you can refer to the comprehensive documentation that explains the Spring Framework in detail.\nThere are a lot of articles, blog entries, and books on the subject.\nSee the Spring framework https://spring.io/projects/spring-framework/[home page] for more information.\n\nIn general, this should be the starting point for developers wanting to try Spring Data Redis.\n\n[[get-started:first-steps:nosql]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Learning Spring", "heading_level": 2, "file_order": 40, "section_index": 1, "content_hash": "81113d35522d66947aa89898c55bffaa61efaeac5e4c7af6caf246b65ba7b5d4", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:5161c87a04cf2d141359a4b0f561cbad236c712e5598eed7b709db9dd870195d", "content": "NoSQL stores have taken the storage world by storm.\nIt is a vast domain with a plethora of solutions, terms, and patterns (to make things worse, even the term itself has multiple https://www.google.com/search?q=nosoql+acronym[meanings]).\nWhile some of the principles are common, it is crucial that you be familiar to some degree with the stores supported by SDR. The best way to get acquainted with these solutions is to read their documentation and follow their examples.\nIt usually does not take more then five to ten minutes to go through them and, if you come from an RDMBS-only background, many times these exercises can be eye-openers.\n\n[[get-started:first-steps:samples]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Learning NoSQL and Key Value Stores", "heading_level": 2, "file_order": 40, "section_index": 2, "content_hash": "5161c87a04cf2d141359a4b0f561cbad236c712e5598eed7b709db9dd870195d", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:6f8d94a67116e5004ba35809f8c45f1a98b9979eb948c95a5202294680bdeb14", "content": "One can find various samples for key-value stores in the dedicated Spring Data example repo, at https://github.com/spring-projects/spring-data-examples/tree/main/redis[https://github.com/spring-projects/spring-data-examples/].\n\n[[requirements]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Trying out the Samples", "heading_level": 3, "file_order": 40, "section_index": 3, "content_hash": "6f8d94a67116e5004ba35809f8c45f1a98b9979eb948c95a5202294680bdeb14", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:479703095007dd46057b2221994cc47c40b02d37020a2e30787fb3ae607fc2f6", "content": "Spring Data Redis binaries require JDK level 17 and above and https://spring.io/projects/spring-framework/[Spring Framework] {springVersion} and above.\n\nIn terms of key-value stores, https://redis.io[Redis] 2.6.x or higher is required.\nSpring Data Redis is currently tested against the latest 6.0 release.\n\n[[get-started:help]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Requirements", "heading_level": 2, "file_order": 40, "section_index": 4, "content_hash": "479703095007dd46057b2221994cc47c40b02d37020a2e30787fb3ae607fc2f6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:c5e1be9b66706782b95c8d0d4dd602a1915ea94ffbc405d8794f4f9886b0ba27", "content": "Learning a new framework is not always straightforward.\nIn this section, we try to provide what we think is an easy-to-follow guide for starting with the Spring Data Redis module.\nHowever, if you encounter issues or you need advice, feel free to use one of the following links:\n\n[get-started:help:community]]\nCommunity Forum :: Spring Data on https://stackoverflow.com/questions/tagged/spring-data[Stack Overflow] is a tag for all Spring Data (not just Document) users to share information and help each other.\nNote that registration is needed only for posting.\n\n[[get-started:help:professional]]\nProfessional Support :: Professional, from-the-source support, with guaranteed response time, is available from https://pivotal.io/[Pivotal Sofware, Inc.], the company behind Spring Data and Spring.\n\n[[get-started:up-to-date]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Additional Help Resources", "heading_level": 2, "file_order": 40, "section_index": 5, "content_hash": "c5e1be9b66706782b95c8d0d4dd602a1915ea94ffbc405d8794f4f9886b0ba27", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:adde0347a7a217fd31acedee98fbd1c6cd6ed386cce2319fc22908bd5a05e7ac", "content": "For information on the Spring Data source code repository, nightly builds, and snapshot artifacts, see the Spring Data home https://spring.io/projects/spring-data/[page].\n\nYou can help make Spring Data best serve the needs of the Spring community by interacting with developers on Stack Overflow at either\nhttps://stackoverflow.com/questions/tagged/spring-data[spring-data] or https://stackoverflow.com/questions/tagged/spring-data-redis[spring-data-redis].\n\nIf you encounter a bug or want to suggest an improvement (including to this documentation), please create a ticket on https://github.com/spring-projects/spring-data-redis/issues/new[Github].\n\nTo stay up to date with the latest news and announcements in the Spring eco system, subscribe to the Spring Community https://spring.io/[Portal].\n\nLastly, you can follow the Spring https://spring.io/blog/[blog] or the project team (https://twitter.com/SpringData[@SpringData]) on Twitter.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Following Development", "heading_level": 2, "file_order": 40, "section_index": 6, "content_hash": "adde0347a7a217fd31acedee98fbd1c6cd6ed386cce2319fc22908bd5a05e7ac", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:2df275c2a623554d534d87608df036768af661f2017734e4929540077c67ba40", "content": "[[redis]]\n\nOne of the key-value stores supported by Spring Data is https://redis.io[Redis].\nTo quote the Redis project home page:\n\n[quote]\nRedis is an advanced key-value store.\nIt is similar to memcached but the dataset is not volatile, and values can be strings, exactly like in memcached, but also lists, sets, and ordered sets.\nAll this data types can be manipulated with atomic operations to push/pop elements, add/remove elements, perform server side union, intersection, difference between sets, and so forth.\nRedis supports different kind of sorting abilities.\n\nSpring Data Redis provides easy configuration and access to Redis from Spring applications.\nIt offers both low-level and high-level abstractions for interacting with the store, freeing the user from infrastructural concerns.\n\nSpring Data support for Redis contains a wide range of features:\n\n* xref:redis/template.adoc[`RedisTemplate` and `ReactiveRedisTemplate` helper class] that increases productivity when performing common Redis operations.\nIncludes integrated serialization between objects and values.\n* Exception translation into Spring's portable Data Access Exception hierarchy.\n* Automatic implementation of xref:repositories.adoc[Repository interfaces], including support for custom query methods.\n* Feature-rich xref:redis/redis-repositories/mapping.adoc[Object Mapping] integrated with Spring's Conversion Service.\n* Annotation-based mapping metadata that is extensible to support other metadata formats.\n* xref:redis/transactions.adoc[Transactions] and xref:redis/pipelining.adoc[Pipelining].\n* xref:redis/redis-cache.adoc[Redis Cache] integration through Spring's Cache abstraction.\n* xref:redis/pubsub.adoc[Redis Pub/Sub Messaging] and xref:redis/redis-streams.adoc[Redis Stream] Listeners.\n* xref:redis/support-classes.adoc[Redis Collection Implementations] for Java such as `RedisList` or `RedisSet`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis.adoc", "title": "redis", "heading": "redis", "heading_level": 1, "file_order": 41, "section_index": 0, "content_hash": "2df275c2a623554d534d87608df036768af661f2017734e4929540077c67ba40", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis.adoc"}}
{"id": "sha256:9e031ac3b60ddbc8e779c3cecc3686325cc7e3476b99f5de8b92c5b020782285", "content": "The Spring Framework is the leading full-stack Java/JEE application framework.\nIt provides a lightweight container and a non-invasive programming model enabled by the use of dependency injection, AOP, and portable service abstractions.\n\nhttps://en.wikipedia.org/wiki/NoSQL[NoSQL] storage systems provide an alternative to classical RDBMS for horizontal scalability and speed.\nIn terms of implementation, key-value stores represent one of the largest (and oldest) members in the NoSQL space.\n\nThe Spring Data Redis (SDR) framework makes it easy to write Spring applications that use the Redis key-value store by eliminating the redundant tasks and boilerplate code required for interacting with the store through Spring's excellent infrastructure support.\n\n[[redis:architecture]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis.adoc", "title": "redis", "heading": "Why Spring Data Redis?", "heading_level": 2, "file_order": 41, "section_index": 1, "content_hash": "9e031ac3b60ddbc8e779c3cecc3686325cc7e3476b99f5de8b92c5b020782285", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis.adoc"}}
{"id": "sha256:751911f992eb700683f05d4e4226d57f9bccad7fba0be81656097659c33c8363", "content": "The Redis support provides several components.For most tasks, the high-level abstractions and support services are the best choice.Note that, at any point, you can move between layers.For example, you can get a low-level connection (or even the native library) to communicate directly with Redis.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/redis.adoc", "title": "redis", "heading": "Redis Support High-level View", "heading_level": 2, "file_order": 41, "section_index": 2, "content_hash": "751911f992eb700683f05d4e4226d57f9bccad7fba0be81656097659c33c8363", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/redis.adoc"}}
{"id": "sha256:c683535243b0f66f7e7ac5e0580abf0792b63711d7ed92e8633b59fe7dd47201", "content": "[[redis.repositories]]\n\nThis chapter explains the basic foundations of Spring Data repositories and Redis specifics.\nBefore continuing to the Redis specifics, make sure you have a sound understanding of the basic concepts.\n\nThe goal of the Spring Data repository abstraction is to significantly reduce the amount of boilerplate code required to implement data access layers for various persistence stores.\n\nWorking with Redis Repositories lets you seamlessly convert and store domain objects in Redis Hashes, apply custom mapping strategies, and use secondary indexes.\n\nIMPORTANT: Redis Repositories require at least Redis Server version 2.8.0 and do not work with transactions.\nMake sure to use a `RedisTemplate` with xref:redis/transactions.adoc#tx.spring[disabled transaction support].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/repositories.adoc", "title": "repositories", "heading": "repositories", "heading_level": 1, "file_order": 42, "section_index": 0, "content_hash": "c683535243b0f66f7e7ac5e0580abf0792b63711d7ed92e8633b59fe7dd47201", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/repositories.adoc"}}
{"id": "sha256:ece916769b4b35542315833589561e338269c87857abd6bb9709d1429c578801", "content": "[[redis.upgrading]]\n\nThis section contains details about migration steps, deprecations, and removals.\n\n[[upgrading.2-to-3]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "upgrading", "heading_level": 1, "file_order": 43, "section_index": 0, "content_hash": "ece916769b4b35542315833589561e338269c87857abd6bb9709d1429c578801", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:20f1f864dc84cf3bf048695fbfa807069d51eeda661737c0cd73a1a6a814422a", "content": "[[upgrading.2-to-3.types]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Upgrading from 2.x to 3.x", "heading_level": 2, "file_order": 43, "section_index": 1, "content_hash": "20f1f864dc84cf3bf048695fbfa807069d51eeda661737c0cd73a1a6a814422a", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:69d97564f28bfd5445980aa8740ccea6facdb34ebcc4e05bb9ed0b7b9c7c59a5", "content": "|===\n|Type |Replacement\n\n|o.s.d.redis.Version\n|o.s.d.util.Version\n\n|o.s.d.redis.VersionParser\n|-\n\n|o.s.d.redis.connection.RedisZSetCommands.Aggregate\n|o.s.d.redis.connection.zset.Aggregate\n\n|o.s.d.redis.connection.RedisZSetCommands.Tuple\n|o.s.d.redis.connection.zset.Tuple\n\n|o.s.d.redis.connection.RedisZSetCommands.Weights\n|o.s.d.redis.connection.zset.Weights\n\n|o.s.d.redis.connection.RedisZSetCommands.Range\n|o.s.d.domain.Range\n\n|o.s.d.redis.connection.RedisZSetCommands.Limit\n|o.s.d.redis.connection.Limit.java\n\n|o.s.d.redis.connection.jedis.JedisUtils\n|-\n\n|o.s.d.redis.connection.jedis.JedisVersionUtil\n|-\n\n|o.s.d.redis.core.convert.CustomConversions\n|o.s.d.convert.CustomConversions\n\n|===\n\n[[changed-methods-and-types]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Re-/moved Types", "heading_level": 3, "file_order": 43, "section_index": 2, "content_hash": "69d97564f28bfd5445980aa8740ccea6facdb34ebcc4e05bb9ed0b7b9c7c59a5", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:a0235b07f964cf05ee87335204cfc22539c96e45df5f01407c1292bb6522438c", "content": ".Core\n|===\n|Type |Method |Replacement\n\n|o.s.d.redis.core.Cursor\n|open\n|-\n\n|o.s.d.redis.core.RedisTemplate\n|execute\n|doWithKeys\n\n|o.s.d.redis.stream.StreamMessageListenerContainer\n|isAutoAck\n|isAutoAcknowledge\n\n|o.s.d.redis.stream.StreamMessageListenerContainer\n|autoAck\n|autoAcknowledge\n\n|===\n\n.Redis Connection\n|===\n|Type |Method |Replacement\n\n|o.s.d.redis.connection.ClusterCommandExecutionFailureException\n|getCauses\n|getSuppressed\n\n|o.s.d.redis.connection.RedisConnection\n|bgWriteAof\n|bgReWriteAof\n\n|o.s.d.redis.connection.RedisConnection\n|slaveOf\n|replicaOf\n\n|o.s.d.redis.connection.RedisConnection\n|slaveOfNoOne\n|replicaOfNoOne\n\n|o.s.d.redis.connection.ReactiveClusterCommands\n|clusterGetSlaves\n|clusterGetReplicas\n\n|o.s.d.redis.connection.ReactiveClusterCommands\n|clusterGetMasterSlaveMap\n|clusterGetMasterReplicaMap\n\n|o.s.d.redis.connection.ReactiveKeyCommands\n|getNewName\n|getNewKey\n\n|o.s.d.redis.connection.RedisClusterNode.Flag\n|SLAVE\n|REPLICA\n\n|o.s.d.redis.connection.RedisClusterNode.Builder\n|slaveOf\n|replicaOf\n\n|o.s.d.redis.connection.RedisNode\n|isSlave\n|isReplica\n\n|o.s.d.redis.connection.RedisSentinelCommands\n|slaves\n|replicas\n\n|o.s.d.redis.connection.RedisServer\n|getNumberSlaves\n|getNumberReplicas\n\n|o.s.d.redis.connection.RedisServerCommands\n|slaveOf\n|replicaOf\n\n|o.s.d.redis.core.ClusterOperations\n|getSlaves\n|getReplicas\n\n|o.s.d.redis.core.RedisOperations\n|slaveOf\n|replicaOf\n\n|===\n\n.Redis Operations\n|===\n|Type |Method |Replacement\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoAdd\n|add\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoDist\n|distance\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoHash\n|hash\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoPos\n|position\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoRadius\n|radius\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoRadiusByMember\n|radius\n\n|o.s.d.redis.core.GeoOperations & BoundGeoOperations\n|geoRemove\n|remove\n\n|===\n\n.Redis Cache\n|===\n|Type |Method |Replacement\n\n|o.s.d.redis.cache.RedisCacheConfiguration\n|prefixKeysWith\n|prefixCacheNameWith\n\n|o.s.d.redis.cache.RedisCacheConfiguration\n|getKeyPrefix\n|getKeyPrefixFor\n\n|===\n\n[[upgrading.2-to-3.jedis]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Changed Methods and Types", "heading_level": 3, "file_order": 43, "section_index": 3, "content_hash": "a0235b07f964cf05ee87335204cfc22539c96e45df5f01407c1292bb6522438c", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:fb07ac67c7ca25b844ce5acce06a5e7de0ca2fae60f8605c32fdbb5477f6d4f2", "content": "Please read the Jedis https://github.com/redis/jedis/blob/v4.0.0/docs/3to4.md[upgrading guide] which covers important driver changes.\n\n.Jedis Redis Connection\n|===\n|Type |Method |Replacement\n\n|o.s.d.redis.connection.jedis.JedisConnectionFactory\n|getShardInfo\n|_can be obtained via JedisClientConfiguration_\n\n|o.s.d.redis.connection.jedis.JedisConnectionFactory\n|setShardInfo\n|_can be set via JedisClientConfiguration_\n\n|o.s.d.redis.connection.jedis.JedisConnectionFactory\n|createCluster\n|_now requires a `Connection` instead of `Jedis` instance_\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|\n|has package visibility now\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|tuplesToTuples\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|tuplesToTuples\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|stringListToByteList\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|stringSetToByteSet\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|stringMapToByteMap\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|tupleSetToTupleSet\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|toTupleSet\n|-\n\n|o.s.d.redis.connection.jedis.JedisConverters\n|toDataAccessException\n|o.s.d.redis.connection.jedis.JedisExceptionConverter#convert\n\n|===\n\n[[upgrading.2-to-3.jedis.transactions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Jedis", "heading_level": 3, "file_order": 43, "section_index": 4, "content_hash": "fb07ac67c7ca25b844ce5acce06a5e7de0ca2fae60f8605c32fdbb5477f6d4f2", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:daeb7236343664f26786a0b35f01dbf15d4c777a67b6701df44f3e0d0a0c1e1b", "content": "Pipelining and Transactions are now mutually exclusive.\nThe usage of server or connection commands in pipeline/transactions mode is no longer possible.\n\n[[upgrading.2-to-3.lettuce]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Transactions / Pipelining", "heading_level": 3, "file_order": 43, "section_index": 5, "content_hash": "daeb7236343664f26786a0b35f01dbf15d4c777a67b6701df44f3e0d0a0c1e1b", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:a92a8eaee37c0608e9ec9709d421a02cfb4fac38c072bc1b8df73d90df9ae098", "content": "[[upgrading.2-to-3.lettuce.pool]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Lettuce", "heading_level": 3, "file_order": 43, "section_index": 6, "content_hash": "a92a8eaee37c0608e9ec9709d421a02cfb4fac38c072bc1b8df73d90df9ae098", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:73026e6a74a44b8c9d4fef5eb67bc82c479d2690178ca8aedbe62217a0565691", "content": "`LettucePool` and its implementation `DefaultLettucePool` have been removed without replacement.\nPlease refer to the https://lettuce.io/core/release/reference/index.html#_connection_pooling[driver documentation] for driver native pooling capabilities.\nMethods accepting pooling parameters have been updated.\nThis effects methods on `LettuceConnectionFactory` and `LettuceConnection`.\n\n[[upgrading.2-to-3.lettuce.authentication]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Lettuce Pool", "heading_level": 4, "file_order": 43, "section_index": 7, "content_hash": "73026e6a74a44b8c9d4fef5eb67bc82c479d2690178ca8aedbe62217a0565691", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
{"id": "sha256:3dd267583dbd64b37ff4485ccdac4c9c048a5d6778b5e7bf067e7179000aa5b6", "content": "`AuthenticatingRedisClient` has been removed without replacement.\nPlease refer to the https://lettuce.io/core/release/reference/index.html#basic.redisuri[driver documentation] for `RedisURI` to set authentication data.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-redis", "path": "antora/modules/ROOT/pages/upgrading.adoc", "title": "upgrading", "heading": "Lettuce Authentication", "heading_level": 4, "file_order": 43, "section_index": 8, "content_hash": "3dd267583dbd64b37ff4485ccdac4c9c048a5d6778b5e7bf067e7179000aa5b6", "source_url": "https://github.com/spring-projects/spring-data-redis/blob/65a88f564fc96a242b1043f15ce249ab2ed0975f/src/main/antora/modules/ROOT/pages/upgrading.adoc"}}
