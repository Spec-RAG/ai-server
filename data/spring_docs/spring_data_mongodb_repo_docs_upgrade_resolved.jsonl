{"id": "sha256:43cbd2549100ed63938f23081eadc0002eee8b9c544f083a434936d68ae31979", "content": "include::{commons}@data-commons::page$upgrade.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/commons/upgrade.adoc", "title": "upgrade", "heading": "upgrade", "heading_level": 1, "file_order": 0, "section_index": 0, "content_hash": "43cbd2549100ed63938f23081eadc0002eee8b9c544f083a434936d68ae31979", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/commons/upgrade.adoc"}}
{"id": "sha256:ba1405904aaa6e2349ad66b674e67a026aa319dafffb49414d028c62bf5eb0a3", "content": "include::{commons}@data-commons::page$kotlin/coroutines.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/coroutines.adoc", "title": "coroutines", "heading": "coroutines", "heading_level": 1, "file_order": 1, "section_index": 0, "content_hash": "ba1405904aaa6e2349ad66b674e67a026aa319dafffb49414d028c62bf5eb0a3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/coroutines.adoc"}}
{"id": "sha256:4a8c44cb5fb8c2a38f5342187ad15a43c88d7548dea8de6eaa8e2b77bb3aed82", "content": "include::{commons}@data-commons::page$kotlin/extensions.adoc[]\n\nTo retrieve a list of `SWCharacter` objects in Java, you would normally write the following:\n\n[source,java]\n----\nFlux<SWCharacter> characters = template.query(SWCharacter.class).inTable(\"star-wars\").all()\n----\n\nWith Kotlin and the Spring Data extensions, you can instead write the following:\n\n[source,kotlin]\n----\nval characters = template.query<SWCharacter>().inTable(\"star-wars\").all()\nval characters : Flux<SWCharacter> = template.query().inTable(\"star-wars\").all()\n----\n\nAs in Java, `characters` in Kotlin is strongly typed, but Kotlin's clever type inference allows for shorter syntax.\n\n[[mongo.query.kotlin-support]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/extensions.adoc", "title": "extensions", "heading": "extensions", "heading_level": 1, "file_order": 2, "section_index": 0, "content_hash": "4a8c44cb5fb8c2a38f5342187ad15a43c88d7548dea8de6eaa8e2b77bb3aed82", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/extensions.adoc"}}
{"id": "sha256:47c63ceccef5ed675f9618777d5aae255e5e9aaae137e51fe6621ffc3d63b743", "content": "Kotlin embraces domain-specific language creation through its language syntax and its extension system.\nSpring Data MongoDB ships with a Kotlin Extension for `Criteria` using https://kotlinlang.org/docs/reference/reflection.html#property-references[Kotlin property references] to build type-safe queries.\nQueries using this extension are typically benefit from improved readability.\nMost keywords on `Criteria` have a matching Kotlin extension, such as `inValues` and `regex`.\n\nConsider the following example explaining Type-safe Queries:\n\n====\n[source,kotlin]\n----\nimport org.springframework.data.mongodb.core.query.*\n\nmongoOperations.find<Book>(\n Query(Book::title isEqualTo \"Moby-Dick\") <1>\n)\n\nmongoOperations.find<Book>(\n Query(titlePredicate = Book::title exists true)\n)\n\nmongoOperations.find<Book>(\n Query(\n Criteria().andOperator(\n Book::price gt 5,\n Book::price lt 10\n ))\n)\n\nmongoOperations.find<BinaryMessage>(\n Query(BinaryMessage::payload bits { allClear(0b101) }) <2>\n)\n\nmongoOperations.find<Book>(\n Query(Book::author / Author::name regex \"^H\") <3>\n)\n----\n<1> `isEqualTo()` is an infix extension function with receiver type `KProperty<T>` that returns `Criteria`.\n<2> For bitwise operators, pass a lambda argument where you call one of the methods of `Criteria.BitwiseCriteriaOperators`.\n<3> To construct nested properties, use the `/` character (overloaded operator `div`).\n====\n\n[[mongo.update.kotlin-support]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/extensions.adoc", "title": "extensions", "heading": "Type-safe Queries for Kotlin", "heading_level": 2, "file_order": 2, "section_index": 1, "content_hash": "47c63ceccef5ed675f9618777d5aae255e5e9aaae137e51fe6621ffc3d63b743", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/extensions.adoc"}}
{"id": "sha256:d36fd0533ab84bcd5149145d649f76d221d4dc580cc1a407b19cc62e16d13355", "content": "A syntax similar to <<mongo.query.kotlin-support>> can be used to update documents:\n\n====\n[source,kotlin]\n----\nmongoOperations.updateMulti<Book>(\n Query(Book::title isEqualTo \"Moby-Dick\"),\n update(Book:title, \"The Whale\") <1>\n .inc(Book::price, 100) <2>\n .addToSet(Book::authors, \"Herman Melville\") <3>\n)\n----\n<1> `update()` is a factory function with receiver type `KProperty<T>` that returns `Update`.\n<2> Most methods from `Update` have a matching Kotlin extension.\n<3> Functions with `KProperty<T>` can be used as well on collections types\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/extensions.adoc", "title": "extensions", "heading": "Type-safe Updates for Kotlin", "heading_level": 2, "file_order": 2, "section_index": 2, "content_hash": "d36fd0533ab84bcd5149145d649f76d221d4dc580cc1a407b19cc62e16d13355", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/extensions.adoc"}}
{"id": "sha256:3890a18a8bd49eea65aed311989780538fe511ebfca5d4bdb8d8e0d6aff12dcf", "content": "include::{commons}@data-commons::page$kotlin/null-safety.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/null-safety.adoc", "title": "null-safety", "heading": "null-safety", "heading_level": 1, "file_order": 3, "section_index": 0, "content_hash": "3890a18a8bd49eea65aed311989780538fe511ebfca5d4bdb8d8e0d6aff12dcf", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/null-safety.adoc"}}
{"id": "sha256:1f6afc6d72333158d4bf66d1cf63e174d0e4613324cf34acbcec5e53ea8d8b24", "content": "include::{commons}@data-commons::page$kotlin/requirements.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin/requirements.adoc", "title": "requirements", "heading": "requirements", "heading_level": 1, "file_order": 4, "section_index": 0, "content_hash": "1f6afc6d72333158d4bf66d1cf63e174d0e4613324cf34acbcec5e53ea8d8b24", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin/requirements.adoc"}}
{"id": "sha256:1cd132fe897a0b4bf5ee0fac76f64626dfe88a7752004f6ddc65227fcfd6be53", "content": "[[mongodb.migration.2.x-3.x]]\n\nSpring Data MongoDB 3.x requires the MongoDB Java Driver 4.x +\nTo learn more about driver versions please visit the https://www.mongodb.com/docs/drivers/java/sync/current/upgrade/[MongoDB Documentation].\n\n[[dependency-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc", "title": "migration-guide-2.x-to-3.x", "heading": "migration-guide-2.x-to-3.x", "heading_level": 1, "file_order": 5, "section_index": 0, "content_hash": "1cd132fe897a0b4bf5ee0fac76f64626dfe88a7752004f6ddc65227fcfd6be53", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc"}}
{"id": "sha256:1e702487c6b482f7205805360024438421754bdf2e13303608c9a004f1f0191a", "content": "* `org.mongodb:mongo-java-driver` (uber jar) got replaced with:\n** bson-jar\n** core-jar\n** sync-jar\n\nThe change in dependencies allows usage of the reactive support without having to pull the synchronous driver.\nNOTE: The new sync driver does no longer support `com.mongodb.DBObject`. Please use `org.bson.Document` instead.\n\n[[signature-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc", "title": "migration-guide-2.x-to-3.x", "heading": "Dependency Changes", "heading_level": 2, "file_order": 5, "section_index": 1, "content_hash": "1e702487c6b482f7205805360024438421754bdf2e13303608c9a004f1f0191a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc"}}
{"id": "sha256:1872eadaa7abc02f119c28ba7f73c24dd3f83798a5b1c4729e753ceb2e2459a9", "content": "* `MongoTemplate` no longer supports `com.mongodb.MongoClient` and `com.mongodb.MongoClientOptions`.\nPlease use `com.mongodb.client.MongoClient` and `com.mongodb.MongoClientSettings` instead.\n\nIn case you're using `AbstractMongoConfiguration` please switch to `AbstractMongoClientConfiguration`.\n\n[[namespace-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc", "title": "migration-guide-2.x-to-3.x", "heading": "Signature Changes", "heading_level": 2, "file_order": 5, "section_index": 2, "content_hash": "1872eadaa7abc02f119c28ba7f73c24dd3f83798a5b1c4729e753ceb2e2459a9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc"}}
{"id": "sha256:f6face6f68a2d2580de41b1b2fc7dbb5c61eb63f2e3b29302529cb26a5317d86", "content": "The switch to `com.mongodb.client.MongoClient` requires an update of your configuration XML if you have one.\nThe best way to provide required connection information is by using a connection string.\nPlease see the https://docs.mongodb.com/manual/reference/connection-string/[MongoDB Documentation] for details.\n\n====\n[source,xml]\n----\n<mongo:mongo.mongo-client id=\"with-defaults\" />\n----\n\n[source,xml]\n----\n<context:property-placeholder location=\"classpath:...\"/>\n\n<mongo:mongo.mongo-client id=\"client-just-host-port\"\n host=\"${mongo.host}\" port=\"${mongo.port}\" />\n\n<mongo:mongo.mongo-client id=\"client-using-connection-string\"\n connection-string=\"mongodb://${mongo.host}:${mongo.port}/?replicaSet=rs0\" />\n----\n\n[source,xml]\n----\n<mongo:mongo.mongo-client id=\"client-with-settings\" replica-set=\"rs0\">\n <mongo:client-settings cluster-connection-mode=\"MULTIPLE\"\n cluster-type=\"REPLICA_SET\"\n cluster-server-selection-timeout=\"300\"\n cluster-local-threshold=\"100\"\n cluster-hosts=\"localhost:27018,localhost:27019,localhost:27020\" />\n\t</mongo:mongo.mongo-client>\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc", "title": "migration-guide-2.x-to-3.x", "heading": "Namespace Changes", "heading_level": 2, "file_order": 5, "section_index": 3, "content_hash": "f6face6f68a2d2580de41b1b2fc7dbb5c61eb63f2e3b29302529cb26a5317d86", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-2.x-to-3.x.adoc"}}
{"id": "sha256:2141ae51b26358d005dcbc22c9fd7f344cf15fff1ff92c50385a24db8b3365ef", "content": "[[mongodb.migration.3.x-4.x]]\n\nSpring Data MongoDB 4.x requires the MongoDB Java Driver 4.8.x +\nTo learn more about driver versions please visit the https://www.mongodb.com/docs/drivers/java/sync/current/upgrade/[MongoDB Documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-3.x-to-4.x.adoc", "title": "migration-guide-3.x-to-4.x", "heading": "migration-guide-3.x-to-4.x", "heading_level": 1, "file_order": 6, "section_index": 0, "content_hash": "2141ae51b26358d005dcbc22c9fd7f344cf15fff1ff92c50385a24db8b3365ef", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-3.x-to-4.x.adoc"}}
{"id": "sha256:a74c1d2cd403f3ebd23d1f605f9f48f4c05bd7d6577ab2ff1b5d7f59fd1f1655", "content": "[[mongodb.migration.4.x-5.x]]\n\nSpring Data MongoDB 5.x requires the MongoDB Java Driver 5.6+ +\nTo learn more about driver versions please visit the https://www.mongodb.com/docs/drivers/java/sync/current/upgrade/[MongoDB Documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "migration-guide-4.x-to-5.x", "heading_level": 1, "file_order": 7, "section_index": 0, "content_hash": "a74c1d2cd403f3ebd23d1f605f9f48f4c05bd7d6577ab2ff1b5d7f59fd1f1655", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:f0c1b7085d69748a969bb10e0d2de543ef1ab39a8696fc10b41e618268c89900", "content": "Spring Data MongoDB does no longer support the 4.x MongoDB Java Driver generation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "MongoDB Java Driver 4.x Driver Compatibility Removed", "heading_level": 2, "file_order": 7, "section_index": 1, "content_hash": "f0c1b7085d69748a969bb10e0d2de543ef1ab39a8696fc10b41e618268c89900", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:f6148fbe544ac0820c62a3f4e1ff33fce0ccfa2bd349552dfaa9a53d74105dfb", "content": "Spring Data no longer defaults UUID settings via its configuration support classes, factory beans, nor XML namespace. +\nIn order to persist UUID values the `UuidRepresentation` hast to be set explicitly.\n\n[tabs]\n======\nJava::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\nstatic class Config extends AbstractMongoClientConfiguration {\n\n\t@Override\n\tprotected void configureClientSettings(MongoClientSettings.Builder builder) {\n builder.uuidRepresentation(UuidRepresentation.STANDARD);\n\t}\n\n // ...\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<mongo:mongo-client>\n\t<mongo:client-settings uuid-representation=\"STANDARD\"/>\n</mongo:mongo-client>\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "UUID Representation Changes", "heading_level": 2, "file_order": 7, "section_index": 2, "content_hash": "f6148fbe544ac0820c62a3f4e1ff33fce0ccfa2bd349552dfaa9a53d74105dfb", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:8f39d9cf998eccb7df6fd761e5fb8622e6594455c743681569d2f5f56a7eb442", "content": "Spring Data no longer defaults BigInteger/BigDecimal conversion via its configuration support classes.\nIn order to persist those values the default `BigDecimalRepresentation` hast to be set explicitly.\n\n[source,java]\n----\n@Configuration\nstatic class Config extends AbstractMongoClientConfiguration {\n\n\t@Override\n\tprotected void configureConverters(MongoConverterConfigurationAdapter configAdapter) {\n configAdapter.bigDecimal(BigDecimalRepresentation.DECIMAL128);\n\t}\n\n // ...\n}\n----\n\nUsers upgrading from prior versions may choose `BigDecimalRepresentation.STRING` as default to retain previous behaviour.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "BigInteger/BigDecimal Conversion Changes", "heading_level": 2, "file_order": 7, "section_index": 3, "content_hash": "8f39d9cf998eccb7df6fd761e5fb8622e6594455c743681569d2f5f56a7eb442", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:dde9464dcad517f847780d7214ba429fc16c43e3a6efc75ffd3f51ebde6e46f7", "content": "The `DefaultMessageListenerContainer` that can be used to listen to e.g. _Change Streams_ now defaults its `SmartLifecycle` auto startup to `true`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "DefaultMessageListenerContainer auto startup", "heading_level": 2, "file_order": 7, "section_index": 4, "content_hash": "dde9464dcad517f847780d7214ba429fc16c43e3a6efc75ffd3f51ebde6e46f7", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:431ead2967011eb9451893aae4a0007a0f5ea5b28b642cbca44293a46349279b", "content": "We recommend switching to Spring Boot https://docs.spring.io/spring-boot/reference/actuator/endpoints.html[Actuator Endpoints].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc", "title": "migration-guide-4.x-to-5.x", "heading": "JMX Support Discontinued.", "heading_level": 2, "file_order": 7, "section_index": 5, "content_hash": "431ead2967011eb9451893aae4a0007a0f5ea5b28b642cbca44293a46349279b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guide/migration-guide-4.x-to-5.x.adoc"}}
{"id": "sha256:095fd3fcb341652338f9cdc05bd0d3344e8c7d48d026e633b40e52105769e55f", "content": "include::{commons}@data-commons::page$custom-conversions.adoc[]\n\n[[mongo.custom-converters]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "custom-conversions", "heading_level": 1, "file_order": 8, "section_index": 0, "content_hash": "095fd3fcb341652338f9cdc05bd0d3344e8c7d48d026e633b40e52105769e55f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:95255b7b690f8986bda37bd516e4046ff28496d34cacad0d24037e830e87ea8d", "content": "The most trivial way of influencing the mapping result is by specifying the desired native MongoDB target type via the `@Field` annotation.\nThis allows to work with non MongoDB types like `BigDecimal` in the domain model while persisting values in eg. `String` format.\n\n.Explicit target type mapping\n====\n[source,java]\n----\npublic class Payment {\n\n @Id String id; <1>\n\n @Field(targetType = FieldType.STRING) <2>\n BigDecimal value;\n\n Date date; <3>\n\n}\n----\n\n[source,java]\n----\n{\n \"_id\" : ObjectId(\"5ca4a34fa264a01503b36af8\"), <1>\n \"value\" : \"2.099\", <2>\n \"date\" : ISODate(\"2019-04-03T12:11:01.870Z\") <3>\n}\n----\n<1> String _id_ values that represent a valid `ObjectId` are converted automatically. See xref:mongodb/template-crud-operations.adoc#mongo-template.id-handling[How the `_id` Field is Handled in the Mapping Layer]\nfor details.\n<2> The desired target type is explicitly defined as `String`.\nOtherwise.\n<3> `Date` values are handled by the MongoDB driver itself are stored as `ISODate`.\n====\n\nThe snippet above is handy for providing simple type hints. To gain more fine-grained control over the mapping process,\n you can register Spring converters with the `MongoConverter` implementations, such as the `MappingMongoConverter`.\n\nThe `MappingMongoConverter` checks to see if any Spring converters can handle a specific class before attempting to map the object itself. To 'hijack' the normal mapping strategies of the `MappingMongoConverter`, perhaps for increased performance or other custom mapping needs, you first need to create an implementation of the Spring `Converter` interface and then register it with the `MappingConverter`.\n\nNOTE: For more information on the Spring type conversion service, see the reference docs link:{springDocsUrl}/core.html#validation[here].\n\n[[mongo.custom-converters.writer]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "Type based Converter", "heading_level": 2, "file_order": 8, "section_index": 1, "content_hash": "95255b7b690f8986bda37bd516e4046ff28496d34cacad0d24037e830e87ea8d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:c99906d50fc0924a5663cfa51f0873fd5957d2595b8be14cf6d6fb583eef19cc", "content": "The following example shows an implementation of the `Converter` that converts from a `Person` object to a `org.bson.Document`:\n\n[source,java]\n----\nimport org.springframework.core.convert.converter.Converter;\n\nimport org.bson.Document;\n\npublic class PersonWriteConverter implements Converter<Person, Document> {\n\n public Document convert(Person source) {\n Document document = new Document();\n document.put(\"_id\", source.getId());\n document.put(\"name\", source.getFirstName());\n document.put(\"age\", source.getAge());\n return document;\n }\n}\n----\n\n[[mongo.custom-converters.reader]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "Writing Converter", "heading_level": 3, "file_order": 8, "section_index": 2, "content_hash": "c99906d50fc0924a5663cfa51f0873fd5957d2595b8be14cf6d6fb583eef19cc", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:093175d0b7361b379befead38419fdc6ce26acf905dc9ab2018dbe5bd24e8027", "content": "The following example shows an implementation of a `Converter` that converts from a `Document` to a `Person` object:\n\n[source,java]\n----\npublic class PersonReadConverter implements Converter<Document, Person> {\n\n public Person convert(Document source) {\n Person p = new Person((ObjectId) source.get(\"_id\"), (String) source.get(\"name\"));\n p.setAge((Integer) source.get(\"age\"));\n return p;\n }\n}\n----\n\n[[mongo.custom-converters.xml]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "Reading Converter", "heading_level": 3, "file_order": 8, "section_index": 3, "content_hash": "093175d0b7361b379befead38419fdc6ce26acf905dc9ab2018dbe5bd24e8027", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:a4572e82938b213817599f5436e1e235714827329001b7cd87de3006d60e5faa", "content": "[source,java]\n----\nclass MyMongoConfiguration extends AbstractMongoClientConfiguration {\n\n\t@Override\n\tpublic String getDatabaseName() {\n return \"database\";\n\t}\n\n\t@Override\n\tprotected void configureConverters(MongoConverterConfigurationAdapter adapter) {\n adapter.registerConverter(new com.example.PersonReadConverter());\n adapter.registerConverter(new com.example.PersonWriteConverter());\n\t}\n}\n----\n\n[[mongo.numeric-conversion]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "Registering Converters", "heading_level": 3, "file_order": 8, "section_index": 4, "content_hash": "a4572e82938b213817599f5436e1e235714827329001b7cd87de3006d60e5faa", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:3122de21f988bc863de558d45b48be7dc33afb72238e86a8f630ac00498ca12f", "content": "MongoDB in its early days did not have support for large numeric values such as `BigDecimal`.\nTo persist `BigDecimal` and `BigInteger` values, Spring Data MongoDB converted values their `String` representation.\nThis approach had several downsides due to lexical instead of numeric comparison for queries, updates, etc.\n\nWith MongoDB Server 3.4, `org.bson.types.Decimal128` offers a native representation for `BigDecimal` and `BigInteger`.\nAs of Spring Data MongoDB 5.0. there no longer is a default representation of those types and conversion needs to be configured explicitly.\nYou can register multiple formats, 1st being default, and still retain the previous behaviour by configuring the `BigDecimalRepresentation` in `MongoCustomConversions` through `MongoCustomConversions.create(config -> config.bigDecimal(BigDecimalRepresentation.STRING, BigDecimalRepresentation.DECIMAL128))`.\nThis allows you to make use of the explicit storage type format via `@Field(targetType = DECIMAL128)` while keeping default conversion set to String.\nChoosing none of the provided representations is valid as long as those values are no persisted.\n\n[NOTE]\n====\nVery large values, though being a valid `BigDecimal` or `BigInteger`, might exceed the maximum bit length of `org.bson.types.Decimal128` in their store native representation.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc", "title": "custom-conversions", "heading": "Big Number Format", "heading_level": 2, "file_order": 8, "section_index": 5, "content_hash": "3122de21f988bc863de558d45b48be7dc33afb72238e86a8f630ac00498ca12f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/custom-conversions.adoc"}}
{"id": "sha256:6d421b6720a9f0192128f209a942bfc1e72ae72fc27d8b8cbfacd2325cc5b6f8", "content": "[[mapping-usage-references]]\n\nThe mapping framework does not have to store child objects embedded within the document.\nYou can also store them separately and use a `DBRef` to refer to that document.\nWhen the object is loaded from MongoDB, those references are eagerly resolved so that you get back a mapped object that looks the same as if it had been stored embedded within your top-level document.\n\nThe following example uses a DBRef to refer to a specific document that exists independently of the object in which it is referenced (both classes are shown in-line for brevity's sake):\n\n====\n[source,java]\n----\n@Document\npublic class Account {\n\n @Id\n private ObjectId id;\n private Float total;\n}\n\n@Document\npublic class Person {\n\n @Id\n private ObjectId id;\n @Indexed\n private Integer ssn;\n @DBRef\n private List<Account> accounts;\n}\n----\n====\n\nYou need not use `@OneToMany` or similar mechanisms because the List of objects tells the mapping framework that you want a one-to-many relationship.\nWhen the object is stored in MongoDB, there is a list of DBRefs rather than the `Account` objects themselves.\nWhen it comes to loading collections of ``DBRef``s it is advisable to restrict references held in collection types to a specific MongoDB collection.\nThis allows bulk loading of all references, whereas references pointing to different MongoDB collections need to be resolved one by one.\n\nIMPORTANT: The mapping framework does not handle cascading saves.\nIf you change an `Account` object that is referenced by a `Person` object, you must save the `Account` object separately.\nCalling `save` on the `Person` object does not automatically save the `Account` objects in the `accounts` property.\n\n``DBRef``s can also be resolved lazily.\nIn this case the actual `Object` or `Collection` of references is resolved on first access of the property.\nUse the `lazy` attribute of `@DBRef` to specify this.\nRequired properties that are also defined as lazy loading ``DBRef`` and used as constructor arguments are also decorated with the lazy loading proxy making sure to put as little pressure on the database and network as possible.\n\nTIP: Lazily loaded ``DBRef``s can be hard to debug.\nMake sure tooling does not accidentally trigger proxy resolution by e.g. calling `toString()` or some inline debug rendering invoking property getters.\nPlease consider to enable _trace_ logging for `org.springframework.data.mongodb.core.convert.DefaultDbRefResolver` to gain insight on `DBRef` resolution. +\nThough technically possible, avoid saving back individual lazily loaded entities obtained via properties of the referencing root.\n\nCAUTION: Lazy loading may require class proxies, that in turn, might need access to jdk internals, that are not open, starting with Java 16+, due to https://openjdk.java.net/jeps/396[JEP 396: Strongly Encapsulate JDK Internals by Default].\nFor those cases please consider falling back to an interface type (eg. switch from `ArrayList` to `List`) or provide the required `--add-opens` argument. +\n\n[[mapping-usage.document-references]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/document-references.adoc", "title": "document-references", "heading": "document-references", "heading_level": 1, "file_order": 9, "section_index": 0, "content_hash": "6d421b6720a9f0192128f209a942bfc1e72ae72fc27d8b8cbfacd2325cc5b6f8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/document-references.adoc"}}
{"id": "sha256:0bfd74789b2310dcf4050dacea7f292d7d7d97447a3d304104b78e3c45763e1e", "content": "Using `@DocumentReference` offers a flexible way of referencing entities in MongoDB.\nWhile the goal is the same as when using xref:mongodb/mapping/document-references.adoc[DBRefs], the store representation is different.\n`DBRef` resolves to a document with a fixed structure as outlined in the https://docs.mongodb.com/manual/reference/database-references/[MongoDB Reference documentation]. +\nDocument references, do not follow a specific format.\nThey can be literally anything, a single value, an entire document, basically everything that can be stored in MongoDB.\nBy default, the mapping layer will use the referenced entities _id_ value for storage and retrieval, like in the sample below.\n\n====\n[source,java]\n----\n@Document\nclass Account {\n\n @Id\n String id;\n Float total;\n}\n\n@Document\nclass Person {\n\n @Id\n String id;\n\n @DocumentReference <1>\n List<Account> accounts;\n}\n----\n\n[source,java]\n----\nAccount account = …\n\ntemplate.insert(account); <2>\n\ntemplate.update(Person.class)\n .matching(where(\"id\").is(…))\n .apply(new Update().push(\"accounts\").value(account)) <3>\n .first();\n----\n\n[source,json]\n----\n{\n \"_id\" : …,\n \"accounts\" : [ \"6509b9e\" … ] <4>\n}\n----\n<1> Mark the collection of `Account` values to be referenced.\n<2> The mapping framework does not handle cascading saves, so make sure to persist the referenced entity individually.\n<3> Add the reference to the existing entity.\n<4> Referenced `Account` entities are represented as an array of their `_id` values.\n====\n\nThe sample above uses an ``_id``-based fetch query (`{ '_id' : ?#{#target} }`) for data retrieval and resolves linked entities eagerly.\nIt is possible to alter resolution defaults (listed below) using the attributes of `@DocumentReference`\n\n.@DocumentReference defaults\n[cols=\"2,3,5\",options=\"header\"]\n|===\n| Attribute | Description | Default\n\n| `db`\n| The target database name for collection lookup.\n| `MongoDatabaseFactory.getMongoDatabase()`\n\n| `collection`\n| The target collection name.\n| The annotated property's domain type, respectively the value type in case of `Collection` like or `Map` properties, collection name.\n\n| `lookup`\n| The single document lookup query evaluating placeholders via SpEL expressions using `#target` as the marker for a given source value. `Collection` like or `Map` properties combine individual lookups via an `$or` operator.\n| An `_id` field based query (`{ '_id' : ?#{#target} }`) using the loaded source value.\n\n| `sort`\n| Used for sorting result documents on server side.\n| None by default.\nResult order of `Collection` like properties is restored based on the used lookup query on a best-effort basis.\n\n| `lazy`\n| If set to `true` value resolution is delayed upon first access of the property.\n| Resolves properties eagerly by default.\n|===\n\nCAUTION: Lazy loading may require class proxies, that in turn, might need access to jdk internals, that are not open, starting with Java 16+, due to https://openjdk.java.net/jeps/396[JEP 396: Strongly Encapsulate JDK Internals by Default].\nFor those cases please consider falling back to an interface type (eg. switch from `ArrayList` to `List`) or provide the required `--add-opens` argument.\n\n`@DocumentReference(lookup)` allows defining filter queries that can be different from the `_id` field and therefore offer a flexible way of defining references between entities as demonstrated in the sample below, where the `Publisher` of a book is referenced by its acronym instead of the internal `id`.\n\n====\n[source,java]\n----\n@Document\nclass Book {\n\n @Id\n ObjectId id;\n String title;\n List<String> author;\n\n @Field(\"publisher_ac\")\n @DocumentReference(lookup = \"{ 'acronym' : ?#{#target} }\") <1>\n Publisher publisher;\n}\n\n@Document\nclass Publisher {\n\n @Id\n ObjectId id;\n String acronym; <1>\n String name;\n\n @DocumentReference(lazy = true) <2>\n List<Book> books;\n\n}\n----\n\n.`Book` document\n[source,json]\n----\n{\n \"_id\" : 9a48e32,\n \"title\" : \"The Warded Man\",\n \"author\" : [\"Peter V. Brett\"],\n \"publisher_ac\" : \"DR\"\n}\n----\n\n.`Publisher` document\n[source,json]\n----\n{\n \"_id\" : 1a23e45,\n \"acronym\" : \"DR\",\n \"name\" : \"Del Rey\",\n …\n}\n----\n<1> Use the `acronym` field to query for entities in the `Publisher` collection.\n<2> Lazy load back references to the `Book` collection.\n====\n\nThe above snippet shows the reading side of things when working with custom referenced objects.\nWriting requires a bit of additional setup as the mapping information do not express where `#target` stems from.\nThe mapping layer requires registration of a `Converter` between the target document and `DocumentPointer`, like the one below:\n\n====\n[source,java]\n----\n@WritingConverter\nclass PublisherReferenceConverter implements Converter<Publisher, DocumentPointer<String>> {\n\n\t@Override\n\tpublic DocumentPointer<String> convert(Publisher source) {\n return () -> source.getAcronym();\n\t}\n}\n----\n====\n\nIf no `DocumentPointer` converter is provided the target reference document can be computed based on the given lookup query.\nIn this case the association target properties are evaluated as shown in the following sample.\n\n====\n[source,java]\n----\n@Document\nclass Book {\n\n @Id\n ObjectId id;\n String title;\n List<String> author;\n\n @DocumentReference(lookup = \"{ 'acronym' : ?#{acc} }\") <1> <2>\n Publisher publisher;\n}\n\n@Document\nclass Publisher {\n\n @Id\n ObjectId id;\n String acronym; <1>\n String name;\n\n // ...\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : 9a48e32,\n \"title\" : \"The Warded Man\",\n \"author\" : [\"Peter V. Brett\"],\n \"publisher\" : {\n \"acc\" : \"DOC\"\n }\n}\n----\n<1> Use the `acronym` field to query for entities in the `Publisher` collection.\n<2> The field value placeholders of the lookup query (like `acc`) is used to form the reference document.\n====\n\nIt is also possible to model relational style _One-To-Many_ references using a combination of `@ReadonlyProperty` and `@DocumentReference`.\nThis approach allows link types without storing the linking values within the owning document but rather on the referencing document as shown in the example below.\n\n====\n[source,java]\n----\n@Document\nclass Book {\n\n @Id\n ObjectId id;\n String title;\n List<String> author;\n\n ObjectId publisherId; <1>\n}\n\n@Document\nclass Publisher {\n\n @Id\n ObjectId id;\n String acronym;\n String name;\n\n @ReadOnlyProperty <2>\n @DocumentReference(lookup=\"{'publisherId':?#{#self._id} }\") <3>\n List<Book> books;\n}\n----\n\n.`Book` document\n[source,json]\n----\n{\n \"_id\" : 9a48e32,\n \"title\" : \"The Warded Man\",\n \"author\" : [\"Peter V. Brett\"],\n \"publisherId\" : 8cfb002\n}\n----\n\n.`Publisher` document\n[source,json]\n----\n{\n \"_id\" : 8cfb002,\n \"acronym\" : \"DR\",\n \"name\" : \"Del Rey\"\n}\n----\n<1> Set up the link from `Book` (reference) to `Publisher` (owner) by storing the `Publisher.id` within the `Book` document.\n<2> Mark the property holding the references to be readonly.\nThis prevents storing references to individual ``Book``s with the `Publisher` document.\n<3> Use the `#self` variable to access values within the `Publisher` document and in this retrieve `Books` with matching `publisherId`.\n====\n\nWith all the above in place it is possible to model all kind of associations between entities.\nHave a look at the non-exhaustive list of samples below to get feeling for what is possible.\n\n.Simple Document Reference using _id_ field\n====\n[source,java]\n----\nclass Entity {\n @DocumentReference\n ReferencedObject ref;\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"8cfb002\",\n \"ref\" : \"9a48e32\" <1>\n}\n\n{\n \"_id\" : \"9a48e32\" <1>\n}\n----\n<1> MongoDB simple type can be directly used without further configuration.\n====\n\n.Simple Document Reference using _id_ field with explicit lookup query\n====\n[source,java]\n----\nclass Entity {\n @DocumentReference(lookup = \"{ '_id' : '?#{#target}' }\") <1>\n ReferencedObject ref;\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"8cfb002\",\n \"ref\" : \"9a48e32\" <1>\n}\n\n{\n \"_id\" : \"9a48e32\"\n}\n----\n<1> _target_ defines the reference value itself.\n====\n\n.Document Reference extracting the `refKey` field for the lookup query\n====\n[source,java]\n----\nclass Entity {\n @DocumentReference(lookup = \"{ '_id' : '?#{refKey}' }\") <1> <2>\n private ReferencedObject ref;\n}\n----\n\n[source,java]\n----\n@WritingConverter\nclass ToDocumentPointerConverter implements Converter<ReferencedObject, DocumentPointer<Document>> {\n\tpublic DocumentPointer<Document> convert(ReferencedObject source) {\n return () -> new Document(\"refKey\", source.id); <1>\n\t}\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"8cfb002\",\n \"ref\" : {\n \"refKey\" : \"9a48e32\" <1>\n }\n}\n\n{\n \"_id\" : \"9a48e32\"\n}\n----\n<1> The key used for obtaining the reference value must be the one used during write.\n<2> `refKey` is short for `target.refKey`.\n====\n\n.Document Reference with multiple values forming the lookup query\n====\n[source,java]\n----\nclass Entity {\n @DocumentReference(lookup = \"{ 'firstname' : '?#{fn}', 'lastname' : '?#{ln}' }\") <1> <2>\n ReferencedObject ref;\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"8cfb002\",\n \"ref\" : {\n \"fn\" : \"Josh\", <1>\n \"ln\" : \"Long\" <1>\n }\n}\n\n{\n \"_id\" : \"9a48e32\",\n \"firstname\" : \"Josh\", <2>\n \"lastname\" : \"Long\", <2>\n}\n----\n<1> Read/write the keys `fn` & `ln` from/to the linkage document based on the lookup query.\n<2> Use non _id_ fields for the lookup of the target documents.\n====\n\n.Document Reference reading from a target collection\n====\n[source,java]\n----\nclass Entity {\n @DocumentReference(lookup = \"{ '_id' : '?#{id}' }\", collection = \"?#{collection}\") <2>\n private ReferencedObject ref;\n}\n----\n\n[source,java]\n----\n@WritingConverter\nclass ToDocumentPointerConverter implements Converter<ReferencedObject, DocumentPointer<Document>> {\n\tpublic DocumentPointer<Document> convert(ReferencedObject source) {\n return () -> new Document(\"id\", source.id) <1>\n .append(\"collection\", … ); <2>\n\t}\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"8cfb002\",\n \"ref\" : {\n \"id\" : \"9a48e32\", <1>\n \"collection\" : \"…\" <2>\n }\n}\n----\n<1> Read/write the keys `_id` from/to the reference document to use them in the lookup query.\n<2> The collection name can be read from the reference document using its key.\n====\n\n[WARNING]\n====\nWe know it is tempting to use all kinds of MongoDB query operators in the lookup query and this is fine.\nBut there a few aspects to consider:\n\n* Make sure to have indexes in place that support your lookup.\n* Make sure to use the same data types: `@DocumentReference(lookup=\"{'someRef':?#{#self._id} }\")` can easily fail when using `@Id String id` and `String someRef` as ``String @Id``'s are subject to automatic ObjectId conversion (but not other `String` properties containing `ObjectId.toString()`).\nReference lookup uses values from the resulting `Document` and in that case, it would query a String field using an `ObjectId` yielding no results.\n* Mind that resolution requires a server roundtrip inducing latency, consider a lazy strategy.\n* A collection of document references is bulk loaded using the `$or` operator. +\nThe original element order is restored in memory on a best-effort basis.\nRestoring the order is only possible when using equality expressions and cannot be done when using MongoDB query operators.\nIn this case results will be ordered as they are received from the store or via the provided `@DocumentReference(sort)` attribute.\n\nA few more general remarks:\n\n* Do you use cyclic references?\nAsk your self if you need them.\n* Lazy document references are hard to debug.\nMake sure tooling does not accidentally trigger proxy resolution by e.g. calling `toString()`. +\nThough technically possible, avoid saving back individual lazily loaded entities obtained via properties of the referencing root.\n* There is no support for reading document references using reactive infrastructure.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/document-references.adoc", "title": "document-references", "heading": "Using Document References", "heading_level": 2, "file_order": 9, "section_index": 1, "content_hash": "0bfd74789b2310dcf4050dacea7f292d7d7d97447a3d304104b78e3c45763e1e", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/document-references.adoc"}}
{"id": "sha256:8c3533f9b53e00d35e337af7fc5969e851ce2b88732413ea156fcccc670c6f74", "content": "[[mapping.index-creation]]\n\nSpring Data MongoDB can automatically create indexes for entity types annotated with `@Document`.\nIndex creation must be explicitly enabled since version 3.0 to prevent undesired effects with collection lifecyle and performance impact.\nIndexes are automatically created for the initial entity set on application startup and when accessing an entity type for the first time while the application runs.\n\nWe generally recommend explicit index creation for application-based control of indexes as Spring Data cannot automatically create indexes for collections that were recreated while the application was running.\n\n`IndexResolver` provides an abstraction for programmatic index definition creation if you want to make use of `@Indexed` annotations such as `@GeoSpatialIndexed`, `@TextIndexed`, `@CompoundIndex` and `@WildcardIndexed`.\nYou can use index definitions with `IndexOperations` to create indexes.\nA good point in time for index creation is on application startup, specifically after the application context was refreshed, triggered by observing `ContextRefreshedEvent`.\nThis event guarantees that the context is fully initialized.\nNote that at this time other components, especially bean factories might have access to the MongoDB database.\n\n[WARNING]\n====\n``Map``-like properties are skipped by the `IndexResolver` unless annotated with `@WildcardIndexed` because the _map key_ must be part of the index definition. Since the purpose of maps is the usage of dynamic keys and values, the keys cannot be resolved from static mapping metadata.\n====\n\n.Programmatic Index Creation for a single Domain Type\n====\n[source,java]\n----\nclass MyListener {\n\n @EventListener(ContextRefreshedEvent.class)\n public void initIndicesAfterStartup() {\n\n MappingContext<? extends MongoPersistentEntity<?>, MongoPersistentProperty> mappingContext = mongoTemplate\n .getConverter().getMappingContext();\n\n IndexResolver resolver = new MongoPersistentEntityIndexResolver(mappingContext);\n\n IndexOperations indexOps = mongoTemplate.indexOps(DomainType.class);\n resolver.resolveIndexFor(DomainType.class).forEach(indexOps::ensureIndex);\n }\n}\n----\n====\n\n.Programmatic Index Creation for all Initial Entities\n====\n[source,java]\n----\nclass MyListener {\n\n @EventListener(ContextRefreshedEvent.class)\n public void initIndicesAfterStartup() {\n\n MappingContext<? extends MongoPersistentEntity<?>, MongoPersistentProperty> mappingContext = mongoTemplate.\n getConverter().getMappingContext();\n\n IndexResolver resolver = new MongoPersistentEntityIndexResolver(mappingContext);\n\n // consider only entities that are annotated with @Document\n mappingContext.getPersistentEntities()\n .stream()\n .filter(it -> it.isAnnotationPresent(Document.class))\n .forEach(it -> {\n\n IndexOperations indexOps = mongoTemplate.indexOps(it.getType());\n resolver.resolveIndexFor(it.getType()).forEach(indexOps::ensureIndex);\n });\n }\n}\n----\n====\n\nAlternatively, if you want to ensure index and collection presence before any component is able to access your database from your application, declare a `@Bean` method for `MongoTemplate` and include the code from above before returning the `MongoTemplate` object.\n\n[NOTE]\n====\nTo turn automatic index creation _ON_ please override `autoIndexCreation()` in your configuration.\n[source,java]\n----\n@Configuration\npublic class Config extends AbstractMongoClientConfiguration {\n\n @Override\n public boolean autoIndexCreation() {\n return true;\n }\n\n}\n----\n====\n\nIMPORTANT: Automatic index creation is turned _OFF_ by default as of version 3.0.\n\n[[mapping-usage-indexes.compound-index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc", "title": "mapping-index-management", "heading": "mapping-index-management", "heading_level": 1, "file_order": 10, "section_index": 0, "content_hash": "8c3533f9b53e00d35e337af7fc5969e851ce2b88732413ea156fcccc670c6f74", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc"}}
{"id": "sha256:47772e22c2d65946ae21ccb1791cde4bd34cf4467b44a12e3a55fbcbeece373e", "content": "Compound indexes are also supported. They are defined at the class level, rather than on individual properties.\n\nNOTE: Compound indexes are very important to improve the performance of queries that involve criteria on multiple fields\n\nHere's an example that creates a compound index of `lastName` in ascending order and `age` in descending order:\n\n.Example Compound Index Usage\n====\n[source,java]\n----\npackage com.mycompany.domain;\n\n@Document\n@CompoundIndex(name = \"age_idx\", def = \"{'lastName': 1, 'age': -1}\")\npublic class Person {\n\n @Id\n private ObjectId id;\n private Integer age;\n private String firstName;\n private String lastName;\n\n}\n----\n====\n\n[TIP]\n====\n`@CompoundIndex` is repeatable using `@CompoundIndexes` as its container.\n\n[source,java]\n----\n@Document\n@CompoundIndexes({\n @CompoundIndex(name = \"cmp-idx-one\", def = \"{'firstname': 1, 'lastname': -1}\"),\n @CompoundIndex(name = \"cmp-idx-two\", def = \"{'address.city': -1, 'address.street': 1}\")\n})\npublic class Person {\n\n String firstname;\n String lastname;\n\n Address address;\n\n // ...\n}\n----\n====\n\n[[mapping-usage-indexes.hashed-index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc", "title": "mapping-index-management", "heading": "Compound Indexes", "heading_level": 2, "file_order": 10, "section_index": 1, "content_hash": "47772e22c2d65946ae21ccb1791cde4bd34cf4467b44a12e3a55fbcbeece373e", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc"}}
{"id": "sha256:ffa9fa1c5e11692c6800554e881b70fbdf54b691d3e018fd5d78376faa11ea0b", "content": "Hashed indexes allow hash based sharding within a sharded cluster.\nUsing hashed field values to shard collections results in a more random distribution.\nFor details, refer to the https://docs.mongodb.com/manual/core/index-hashed/[MongoDB Documentation].\n\nHere's an example that creates a hashed index for `_id`:\n\n.Example Hashed Index Usage\n====\n[source,java]\n----\n@Document\npublic class DomainType {\n\n @HashIndexed @Id String id;\n\n // ...\n}\n----\n====\n\nHashed indexes can be created next to other index definitions like shown below, in that case both indices are created:\n\n.Example Hashed Index Usage togehter with simple index\n====\n[source,java]\n----\n@Document\npublic class DomainType {\n\n @Indexed\n @HashIndexed\n String value;\n\n // ...\n}\n----\n====\n\nIn case the example above is too verbose, a compound annotation allows to reduce the number of annotations that need to be declared on a property:\n\n.Example Composed Hashed Index Usage\n====\n[source,java]\n----\n@Document\npublic class DomainType {\n\n @IndexAndHash(name = \"idx...\") <1>\n String value;\n\n // ...\n}\n\n@Indexed\n@HashIndexed\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface IndexAndHash {\n\n @AliasFor(annotation = Indexed.class, attribute = \"name\") <1>\n String name() default \"\";\n}\n----\n<1> Potentially register an alias for certain attributes of the meta annotation.\n====\n\n[NOTE]\n====\nAlthough index creation via annotations comes in handy for many scenarios cosider taking over more control by setting up indices manually via `IndexOperations`.\n\n[source,java]\n----\nmongoOperations.indexOpsFor(Jedi.class)\n .ensureIndex(HashedIndex.hashed(\"useTheForce\"));\n----\n====\n\n[[mapping-usage-indexes.wildcard-index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc", "title": "mapping-index-management", "heading": "Hashed Indexes", "heading_level": 2, "file_order": 10, "section_index": 2, "content_hash": "ffa9fa1c5e11692c6800554e881b70fbdf54b691d3e018fd5d78376faa11ea0b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc"}}
{"id": "sha256:2f51145bc39f6de183988bb278956e165ec31b49b05d49a7c34b3eb57d721ee6", "content": "A `WildcardIndex` is an index that can be used to include all fields or specific ones based a given (wildcard) pattern.\nFor details, refer to the https://docs.mongodb.com/manual/core/index-wildcard/[MongoDB Documentation].\n\nThe index can be set up programmatically using `WildcardIndex` via `IndexOperations`.\n\n.Programmatic WildcardIndex setup\n====\n[source,java]\n----\nmongoOperations\n .indexOps(User.class)\n .ensureIndex(new WildcardIndex(\"userMetadata\"));\n----\n[source,javascript]\n----\ndb.user.createIndex({ \"userMetadata.$**\" : 1 }, {})\n----\n====\n\nThe `@WildcardIndex` annotation allows a declarative index setup that can used either with a document type or property.\n\nIf placed on a type that is a root level domain entity (one annotated with `@Document`) , the index resolver will create a\nwildcard index for it.\n\n.Wildcard index on domain type\n====\n[source,java]\n----\n@Document\n@WildcardIndexed\npublic class Product {\n\t// …\n}\n----\n[source,javascript]\n----\ndb.product.createIndex({ \"$**\" : 1 },{})\n----\n====\n\nThe `wildcardProjection` can be used to specify keys to in-/exclude in the index.\n\n.Wildcard index with `wildcardProjection`\n====\n[source,java]\n----\n@Document\n@WildcardIndexed(wildcardProjection = \"{ 'userMetadata.age' : 0 }\")\npublic class User {\n private @Id String id;\n private UserMetadata userMetadata;\n}\n----\n[source,javascript]\n----\ndb.user.createIndex(\n { \"$**\" : 1 },\n { \"wildcardProjection\" :\n { \"userMetadata.age\" : 0 }\n }\n)\n----\n====\n\nWildcard indexes can also be expressed by adding the annotation directly to the field.\nPlease note that `wildcardProjection` is not allowed on nested paths such as properties.\nProjections on types annotated with `@WildcardIndexed` are omitted during index creation.\n\n.Wildcard index on property\n====\n[source,java]\n----\n@Document\npublic class User {\n private @Id String id;\n\n @WildcardIndexed\n private UserMetadata userMetadata;\n}\n----\n[source,javascript]\n----\ndb.user.createIndex({ \"userMetadata.$**\" : 1 }, {})\n----\n====\n\n[[mapping-usage-indexes.text-index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc", "title": "mapping-index-management", "heading": "Wildcard Indexes", "heading_level": 2, "file_order": 10, "section_index": 3, "content_hash": "2f51145bc39f6de183988bb278956e165ec31b49b05d49a7c34b3eb57d721ee6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc"}}
{"id": "sha256:050b3003affb22bf1d513a079904f0a800207c515982590f79da94b6980a486f", "content": "NOTE: The text index feature is disabled by default for MongoDB v.2.4.\n\nCreating a text index allows accumulating several fields into a searchable full-text index.\nIt is only possible to have one text index per collection, so all fields marked with `@TextIndexed` are combined into this index.\nProperties can be weighted to influence the document score for ranking results.\nThe default language for the text index is English.To change the default language, set the `language` attribute to whichever language you want (for example,`@Document(language=\"spanish\")`).\nUsing a property called `language` or `@Language` lets you define a language override on a per-document base.\nThe following example shows how to created a text index and set the language to Spanish:\n\n.Example Text Index Usage\n====\n[source,java]\n----\n@Document(language = \"spanish\")\nclass SomeEntity {\n\n @TextIndexed String foo;\n\n @Language String lang;\n\n Nested nested;\n}\n\nclass Nested {\n\n @TextIndexed(weight=5) String bar;\n String roo;\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc", "title": "mapping-index-management", "heading": "Text Indexes", "heading_level": 2, "file_order": 10, "section_index": 4, "content_hash": "050b3003affb22bf1d513a079904f0a800207c515982590f79da94b6980a486f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-index-management.adoc"}}
{"id": "sha256:0e3865df08ab09d5fe63eefe9d0ada3ee142b2b6572d8a1e39a54822bdcfc542", "content": "[[mongo.jsonSchema]]\n\nAs of version 3.6, MongoDB supports collections that validate documents against a provided https://docs.mongodb.com/manual/core/schema-validation/#json-schema[JSON Schema].\nThe schema itself and both validation action and level can be defined when creating the collection, as the following example shows:\n\n.Sample JSON schema\n====\n[source,json]\n----\n{\n \"type\": \"object\", <1>\n\n \"required\": [ \"firstname\", \"lastname\" ], <2>\n\n \"properties\": { <3>\n\n \"firstname\": { <4>\n \"type\": \"string\",\n \"enum\": [ \"luke\", \"han\" ]\n },\n \"address\": { <5>\n \"type\": \"object\",\n \"properties\": {\n \"postCode\": { \"type\": \"string\", \"minLength\": 4, \"maxLength\": 5 }\n }\n }\n }\n}\n----\n<1> JSON schema documents always describe a whole document from its root. A schema is a schema object itself that can contain\nembedded schema objects that describe properties and subdocuments.\n<2> `required` is a property that describes which properties are required in a document. It can be specified optionally, along with other\nschema constraints. See MongoDB's documentation on https://docs.mongodb.com/manual/reference/operator/query/jsonSchema/#available-keywords[available keywords].\n<3> `properties` is related to a schema object that describes an `object` type. It contains property-specific schema constraints.\n<4> `firstname` specifies constraints for the `firstname` field inside the document. Here, it is a string-based `properties` element declaring\n possible field values.\n<5> `address` is a subdocument defining a schema for values in its `postCode` field.\n====\n\nYou can provide a schema either by specifying a schema document (that is, by using the `Document` API to parse or build a document object) or by building it with Spring Data's JSON schema utilities in `org.springframework.data.mongodb.core.schema`. `MongoJsonSchema` is the entry point for all JSON schema-related operations. The following example shows how use `MongoJsonSchema.builder()` to create a JSON schema:\n\n.Creating a JSON schema\n====\n[source,java]\n----\nMongoJsonSchema.builder() <1>\n .required(\"lastname\") <2>\n\n .properties(\n required(string(\"firstname\").possibleValues(\"luke\", \"han\")), <3>\n\n object(\"address\")\n .properties(string(\"postCode\").minLength(4).maxLength(5)))\n\n .build(); <4>\n----\n<1> Obtain a schema builder to configure the schema with a fluent API.\n<2> Configure required properties either directly as shown here or with more details as in 3.\n<3> Configure the required String-typed `firstname` field, allowing only `luke` and `han` values. Properties can be typed or untyped. Use a static import of `JsonSchemaProperty` to make the syntax slightly more compact and to get entry points such as `string(…)`.\n<4> Build the schema object.\n====\n\nThere are already some predefined and strongly typed schema objects (`JsonSchemaObject` and `JsonSchemaProperty`) available\nthrough static methods on the gateway interfaces.\nHowever, you may need to build custom property validation rules, which can be created through the builder API, as the following example shows:\n\n[source,java]\n----\nJsonSchemaProperty.named(\"birthdate\").ofType(Type.dateType());\n\nJsonSchemaProperty.named(\"birthdate\").with(JsonSchemaObject.of(Type.dateType()).description(\"Must be a date\"));\n----\n\n`CollectionOptions` provides the entry point to schema support for collections, as the following example shows:\n\n.Create collection with `$jsonSchema`\n====\n[source,java]\n----\nMongoJsonSchema schema = MongoJsonSchema.builder().required(\"firstname\", \"lastname\").build();\n\ntemplate.createCollection(Person.class, CollectionOptions.empty().schema(schema));\n----\n====\n\n[[mongo.jsonSchema.generated]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc", "title": "mapping-schema", "heading": "mapping-schema", "heading_level": 1, "file_order": 11, "section_index": 0, "content_hash": "0e3865df08ab09d5fe63eefe9d0ada3ee142b2b6572d8a1e39a54822bdcfc542", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc"}}
{"id": "sha256:bb0c84d598f0418c5f2b2d72a0368dbf68113953b65d17db599d24373cd8b942", "content": "Setting up a schema can be a time consuming task and we encourage everyone who decides to do so, to really take the time it takes.\nIt's important, schema changes can be hard.\nHowever, there might be times when one does not want to balked with it, and that is where `JsonSchemaCreator` comes into play.\n\n`JsonSchemaCreator` and its default implementation generates a `MongoJsonSchema` out of domain types metadata provided by the mapping infrastructure.\nThis means, that xref:mongodb/mapping/mapping.adoc#mapping-usage-annotations[annotated properties] as well as potential xref:mongodb/mapping/mapping.adoc#mapping-configuration[custom conversions] are considered.\n\n.Generate Json Schema from domain type\n====\n[source,java]\n----\npublic class Person {\n\n private final String firstname; <1>\n private final int age; <2>\n private Species species; <3>\n private Address address; <4>\n private @Field(fieldType=SCRIPT) String theForce; <5>\n private @Transient Boolean useTheForce; <6>\n\n public Person(String firstname, int age) { <1> <2>\n\n this.firstname = firstname;\n this.age = age;\n }\n\n // gettter / setter omitted\n}\n\nMongoJsonSchema schema = MongoJsonSchemaCreator.create(mongoOperations.getConverter())\n .createSchemaFor(Person.class);\n\ntemplate.createCollection(Person.class, CollectionOptions.empty().schema(schema));\n----\n\n[source,json]\n----\n{\n 'type' : 'object',\n 'required' : ['age'], <2>\n 'properties' : {\n 'firstname' : { 'type' : 'string' }, <1>\n 'age' : { 'bsonType' : 'int' } <2>\n 'species' : { <3>\n 'type' : 'string',\n 'enum' : ['HUMAN', 'WOOKIE', 'UNKNOWN']\n }\n 'address' : { <4>\n 'type' : 'object'\n 'properties' : {\n 'postCode' : { 'type': 'string' }\n }\n },\n 'theForce' : { 'type' : 'javascript'} <5>\n }\n}\n----\n<1> Simple object properties are consideres regular properties.\n<2> Primitive types are considered required properties\n<3> Enums are restricted to possible values.\n<4> Object type properties are inspected and represented as nested documents.\n<5> `String` type property that is converted to `Code` by the converter.\n<6> `@Transient` properties are omitted when generating the schema.\n====\n\nNOTE: `_id` properties using types that can be converted into `ObjectId` like `String` are mapped to `{ type : 'object' }`\nunless there is more specific information available via the `@MongoId` annotation.\n\n[cols=\"2,2,6\", options=\"header\"]\n.Sepcial Schema Generation rules\n|===\n| Java\n| Schema Type\n| Notes\n\n| `Object`\n| `type : object`\n| with `properties` if metadata available.\n\n| `Collection`\n| `type : array`\n| -\n\n| `Map`\n| `type : object`\n| -\n\n| `Enum`\n| `type : string`\n| with `enum` property holding the possible enumeration values.\n\n| `array`\n| `type : array`\n| simple type array unless it's a `byte[]`\n\n| `byte[]`\n| `bsonType : binData`\n| -\n\n|===\n\nThe above example demonstrated how to derive the schema from a very precise typed source.\nUsing polymorphic elements within the domain model can lead to inaccurate schema representation for `Object` and generic `<T>` types, which are likely to represented as `{ type : 'object' }` without further specification.\n`MongoJsonSchemaCreator.property(…)` allows defining additional details such as nested document types that should be considered when rendering the schema.\n\n.Specify additional types for properties\n====\n[source,java]\n----\nclass Root {\n\tObject value;\n}\n\nclass A {\n\tString aValue;\n}\n\nclass B {\n\tString bValue;\n}\nMongoJsonSchemaCreator.create()\n .property(\"value\").withTypes(A.class, B.class) <1>\n----\n\n[source,json]\n----\n{\n 'type' : 'object',\n 'properties' : {\n 'value' : {\n 'type' : 'object',\n 'properties' : { <1>\n 'aValue' : { 'type' : 'string' },\n 'bValue' : { 'type' : 'string' }\n }\n }\n }\n}\n----\n<1> Properties of the given types are merged into one element.\n====\n\nMongoDBs schema-free approach allows storing documents of different structure in one collection.\nThose may be modeled having a common base class.\nRegardless of the chosen approach, `MongoJsonSchemaCreator.merge(…)` can help circumvent the need of merging multiple schema into one.\n\n.Merging multiple Schemas into a single Schema definition\n====\n[source,java]\n----\nabstract class Root {\n\tString rootValue;\n}\n\nclass A extends Root {\n\tString aValue;\n}\n\nclass B extends Root {\n\tString bValue;\n}\n\nMongoJsonSchemaCreator.mergedSchemaFor(A.class, B.class) <1>\n----\n\n[source,json]\n----\n{\n 'type' : 'object',\n 'properties' : { <1>\n 'rootValue' : { 'type' : 'string' },\n 'aValue' : { 'type' : 'string' },\n 'bValue' : { 'type' : 'string' }\n }\n }\n}\n----\n<1> Properties (and their inherited ones) of the given types are combined into one schema.\n====\n\n[NOTE]\n====\nProperties with the same name need to refer to the same JSON schema in order to be combined.\nThe following example shows a definition that cannot be merged automatically because of a data type mismatch.\nIn this case a `ConflictResolutionFunction` must be provided to `MongoJsonSchemaCreator`.\n\n[source,java]\n----\nclass A extends Root {\n\tString value;\n}\n\nclass B extends Root {\n\tInteger value;\n}\n----\n====\n\n[[mongo.jsonSchema.encrypted-fields]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc", "title": "mapping-schema", "heading": "Generating a Schema", "heading_level": 2, "file_order": 11, "section_index": 1, "content_hash": "bb0c84d598f0418c5f2b2d72a0368dbf68113953b65d17db599d24373cd8b942", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc"}}
{"id": "sha256:803249ba7a45b53f040afa6bbd79d5348c64381084874142669bbadbc35de4d3", "content": "MongoDB 4.2 https://docs.mongodb.com/master/core/security-client-side-encryption/[Field Level Encryption] allows to directly encrypt individual properties.\n\nProperties can be wrapped within an encrypted property when setting up the JSON Schema as shown in the example below.\n\n.Client-Side Field Level Encryption via Json Schema\n====\n[source,java]\n----\nMongoJsonSchema schema = MongoJsonSchema.builder()\n .properties(\n encrypted(string(\"ssn\"))\n .algorithm(\"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\")\n .keyId(\"*key0_id\")\n\t).build();\n----\n====\n\nInstead of defining encrypted fields manually it is possible leverage the `@Encrypted` annotation as shown in the snippet below.\n\n.Client-Side Field Level Encryption via Json Schema\n====\n[source,java]\n----\n@Document\n@Encrypted(keyId = \"xKVup8B1Q+CkHaVRx+qa+g==\", algorithm = \"AEAD_AES_256_CBC_HMAC_SHA_512-Random\") <1>\nstatic class Patient {\n\n @Id String id;\n String name;\n\n @Encrypted <2>\n String bloodType;\n\n @Encrypted(algorithm = \"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\") <3>\n Integer ssn;\n}\n----\n<1> Default encryption settings that will be set for `encryptMetadata`.\n<2> Encrypted field using default encryption settings.\n<3> Encrypted field overriding the default encryption algorithm.\n====\n\n[TIP]\n====\nThe `@Encrypted` Annotation supports resolving keyIds via SpEL Expressions.\nTo do so additional environment metadata (via the `MappingContext`) is required and must be provided.\n\n[source,java]\n----\n@Document\n@Encrypted(keyId = \"#{mongocrypt.keyId(#target)}\")\nstatic class Patient {\n\n @Id String id;\n String name;\n\n @Encrypted(algorithm = \"AEAD_AES_256_CBC_HMAC_SHA_512-Random\")\n String bloodType;\n\n @Encrypted(algorithm = \"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\")\n Integer ssn;\n}\n\nMongoJsonSchemaCreator schemaCreator = MongoJsonSchemaCreator.create(mappingContext);\nMongoJsonSchema patientSchema = schemaCreator\n .filter(MongoJsonSchemaCreator.encryptedOnly())\n .createSchemaFor(Patient.class);\n----\n\nThe `mongocrypt.keyId` function is defined via an `EvaluationContextExtension` as shown in the snippet below.\nProviding a custom extension provides the most flexible way of computing keyIds.\n\n[source,java]\n----\npublic class EncryptionExtension implements EvaluationContextExtension {\n\n @Override\n public String getExtensionId() {\n return \"mongocrypt\";\n }\n\n @Override\n public Map<String, Function> getFunctions() {\n return Collections.singletonMap(\"keyId\", new Function(getMethod(\"computeKeyId\", String.class), this));\n }\n\n public String computeKeyId(String target) {\n // ... lookup via target element name\n }\n}\n----\n====\n\n[[mongo.jsonSchema.types]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc", "title": "mapping-schema", "heading": "Encrypted Fields", "heading_level": 2, "file_order": 11, "section_index": 2, "content_hash": "803249ba7a45b53f040afa6bbd79d5348c64381084874142669bbadbc35de4d3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc"}}
{"id": "sha256:8ee98025a1c213d45decce1ebf045845ec94b6c5d998af59630c96850327d02b", "content": "The following table shows the supported JSON schema types:\n\n[cols=\"3,1,6\", options=\"header\"]\n.Supported JSON schema types\n|===\n| Schema Type\n| Java Type\n| Schema Properties\n\n| `untyped`\n| -\n| `description`, generated `description`, `enum`, `allOf`, `anyOf`, `oneOf`, `not`\n\n| `object`\n| `Object`\n| `required`, `additionalProperties`, `properties`, `minProperties`, `maxProperties`, `patternProperties`\n\n| `array`\n| any array except `byte[]`\n| `uniqueItems`, `additionalItems`, `items`, `minItems`, `maxItems`\n\n| `string`\n| `String`\n| `minLength`, `maxLentgth`, `pattern`\n\n| `int`\n| `int`, `Integer`\n| `multipleOf`, `minimum`, `exclusiveMinimum`, `maximum`, `exclusiveMaximum`\n\n| `long`\n| `long`, `Long`\n| `multipleOf`, `minimum`, `exclusiveMinimum`, `maximum`, `exclusiveMaximum`\n\n| `double`\n| `float`, `Float`, `double`, `Double`\n| `multipleOf`, `minimum`, `exclusiveMinimum`, `maximum`, `exclusiveMaximum`\n\n| `decimal`\n| `BigDecimal`\n| `multipleOf`, `minimum`, `exclusiveMinimum`, `maximum`, `exclusiveMaximum`\n\n| `number`\n| `Number`\n| `multipleOf`, `minimum`, `exclusiveMinimum`, `maximum`, `exclusiveMaximum`\n\n| `binData`\n| `byte[]`\n| (none)\n\n| `boolean`\n| `boolean`, `Boolean`\n| (none)\n\n| `null`\n| `null`\n| (none)\n\n| `objectId`\n| `ObjectId`\n| (none)\n\n| `date`\n| `java.util.Date`\n| (none)\n\n| `timestamp`\n| `BsonTimestamp`\n| (none)\n\n| `regex`\n| `java.util.regex.Pattern`\n| (none)\n\n|===\n\nNOTE: `untyped` is a generic type that is inherited by all typed schema types. It provides all `untyped` schema properties to typed schema types.\n\nFor more information, see https://docs.mongodb.com/manual/reference/operator/query/jsonSchema/#op._S_jsonSchema[$jsonSchema].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc", "title": "mapping-schema", "heading": "JSON Schema Types", "heading_level": 2, "file_order": 11, "section_index": 3, "content_hash": "8ee98025a1c213d45decce1ebf045845ec94b6c5d998af59630c96850327d02b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping-schema.adoc"}}
{"id": "sha256:72e7b0a0192e2bde76b095a49c00000488a9d818edf75a5ae83d31f9e7e1f8a3", "content": "[[mapping-chapter]]\n\nRich mapping support is provided by the `MappingMongoConverter`.\nThe converter holds a metadata model that provides a full feature set to map domain objects to MongoDB documents.\nThe mapping metadata model is populated by using annotations on your domain objects.\nHowever, the infrastructure is not limited to using annotations as the only source of metadata information.\nThe `MappingMongoConverter` also lets you map objects to documents without providing any additional metadata, by following a set of conventions.\n\nThis section describes the features of the `MappingMongoConverter`, including fundamentals, how to use conventions for mapping objects to documents and how to override those conventions with annotation-based mapping metadata.\n\ninclude::{commons}@data-commons::page$object-mapping.adoc[leveloffset=+1]\n\n[[mapping-conventions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "mapping", "heading_level": 1, "file_order": 12, "section_index": 0, "content_hash": "72e7b0a0192e2bde76b095a49c00000488a9d818edf75a5ae83d31f9e7e1f8a3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:26ee8e84a947a4801c413da4f1a4bd4f2a8028a47cbdfa607b2bbf304479c516", "content": "`MappingMongoConverter` has a few conventions for mapping objects to documents when no additional mapping metadata is provided.\nThe conventions are:\n\n* The short Java class name is mapped to the collection name in the following manner.\nThe class `com.bigbank.SavingsAccount` maps to the `savingsAccount` collection name.\n* All nested objects are stored as nested objects in the document and *not* as DBRefs.\n* The converter uses any Spring Converters registered with it to override the default mapping of object properties to document fields and values.\n* The fields of an object are used to convert to and from fields in the document.\nPublic `JavaBean` properties are not used.\n* If you have a single non-zero-argument constructor whose constructor argument names match top-level field names of document, that constructor is used.Otherwise, the zero-argument constructor is used.If there is more than one non-zero-argument constructor, an exception will be thrown.\n\n[[mapping.conventions.id-field]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Convention-based Mapping", "heading_level": 2, "file_order": 12, "section_index": 1, "content_hash": "26ee8e84a947a4801c413da4f1a4bd4f2a8028a47cbdfa607b2bbf304479c516", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:dc40d48eecf9000adf0985b04d9b0abd945d4ee6e83854550ea7ac25993fb8e9", "content": "MongoDB requires that you have an `_id` field for all documents.If you don't provide one the driver will assign a ObjectId with a generated value.The `_id` field can be of any type, other than arrays, so long as it is unique.The driver naturally supports all primitive types and Dates.When using the `MappingMongoConverter` there are certain rules that govern how properties from the Java class are mapped to the `_id` field.\n\nThe following outlines what field will be mapped to the `_id` document field:\n\n* A field annotated with `@Id` (`org.springframework.data.annotation.Id`) will be mapped to the `_id` field. +\nAdditionally, the name of the document field can be customized via the `@Field` annotation, in which case the document will not contain a field `_id`.\n* A field without an annotation but named `id` will be mapped to the `_id` field.\n\n[cols=\"1,2\",options=\"header\"]\n.Examples for the translation of `_id` field definitions\n|===\n| Field definition\n| Resulting Id-Fieldname in MongoDB\n\n| `String` id\n| `_id`\n\n| `@Field` `String` id\n| `_id`\n\n| `@Field(\"x\")` `String` id\n| `x`\n\n| `@Id` `String` x\n| `_id`\n\n| `@Field(\"x\")` `@Id` `String` y\n| `_id` (`@Field(name)` is ignored, `@Id` takes precedence)\n|===\n\nThe following outlines what type conversion, if any, will be done on the property mapped to the _id document field.\n\n* If a field named `id` is declared as a String or BigInteger in the Java class it will be converted to and stored as an ObjectId if possible.\nObjectId as a field type is also valid.\nIf you specify a value for `id` in your application, the conversion to an ObjectId is done by the MongoDB driver.\nIf the specified `id` value cannot be converted to an ObjectId, then the value will be stored as is in the document's `_id` field.\nThis also applies if the field is annotated with `@Id`.\n* If a field is annotated with `@MongoId` in the Java class it will be converted to and stored as using its actual type.\nNo further conversion happens unless `@MongoId` declares a desired field type.\nIf no value is provided for the `id` field, a new `ObjectId` will be created and converted to the properties type.\n* If a field is annotated with `@MongoId(FieldType.…)` in the Java class it will be attempted to convert the value to the declared `FieldType`.\nIf no value is provided for the `id` field, a new `ObjectId` will be created and converted to the declared type.\n* If a field named `id` is not declared as a String, BigInteger, or ObjectID in the Java class then you should assign it a value in your application so it can be stored 'as-is' in the document's `_id` field.\n* If no field named `id` is present in the Java class then an implicit `_id` file will be generated by the driver but not mapped to a property or field of the Java class.\n\nWhen querying and updating `MongoTemplate` will use the converter to handle conversions of the `Query` and `Update` objects that correspond to the above rules for saving documents so field names and types used in your queries will be able to match what is in your domain classes.\n\n[[mapping-conversion]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "How the `_id` field is handled in the mapping layer.", "heading_level": 3, "file_order": 12, "section_index": 2, "content_hash": "dc40d48eecf9000adf0985b04d9b0abd945d4ee6e83854550ea7ac25993fb8e9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:b4f85e225f8ae5e8e9667c259e5355f24815035bd7be038baedd0ae40b16b217", "content": "Spring Data MongoDB supports all types that can be represented as BSON, MongoDB's internal document format.\nIn addition to these types, Spring Data MongoDB provides a set of built-in converters to map additional types.\nYou can provide your own converters to adjust type conversion.\nSee xref:mongodb/mapping/custom-conversions.adoc[Custom Conversions - Overriding Default Mapping] for further details.\n\n.Built in Type conversions:\n[%collapsible]\n====\n[cols=\"3,1,6\",options=\"header\"]\n.Type\n|===\n| Type\n| Type conversion\n| Sample\n\n| `String`\n| native\n| `{\"firstname\" : \"Dave\"}`\n\n| `double`, `Double`, `float`, `Float`\n| native\n| `{\"weight\" : 42.5}`\n\n| `int`, `Integer`, `short`, `Short`\n| native +\n32-bit integer\n| `{\"height\" : 42}`\n\n| `long`, `Long`\n| native +\n64-bit integer\n| `{\"height\" : 42}`\n\n| `Date`, `Timestamp`\n| native\n| `{\"date\" : ISODate(\"2019-11-12T23:00:00.809Z\")}`\n\n| `byte[]`\n| native\n| `{\"bin\" : { \"$binary\" : \"AQIDBA==\", \"$type\" : \"00\" }}`\n\n| `java.util.UUID` (According to UuidRepresentation)\n| native\n| `{\"uuid\" : { \"$binary\" : \"MEaf1CFQ6lSphaa3b9AtlA==\", \"$type\" : \"04\" }}`\n\n| `Date`\n| native\n| `{\"date\" : ISODate(\"2019-11-12T23:00:00.809Z\")}`\n\n| `ObjectId`\n| native\n| `{\"_id\" : ObjectId(\"5707a2690364aba3136ab870\")}`\n\n| Array, `List`, `BasicDBList`\n| native\n| `{\"cookies\" : [ … ]}`\n\n| `boolean`, `Boolean`\n| native\n| `{\"active\" : true}`\n\n| `null`\n| native\n| `{\"value\" : null}`\n\n| `Document`\n| native\n| `{\"value\" : { … }}`\n\n| `Decimal128`\n| native\n| `{\"value\" : NumberDecimal(…)}`\n\n| `AtomicInteger` +\ncalling `get()` before the actual conversion\n| converter +\n32-bit integer\n| `{\"value\" : \"741\" }`\n\n| `AtomicLong` +\ncalling `get()` before the actual conversion\n| converter +\n64-bit integer\n| `{\"value\" : \"741\" }`\n\n| `BigInteger`\n| native +\n`NumberDecimal`, `String` (see `BigDecimalRepresentation`)\n| `{\"value\" : NumberDecimal(741) }`, `{\"value\" : \"741\" }`\n\n| `BigDecimal`\n| native +\n`NumberDecimal`, `String` (see `BigDecimalRepresentation`)\n| `{\"value\" : NumberDecimal(741.99) }`, `{\"value\" : \"741.99\" }`\n\n| `URL`\n| converter\n| `{\"website\" : \"https://spring.io/projects/spring-data-mongodb/\" }`\n\n| `Locale`\n| converter\n| `{\"locale : \"en_US\" }`\n\n| `char`, `Character`\n| converter\n| `{\"char\" : \"a\" }`\n\n| `NamedMongoScript`\n| converter +\n`Code`\n| `{\"_id\" : \"script name\", value: (some javascript code)`}\n\n| `java.util.Currency`\n| converter\n| `{\"currencyCode\" : \"EUR\"}`\n\n| `Instant` +\n(Java 8)\n| native\n| `{\"date\" : ISODate(\"2019-11-12T23:00:00.809Z\")}`\n\n| `Instant` +\n(Java 8)\n| converter\n| `{\"date\" : ISODate(\"2019-11-12T23:00:00.809Z\")}`\n\n| `LocalDate` +\n(Java 8)\n| converter / native (Java 8)footnote:[Uses UTC zone offset. Configure via xref:mongodb/mapping/mapping.adoc#mapping-configuration[MongoConverterConfigurationAdapter]]\n| `{\"date\" : ISODate(\"2019-11-12T00:00:00.000Z\")}`\n\n| `LocalDateTime`, `LocalTime` +\n(Java 8)\n| converter / native (Java 8)footnote:[Uses UTC zone offset. Configure via xref:mongodb/mapping/mapping.adoc#mapping-configuration[MongoConverterConfigurationAdapter]]\n| `{\"date\" : ISODate(\"2019-11-12T23:00:00.809Z\")}`\n\n| `ZoneId` (Java 8)\n| converter\n| `{\"zoneId\" : \"ECT - Europe/Paris\"}`\n\n| `Box`\n| converter\n| `{\"box\" : { \"first\" : { \"x\" : 1.0 , \"y\" : 2.0} , \"second\" : { \"x\" : 3.0 , \"y\" : 4.0}}`\n\n| `Polygon`\n| converter\n| `{\"polygon\" : { \"points\" : [ { \"x\" : 1.0 , \"y\" : 2.0} , { \"x\" : 3.0 , \"y\" : 4.0} , { \"x\" : 4.0 , \"y\" : 5.0}]}}`\n\n| `Circle`\n| converter\n| `{\"circle\" : { \"center\" : { \"x\" : 1.0 , \"y\" : 2.0} , \"radius\" : 3.0 , \"metric\" : \"NEUTRAL\"}}`\n\n| `Point`\n| converter\n| `{\"point\" : { \"x\" : 1.0 , \"y\" : 2.0}}`\n\n| `GeoJsonPoint`\n| converter\n| `{\"point\" : { \"type\" : \"Point\" , \"coordinates\" : [3.0 , 4.0] }}`\n\n| `GeoJsonMultiPoint`\n| converter\n| `{\"geoJsonLineString\" : {\"type\":\"MultiPoint\", \"coordinates\": [ [ 0 , 0 ], [ 0 , 1 ], [ 1 , 1 ] ] }}`\n\n| `Sphere`\n| converter\n| `{\"sphere\" : { \"center\" : { \"x\" : 1.0 , \"y\" : 2.0} , \"radius\" : 3.0 , \"metric\" : \"NEUTRAL\"}}`\n\n| `GeoJsonPolygon`\n| converter\n| `{\"polygon\" : { \"type\" : \"Polygon\", \"coordinates\" : [[ [ 0 , 0 ], [ 3 , 6 ], [ 6 , 1 ], [ 0 , 0 ] ]] }}`\n\n| `GeoJsonMultiPolygon`\n| converter\n| `{\"geoJsonMultiPolygon\" : { \"type\" : \"MultiPolygon\", \"coordinates\" : [\n[ [ [ -73.958 , 40.8003 ] , [ -73.9498 , 40.7968 ] ] ],\n[ [ [ -73.973 , 40.7648 ] , [ -73.9588 , 40.8003 ] ] ]\n] }}`\n\n| `GeoJsonLineString`\n| converter\n| `{ \"geoJsonLineString\" : { \"type\" : \"LineString\", \"coordinates\" : [ [ 40 , 5 ], [ 41 , 6 ] ] }}`\n\n| `GeoJsonMultiLineString`\n| converter\n| `{\"geoJsonLineString\" : { \"type\" : \"MultiLineString\", coordinates: [\n[ [ -73.97162 , 40.78205 ], [ -73.96374 , 40.77715 ] ],\n[ [ -73.97880 , 40.77247 ], [ -73.97036 , 40.76811 ] ]\n] }}`\n|===\n====\n\n.Collection Handling\n[NOTE]\n====\nCollection handling depends on the actual values returned by MongoDB.\n\n* If a document does **not** contain a field mapped to a collection, the mapping will not update the property.\nWhich means the value will remain `null`, a java default or any value set during object creation.\n* If a document contains a field to be mapped, but the field holds a `null` value (like: `{ 'list' : null }`), the property value is set to `null`.\n* If a document contains a field to be mapped to a collection which is **not** `null` (like: `{ 'list' : [ ... ] }`), the collection is populated with the mapped values.\n\nGenerally, if you use constructor creation, then you can get hold of the value to be set.\nProperty population can make use of default initialization values if a property value is not being provided by a query response.\n====\n\n[[mapping-configuration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Data Mapping and Type Conversion", "heading_level": 2, "file_order": 12, "section_index": 3, "content_hash": "b4f85e225f8ae5e8e9667c259e5355f24815035bd7be038baedd0ae40b16b217", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:98517f66910fbbd8342b1e76a74093f35aa605ae78c3134bfa104980e9834578", "content": "Unless explicitly configured, an instance of `MappingMongoConverter` is created by default when you create a `MongoTemplate`.\nYou can create your own instance of the `MappingMongoConverter`.\nDoing so lets you dictate where in the classpath your domain classes can be found, so that Spring Data MongoDB can extract metadata and construct indexes.\nAlso, by creating your own instance, you can register Spring converters to map specific classes to and from the database.\n\nYou can configure the `MappingMongoConverter` as well as `com.mongodb.client.MongoClient` and MongoTemplate by using either Java-based or XML-based metadata.\nThe following example shows the configuration:\n\n[tabs]\n======\nJava::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\npublic class MongoConfig extends AbstractMongoClientConfiguration {\n\n @Override\n public String getDatabaseName() {\n return \"database\";\n }\n\n // the following are optional\n\n @Override\n public String getMappingBasePackage() { <1>\n return \"com.bigbank.domain\";\n }\n\n @Override\n void configureConverters(MongoConverterConfigurationAdapter adapter) { <2>\n\n adapter.registerConverter(new org.springframework.data.mongodb.test.PersonReadConverter());\n adapter.registerConverter(new org.springframework.data.mongodb.test.PersonWriteConverter());\n }\n\n @Bean\n public LoggingEventListener<MongoMappingEvent> mappingEventsListener() {\n return new LoggingEventListener<MongoMappingEvent>();\n }\n}\n----\n\n<1> The mapping base package defines the root path used to scan for entities used to pre initialize the `MappingContext`.\nBy default the configuration classes package is used.\n<2> Configure additional custom converters for specific domain types that replace the default mapping procedure for those types with your custom implementation.\n====\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:mongo=\"http://www.springframework.org/schema/data/mongo\"\n xsi:schemaLocation=\"\n http://www.springframework.org/schema/data/mongo https://www.springframework.org/schema/data/mongo/spring-mongo.xsd\n http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans-3.0.xsd\">\n\n <!-- Default bean name is 'mongo' -->\n <mongo:mongo-client host=\"localhost\" port=\"27017\"/>\n\n <mongo:db-factory dbname=\"database\" mongo-ref=\"mongoClient\"/>\n\n <!-- by default look for a Mongo object named 'mongo' - default name used for the converter is 'mappingConverter' -->\n <mongo:mapping-converter base-package=\"com.bigbank.domain\">\n <mongo:custom-converters>\n <mongo:converter ref=\"readConverter\"/>\n <mongo:converter>\n <bean class=\"org.springframework.data.mongodb.test.PersonWriteConverter\"/>\n </mongo:converter>\n </mongo:custom-converters>\n </mongo:mapping-converter>\n\n <bean id=\"readConverter\" class=\"org.springframework.data.mongodb.test.PersonReadConverter\"/>\n\n <!-- set the mapping converter to be used by the MongoTemplate -->\n <bean id=\"mongoTemplate\" class=\"org.springframework.data.mongodb.core.MongoTemplate\">\n <constructor-arg name=\"mongoDbFactory\" ref=\"mongoDbFactory\"/>\n <constructor-arg name=\"mongoConverter\" ref=\"mappingConverter\"/>\n </bean>\n\n <bean class=\"org.springframework.data.mongodb.core.mapping.event.LoggingEventListener\"/>\n\n</beans>\n----\n======\n\n`AbstractMongoClientConfiguration` requires you to implement methods that define a `com.mongodb.client.MongoClient` as well as provide a database name.\n`AbstractMongoClientConfiguration` also has a method named `getMappingBasePackage(…)` that you can override to tell the converter where to scan for classes annotated with the `@Document` annotation.\n\nYou can add additional converters to the converter by overriding the `customConversionsConfiguration` method.\nMongoDB's native JSR-310 support can be enabled through `MongoConverterConfigurationAdapter.useNativeDriverJavaTimeCodecs()`.\nAlso shown in the preceding example is a `LoggingEventListener`, which logs `MongoMappingEvent` instances that are posted onto Spring's `ApplicationContextEvent` infrastructure.\n\n[TIP]\n====\n.Java Time Types\nWe recommend using MongoDB's native JSR-310 support via `MongoConverterConfigurationAdapter.useNativeDriverJavaTimeCodecs()` as described above as it is using an `UTC` based approach.\nThe default JSR-310 support for `java.time` types inherited from Spring Data Commons uses the local machine timezone as reference and should only be used for backwards compatibility.\n====\n\nNOTE: `AbstractMongoClientConfiguration` creates a `MongoTemplate` instance and registers it with the container under the name `mongoTemplate`.\n\nThe `base-package` property tells it where to scan for classes annotated with the `@org.springframework.data.mongodb.core.mapping.Document` annotation.\n\n[TIP]\n====\nIf you want to rely on https://spring.io/projects/spring-boot[Spring Boot] to bootstrap Data MongoDB, but still want to override certain aspects of the configuration, you may want to expose beans of that type.\nFor custom conversions you may eg. choose to register a bean of type `MongoCustomConversions` that will be picked up the by the Boot infrastructure.\nTo learn more about this please make sure to read the Spring Boot https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.nosql.mongodb[Reference Documentation].\n====\n\n[[mapping-usage]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Mapping Configuration", "heading_level": 2, "file_order": 12, "section_index": 4, "content_hash": "98517f66910fbbd8342b1e76a74093f35aa605ae78c3134bfa104980e9834578", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:b2773c94fa9de027941efac6e47b940cec705cb8d70e4c2e36d7152aa1c6ec03", "content": "To take full advantage of the object mapping functionality inside the Spring Data MongoDB support, you should annotate your mapped objects with the `@Document` annotation.\nAlthough it is not necessary for the mapping framework to have this annotation (your POJOs are mapped correctly, even without any annotations), it lets the classpath scanner find and pre-process your domain objects to extract the necessary metadata.\nIf you do not use this annotation, your application takes a slight performance hit the first time you store a domain object, because the mapping framework needs to build up its internal metadata model so that it knows about the properties of your domain object and how to persist them.\nThe following example shows a domain object:\n\n.Example domain object\n====\n[source,java]\n----\npackage com.mycompany.domain;\n\n@Document\npublic class Person {\n\n @Id\n private ObjectId id;\n\n @Indexed\n private Integer ssn;\n\n private String firstName;\n\n @Indexed\n private String lastName;\n}\n----\n====\n\nIMPORTANT: The `@Id` annotation tells the mapper which property you want to use for the MongoDB `_id` property, and the `@Indexed` annotation tells the mapping framework to call `createIndex(…)` on that property of your document, making searches faster.\nAutomatic index creation is only done for types annotated with `@Document`.\n\nWARNING: Auto index creation is **disabled** by default and needs to be enabled through the configuration (see xref:mongodb/mapping/mapping.adoc#mapping.index-creation[Index Creation]).\n\n[[mapping-usage-annotations]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Metadata-based Mapping", "heading_level": 2, "file_order": 12, "section_index": 5, "content_hash": "b2773c94fa9de027941efac6e47b940cec705cb8d70e4c2e36d7152aa1c6ec03", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:9d2ad68048103b2f8f5cc9367be10f8c7996a2b3988397350ed48b1b922681ef", "content": "The MappingMongoConverter can use metadata to drive the mapping of objects to documents.\nThe following annotations are available:\n\n* `@Id`: Applied at the field level to mark the field used for identity purpose.\n* `@MongoId`: Applied at the field level to mark the field used for identity purpose.\nAccepts an optional `FieldType` to customize id conversion.\n* `@Document`: Applied at the class level to indicate this class is a candidate for mapping to the database.\nYou can specify the name of the collection where the data will be stored.\n* `@DBRef`: Applied at the field to indicate it is to be stored using a com.mongodb.DBRef.\n* `@DocumentReference`: Applied at the field to indicate it is to be stored as a pointer to another document.\nThis can be a single value (the _id_ by default), or a `Document` provided via a converter.\n* `@Indexed`: Applied at the field level to describe how to index the field.\n* `@CompoundIndex` (repeatable): Applied at the type level to declare Compound Indexes.\n* `@GeoSpatialIndexed`: Applied at the field level to describe how to geoindex the field.\n* `@TextIndexed`: Applied at the field level to mark the field to be included in the text index.\n* `@HashIndexed`: Applied at the field level for usage within a hashed index to partition data across a sharded cluster.\n* `@Language`: Applied at the field level to set the language override property for text index.\n* `@Transient`: By default, all fields are mapped to the document.\nThis annotation excludes the field where it is applied from being stored in the database.\nTransient properties cannot be used within a persistence constructor as the converter cannot materialize a value for the constructor argument.\n* `@PersistenceCreator`: Marks a given constructor or a `static` factory method - even a package protected one - to use when instantiating the object from the database.\nConstructor arguments are mapped by name to the key values in the retrieved Document.\n* `@Value`: This annotation is part of the Spring Framework . Within the mapping framework it can be applied to constructor arguments.\nThis lets you use a Spring Expression Language statement to transform a key's value retrieved in the database before it is used to construct a domain object.\nIn order to reference a property of a given document one has to use expressions like: `@Value(\"#root.myProperty\")` where `root` refers to the root of the given document.\n* `@Field`: Applied at the field level it allows to describe the name and type of the field as it will be represented in the MongoDB BSON document thus allowing the name and type to be different than the fieldname of the class as well as the property type.\n* `@Version`: Applied at field level is used for optimistic locking and checked for modification on save operations.\nThe initial value is `zero` (`one` for primitive types) which is bumped automatically on every update.\n\nThe mapping metadata infrastructure is defined in a separate spring-data-commons project that is technology agnostic.\nSpecific subclasses are using in the MongoDB support to support annotation based metadata.\nOther strategies are also possible to put in place if there is demand.\n\n.Here is an example of a more complex mapping\n[%collapsible]\n====\n[source,java]\n----\n@Document\n@CompoundIndex(name = \"age_idx\", def = \"{'lastName': 1, 'age': -1}\")\npublic class Person<T extends Address> {\n\n @Id\n private String id;\n\n @Indexed(unique = true)\n private Integer ssn;\n\n @Field(\"fName\")\n private String firstName;\n\n @Indexed\n private String lastName;\n\n private Integer age;\n\n @Transient\n private Integer accountTotal;\n\n @DBRef\n private List<Account> accounts;\n\n private T address;\n\n public Person(Integer ssn) {\n this.ssn = ssn;\n }\n\n @PersistenceCreator\n public Person(Integer ssn, String firstName, String lastName, Integer age, T address) {\n this.ssn = ssn;\n this.firstName = firstName;\n this.lastName = lastName;\n this.age = age;\n this.address = address;\n }\n\n public String getId() {\n return id;\n }\n\n // no setter for Id. (getter is only exposed for some unit testing)\n\n public Integer getSsn() {\n return ssn;\n }\n\n}\n----\n====\n\n[TIP]\n====\n`@Field(targetType=...)` can come in handy when the native MongoDB type inferred by the mapping infrastructure does not match the expected one.\nLike for `BigDecimal`, which is represented as `String` instead of `Decimal128`, just because earlier versions of MongoDB Server did not have support for it.\n\n[source,java]\n----\npublic class Balance {\n\n @Field(targetType = STRING)\n private BigDecimal value;\n\n // ...\n}\n----\n\nYou may even consider your own, custom annotation.\n\n[source,java]\n----\n@Target(ElementType.FIELD)\n@Retention(RetentionPolicy.RUNTIME)\n@Field(targetType = FieldType.STRING)\npublic @interface AsString { }\n\npublic class Balance {\n\n @AsString\n private BigDecimal value;\n\n // ...\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Mapping Annotation Overview", "heading_level": 3, "file_order": 12, "section_index": 6, "content_hash": "9d2ad68048103b2f8f5cc9367be10f8c7996a2b3988397350ed48b1b922681ef", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:1bbb4b7ac350f2adfde38275edf6c63820279cc38ca7aa26a3aa096dcc564c13", "content": "Generally speaking MongoDB uses the dot (`.`) character as a path separator for nested documents or arrays.\nThis means that in a query (or update statement) a key like `a.b.c` targets an object structure as outlined below:\n\n[source,json]\n----\n{\n 'a' : {\n 'b' : {\n 'c' : …\n }\n }\n}\n----\n\nTherefore, up until MongoDB 5.0 field names must not contain dots (`.`). +\nUsing a `MappingMongoConverter#setMapKeyDotReplacement` allowed circumvent some of the limitations when storing `Map` structures by substituting dots on write with another character.\n\n[source,java]\n----\nconverter.setMapKeyDotReplacement(\"-\");\n\nsource.map = Map.of(\"key.with.dot\", \"value\")\nconverter.write(source,...) // -> map : { 'key-with-dot', 'value' }\n----\n\nWith the release of MongoDB 5.0 this restriction on `Document` field names containing special characters was lifted.\nWe highly recommend reading more about limitations on using dots in field names in the https://www.mongodb.com/docs/manual/core/dot-dollar-considerations/[MongoDB Reference]. +\nTo allow dots in `Map` structures please set `preserveMapKeys` on the `MappingMongoConverter`.\n\nUsing `@Field` allows customizing the field name to consider dots in two ways.\n\n. `@Field(name = \"a.b\")`: The name is considered to be a path.\nOperations expect a structure of nested objects such as `{ a : { b : … } }`.\n. `@Field(name = \"a.b\", fieldNameType = KEY)`: The names is considered a name as-is.\nOperations expect a field with the given value as `{ 'a.b' : ….. }`\n\n[WARNING]\n====\nDue to the special nature of the dot character in both MongoDB query and update statements field names containing dots cannot be targeted directly and therefore are excluded from being used in derived query methods.\nConsider the following `Item` having a `categoryId` property that is mapped to the field named `cat.id`.\n\n[source,java]\n----\npublic class Item {\n\n\t@Field(name = \"cat.id\", fieldNameType = KEY)\n\tString categoryId;\n\n\t// ...\n}\n----\n\nIts raw representation will look like\n\n[source,json]\n----\n{\n 'cat.id' : \"5b28b5e7-52c2\",\n ...\n}\n----\n\nSince we cannot target the `cat.id` field directly (as this would be interpreted as a path) we need the help of the xref:mongodb/aggregation-framework.adoc#mongo.aggregation[Aggregation Framework].\n\n.Query fields with a dot in its name\n[source,java]\n----\ntemplate.query(Item.class)\n // $expr : { $eq : [ { $getField : { input : '$$CURRENT', 'cat.id' }, '5b28b5e7-52c2' ] }\n .matching(expr(ComparisonOperators.valueOf(ObjectOperators.getValueOf(\"value\")).equalToValue(\"5b28b5e7-52c2\"))) <1>\n .all();\n----\n\n<1> The mapping layer takes care of translating the property name `value` into the actual field name.\nIt is absolutely valid to use the target field name here as well.\n\n.Update fields with a dot in its name\n[source,java]\n----\ntemplate.update(Item.class)\n .matching(where(\"id\").is(\"r2d2\"))\n // $replaceWith: { $setField : { input: '$$CURRENT', field : 'cat.id', value : 'af29-f87f4e933f97' } }\n .apply(AggregationUpdate.newUpdate(ReplaceWithOperation.replaceWithValue(ObjectOperators.setValueTo(\"value\", \"af29-f87f4e933f97\")))) <1>\n .first();\n----\n\n<1> The mapping layer takes care of translating the property name `value` into the actual field name.\nIt is absolutely valid to use the target field name here as well.\n\nThe above shows a simple example where the special field is present on the top document level.\nIncreased levels of nesting increase the complexity of the aggregation expression required to interact with the field.\n====\n\n[[mapping-custom-object-construction]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Special Field Names", "heading_level": 3, "file_order": 12, "section_index": 7, "content_hash": "1bbb4b7ac350f2adfde38275edf6c63820279cc38ca7aa26a3aa096dcc564c13", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:72fec1ae259f4f9ec5ad03d0ce60a91c9ee805447f49bdc3cb618606030ae661", "content": "The mapping subsystem allows the customization of the object construction by annotating a constructor with the `@PersistenceCreator` annotation.\nThe values to be used for the constructor parameters are resolved in the following way:\n\n* If a parameter is annotated with the `@Value` annotation, the given expression is evaluated and the result is used as the parameter value.\n* If the Java type has a property whose name matches the given field of the input document, then it's property information is used to select the appropriate constructor parameter to pass the input field value to.\nThis works only if the parameter name information is present in the java `.class` files which can be achieved by compiling the source with debug information or using the new `-parameters` command-line switch for javac in Java 8.\n* Otherwise, a `MappingException` will be thrown indicating that the given constructor parameter could not be bound.\n\n[source,java]\n----\nclass OrderItem {\n\n private @Id String id;\n private int quantity;\n private double unitPrice;\n\n OrderItem(String id, @Value(\"#root.qty ?: 0\") int quantity, double unitPrice) {\n this.id = id;\n this.quantity = quantity;\n this.unitPrice = unitPrice;\n }\n\n // getters/setters ommitted\n}\n\nDocument input = new Document(\"id\", \"4711\");\ninput.put(\"unitPrice\", 2.5);\ninput.put(\"qty\",5);\nOrderItem item = converter.read(OrderItem.class, input);\n----\n\nNOTE: The SpEL expression in the `@Value` annotation of the `quantity` parameter falls back to the value `0` if the given property path cannot be resolved.\n\nAdditional examples for using the `@PersistenceCreator` annotation can be found in the https://github.com/spring-projects/spring-data-mongodb/blob/master/spring-data-mongodb/src/test/java/org/springframework/data/mongodb/core/convert/MappingMongoConverterUnitTests.java[MappingMongoConverterUnitTests] test suite.\n\n[[mapping-usage-events]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Customized Object Construction", "heading_level": 3, "file_order": 12, "section_index": 8, "content_hash": "72fec1ae259f4f9ec5ad03d0ce60a91c9ee805447f49bdc3cb618606030ae661", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:eceb47df4fff99a92cad5b87ecd8d0a7d5f56fa31f6f155e5606f7dd27efa933", "content": "Events are fired throughout the lifecycle of the mapping process.\nThis is described in the xref:mongodb/lifecycle-events.adoc[Lifecycle Events] section.\n\nDeclaring these beans in your Spring ApplicationContext causes them to be invoked whenever the event is dispatched.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc", "title": "mapping", "heading": "Mapping Framework Events", "heading_level": 3, "file_order": 12, "section_index": 9, "content_hash": "eceb47df4fff99a92cad5b87ecd8d0a7d5f56fa31f6f155e5606f7dd27efa933", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/mapping.adoc"}}
{"id": "sha256:fddc9a3bee941bdc325659fe9a8aede2d96772e48409cefef6e794080ba674fb", "content": "[[mongo.property-converters]]\n\nWhile xref:mongodb/mapping/custom-conversions.adoc[type-based conversion] already offers ways to influence the conversion and representation of certain types within the target store, it has limitations when only certain values or properties of a particular type should be considered for conversion.\nProperty-based converters allow configuring conversion rules on a per-property basis, either declaratively (via `@ValueConverter`) or programmatically (by registering a `PropertyValueConverter` for a specific property).\n\nA `PropertyValueConverter` can transform a given value into its store representation (write) and back (read) as the following listing shows.\nThe additional `ValueConversionContext` provides additional information, such as mapping metadata and direct `read` and `write` methods.\n\n.A simple PropertyValueConverter\n====\n[source,java]\n----\nclass ReversingValueConverter implements PropertyValueConverter<String, String, ValueConversionContext> {\n\n @Override\n public String read(String value, ValueConversionContext context) {\n return reverse(value);\n }\n\n @Override\n public String write(String value, ValueConversionContext context) {\n return reverse(value);\n }\n}\n----\n====\n\nYou can obtain `PropertyValueConverter` instances from `CustomConversions#getPropertyValueConverter(…)` by delegating to `PropertyValueConversions`, typically by using a `PropertyValueConverterFactory` to provide the actual converter.\nDepending on your application's needs, you can chain or decorate multiple instances of `PropertyValueConverterFactory` -- for example, to apply caching.\nBy default, Spring Data MongoDB uses a caching implementation that can serve types with a default constructor or enum values.\nA set of predefined factories is available through the factory methods in `PropertyValueConverterFactory`.\nYou can use `PropertyValueConverterFactory.beanFactoryAware(…)` to obtain a `PropertyValueConverter` instance from an `ApplicationContext`.\n\nYou can change the default behavior through `ConverterConfiguration`.\n\n[[mongo.property-converters.declarative]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc", "title": "property-converters", "heading": "property-converters", "heading_level": 1, "file_order": 13, "section_index": 0, "content_hash": "fddc9a3bee941bdc325659fe9a8aede2d96772e48409cefef6e794080ba674fb", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc"}}
{"id": "sha256:38169c30ae6834c44a804452c392bab9649944ecefde506d06cef07c98c500f6", "content": "The most straight forward usage of a `PropertyValueConverter` is by annotating properties with the `@ValueConverter` annotation that defines the converter type:\n\n.Declarative PropertyValueConverter\n====\n[source,java]\n----\nclass Person {\n\n @ValueConverter(ReversingValueConverter.class)\n String ssn;\n}\n----\n====\n\n[[mongo.property-converters.programmatic]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc", "title": "property-converters", "heading": "Declarative Value Converter", "heading_level": 2, "file_order": 13, "section_index": 1, "content_hash": "38169c30ae6834c44a804452c392bab9649944ecefde506d06cef07c98c500f6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc"}}
{"id": "sha256:4e3a657ca35a400366368cf2cc0cae295f1664f07bfd6ea911876d94bf6e4058", "content": "Programmatic registration registers `PropertyValueConverter` instances for properties within an entity model by using a `PropertyValueConverterRegistrar`, as the following example shows.\nThe difference between declarative registration and programmatic registration is that programmatic registration happens entirely outside of the entity model.\nSuch an approach is useful if you cannot or do not want to annotate the entity model.\n\n.Programmatic PropertyValueConverter registration\n====\n[source,java]\n----\nPropertyValueConverterRegistrar registrar = new PropertyValueConverterRegistrar();\n\nregistrar.registerConverter(Address.class, \"street\", new PropertyValueConverter() { … }); <1>\n\nregistrar.registerConverter(Person.class, Person::getSsn()) <2>\n .writing(value -> encrypt(value))\n .reading(value -> decrypt(value));\n----\n\n<1> Register a converter for the field identified by its name.\n<2> Type safe variant that allows to register a converter and its conversion functions.\nThis method uses class proxies to determine the property.\nMake sure that neither the class nor the accessors are `final` as otherwise this approach doesn't work.\n====\n\nWARNING: Dot notation (such as `registerConverter(Person.class, \"address.street\", …)`) for nagivating across properties into subdocuments is *not* supported when registering converters.\n\nTIP: `MongoValueConverter` offers a pre-typed `PropertyValueConverter` interface that uses `MongoConversionContext`.\n\n[[mongocustomconversions-configuration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc", "title": "property-converters", "heading": "Programmatic Value Converter Registration", "heading_level": 2, "file_order": 13, "section_index": 2, "content_hash": "4e3a657ca35a400366368cf2cc0cae295f1664f07bfd6ea911876d94bf6e4058", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc"}}
{"id": "sha256:7f3b9c0aab4feed728d8f39145421417e6d2f5b3627b49dfc7baa176fd2176d7", "content": "By default, `MongoCustomConversions` can handle declarative value converters, depending on the configured `PropertyValueConverterFactory`.\n`MongoConverterConfigurationAdapter` helps to set up programmatic value conversions or define the `PropertyValueConverterFactory` to be used.\n\n.Configuration Sample\n====\n[source,java]\n----\nMongoCustomConversions.create(configurationAdapter -> {\n\n SimplePropertyValueConversions valueConversions = new SimplePropertyValueConversions();\n valueConversions.setConverterFactory(…);\n valueConversions.setValueConverterRegistry(new PropertyValueConverterRegistrar()\n .registerConverter(…)\n .buildRegistry());\n\n configurationAdapter.setPropertyValueConversions(valueConversions);\n});\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc", "title": "property-converters", "heading": "MongoCustomConversions configuration", "heading_level": 2, "file_order": 13, "section_index": 3, "content_hash": "7f3b9c0aab4feed728d8f39145421417e6d2f5b3627b49dfc7baa176fd2176d7", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/property-converters.adoc"}}
{"id": "sha256:3016527b7cb166f46a580c960d2ed1aed68ae1bc7dddcf54bf4aa63c005bc24d", "content": "[[unwrapped-entities]]\n\nUnwrapped entities are used to design value objects in your Java domain model whose properties are flattened out into the parent's MongoDB Document.\n\n[[unwrapped-entities.mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "unwrapping-entities", "heading_level": 1, "file_order": 14, "section_index": 0, "content_hash": "3016527b7cb166f46a580c960d2ed1aed68ae1bc7dddcf54bf4aa63c005bc24d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:97b981708ba5cd2040175d617ae101f8842eb32a193e6daa409082b3a89b1460", "content": "Consider the following domain model where `User.name` is annotated with `@Unwrapped`.\nThe `@Unwrapped` annotation signals that all properties of `UserName` should be flattened out into the `user` document that owns the `name` property.\n\n.Sample Code of unwrapping objects\n====\n[source,java]\n----\nclass User {\n\n @Id\n String userId;\n\n @Unwrapped(onEmpty = USE_NULL) <1>\n UserName name;\n}\n\nclass UserName {\n\n String firstname;\n\n String lastname;\n\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"1da2ba06-3ba7\",\n \"firstname\" : \"Emma\",\n \"lastname\" : \"Frost\"\n}\n----\n<1> When loading the `name` property its value is set to `null` if both `firstname` and `lastname` are either `null` or not present.\nBy using `onEmpty=USE_EMPTY` an empty `UserName`, with potential `null` value for its properties, will be created.\n====\n\nFor less verbose embeddable type declarations use `@Unwrapped.Nullable` and `@Unwrapped.Empty` instead `@Unwrapped(onEmpty = USE_NULL)` and `@Unwrapped(onEmpty = USE_EMPTY)`.\nBoth annotations are meta-annotated with JSR-305 `@javax.annotation.Nonnull` to aid with nullability inspections.\n\n[WARNING]\n====\nIt is possible to use complex types within an unwrapped object.\nHowever, those must not be, nor contain unwrapped fields themselves.\n====\n\n[[unwrapped-entities.mapping.field-names]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Unwrapped Types Mapping", "heading_level": 2, "file_order": 14, "section_index": 1, "content_hash": "97b981708ba5cd2040175d617ae101f8842eb32a193e6daa409082b3a89b1460", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:8f2283d0b7974d31035e605fedf818e4ac36142aaaaddd0f8419311afc3a4a2f", "content": "A value object can be unwrapped multiple times by using the optional `prefix` attribute of the `@Unwrapped` annotation.\nBy dosing so the chosen prefix is prepended to each property or `@Field(\"…\")` name in the unwrapped object.\nPlease note that values will overwrite each other if multiple properties render to the same field name.\n\n.Sample Code of unwrapped object with name prefix\n====\n[source,java]\n----\nclass User {\n\n @Id\n String userId;\n\n @Unwrapped.Nullable(prefix = \"u_\") <1>\n UserName name;\n\n @Unwrapped.Nullable(prefix = \"a_\") <2>\n UserName name;\n}\n\nclass UserName {\n\n String firstname;\n\n String lastname;\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"a6a805bd-f95f\",\n \"u_firstname\" : \"Jean\", <1>\n \"u_lastname\" : \"Grey\",\n \"a_firstname\" : \"Something\", <2>\n \"a_lastname\" : \"Else\"\n}\n----\n<1> All properties of `UserName` are prefixed with `u_`.\n<2> All properties of `UserName` are prefixed with `a_`.\n====\n\nWhile combining the `@Field` annotation with `@Unwrapped` on the very same property does not make sense and therefore leads to an error.\nIt is a totally valid approach to use `@Field` on any of the unwrapped types properties.\n\n.Sample Code unwrapping objects with `@Field` annotation\n====\n[source,java]\n----\npublic class User {\n\n\t@Id\n private String userId;\n\n @Unwrapped.Nullable(prefix = \"u-\") <1>\n UserName name;\n}\n\npublic class UserName {\n\n\t@Field(\"first-name\") <2>\n private String firstname;\n\n\t@Field(\"last-name\")\n private String lastname;\n}\n----\n\n[source,json]\n----\n{\n \"_id\" : \"2647f7b9-89da\",\n \"u-first-name\" : \"Barbara\", <2>\n \"u-last-name\" : \"Gordon\"\n}\n----\n<1> All properties of `UserName` are prefixed with `u-`.\n<2> Final field names are a result of concatenating `@Unwrapped(prefix)` and `@Field(name)`.\n====\n\n[[unwrapped-entities.queries]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Unwrapped Types field names", "heading_level": 2, "file_order": 14, "section_index": 2, "content_hash": "8f2283d0b7974d31035e605fedf818e4ac36142aaaaddd0f8419311afc3a4a2f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:15e5e296a63485e07c2b2c642b1b42e43ce666ba043cf3c52779132bfe4bf01d", "content": "Defining queries on unwrapped properties is possible on type- as well as field-level as the provided `Criteria` is matched against the domain type.\nPrefixes and potential custom field names will be considered when rendering the actual query.\nUse the property name of the unwrapped object to match against all contained fields as shown in the sample below.\n\n.Query on unwrapped object\n====\n[source,java]\n----\nUserName userName = new UserName(\"Carol\", \"Danvers\")\nQuery findByUserName = query(where(\"name\").is(userName));\nUser user = template.findOne(findByUserName, User.class);\n----\n\n[source,json]\n----\ndb.collection.find({\n \"firstname\" : \"Carol\",\n \"lastname\" : \"Danvers\"\n})\n----\n====\n\nIt is also possible to address any field of the unwrapped object directly using its property name as shown in the snippet below.\n\n.Query on field of unwrapped object\n====\n[source,java]\n----\nQuery findByUserFirstName = query(where(\"name.firstname\").is(\"Shuri\"));\nList<User> users = template.findAll(findByUserFirstName, User.class);\n----\n\n[source,json]\n----\ndb.collection.find({\n \"firstname\" : \"Shuri\"\n})\n----\n====\n\n[[unwrapped-entities.queries.sort]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Query on Unwrapped Objects", "heading_level": 2, "file_order": 14, "section_index": 3, "content_hash": "15e5e296a63485e07c2b2c642b1b42e43ce666ba043cf3c52779132bfe4bf01d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:ebc728c51a2856d9a6d69d526e47508a674f288f1e6a8726fce2e12536e839c7", "content": "Fields of unwrapped objects can be used for sorting via their property path as shown in the sample below.\n\n.Sort on unwrapped field\n====\n[source,java]\n----\nQuery findByUserLastName = query(where(\"name.lastname\").is(\"Romanoff\"));\nList<User> user = template.findAll(findByUserName.withSort(Sort.by(\"name.firstname\")), User.class);\n----\n\n[source,json]\n----\ndb.collection.find({\n \"lastname\" : \"Romanoff\"\n}).sort({ \"firstname\" : 1 })\n----\n====\n\n[NOTE]\n====\nThough possible, using the unwrapped object itself as sort criteria includes all of its fields in unpredictable order and may result in inaccurate ordering.\n====\n\n[[unwrapped-entities.queries.project]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Sort by unwrapped field.", "heading_level": 3, "file_order": 14, "section_index": 4, "content_hash": "ebc728c51a2856d9a6d69d526e47508a674f288f1e6a8726fce2e12536e839c7", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:8af621a170aad6f5f5cbd81aba36560dd107a832fce9b7d7d99aa6b7db8a333c", "content": "Fields of unwrapped objects can be subject for projection either as a whole or via single fields as shown in the samples below.\n\n.Project on unwrapped object.\n====\n[source,java]\n----\nQuery findByUserLastName = query(where(\"name.firstname\").is(\"Gamora\"));\nfindByUserLastName.fields().include(\"name\"); <1>\nList<User> user = template.findAll(findByUserName, User.class);\n----\n\n[source,json]\n----\ndb.collection.find({\n \"lastname\" : \"Gamora\"\n},\n{\n \"firstname\" : 1,\n \"lastname\" : 1\n})\n----\n<1> A field projection on an unwrapped object includes all of its properties.\n====\n\n.Project on a field of an unwrapped object.\n====\n[source,java]\n----\nQuery findByUserLastName = query(where(\"name.lastname\").is(\"Smoak\"));\nfindByUserLastName.fields().include(\"name.firstname\"); <1>\nList<User> user = template.findAll(findByUserName, User.class);\n----\n\n[source,json]\n----\ndb.collection.find({\n \"lastname\" : \"Smoak\"\n},\n{\n \"firstname\" : 1\n})\n----\n<1> A field projection on an unwrapped object includes all of its properties.\n====\n\n[[unwrapped-entities.queries.by-example]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Field projection on unwrapped objects", "heading_level": 3, "file_order": 14, "section_index": 5, "content_hash": "8af621a170aad6f5f5cbd81aba36560dd107a832fce9b7d7d99aa6b7db8a333c", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:2379630b3758c9ae4e510fdec79303b27df4e7822d3e9fcb30f68a11460ab762", "content": "Unwrapped objects can be used within an `Example` probe just as any other type.\nPlease review the xref:mongodb/template-query-operations.adoc#mongo.query-by-example[Query By Example] section, to learn more about this feature.\n\n[[unwrapped-entities.queries.repository]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Query By Example on unwrapped object.", "heading_level": 3, "file_order": 14, "section_index": 6, "content_hash": "2379630b3758c9ae4e510fdec79303b27df4e7822d3e9fcb30f68a11460ab762", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:d1b35787727f2513db6086297475b2c527f4fff2d9223854af1d6c61b310516b", "content": "The `Repository` abstraction allows deriving queries on fields of unwrapped objects as well as the entire object.\n\n.Repository queries on unwrapped objects.\n====\n[source,java]\n----\ninterface UserRepository extends CrudRepository<User, String> {\n\n\tList<User> findByName(UserName username); <1>\n\n\tList<User> findByNameFirstname(String firstname); <2>\n}\n----\n<1> Matches against all fields of the unwrapped object.\n<2> Matches against the `firstname`.\n====\n\n[NOTE]\n====\nIndex creation for unwrapped objects is suspended even if the repository `create-query-indexes` namespace attribute is set to `true`.\n====\n\n[[unwrapped-entities.update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Repository Queries on unwrapped objects.", "heading_level": 3, "file_order": 14, "section_index": 7, "content_hash": "d1b35787727f2513db6086297475b2c527f4fff2d9223854af1d6c61b310516b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:383b3e732e1e89c535cd062f0323a3bf8c712e41e70aaef5f75f27b5603305c6", "content": "Unwrapped objects can be updated as any other object that is part of the domain model.\nThe mapping layer takes care of flattening structures into their surroundings.\nIt is possible to update single attributes of the unwrapped object as well as the entire value as shown in the examples below.\n\n.Update a single field of an unwrapped object.\n====\n[source,java]\n----\nUpdate update = new Update().set(\"name.firstname\", \"Janet\");\ntemplate.update(User.class).matching(where(\"id\").is(\"Wasp\"))\n .apply(update).first()\n----\n\n[source,json]\n----\ndb.collection.update({\n \"_id\" : \"Wasp\"\n},\n{\n \"$set\" { \"firstname\" : \"Janet\" }\n},\n{ ... }\n)\n----\n====\n\n.Update an unwrapped object.\n====\n[source,java]\n----\nUpdate update = new Update().set(\"name\", new Name(\"Janet\", \"van Dyne\"));\ntemplate.update(User.class).matching(where(\"id\").is(\"Wasp\"))\n .apply(update).first()\n----\n\n[source,json]\n----\ndb.collection.update({\n \"_id\" : \"Wasp\"\n},\n{\n \"$set\" {\n \"firstname\" : \"Janet\",\n \"lastname\" : \"van Dyne\",\n }\n},\n{ ... }\n)\n----\n====\n\n[[unwrapped-entities.aggregations]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Update on Unwrapped Objects", "heading_level": 2, "file_order": 14, "section_index": 8, "content_hash": "383b3e732e1e89c535cd062f0323a3bf8c712e41e70aaef5f75f27b5603305c6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:e2c2cf9b48367154f70b56d80112c23add72906dced1fd402c55f7de92a7c5a2", "content": "The xref:mongodb/aggregation-framework.adoc[Aggregation Framework] will attempt to map unwrapped values of typed aggregations.\nPlease make sure to work with the property path including the wrapper object when referencing one of its values.\nOther than that no special action is required.\n\n[[unwrapped-entities.indexes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Aggregations on Unwrapped Objects", "heading_level": 2, "file_order": 14, "section_index": 9, "content_hash": "e2c2cf9b48367154f70b56d80112c23add72906dced1fd402c55f7de92a7c5a2", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:707203827e2318762b00918a72104a64b1d9284439796a49e1f740b8c65070d0", "content": "It is possible to attach the `@Indexed` annotation to properties of an unwrapped type just as it is done with regular objects.\nIt is not possible to use `@Indexed` along with the `@Unwrapped` annotation on the owning property.\n\n====\n[source,java]\n----\npublic class User {\n\n\t@Id\n private String userId;\n\n @Unwrapped(onEmpty = USE_NULL)\n UserName name; <1>\n\n // Invalid -> InvalidDataAccessApiUsageException\n @Indexed <2>\n @Unwrapped(onEmpty = USE_Empty)\n Address address;\n}\n\npublic class UserName {\n\n private String firstname;\n\n @Indexed\n private String lastname; <1>\n}\n----\n<1> Index created for `lastname` in `users` collection.\n<2> Invalid `@Indexed` usage along with `@Unwrapped`\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc", "title": "unwrapping-entities", "heading": "Index on Unwrapped Objects", "heading_level": 2, "file_order": 14, "section_index": 10, "content_hash": "707203827e2318762b00918a72104a64b1d9284439796a49e1f740b8c65070d0", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mapping/unwrapping-entities.adoc"}}
{"id": "sha256:7095c0ab47a99203afc512fcc413ffd6d0cc722e82b720c2a7bac8514d51b342", "content": "[[mongodb.repositories.misc.cdi-integration]]\n\nInstances of the repository interfaces are usually created by a container, and Spring is the most natural choice when working with Spring Data.\nAs of version 1.3.0, Spring Data MongoDB ships with a custom CDI extension that lets you use the repository abstraction in CDI environments.\nThe extension is part of the JAR.\nTo activate it, drop the Spring Data MongoDB JAR into your classpath.\nYou can now set up the infrastructure by implementing a CDI Producer for the `MongoTemplate`, as the following example shows:\n\n[source,java]\n----\nclass MongoTemplateProducer {\n\n @Produces\n @ApplicationScoped\n public MongoOperations createMongoTemplate() {\n\n MongoDatabaseFactory factory = new SimpleMongoClientDatabaseFactory(MongoClients.create(), \"database\");\n return new MongoTemplate(factory);\n }\n}\n----\n\nThe Spring Data MongoDB CDI extension picks up the `MongoTemplate` available as a CDI bean and creates a proxy for a Spring Data repository whenever a bean of a repository type is requested by the container.\nThus, obtaining an instance of a Spring Data repository is a matter of declaring an `@Inject`-ed property, as the following example shows:\n\n[source,java]\n----\nclass RepositoryClient {\n\n @Inject\n PersonRepository repository;\n\n public void businessMethod() {\n List<Person> people = repository.findAll();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/cdi-integration.adoc", "title": "cdi-integration", "heading": "cdi-integration", "heading_level": 1, "file_order": 15, "section_index": 0, "content_hash": "7095c0ab47a99203afc512fcc413ffd6d0cc722e82b720c2a7bac8514d51b342", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/cdi-integration.adoc"}}
{"id": "sha256:1375fc2a2487be2b008c23a2e69146380fe7717b45cb608b31aad17205dac4f1", "content": "[[mongodb.repositories.queries]]\n\nNext to the xref:mongodb/repositories/query-methods.adoc[query methods] it is possible to update data with specialized methods.\n\n[[mongodb.repositories.queries.update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc", "title": "modifying-methods", "heading": "modifying-methods", "heading_level": 1, "file_order": 16, "section_index": 0, "content_hash": "1375fc2a2487be2b008c23a2e69146380fe7717b45cb608b31aad17205dac4f1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc"}}
{"id": "sha256:089be1c4fad6d78693a4f7d4ca08dd1883a2cfde12138300b745a2976c9e57f3", "content": "You can also use the keywords in the preceding table to create queries that identify matching documents for running updates on them.\nThe actual update action is defined by the `@Update` annotation on the method itself, as the following listing shows.\nNote that the naming schema for derived queries starts with `find`.\nUsing `update` (as in `updateAllByLastname(...)`) is allowed only in combination with `@Query`.\n\nThe update is applied to *all* matching documents and it is *not* possible to limit the scope by passing in a `Page` or by using any of the <<repositories.limit-query-result,limiting keywords>>.\nThe return type can be either `void` or a _numeric_ type, such as `long`, to hold the number of modified documents.\n\n.Update Methods\n====\n[source,java]\n----\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n @Update(\"{ '$inc' : { 'visits' : 1 } }\")\n long findAndIncrementVisitsByLastname(String lastname); <1>\n\n @Update(\"{ '$inc' : { 'visits' : ?1 } }\")\n void findAndIncrementVisitsByLastname(String lastname, int increment); <2>\n\n @Update(\"{ '$inc' : { 'visits' : ?#{[1]} } }\")\n long findAndIncrementVisitsUsingSpELByLastname(String lastname, int increment); <3>\n\n @Update(pipeline = {\"{ '$set' : { 'visits' : { '$add' : [ '$visits', ?1 ] } } }\"})\n void findAndIncrementVisitsViaPipelineByLastname(String lastname, int increment); <4>\n\n @Update(\"{ '$push' : { 'shippingAddresses' : ?1 } }\")\n long findAndPushShippingAddressByEmail(String email, Address address); <5>\n\n @Query(\"{ 'lastname' : ?0 }\")\n @Update(\"{ '$inc' : { 'visits' : ?1 } }\")\n void updateAllByLastname(String lastname, int increment); <6>\n}\n----\n\n<1> The filter query for the update is derived from the method name.\nThe update is \"`as is`\" and does not bind any parameters.\n<2> The actual increment value is defined by the `increment` method argument that is bound to the `?1` placeholder.\n<3> Use the Spring Expression Language (SpEL) for parameter binding.\n<4> Use the `pipeline` attribute to issue xref:mongodb/template-crud-operations.adoc#mongo-template.aggregation-update[aggregation pipeline updates].\n<5> The update may contain complex objects.\n<6> Combine a xref:mongodb/repositories/repositories.adoc#mongodb.repositories.queries.json-based[string based query] with an update.\n====\n\nWARNING: Repository updates do not emit persistence nor mapping lifecycle events.\n\n[[mongodb.repositories.queries.delete]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc", "title": "modifying-methods", "heading": "Update Methods", "heading_level": 2, "file_order": 16, "section_index": 1, "content_hash": "089be1c4fad6d78693a4f7d4ca08dd1883a2cfde12138300b745a2976c9e57f3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc"}}
{"id": "sha256:88b243485e4932e75c184adc85b549036af9f4647aa42f4cd20dde9a3c66b524", "content": "The keywords in the preceding table can be used in conjunction with `delete…By` or `remove…By` to create queries that delete matching documents.\n\n.`Delete…By` Query\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n List <Person> deleteByLastname(String lastname); <1>\n\n Long deletePersonByLastname(String lastname); <2>\n\n @Nullable\n Person deleteSingleByLastname(String lastname); <3>\n\n Optional<Person> deleteByBirthdate(Date birthdate); <4>\n}\n----\n<1> Using a return type of `List` retrieves and returns all matching documents before actually deleting them.\n<2> A numeric return type directly removes the matching documents, returning the total number of documents removed.\n<3> A single domain type result retrieves and removes the first matching document.\n<4> Same as in 3 but wrapped in an `Optional` type.\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n Flux<Person> deleteByLastname(String lastname); <1>\n\n Mono<Long> deletePersonByLastname(String lastname); <2>\n\n Mono<Person> deleteSingleByLastname(String lastname); <3>\n}\n----\n<1> Using a return type of `Flux` retrieves and returns all matching documents before actually deleting them.\n<2> A numeric return type directly removes the matching documents, returning the total number of documents removed.\n<3> A single domain type result retrieves and removes the first matching document.\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc", "title": "modifying-methods", "heading": "Delete Methods", "heading_level": 2, "file_order": 16, "section_index": 2, "content_hash": "88b243485e4932e75c184adc85b549036af9f4647aa42f4cd20dde9a3c66b524", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/modifying-methods.adoc"}}
{"id": "sha256:0825db3562f1d163131284d531df2fffd9e4b4c6c8a540c7d4ffd14abab2287a", "content": "[[mongodb.repositories.queries]]\n\nMost of the data access operations you usually trigger on a repository result in a query being executed against the MongoDB databases.\nDefining such a query is a matter of declaring a method on the repository interface, as the following example shows:\n\n.PersonRepository with query methods\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends PagingAndSortingRepository<Person, String> {\n\n List<Person> findByLastname(String lastname); <1>\n\n Page<Person> findByFirstname(String firstname, Pageable pageable); <2>\n\n Person findByShippingAddresses(Address address); <3>\n\n Person findFirstByLastname(String lastname); <4>\n\n Stream<Person> findAllBy(); <5>\n}\n----\n<1> The `findByLastname` method shows a query for all people with the given last name.\nThe query is derived by parsing the method name for constraints that can be concatenated with `And` and `Or`.\nThus, the method name results in a query expression of `{\"lastname\" : lastname}`.\n<2> Applies pagination to a query.\nYou can equip your method signature with a `Pageable` parameter and let the method return a `Page` instance and Spring Data automatically pages the query accordingly.\n<3> Shows that you can query based on properties that are not primitive types.\nThrows `IncorrectResultSizeDataAccessException` if more than one match is found.\n<4> Uses the `First` keyword to restrict the query to only the first result.\nUnlike <3>, this method does not throw an exception if more than one match is found.\n<5> Uses a Java 8 `Stream` that reads and converts individual elements while iterating the stream.\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface ReactivePersonRepository extends ReactiveSortingRepository<Person, String> {\n\n Flux<Person> findByFirstname(String firstname); <1>\n\n Flux<Person> findByFirstname(Publisher<String> firstname); <2>\n\n Flux<Person> findByFirstnameOrderByLastname(String firstname, Pageable pageable); <3>\n\n Mono<Person> findByFirstnameAndLastname(String firstname, String lastname); <4>\n\n Mono<Person> findFirstByLastname(String lastname); <5>\n}\n----\n<1> The method shows a query for all people with the given `lastname`. The query is derived by parsing the method name for constraints that can be concatenated with `And` and `Or`. Thus, the method name results in a query expression of `{\"lastname\" : lastname}`.\n<2> The method shows a query for all people with the given `firstname` once the `firstname` is emitted by the given `Publisher`.\n<3> Use `Pageable` to pass offset and sorting parameters to the database.\n<4> Find a single entity for the given criteria. It completes with `IncorrectResultSizeDataAccessException` on non-unique results.\n<5> Unless <4>, the first entity is always emitted even if the query yields more result documents.\n\nWARNING: The `Page` return type (as in `Mono<Page>`) is not supported by reactive repositories.\n\nIt is possible to use `Pageable` in derived finder methods, to pass on `sort`, `limit` and `offset` parameters to the query to reduce load and network traffic.\nThe returned `Flux` will only emit data within the declared range.\n\n[source,java]\n----\nPageable page = PageRequest.of(1, 10, Sort.by(\"lastname\"));\nFlux<Person> persons = repository.findByFirstnameOrderByLastname(\"luke\", page);\n----\n====\n======\n\nNOTE: We do not support referring to parameters that are mapped as `DBRef` in the domain class.\n\n.Supported keywords for query methods\n[%collapsible]\n====\n[cols=\"1,2,3\",options=\"header\"]\n|===\n| Keyword\n| Sample\n| Logical result\n\n| `After`\n| `findByBirthdateAfter(Date date)`\n| `{\"birthdate\" : {\"$gt\" : date}}`\n\n| `GreaterThan`\n| `findByAgeGreaterThan(int age)`\n| `{\"age\" : {\"$gt\" : age}}`\n\n| `GreaterThanEqual`\n| `findByAgeGreaterThanEqual(int age)`\n| `{\"age\" : {\"$gte\" : age}}`\n\n| `Before`\n| `findByBirthdateBefore(Date date)`\n| `{\"birthdate\" : {\"$lt\" : date}}`\n\n| `LessThan`\n| `findByAgeLessThan(int age)`\n| `{\"age\" : {\"$lt\" : age}}`\n\n| `LessThanEqual`\n| `findByAgeLessThanEqual(int age)`\n| `{\"age\" : {\"$lte\" : age}}`\n\n| `Between`\n| `findByAgeBetween(int from, int to)` +\n`findByAgeBetween(Range<Integer> range)`\n| `{\"age\" : {\"$gt\" : from, \"$lt\" : to}}` +\nlower / upper bounds (`$gt` / `$gte` & `$lt` / `$lte`) according to `Range`\n\n| `In`\n| `findByAgeIn(Collection ages)`\n| `{\"age\" : {\"$in\" : [ages...]}}`\n\n| `NotIn`\n| `findByAgeNotIn(Collection ages)`\n| `{\"age\" : {\"$nin\" : [ages...]}}`\n\n| `IsNotNull`, `NotNull`\n| `findByFirstnameNotNull()`\n| `{\"firstname\" : {\"$ne\" : null}}`\n\n| `IsNull`, `Null`\n| `findByFirstnameNull()`\n| `{\"firstname\" : null}`\n\n| `Like`, `StartingWith`, `EndingWith`\n| `findByFirstnameLike(String name)`\n| `{\"firstname\" : name} (name as regex)`\n\n| `NotLike`, `IsNotLike`\n| `findByFirstnameNotLike(String name)`\n| `{\"firstname\" : { \"$not\" : name }} (name as regex)`\n\n| `Containing` on String\n| `findByFirstnameContaining(String name)`\n| `{\"firstname\" : name} (name as regex)`\n\n| `NotContaining` on String\n| `findByFirstnameNotContaining(String name)`\n| `{\"firstname\" : { \"$not\" : name}} (name as regex)`\n\n| `Containing` on Collection\n| `findByAddressesContaining(Address address)`\n| `{\"addresses\" : { \"$in\" : address}}`\n\n| `NotContaining` on Collection\n| `findByAddressesNotContaining(Address address)`\n| `{\"addresses\" : { \"$not\" : { \"$in\" : address}}}`\n\n| `Regex`\n| `findByFirstnameRegex(String firstname)`\n| `{\"firstname\" : {\"$regex\" : firstname }}`\n\n| `(No keyword)`\n| `findByFirstname(String name)`\n| `{\"firstname\" : name}`\n\n| `Not`\n| `findByFirstnameNot(String name)`\n| `{\"firstname\" : {\"$ne\" : name}}`\n\n| `Near`\n| `findByLocationNear(Point point)`\n| `{\"location\" : {\"$near\" : [x,y]}}`\n\n| `Near`\n| `findByLocationNear(Point point, Distance max)`\n| `{\"location\" : {\"$near\" : [x,y], \"$maxDistance\" : max}}`\n\n| `Near`\n| `findByLocationNear(Point point, Distance min, Distance max)`\n| `{\"location\" : {\"$near\" : [x,y], \"$minDistance\" : min, \"$maxDistance\" : max}}`\n\n| `Within`\n| `findByLocationWithin(Circle circle)`\n| `{\"location\" : {\"$geoWithin\" : {\"$center\" : [ [x, y], distance]}}}`\n\n| `Within`\n| `findByLocationWithin(Box box)`\n| `{\"location\" : {\"$geoWithin\" : {\"$box\" : [ [x1, y1], x2, y2]}}}`\n\n| `IsTrue`, `True`\n| `findByActiveIsTrue()`\n| `{\"active\" : true}`\n\n| `IsFalse`, `False`\n| `findByActiveIsFalse()`\n| `{\"active\" : false}`\n\n| `Exists`\n| `findByLocationExists(boolean exists)`\n| `{\"location\" : {\"$exists\" : exists }}`\n\n| `IgnoreCase`\n| `findByUsernameIgnoreCase(String username)`\n| `{\"username\" : {\"$regex\" : \"^username$\", \"$options\" : \"i\" }}`\n|===\n====\n\nNOTE: If the property criterion compares a document, the order of the fields and exact equality in the document matters.\n\nNOTE: In some scenarios, you might require additional options, such as a maximum run time, additional log comments, or the permission to temporarily write data to disk.\nUse the `@Meta` annotation to set those options via `maxExecutionTimeMs`, `comment` or `allowDiskUse`. `@Meta` can only be used on repository query methods, not on base interface or fragment interface methods.\n\n[[mongodb.repositories.queries.geo-spatial]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "query-methods", "heading_level": 1, "file_order": 17, "section_index": 0, "content_hash": "0825db3562f1d163131284d531df2fffd9e4b4c6c8a540c7d4ffd14abab2287a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:76b65348d59086a12dadb777d0d98302e94c7fcebb202b5dc4f99943880637b6", "content": "As you saw in the preceding table of keywords, a few keywords trigger geo-spatial operations within a MongoDB query.\nThe `Near` and `Within` keywords allows some further modification, as the next few examples show.\n\nThe following example shows how to define a `near` / `within` query that finds all persons using different shapes:\n\n.Advanced `Near` queries\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n // { 'location' : { '$near' : [point.x, point.y], '$maxDistance' : distance } }\n List<Person> findByLocationNear(Point location, Distance distance);\n\n // { 'location' : { $geoWithin: { $center: [ [ circle.center.x, circle.center.y ], circle.radius ] } } }\n List<Person> findByLocationWithin(Circle circle);\n\n // { 'location' : { $geoWithin: { $box: [ [ box.first.x, box.first.y ], [ box.second.x, box.second.y ] ] } } }\n List<Person> findByLocationWithin(Box box);\n\n // { 'location' : { $geoWithin: { $polygon: [ [ polygon.x1, polygon.y1 ], [ polygon.x2, polygon.y2 ], ... ] } } }\n List<Person> findByLocationWithin(Polygon polygon);\n\n // { 'location' : { $geoWithin: { $geometry: { $type : 'polygon', coordinates: [[ polygon.x1, polygon.y1 ], [ polygon.x2, polygon.y2 ], ... ] } } } }\n List<Person> findByLocationWithin(GeoJsonPolygon polygon);\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ninterface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n // { 'location' : { '$near' : [point.x, point.y], '$maxDistance' : distance } }\n Flux<Person> findByLocationNear(Point location, Distance distance);\n\n // { 'location' : { $geoWithin: { $center: [ [ circle.center.x, circle.center.y ], circle.radius ] } } }\n Flux<Person> findByLocationWithin(Circle circle);\n\n // { 'location' : { $geoWithin: { $box: [ [ box.first.x, box.first.y ], [ box.second.x, box.second.y ] ] } } }\n Flux<Person> findByLocationWithin(Box box);\n\n // { 'location' : { $geoWithin: { $polygon: [ [ polygon.x1, polygon.y1 ], [ polygon.x2, polygon.y2 ], ... ] } } }\n Flux<Person> findByLocationWithin(Polygon polygon);\n\n // { 'location' : { $geoWithin: { $geometry: { $type : 'polygon', coordinates: [[ polygon.x1, polygon.y1 ], [ polygon.x2, polygon.y2 ], ... ] } } } }\n Flux<Person> findByLocationWithin(GeoJsonPolygon polygon);\n}\n----\n======\n\nAdding a `Distance` parameter to the query method allows restricting results to those within the given distance.\nIf the `Distance` was set up containing a `Metric`, we transparently use `$nearSphere` instead of `$code`, as the following example shows:\n\n.Using `Distance` with `Metrics`\n====\n[source,java]\n----\nPoint point = new Point(43.7, 48.8);\nDistance distance = new Distance(200, Metrics.KILOMETERS);\n… = repository.findByLocationNear(point, distance);\n----\n====\n\nNOTE: Reactive Geo-spatial repository queries support the domain type and `GeoResult<T>` results within a reactive wrapper type. `GeoPage` and `GeoResults` are not supported as they contradict the deferred result approach with pre-calculating the average distance. However, you can still pass in a `Pageable` argument to page results yourself.\n\nUsing a `Distance` with a `Metric` causes a `$nearSphere` (instead of a plain `$near`) clause to be added.\nBeyond that, the actual distance gets calculated according to the `Metrics` used.\n\n(Note that `Metric` does not refer to metric units of measure.\nIt could be miles rather than kilometers.\nRather, `metric` refers to the concept of a system of measurement, regardless of which system you use.)\n\nNOTE: Using `@GeoSpatialIndexed(type = GeoSpatialIndexType.GEO_2DSPHERE)` on the target property forces usage of the `$nearSphere` operator.\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n // {'geoNear' : 'location', 'near' : [x, y] }\n GeoResults<Person> findByLocationNear(Point location);\n\n // No metric: {'geoNear' : 'person', 'near' : [x, y], maxDistance : distance }\n // Metric: {'geoNear' : 'person', 'near' : [x, y], 'maxDistance' : distance,\n // 'distanceMultiplier' : metric.multiplier, 'spherical' : true }\n GeoResults<Person> findByLocationNear(Point location, Distance distance);\n\n // Metric: {'geoNear' : 'person', 'near' : [x, y], 'minDistance' : min,\n // 'maxDistance' : max, 'distanceMultiplier' : metric.multiplier,\n // 'spherical' : true }\n GeoResults<Person> findByLocationNear(Point location, Distance min, Distance max);\n\n // {'geoNear' : 'location', 'near' : [x, y] }\n GeoResults<Person> findByLocationNear(Point location);\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ninterface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n // {'geoNear' : 'location', 'near' : [x, y] }\n Flux<GeoResult<Person>> findByLocationNear(Point location);\n\n // No metric: {'geoNear' : 'person', 'near' : [x, y], maxDistance : distance }\n // Metric: {'geoNear' : 'person', 'near' : [x, y], 'maxDistance' : distance,\n // 'distanceMultiplier' : metric.multiplier, 'spherical' : true }\n Flux<GeoResult<Person>> findByLocationNear(Point location, Distance distance);\n\n // Metric: {'geoNear' : 'person', 'near' : [x, y], 'minDistance' : min,\n // 'maxDistance' : max, 'distanceMultiplier' : metric.multiplier,\n // 'spherical' : true }\n Flux<GeoResult<Person>> findByLocationNear(Point location, Distance min, Distance max);\n\n // {'geoNear' : 'location', 'near' : [x, y] }\n Flux<GeoResult<Person>> findByLocationNear(Point location);\n}\n----\n======\n\n[[mongodb.repositories.queries.json-based]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Geo-spatial Queries", "heading_level": 2, "file_order": 17, "section_index": 1, "content_hash": "76b65348d59086a12dadb777d0d98302e94c7fcebb202b5dc4f99943880637b6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:2a1e8d5d658f083ef3d1867f86f4080924041766c487ea076ea6f86a87ee63a6", "content": "By adding the `org.springframework.data.mongodb.repository.Query` annotation to your repository query methods, you can specify a MongoDB JSON query string to use instead of having the query be derived from the method name, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n @Query(\"{ 'firstname' : ?0 }\")\n List<Person> findByThePersonsFirstname(String firstname);\n\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n @Query(\"{ 'firstname' : ?0 }\")\n Flux<Person> findByThePersonsFirstname(String firstname);\n\n}\n----\n======\n\nThe `?0` placeholder lets you substitute the value from the method arguments into the JSON query string.\n\nNOTE: `String` parameter values are escaped during the binding process, which means that it is not possible to add MongoDB specific operators through the argument.\n\nYou can also use the filter property to restrict the set of properties that is mapped into the Java object, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n @Query(value=\"{ 'firstname' : ?0 }\", fields=\"{ 'firstname' : 1, 'lastname' : 1}\")\n List<Person> findByThePersonsFirstname(String firstname);\n\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n @Query(value=\"{ 'firstname' : ?0 }\", fields=\"{ 'firstname' : 1, 'lastname' : 1}\")\n Flux<Person> findByThePersonsFirstname(String firstname);\n\n}\n----\n======\n\nThe query in the preceding example returns only the `firstname`, `lastname` and `Id` properties of the `Person` objects.\nThe `age` property, a `java.lang.Integer`, is not set and its value is therefore null.\n\n[[mongodb.repositories.queries.json-spel]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "JSON-based Query Methods and Field Restriction", "heading_level": 2, "file_order": 17, "section_index": 2, "content_hash": "2a1e8d5d658f083ef3d1867f86f4080924041766c487ea076ea6f86a87ee63a6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:08d931437f7d97c6277c56d2c4f0096e5bc82100ab09bce9e14a0936db3b281b", "content": "Query strings and field definitions can be used together with SpEL expressions to create dynamic queries at runtime.\nSpEL expressions can provide predicate values and can be used to extend predicates with subdocuments.\n\nExpressions expose method arguments through an array that contains all the arguments.\nThe following query uses `[0]`\nto declare the predicate value for `lastname` (which is equivalent to the `?0` parameter binding):\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n @Query(\"{'lastname': ?#{[0]} }\")\n List<Person> findByQueryWithExpression(String param0);\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n @Query(\"{'lastname': ?#{[0]} }\")\n Flux<Person> findByQueryWithExpression(String param0);\n}\n----\n======\n\nExpressions can be used to invoke functions, evaluate conditionals, and construct values.\nSpEL expressions used in conjunction with JSON reveal a side effect, because Map-like declarations inside of SpEL read like JSON, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n @Query(\"{'id': ?#{ [0] ? {$exists :true} : [1] }}\")\n List<Person> findByQueryWithExpressionAndNestedObject(boolean param0, String param1);\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n @Query(\"{'id': ?#{ [0] ? {$exists :true} : [1] }}\")\n Flux<Person> findByQueryWithExpressionAndNestedObject(boolean param0, String param1);\n}\n----\n======\n\nWARNING: SpEL in query strings can be a powerful way to enhance queries.\nHowever, they can also accept a broad range of unwanted arguments.\nMake sure to sanitize strings before passing them to the query to avoid creation of vulnerabilities or unwanted changes to your query.\n\nExpression support is extensible through the Query SPI: `EvaluationContextExtension` & `ReactiveEvaluationContextExtension`\nThe Query SPI can contribute properties and functions and can customize the root object.\nExtensions are retrieved from the application context at the time of SpEL evaluation when the query is built.\nThe following example shows how to use an evaluation context extension:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic class SampleEvaluationContextExtension extends EvaluationContextExtensionSupport {\n\n @Override\n public String getExtensionId() {\n return \"security\";\n }\n\n @Override\n public Map<String, Object> getProperties() {\n return Collections.singletonMap(\"principal\", SecurityContextHolder.getCurrent().getPrincipal());\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic class SampleEvaluationContextExtension implements ReactiveEvaluationContextExtension {\n\n @Override\n public String getExtensionId() {\n return \"security\";\n }\n\n @Override\n public Mono<? extends EvaluationContextExtension> getExtension() {\n return Mono.just(new EvaluationContextExtensionSupport() { ... });\n }\n}\n----\n======\n\nNOTE: Bootstrapping `MongoRepositoryFactory` yourself is not application context-aware and requires further configuration to pick up Query SPI extensions.\n\nNOTE: Reactive query methods can make use of `org.springframework.data.spel.spi.ReactiveEvaluationContextExtension`.\n\n[[mongodb.repositories.queries.full-text]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "JSON-based Queries with SpEL Expressions", "heading_level": 2, "file_order": 17, "section_index": 3, "content_hash": "08d931437f7d97c6277c56d2c4f0096e5bc82100ab09bce9e14a0936db3b281b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:d4f8709c7aa431aa02429e0d9efdaf8ff1e4006bca0476eac72e91ecc2225074", "content": "MongoDB's full-text search feature is store-specific and, therefore, can be found on `MongoRepository` rather than on the more general `CrudRepository`.\nWe need a document with a full-text index (see \"`xref:mongodb/mapping/mapping.adoc#mapping-usage-indexes.text-index[Text Indexes]`\" to learn how to create a full-text index).\n\nAdditional methods on `MongoRepository` take `TextCriteria` as an input parameter.\nIn addition to those explicit methods, it is also possible to add a `TextCriteria`-derived repository method.\nThe criteria are added as an additional `AND` criteria.\nOnce the entity contains a `@TextScore`-annotated property, the document's full-text score can be retrieved.\nFurthermore, the `@TextScore` annotated also makes it possible to sort by the document's score, as the following example shows:\n\n[source,java]\n----\n@Document\nclass FullTextDocument {\n\n @Id String id;\n @TextIndexed String title;\n @TextIndexed String content;\n @TextScore Float score;\n}\n\ninterface FullTextRepository extends Repository<FullTextDocument, String> {\n\n // Execute a full-text search and define sorting dynamically\n List<FullTextDocument> findAllBy(TextCriteria criteria, Sort sort);\n\n // Paginate over a full-text search result\n Page<FullTextDocument> findAllBy(TextCriteria criteria, Pageable pageable);\n\n // Combine a derived query with a full-text search\n List<FullTextDocument> findByTitleOrderByScoreDesc(String title, TextCriteria criteria);\n}\n\nSort sort = Sort.by(\"score\");\nTextCriteria criteria = TextCriteria.forDefaultLanguage().matchingAny(\"spring\", \"data\");\nList<FullTextDocument> result = repository.findAllBy(criteria, sort);\n\ncriteria = TextCriteria.forDefaultLanguage().matching(\"film\");\nPage<FullTextDocument> page = repository.findAllBy(criteria, PageRequest.of(1, 1, sort));\nList<FullTextDocument> result = repository.findByTitleOrderByScoreDesc(\"mongodb\", criteria);\n----\n\n[[mongodb.repositories.queries.aggregation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Full-text Search Queries", "heading_level": 2, "file_order": 17, "section_index": 4, "content_hash": "d4f8709c7aa431aa02429e0d9efdaf8ff1e4006bca0476eac72e91ecc2225074", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:69ac92f82f0b9e408861c9036a7e944a9f42267ddb185f8edda0615a7490252a", "content": "The repository layer offers means to interact with xref:mongodb/aggregation-framework.adoc[the aggregation framework] via annotated repository query methods.\nSimilar to the xref:mongodb/repositories/repositories.adoc#mongodb.repositories.queries.json-based[JSON based queries], you can define a pipeline using the `org.springframework.data.mongodb.repository.Aggregation` annotation.\nThe definition may contain simple placeholders like `?0` as well as link:{springDocsUrl}/core.html#expressions[SpEL expressions] `?#{ … }`.\n\n.Aggregating Repository Method\n====\n[source,java]\n----\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : $firstname } } }\")\n List<PersonAggregate> groupByLastnameAndFirstnames(); <1>\n\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : $firstname } } }\")\n List<PersonAggregate> groupByLastnameAndFirstnames(Sort sort); <2>\n\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : ?0 } } }\")\n List<PersonAggregate> groupByLastnameAnd(String property); <3>\n\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : ?0 } } }\")\n Slice<PersonAggregate> groupByLastnameAnd(String property, Pageable page); <4>\n\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : $firstname } } }\")\n Stream<PersonAggregate> groupByLastnameAndFirstnamesAsStream(); <5>\n\n @Aggregation(pipeline = {\n \"{ '$match' : { 'lastname' : '?0'} }\",\n \"{ '$project': { _id : 0, firstname : 1, lastname : 1 } }\"\n })\n Stream<PersonAggregate> groupByLastnameAndFirstnamesAsStream(); <6>\n\n @Aggregation(\"{ $group : { _id : null, total : { $sum : $age } } }\")\n SumValue sumAgeUsingValueWrapper(); <7>\n\n @Aggregation(\"{ $group : { _id : null, total : { $sum : $age } } }\")\n Long sumAge(); <8>\n\n @Aggregation(\"{ $group : { _id : null, total : { $sum : $age } } }\")\n AggregationResults<SumValue> sumAgeRaw(); <9>\n\n @Aggregation(\"{ '$project': { '_id' : '$lastname' } }\")\n List<String> findAllLastnames(); <10>\n\n @Aggregation(pipeline = {\n \"{ $group : { _id : '$author', books: { $push: '$title' } } }\",\n \"{ $out : 'authors' }\"\n })\n void groupAndOutSkippingOutput(); <11>\n}\n----\n[source,java]\n----\npublic class PersonAggregate {\n\n private @Id String lastname; <2>\n private List<String> names;\n\n public PersonAggregate(String lastname, List<String> names) {\n // ...\n }\n\n // Getter / Setter omitted\n}\n\npublic class SumValue {\n\n private final Long total; <6> <8>\n\n public SumValue(Long total) {\n // ...\n }\n\n // Getter omitted\n}\n\ninterface PersonProjection {\n String getFirstname();\n String getLastname();\n}\n----\n<1> Aggregation pipeline to group first names by `lastname` in the `Person` collection returning these as `PersonAggregate`.\n<2> If `Sort` argument is present, `$sort` is appended after the declared pipeline stages so that it only affects the order of the final results after having passed all other aggregation stages.\nTherefore, the `Sort` properties are mapped against the methods return type `PersonAggregate` which turns `Sort.by(\"lastname\")` into `{ $sort : { '_id', 1 } }` because `PersonAggregate.lastname` is annotated with `@Id`.\n<3> Replaces `?0` with the given value for `property` for a dynamic aggregation pipeline.\n<4> `$skip`, `$limit` and `$sort` can be passed on via a `Pageable` argument. Same as in <2>, the operators are appended to the pipeline definition. Methods accepting `Pageable` can return `Slice` for easier pagination.\n<5> Aggregation methods can return interface based projections wrapping the resulting `org.bson.Document` behind a proxy, exposing getters delegating to fields within the document.\n<6> Aggregation methods can return `Stream` to consume results directly from an underlying cursor. Make sure to close the stream after consuming it to release the server-side cursor by either calling `close()` or through `try-with-resources`.\n<7> Map the result of an aggregation returning a single `Document` to an instance of a desired `SumValue` target type.\n<8> Aggregations resulting in single document holding just an accumulation result like e.g. `$sum` can be extracted directly from the result `Document`.\nTo gain more control, you might consider `AggregationResult` as method return type as shown in <7>.\n<9> Obtain the raw `AggregationResults` mapped to the generic target wrapper type `SumValue` or `org.bson.Document`.\n<10> Like in <6>, a single value can be directly obtained from multiple result ``Document``s.\n<11> Skips the output of the `$out` stage when return type is `void`.\n====\n\nIn some scenarios, aggregations might require additional options, such as a maximum run time, additional log comments, or the permission to temporarily write data to disk.\nUse the `@Meta` annotation to set those options via `maxExecutionTimeMs`, `comment` or `allowDiskUse`.\n\n[source,java]\n----\ninterface PersonRepository extends CrudRepository<Person, String> {\n\n @Meta(allowDiskUse = \"true\")\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : $firstname } } }\")\n List<PersonAggregate> groupByLastnameAndFirstnames();\n}\n----\n\nOr use `@Meta` to create your own annotation as shown in the sample below.\n\n[source,java]\n----\n@Retention(RetentionPolicy.RUNTIME)\n@Target({ ElementType.METHOD })\n@Meta(allowDiskUse = \"true\")\n@interface AllowDiskUse { }\n\ninterface PersonRepository extends CrudRepository<Person, String> {\n\n @AllowDiskUse\n @Aggregation(\"{ $group: { _id : $lastname, names : { $addToSet : $firstname } } }\")\n List<PersonAggregate> groupByLastnameAndFirstnames();\n}\n----\n\n[NOTE]\n====\nSimple-type single-result inspects the returned `Document` and checks for the following:\n\n. Only one entry in the document, return it.\n. Two entries, one is the `_id` value. Return the other.\n. Return for the first value assignable to the return type.\n. Throw an exception if none of the above is applicable.\n====\n\nWARNING: The `Page` return type is not supported for repository methods using `@Aggregation`. However, you can use a\n`Pageable` argument to add `$skip`, `$limit` and `$sort` to the pipeline and let the method return `Slice`.\n\n[[mongodb.repositories.queries.by-example]]\ninclude::{commons}@data-commons::query-by-example.adoc[]\n\n[[query-by-example.running]]\n== Running an Example\n\nThe following example shows how to query by example when using a repository (of `Person` objects, in this case):\n\n.Query by Example using a repository\n====\n[source, java]\n----\npublic interface PersonRepository extends QueryByExampleExecutor<Person> {\n\n}\n\npublic class PersonService {\n\n  @Autowired PersonRepository personRepository;\n\n  public List<Person> findPeople(Person probe) {\n    return personRepository.findAll(Example.of(probe));\n  }\n}\n----\n====\n\n[[mongodb.repositories.queries.scroll]]\ninclude::{commons}@data-commons::page$repositories/scrolling.adoc[leveloffset=+1]\n\n[[mongodb.repositories.queries.sort]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Aggregation Methods", "heading_level": 2, "file_order": 17, "section_index": 5, "content_hash": "69ac92f82f0b9e408861c9036a7e944a9f42267ddb185f8edda0615a7490252a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:f1a5d4b13bfa773a381104af371b21c3b41831df3ac34eb393d58a803283522b", "content": "MongoDB repositories allow various approaches to define sorting order.\nLet's take a look at the following example:\n\n.Sorting Query Results\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n List<Person> findByFirstnameSortByAgeDesc(String firstname); <1>\n\n List<Person> findByFirstname(String firstname, Sort sort); <2>\n\n @Query(sort = \"{ age : -1 }\")\n List<Person> findByFirstname(String firstname); <3>\n\n @Query(sort = \"{ age : -1 }\")\n List<Person> findByLastname(String lastname, Sort sort); <4>\n}\n----\n<1> Static sorting derived from method name. `SortByAgeDesc` results in `{ age : -1 }` for the sort parameter.\n<2> Dynamic sorting using a method argument.\n`Sort.by(DESC, \"age\")` creates `{ age : -1 }` for the sort parameter.\n<3> Static sorting via `Query` annotation.\nSort parameter applied as stated in the `sort` attribute.\n<4> Default sorting via `Query` annotation combined with dynamic one via a method argument. `Sort.unsorted()`\nresults in `{ age : -1 }`.\nUsing `Sort.by(ASC, \"age\")` overrides the defaults and creates `{ age : 1 }`.\n`Sort.by\n(ASC, \"firstname\")` alters the default and results in `{ age : -1, firstname : 1 }`.\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n Flux<Person> findByFirstnameSortByAgeDesc(String firstname);\n\n Flux<Person> findByFirstname(String firstname, Sort sort);\n\n @Query(sort = \"{ age : -1 }\")\n Flux<Person> findByFirstname(String firstname);\n\n @Query(sort = \"{ age : -1 }\")\n Flux<Person> findByLastname(String lastname, Sort sort);\n}\n----\n======\n\n[[mongodb.repositories.index-hint]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Sorting Results", "heading_level": 2, "file_order": 17, "section_index": 6, "content_hash": "f1a5d4b13bfa773a381104af371b21c3b41831df3ac34eb393d58a803283522b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:7a91b289e53f7cc646793823d79ad4ad9f73ab89d87d9cd65b893eb2741d4c8e", "content": "The `@Hint` annotation allows to override MongoDB's default index selection and forces the database to use the specified index instead.\n\n.Example of index hints\n====\n[source,java]\n----\n@Hint(\"lastname-idx\") <1>\nList<Person> findByLastname(String lastname);\n\n@Query(value = \"{ 'firstname' : ?0 }\", hint = \"firstname-idx\") <2>\nList<Person> findByFirstname(String firstname);\n----\n<1> Use the index with name `lastname-idx`.\n<2> The `@Query` annotation defines the `hint` alias which is equivalent to adding the `@Hint` annotation.\n====\n\nFor more information about index creation please refer to the xref:mongodb/template-collection-management.adoc[Collection Management] section.\n\n[[mongo.repositories.collation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Index Hints", "heading_level": 2, "file_order": 17, "section_index": 7, "content_hash": "7a91b289e53f7cc646793823d79ad4ad9f73ab89d87d9cd65b893eb2741d4c8e", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:4dddca7916ba3d9d1efb0814a2d0b174a210f5a3770070d2d83b34c9a2282630", "content": "Next to the xref:mongodb/collation.adoc[general Collation Support] repositories allow to define the collation for various operations.\n\n====\n[source,java]\n----\npublic interface PersonRepository extends MongoRepository<Person, String> {\n\n @Query(collation = \"en_US\") <1>\n List<Person> findByFirstname(String firstname);\n\n @Query(collation = \"{ 'locale' : 'en_US' }\") <2>\n List<Person> findPersonByFirstname(String firstname);\n\n @Query(collation = \"?1\") <3>\n List<Person> findByFirstname(String firstname, Object collation);\n\n @Query(collation = \"{ 'locale' : '?1' }\") <4>\n List<Person> findByFirstname(String firstname, String collation);\n\n List<Person> findByFirstname(String firstname, Collation collation); <5>\n\n @Query(collation = \"{ 'locale' : 'en_US' }\")\n List<Person> findByFirstname(String firstname, @Nullable Collation collation); <6>\n}\n----\n<1> Static collation definition resulting in `{ 'locale' : 'en_US' }`.\n<2> Static collation definition resulting in `{ 'locale' : 'en_US' }`.\n<3> Dynamic collation depending on 2nd method argument. Allowed types include `String` (eg. 'en_US'), `Locacle` (eg. Locacle.US)\nand `Document` (eg. new Document(\"locale\", \"en_US\"))\n<4> Dynamic collation depending on 2nd method argument.\n<5> Apply the `Collation` method parameter to the query.\n<6> The `Collation` method parameter overrides the default `collation` from `@Query` if not null.\n\nNOTE: In case you enabled the automatic index creation for repository finder methods a potential static collation definition,\nas shown in (1) and (2), will be included when creating the index.\n\nTIP: The most specifc `Collation` outrules potentially defined others. Which means Method argument over query method annotation over domain type annotation.\n====\n\nTo streamline usage of collation attributes throughout the codebase it is also possible to use the `@Collation` annotation, which serves as a meta annotation for the ones mentioned above.\nThe same rules and locations apply, plus, direct usage of `@Collation` supersedes any collation values defined on `@Query` and other annotations.\nWhich means, if a collation is declared via `@Query` and additionally via `@Collation`, then the one from `@Collation` is picked.\n\n.Using `@Collation`\n====\n[source,java]\n----\n@Collation(\"en_US\") <1>\nclass Game {\n // ...\n}\n\ninterface GameRepository extends Repository<Game, String> {\n\n @Collation(\"en_GB\") <2>\n List<Game> findByTitle(String title);\n\n @Collation(\"de_AT\") <3>\n @Query(collation=\"en_GB\")\n List<Game> findByDescriptionContaining(String keyword);\n}\n----\n<1> Instead of `@Document(collation=...)`.\n<2> Instead of `@Query(collation=...)`.\n<3> Favors `@Collation` over meta usage.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Collation Support", "heading_level": 2, "file_order": 17, "section_index": 8, "content_hash": "4dddca7916ba3d9d1efb0814a2d0b174a210f5a3770070d2d83b34c9a2282630", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:632373ba8f23b76023b7beb06ecdc27f9b59ac6c25fb8487c985d06fd7a1dee1", "content": "The `@ReadPreference` annotation allows you to configure MongoDB's ReadPreferences.\n\n.Example of read preferences\n====\n[source,java]\n----\n\n@ReadPreference(\"primaryPreferred\") <1>\npublic interface PersonRepository extends CrudRepository<Person, String> {\n\n @ReadPreference(\"secondaryPreferred\") <2>\n List<Person> findWithReadPreferenceAnnotationByLastname(String lastname);\n\n @Query(readPreference = \"nearest\") <3>\n List<Person> findWithReadPreferenceAtTagByFirstname(String firstname);\n\n List<Person> findWithReadPreferenceAtTagByFirstname(String firstname); <4>\n----\n<1> Configure read preference for all repository operations (including inherited, non custom implementation ones) that do not have a query-level definition. Therefore, in this case the read preference mode will be `primaryPreferred`\n<2> Use the read preference mode defined in annotation `ReadPreference`, in this case secondaryPreferred\n<3> The `@Query` annotation defines the `read preference mode` alias which is equivalent to adding the `@ReadPreference` annotation.\n<4> This query will use the read preference mode defined in the repository.\n====\n\n[TIP]\n====\nThe `MongoOperations` and `Query` API offer more fine grained control for `ReadPreference`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc", "title": "query-methods", "heading": "Read Preferences", "heading_level": 2, "file_order": 17, "section_index": 9, "content_hash": "632373ba8f23b76023b7beb06ecdc27f9b59ac6c25fb8487c985d06fd7a1dee1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/query-methods.adoc"}}
{"id": "sha256:ddcbbdef44721590a1982b8660649a2c910a3fb3b990d1e6fecee75c88398b07", "content": "[[mongo.repositories]]\n\n[[mongo-repo-intro]]\nThis chapter points out the specialties for repository support for MongoDB.\nThis chapter builds on the core repository support explained in xref:repositories/core-concepts.adoc[core concepts].\nYou should have a sound understanding of the basic concepts explained there.\n\n[[mongo-repo-usage]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/repositories.adoc", "title": "repositories", "heading": "repositories", "heading_level": 1, "file_order": 18, "section_index": 0, "content_hash": "ddcbbdef44721590a1982b8660649a2c910a3fb3b990d1e6fecee75c88398b07", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/repositories.adoc"}}
{"id": "sha256:58629610a6be356d72a4506acbd2885237ef831ee0515e08d86405765f2aa19a", "content": "To access domain entities stored in a MongoDB, you can use our sophisticated repository support that eases implementation quite significantly.\nTo do so, create an interface for your repository, as the following example shows:\n\n.Sample Person entity\n====\n[source,java]\n----\npublic class Person {\n\n @Id\n private String id;\n private String firstname;\n private String lastname;\n private Address address;\n\n // … getters and setters omitted\n}\n----\n====\n\nNote that the domain type shown in the preceding example has a property named `id` of type `String`.The default serialization mechanism used in `MongoTemplate` (which backs the repository support) regards properties named `id` as the document ID.\nCurrently, we support `String`, `ObjectId`, and `BigInteger` as ID types.\nPlease see xref:mongodb/template-crud-operations.adoc#mongo-template.id-handling[ID mapping] for more information about on how the `id` field is handled in the mapping layer.\n\nNow that we have a domain object, we can define an interface that uses it, as follows:\n\n.Basic repository interface to persist Person entities\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface PersonRepository extends PagingAndSortingRepository<Person, String> {\n\n // additional custom query methods go here\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface PersonRepository extends ReactiveSortingRepository<Person, String> {\n\n // additional custom query methods go here\n}\n----\n======\n\nTo start using the repository, use the `@EnableMongoRepositories` annotation.\nThat annotation carries the same attributes as the namespace element.\nIf no base package is configured, the infrastructure scans the package of the annotated configuration class.\nThe following example shows how to configuration your application to use MongoDB repositories:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\n@EnableMongoRepositories(\"com.acme.*.repositories\")\nclass ApplicationConfig extends AbstractMongoClientConfiguration {\n\n @Override\n protected String getDatabaseName() {\n return \"e-store\";\n }\n\n @Override\n protected String getMappingBasePackage() {\n return \"com.acme.*.repositories\";\n }\n}\n----\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\n@EnableReactiveMongoRepositories(\"com.acme.*.repositories\")\nclass ApplicationConfig extends AbstractReactiveMongoConfiguration {\n\n @Override\n protected String getDatabaseName() {\n return \"e-store\";\n }\n\n @Override\n protected String getMappingBasePackage() {\n return \"com.acme.*.repositories\";\n }\n}\n----\n\nNOTE: MongoDB uses two different drivers for imperative (synchronous/blocking) and reactive (non-blocking) data access. You must create a connection by using the Reactive Streams driver to provide the required infrastructure for Spring Data's Reactive MongoDB support. Consequently, you must provide a separate configuration for MongoDB's Reactive Streams driver. Note that your application operates on two different connections if you use reactive and blocking Spring Data MongoDB templates and repositories.\n====\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"third\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n xmlns:mongo=\"http://www.springframework.org/schema/data/mongo\"\n xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n https://www.springframework.org/schema/beans/spring-beans-3.0.xsd\n http://www.springframework.org/schema/data/mongo\n https://www.springframework.org/schema/data/mongo/spring-mongo-1.0.xsd\">\n\n <mongo:mongo-client id=\"mongoClient\" />\n\n <bean id=\"mongoTemplate\" class=\"org.springframework.data.mongodb.core.MongoTemplate\">\n <constructor-arg ref=\"mongoClient\" />\n <constructor-arg value=\"databaseName\" />\n </bean>\n\n <mongo:repositories base-package=\"com.acme.*.repositories\" />\n\n</beans>\n----\n======\n\nThis namespace element causes the base packages to be scanned for interfaces that extend `MongoRepository` and create Spring beans for each one found.\nBy default, the repositories get a `MongoTemplate` Spring bean wired that is called `mongoTemplate`, so you only need to configure `mongo-template-ref` explicitly if you deviate from this convention.\n\nBecause our domain repository extends `PagingAndSortingRepository`, it provides you with methods for paginated and sorted access to the entities.\nIn the case of reactive repositories only `ReactiveSortingRepository` is available since the notion of a `Page` is not applicable.\nHowever finder methods still accept a `Sort` and `Limit` parameter.\n\n[NOTE]\n====\nThe reactive space offers various reactive composition libraries. The most common libraries are https://github.com/ReactiveX/RxJava[RxJava] and https://projectreactor.io/[Project Reactor].\n\nSpring Data MongoDB is built on top of the https://mongodb.github.io/mongo-java-driver-reactivestreams/[MongoDB Reactive Streams] driver, to provide maximal interoperability by relying on the https://www.reactive-streams.org/[Reactive Streams] initiative. Static APIs, such as `ReactiveMongoOperations`, are provided by using Project Reactor's `Flux` and `Mono` types. Project Reactor offers various adapters to convert reactive wrapper types (`Flux` to `Observable` and vice versa), but conversion can easily clutter your code.\n\nSpring Data's Reactive Repository abstraction is a dynamic API, mostly defined by you and your requirements as you declare query methods. Reactive MongoDB repositories can be implemented by using either RxJava or Project Reactor wrapper types by extending from one of the following library-specific repository interfaces:\n\n* `ReactiveCrudRepository`\n* `ReactiveSortingRepository`\n* `RxJava3CrudRepository`\n* `RxJava3SortingRepository`\n\nSpring Data converts reactive wrapper types behind the scenes so that you can stick to your favorite composition library.\n====\n\nIn case you want to obtain methods for basic CRUD operations also add the `CrudRepository` interface.\nWorking with the repository instance is just a matter of dependency injecting it into a client .\nConsequently, accessing the second page of `Person` objects at a page size of 10 would resemble the following code:\n\n.Paging access to Person entities\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@ExtendWith(SpringExtension.class)\n@ContextConfiguration\nclass PersonRepositoryTests {\n\n @Autowired PersonRepository repository;\n\n @Test\n void readsFirstPageCorrectly() {\n\n Page<Person> persons = repository.findAll(PageRequest.of(0, 10));\n assertThat(persons.isFirstPage()).isTrue();\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@ExtendWith(SpringExtension.class)\n@ContextConfiguration\nclass PersonRepositoryTests {\n\n @Autowired PersonRepository repository;\n\n @Test\n void readsFirstPageCorrectly() {\n\n Flux<Person> persons = repository.findAll(Sort.unsorted(), Limit.of(10));\n\n persons.as(StepVerifer::create)\n .expectNextCount(10)\n .verifyComplete();\n }\n}\n----\n======\n\nThe preceding example creates an application context with Spring's unit test support, which performs annotation-based dependency injection into test cases.\nInside the test method, we use the repository to query the datastore.\nWe hand the repository a `PageRequest` instance that requests the first page of `Person` objects at a page size of 10.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/repositories.adoc", "title": "repositories", "heading": "Usage", "heading_level": 2, "file_order": 18, "section_index": 1, "content_hash": "58629610a6be356d72a4506acbd2885237ef831ee0515e08d86405765f2aa19a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/repositories.adoc"}}
{"id": "sha256:ae673f8dfab19627fd07309fae921b3e8a7b78b792a95bcda5019ad72a6a8426", "content": "include::partial$/vector-search.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/repositories/vector-search.adoc", "title": "vector-search", "heading": "vector-search", "heading_level": 1, "file_order": 19, "section_index": 0, "content_hash": "ae673f8dfab19627fd07309fae921b3e8a7b78b792a95bcda5019ad72a6a8426", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/repositories/vector-search.adoc"}}
{"id": "sha256:37b46646ba3843d21646209441f7babcbd36c2761cdac54a285c588dce74a282", "content": "[[mongo.aggregation]]\n\nSpring Data MongoDB provides support for the Aggregation Framework introduced to MongoDB in version 2.2.\n\nFor further information, see the full https://docs.mongodb.org/manual/aggregation/[reference documentation] of the aggregation framework and other data aggregation tools for MongoDB.\n\n[[mongo.aggregation.basic-concepts]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "aggregation-framework", "heading_level": 1, "file_order": 20, "section_index": 0, "content_hash": "37b46646ba3843d21646209441f7babcbd36c2761cdac54a285c588dce74a282", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:68732bdadf8dd884765f7dac6623f7af3499d71bbdfcf64de8089ab2e52eeab9", "content": "The Aggregation Framework support in Spring Data MongoDB is based on the following key abstractions: javadoc:org.springframework.data.mongodb.core.aggregation.Aggregation[] and javadoc:org.springframework.data.mongodb.core.aggregation.AggregationResults[].\n\n* `Aggregation`\n+\nAn `Aggregation` represents a MongoDB `aggregate` operation and holds the description of the aggregation pipeline instructions. Aggregations are created by invoking the appropriate `newAggregation(…)` static factory method of the `Aggregation` class, which takes a list of `AggregateOperation` and an optional input class.\n+\nThe actual aggregate operation is run by the `aggregate` method of the `MongoTemplate`, which takes the desired output class as a parameter.\n+\n* `TypedAggregation`\n+\nA `TypedAggregation`, just like an `Aggregation`, holds the instructions of the aggregation pipeline and a reference to the input type, that is used for mapping domain properties to actual document fields.\n+\nAt runtime, field references get checked against the given input type, considering potential `@Field` annotations.\n[NOTE]\n====\nChanged in 3.2 referencing non-existent properties does no longer raise errors. To restore the previous behaviour use the `strictMapping` option of `AggregationOptions`.\n====\n* `AggregationDefinition`\n+\nAn `AggregationDefinition` represents a MongoDB aggregation pipeline operation and describes the processing that should be performed in this aggregation step. Although you could manually create an `AggregationDefinition`, we recommend using the static factory methods provided by the `Aggregate` class to construct an `AggregateOperation`.\n+\n* `AggregationResults`\n+\n`AggregationResults` is the container for the result of an aggregate operation. It provides access to the raw aggregation result, in the form of a `Document` to the mapped objects and other information about the aggregation.\n+\nThe following listing shows the canonical example for using the Spring Data MongoDB support for the MongoDB Aggregation Framework:\n+\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nAggregation agg = newAggregation(\n pipelineOP1(),\n pipelineOP2(),\n pipelineOPn()\n);\n\nAggregationResults<OutputType> results = mongoTemplate.aggregate(agg, \"INPUT_COLLECTION_NAME\", OutputType.class);\nList<OutputType> mappedResult = results.getMappedResults();\n----\n\nNote that, if you provide an input class as the first parameter to the `newAggregation` method, the `MongoTemplate` derives the name of the input collection from this class. Otherwise, if you do not not specify an input class, you must provide the name of the input collection explicitly. If both an input class and an input collection are provided, the latter takes precedence.\n\n[[mongo.aggregation.supported-aggregation-operations]]\n[[aggregation-stages]]\n.Supported Aggregation Operations & Stages\n[%collapsible]\n====\nThe MongoDB Aggregation Framework provides the following types of aggregation stages and operations:\n\n* addFields - `AddFieldsOperation`\n* bucket / bucketAuto - `BucketOperation` / `BucketAutoOperation`\n* count - `CountOperation`\n* densify - `DensifyOperation`\n* facet - `FacetOperation`\n* geoNear - `GeoNearOperation`\n* graphLookup - `GraphLookupOperation`\n* group - `GroupOperation`\n* limit - `LimitOperation`\n* lookup - `LookupOperation`\n* match - `MatchOperation`\n* merge - `MergeOperation`\n* project - `ProjectionOperation`\n* redact - `RedactOperation`\n* replaceRoot - `ReplaceRootOperation`\n* sample - `SampleOperation`\n* set - `SetOperation`\n* setWindowFields - `SetWindowFieldsOperation`\n* skip - `SkipOperation`\n* sort / sortByCount - `SortOperation` / `SortByCountOperation`\n* unionWith - `UnionWithOperation`\n* unset - `UnsetOperation`\n* unwind - `UnwindOperation`\n====\n\n[TIP]\n====\nUnsupported aggregation stages (like https://www.mongodb.com/docs/atlas/atlas-search/query-syntax/[$search] for MongoDB Atlas) can be provided by implementing either `AggregationOperation`.\n`Aggregation.stage` is a shortcut for registering a pipeline stage by providing its JSON or `Bson` representation.\n\n[source,java]\n----\nAggregation.stage(\"\"\"\n { $search : {\n \"near\": {\n \"path\": \"released\",\n \"origin\": { \"$date\": { \"$numberLong\": \"...\" } } ,\n \"pivot\": 7\n }\n }\n }\n\"\"\");\n----\n====\n\nAt the time of this writing, we provide support for the following Aggregation Operators in Spring Data MongoDB:\n\n.Aggregation Operators currently supported by Spring Data MongoDB\n[cols=\"2*\"]\n|===\n| Set Aggregation Operators\n| `setEquals`, `setIntersection`, `setUnion`, `setDifference`, `setIsSubset`, `anyElementTrue`, `allElementsTrue`\n\n| Group/Accumulator Aggregation Operators\n| `addToSet`, `bottom`, `bottomN`, `covariancePop`, `covarianceSamp`, `expMovingAvg`, `first`, `firstN`, `last`, `lastN` `max`, `maxN`, `min`, `minN`, `avg`, `push`, `sum`, `top`, `topN`, `count` (+++*+++), `median`, `percentile`, `stdDevPop`, `stdDevSamp`\n\n| Arithmetic Aggregation Operators\n| `abs`, `acos`, `acosh`, `add` (+++*+++ via `plus`), `asin`, `asin`, `atan`, `atan2`, `atanh`, `ceil`, `cos`, `cosh`, `derivative`, `divide`, `exp`, `floor`, `integral`, `ln`, `log`, `log10`, `mod`, `multiply`, `pow`, `round`, `sqrt`, `subtract` (+++*+++ via `minus`), `sin`, `sinh`, `tan`, `tanh`, `trunc`\n\n| String Aggregation Operators\n| `concat`, `substr`, `toLower`, `toUpper`, `strcasecmp`, `indexOfBytes`, `indexOfCP`, `regexFind`, `regexFindAll`, `regexMatch`, `replaceAll`, `replaceOne`, `split`, `strLenBytes`, `strLenCP`, `substrCP`, `trim`, `ltrim`, `rtim`\n\n| Comparison Aggregation Operators\n| `eq` (+++*+++ via `is`), `gt`, `gte`, `lt`, `lte`, `ne`\n\n| Array Aggregation Operators\n| `arrayElementAt`, `arrayToObject`, `concatArrays`, `filter`, `first`, `in`, `indexOfArray`, `isArray`, `last`, `range`, `reverseArray`, `reduce`, `size`, `sortArray`, `slice`, `zip`\n\n| Literal Operators\n| `literal`\n\n| Date Aggregation Operators\n| `dateSubstract`, `dateTrunc`, `dayOfYear`, `dayOfMonth`, `dayOfWeek`, `year`, `month`, `week`, `hour`, `minute`, `second`, `millisecond`, `dateAdd`, `dateDiff`, `dateToString`, `dateFromString`, `dateFromParts`, `dateToParts`, `isoDayOfWeek`, `isoWeek`, `isoWeekYear`, `tsIncrement`, `tsSecond`\n\n| Variable Operators\n| `map`\n\n| Conditional Aggregation Operators\n| `cond`, `ifNull`, `switch`\n\n| Type Aggregation Operators\n| `type`\n\n| Convert Aggregation Operators\n| `convert`, `degreesToRadians`, `toBool`, `toDate`, `toDecimal`, `toDouble`, `toInt`, `toLong`, `toObjectId`, `toString`\n\n| Object Aggregation Operators\n| `objectToArray`, `mergeObjects`, `getField`, `setField`\n\n| Script Aggregation Operators\n| `function`, `accumulator`\n\n|===\n\n+++*+++ The operation is mapped or added by Spring Data MongoDB.\n\nNote that the aggregation operations not listed here are currently not supported by Spring Data MongoDB. Comparison aggregation operators are expressed as `Criteria` expressions.\n\n[[mongo.aggregation.projection]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Basic Concepts", "heading_level": 2, "file_order": 20, "section_index": 1, "content_hash": "68732bdadf8dd884765f7dac6623f7af3499d71bbdfcf64de8089ab2e52eeab9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:a6cd48cc54a30f4b60413f85119d575cd1eac20ba35d3e60d23027fbaf2613b7", "content": "Projection expressions are used to define the fields that are the outcome of a particular aggregation step. Projection expressions can be defined through the `project` method of the `Aggregation` class, either by passing a list of `String` objects or an aggregation framework `Fields` object. The projection can be extended with additional fields through a fluent API by using the `and(String)` method and aliased by using the `as(String)` method.\nNote that you can also define fields with aliases by using the `Fields.field` static factory method of the aggregation framework, which you can then use to construct a new `Fields` instance. References to projected fields in later aggregation stages are valid only for the field names of included fields or their aliases (including newly defined fields and their aliases). Fields not included in the projection cannot be referenced in later aggregation stages. The following listings show examples of projection expression:\n\n.Projection expression examples\n====\n[source,java]\n----\nproject(\"name\", \"netPrice\")\n\nproject().and(\"thing1\").as(\"thing2\")\n\nproject(\"a\",\"b\").and(\"thing1\").as(\"thing2\")\n----\n====\n\n.Multi-Stage Aggregation using Projection and Sorting\n====\n[source,java]\n----\nproject(\"name\", \"netPrice\"), sort(ASC, \"name\")\n\nproject().and(\"firstname\").as(\"name\"), sort(ASC, \"name\")\n\nproject().and(\"firstname\").as(\"name\"), sort(ASC, \"firstname\")\n----\n====\n\nMore examples for project operations can be found in the `AggregationTests` class. Note that further details regarding the projection expressions can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/project/#pipe._S_project[corresponding section] of the MongoDB Aggregation Framework reference documentation.\n\n[[mongo.aggregation.facet]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Projection Expressions", "heading_level": 2, "file_order": 20, "section_index": 2, "content_hash": "a6cd48cc54a30f4b60413f85119d575cd1eac20ba35d3e60d23027fbaf2613b7", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:e2a782b76eef0eea061f7ac2a5f53f4079a3cb26eae602161c8e8a65775d2df7", "content": "As of Version 3.4, MongoDB supports faceted classification by using the Aggregation Framework. A faceted classification uses semantic categories (either general or subject-specific) that are combined to create the full classification entry. Documents flowing through the aggregation pipeline are classified into buckets. A multi-faceted classification enables various aggregations on the same set of input documents, without needing to retrieve the input documents multiple times.\n\n[[buckets]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Faceted Classification", "heading_level": 2, "file_order": 20, "section_index": 3, "content_hash": "e2a782b76eef0eea061f7ac2a5f53f4079a3cb26eae602161c8e8a65775d2df7", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:77bb0e6b2374641452f532a79398096ffe590ff5fd8dba2481488400ca4ec6a3", "content": "Bucket operations categorize incoming documents into groups, called buckets, based on a specified expression and bucket boundaries. Bucket operations require a grouping field or a grouping expression. You can define them by using the `bucket()` and `bucketAuto()` methods of the `Aggregate` class. `BucketOperation` and `BucketAutoOperation` can expose accumulations based on aggregation expressions for input documents. You can extend the bucket operation with additional parameters through a fluent API by using the `with…()` methods and the `andOutput(String)` method. You can alias the operation by using the `as(String)` method. Each bucket is represented as a document in the output.\n\n`BucketOperation` takes a defined set of boundaries to group incoming documents into these categories. Boundaries are required to be sorted. The following listing shows some examples of bucket operations:\n\n.Bucket operation examples\n====\n[source,java]\n----\nbucket(\"price\").withBoundaries(0, 100, 400);\n\nbucket(\"price\").withBoundaries(0, 100).withDefault(\"Other\");\n\nbucket(\"price\").withBoundaries(0, 100).andOutputCount().as(\"count\");\n\nbucket(\"price\").withBoundaries(0, 100).andOutput(\"title\").push().as(\"titles\");\n----\n====\n\n`BucketAutoOperation` determines boundaries in an attempt to evenly distribute documents into a specified number of buckets. `BucketAutoOperation` optionally takes a granularity value that specifies the https://en.wikipedia.org/wiki/Preferred_number[preferred number] series to use to ensure that the calculated boundary edges end on preferred round numbers or on powers of 10. The following listing shows examples of bucket operations:\n\n.Bucket operation examples\n====\n[source,java]\n----\nbucketAuto(\"price\", 5)\n\nbucketAuto(\"price\", 5).withGranularity(Granularities.E24).withDefault(\"Other\");\n\nbucketAuto(\"price\", 5).andOutput(\"title\").push().as(\"titles\");\n----\n====\n\nTo create output fields in buckets, bucket operations can use `AggregationExpression` through `andOutput()` and xref:mongodb/aggregation-framework.adoc#mongo.aggregation.projection.expressions[SpEL expressions] through `andOutputExpression()`.\n\nNote that further details regarding bucket expressions can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/bucket/[`$bucket` section] and\nhttps://docs.mongodb.org/manual/reference/operator/aggregation/bucketAuto/[`$bucketAuto` section] of the MongoDB Aggregation Framework reference documentation.\n\n[[multi-faceted-aggregation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Buckets", "heading_level": 3, "file_order": 20, "section_index": 4, "content_hash": "77bb0e6b2374641452f532a79398096ffe590ff5fd8dba2481488400ca4ec6a3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:3d158d18bedf2eebdba3b0911af6c2651ab186ce460e2cce3c6ce944137edd8d", "content": "Multiple aggregation pipelines can be used to create multi-faceted aggregations that characterize data across multiple dimensions (or facets) within a single aggregation stage. Multi-faceted aggregations provide multiple filters and categorizations to guide data browsing and analysis. A common implementation of faceting is how many online retailers provide ways to narrow down search results by applying filters on product price, manufacturer, size, and other factors.\n\nYou can define a `FacetOperation` by using the `facet()` method of the `Aggregation` class. You can customize it with multiple aggregation pipelines by using the `and()` method. Each sub-pipeline has its own field in the output document where its results are stored as an array of documents.\n\nSub-pipelines can project and filter input documents prior to grouping. Common use cases include extraction of date parts or calculations before categorization. The following listing shows facet operation examples:\n\n.Facet operation examples\n====\n[source,java]\n----\nfacet(match(Criteria.where(\"price\").exists(true)), bucketAuto(\"price\", 5)).as(\"categorizedByPrice\"))\n\nfacet(match(Criteria.where(\"country\").exists(true)), sortByCount(\"country\")).as(\"categorizedByCountry\"))\n\nfacet(project(\"title\").and(\"publicationDate\").extractYear().as(\"publicationYear\"),\n bucketAuto(\"publicationYear\", 5).andOutput(\"title\").push().as(\"titles\"))\n .as(\"categorizedByYear\"))\n----\n====\n\nNote that further details regarding facet operation can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/facet/[`$facet` section] of the MongoDB Aggregation Framework reference documentation.\n\n[[mongo.aggregation.sort-by-count]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Multi-faceted Aggregation", "heading_level": 3, "file_order": 20, "section_index": 5, "content_hash": "3d158d18bedf2eebdba3b0911af6c2651ab186ce460e2cce3c6ce944137edd8d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:57d5572513e2a780b11ccc2ba341b3fca9cdca8fb8569d5dcf1048c0e78e5378", "content": "Sort by count operations group incoming documents based on the value of a specified expression, compute the count of documents in each distinct group, and sort the results by count. It offers a handy shortcut to apply sorting when using xref:mongodb/aggregation-framework.adoc#mongo.aggregation.facet[Faceted Classification]. Sort by count operations require a grouping field or grouping expression. The following listing shows a sort by count example:\n\n.Sort by count example\n====\n[source,java]\n----\nsortByCount(\"country\");\n----\n====\n\nA sort by count operation is equivalent to the following BSON (Binary JSON):\n\n----\n{ $group: { _id: <expression>, count: { $sum: 1 } } },\n{ $sort: { count: -1 } }\n----\n\n[[mongo.aggregation.projection.expressions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Sort By Count", "heading_level": 3, "file_order": 20, "section_index": 6, "content_hash": "57d5572513e2a780b11ccc2ba341b3fca9cdca8fb8569d5dcf1048c0e78e5378", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:b5a886d1ddd6e6358e4fc1ff35aaab26541aabf1e4060d7ed9f361303406f30e", "content": "We support the use of SpEL expressions in projection expressions through the `andExpression` method of the `ProjectionOperation` and `BucketOperation` classes. This feature lets you define the desired expression as a SpEL expression. On running a query, the SpEL expression is translated into a corresponding MongoDB projection expression part. This arrangement makes it much easier to express complex calculations.\n\n[[complex-calculations-with-spel-expressions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Spring Expression Support in Projection Expressions", "heading_level": 3, "file_order": 20, "section_index": 7, "content_hash": "b5a886d1ddd6e6358e4fc1ff35aaab26541aabf1e4060d7ed9f361303406f30e", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:2dcdb0574d2f050f747ec385754fd93e01b6a8069b813b6052e68cabca013ce8", "content": "Consider the following SpEL expression:\n\n[source,java]\n----\n1 + (q + 1) / (q - 1)\n----\n\nThe preceding expression is translated into the following projection expression part:\n\n[source,javascript]\n----\n{ \"$add\" : [ 1, {\n \"$divide\" : [ {\n \"$add\":[\"$q\", 1]}, {\n \"$subtract\":[ \"$q\", 1]}\n ]\n}]}\n----\n\nYou can see examples in more context in xref:mongodb/aggregation-framework.adoc#mongo.aggregation.examples.example5[Aggregation Framework Example 5] and xref:mongodb/aggregation-framework.adoc#mongo.aggregation.examples.example6[Aggregation Framework Example 6].\nYou can find more usage examples for supported SpEL expression constructs in `SpelExpressionTransformerUnitTests`.\n\n.Supported SpEL transformations\n[%collapsible]\n====\n[%header,cols=\"2\"]\n|===\n| SpEL Expression\n| Mongo Expression Part\n| a == b\n| { $eq : [$a, $b] }\n| a != b\n| { $ne : [$a , $b] }\n| a > b\n| { $gt : [$a, $b] }\n| a >= b\n| { $gte : [$a, $b] }\n| a < b\n| { $lt : [$a, $b] }\n| a <= b\n| { $lte : [$a, $b] }\n| a + b\n| { $add : [$a, $b] }\n| a - b\n| { $subtract : [$a, $b] }\n| a * b\n| { $multiply : [$a, $b] }\n| a / b\n| { $divide : [$a, $b] }\n| a^b\n| { $pow : [$a, $b] }\n| a % b\n| { $mod : [$a, $b] }\n| a && b\n| { $and : [$a, $b] }\n| a \\|\\| b\n| { $or : [$a, $b] }\n| !a\n| { $not : [$a] }\n|===\n====\n\nIn addition to the transformations shown in the preceding table, you can use standard SpEL operations such as `new` to (for example) create arrays and reference expressions through their names (followed by the arguments to use in brackets). The following example shows how to create an array in this fashion:\n\n[source,java]\n----\n.andExpression(\"setEquals(a, new int[]{5, 8, 13})\");\n----\n\n[[mongo.aggregation.examples]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Complex Calculations with SpEL expressions", "heading_level": 4, "file_order": 20, "section_index": 8, "content_hash": "2dcdb0574d2f050f747ec385754fd93e01b6a8069b813b6052e68cabca013ce8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:267b23b7ffdd49a3b79ad976b18e2365366406b769c10d043d8d8235a45f60cc", "content": "The examples in this section demonstrate the usage patterns for the MongoDB Aggregation Framework with Spring Data MongoDB.\n\n[[mongo.aggregation.examples.example1]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Examples", "heading_level": 3, "file_order": 20, "section_index": 9, "content_hash": "267b23b7ffdd49a3b79ad976b18e2365366406b769c10d043d8d8235a45f60cc", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:5b563de3c56cd069acf10c500b181665828f2e9730a8b245c773b84f5de97329", "content": "In this introductory example, we want to aggregate a list of tags to get the occurrence count of a particular tag from a MongoDB collection (called `tags`) sorted by the occurrence count in descending order. This example demonstrates the usage of grouping, sorting, projections (selection), and unwinding (result splitting).\n\n[source,java]\n----\nclass TagCount {\n String tag;\n int n;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nAggregation agg = newAggregation(\n project(\"tags\"),\n unwind(\"tags\"),\n group(\"tags\").count().as(\"n\"),\n project(\"n\").and(\"tag\").previousOperation(),\n sort(DESC, \"n\")\n);\n\nAggregationResults<TagCount> results = mongoTemplate.aggregate(agg, \"tags\", TagCount.class);\nList<TagCount> tagCount = results.getMappedResults();\n----\n\nThe preceding listing uses the following algorithm:\n\n. Create a new aggregation by using the `newAggregation` static factory method, to which we pass a list of aggregation operations. These aggregate operations define the aggregation pipeline of our `Aggregation`.\n. Use the `project` operation to select the `tags` field (which is an array of strings) from the input collection.\n. Use the `unwind` operation to generate a new document for each tag within the `tags` array.\n. Use the `group` operation to define a group for each `tags` value for which we aggregate the occurrence count (by using the `count` aggregation operator and collecting the result in a new field called `n`).\n. Select the `n` field and create an alias for the ID field generated from the previous group operation (hence the call to `previousOperation()`) with a name of `tag`.\n. Use the `sort` operation to sort the resulting list of tags by their occurrence count in descending order.\n. Call the `aggregate` method on `MongoTemplate` to let MongoDB perform the actual aggregation operation, with the created `Aggregation` as an argument.\n\nNote that the input collection is explicitly specified as the `tags` parameter to the `aggregate` Method. If the name of the input collection is not specified explicitly, it is derived from the input class passed as the first parameter to the `newAggreation` method.\n\n[[mongo.aggregation.examples.example2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 1", "heading_level": 4, "file_order": 20, "section_index": 10, "content_hash": "5b563de3c56cd069acf10c500b181665828f2e9730a8b245c773b84f5de97329", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:4d73cc5933e22ae83eac8fac40a0fcfeb49f0b66ff5e09e9b21897f41db44fdf", "content": "This example is based on the https://docs.mongodb.org/manual/tutorial/aggregation-examples/#largest-and-smallest-cities-by-state[Largest and Smallest Cities by State] example from the MongoDB Aggregation Framework documentation. We added additional sorting to produce stable results with different MongoDB versions. Here we want to return the smallest and largest cities by population for each state by using the aggregation framework. This example demonstrates grouping, sorting, and projections (selection).\n\n[source,java]\n----\nclass ZipInfo {\n String id;\n String city;\n String state;\n @Field(\"pop\") int population;\n @Field(\"loc\") double[] location;\n}\n\nclass City {\n String name;\n int population;\n}\n\nclass ZipInfoStats {\n String id;\n String state;\n City biggestCity;\n City smallestCity;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nTypedAggregation<ZipInfo> aggregation = newAggregation(ZipInfo.class,\n group(\"state\", \"city\")\n .sum(\"population\").as(\"pop\"),\n sort(ASC, \"pop\", \"state\", \"city\"),\n group(\"state\")\n .last(\"city\").as(\"biggestCity\")\n .last(\"pop\").as(\"biggestPop\")\n .first(\"city\").as(\"smallestCity\")\n .first(\"pop\").as(\"smallestPop\"),\n project()\n .and(\"state\").previousOperation()\n .and(\"biggestCity\")\n .nested(bind(\"name\", \"biggestCity\").and(\"population\", \"biggestPop\"))\n .and(\"smallestCity\")\n .nested(bind(\"name\", \"smallestCity\").and(\"population\", \"smallestPop\")),\n sort(ASC, \"state\")\n);\n\nAggregationResults<ZipInfoStats> result = mongoTemplate.aggregate(aggregation, ZipInfoStats.class);\nZipInfoStats firstZipInfoStats = result.getMappedResults().get(0);\n----\n\nNote that the `ZipInfo` class maps the structure of the given input-collection. The `ZipInfoStats` class defines the structure in the desired output format.\n\nThe preceding listings use the following algorithm:\n\n. Use the `group` operation to define a group from the input-collection. The grouping criteria is the combination of the `state` and `city` fields, which forms the ID structure of the group. We aggregate the value of the `population` property from the grouped elements by using the `sum` operator and save the result in the `pop` field.\n. Use the `sort` operation to sort the intermediate-result by the `pop`, `state` and `city` fields, in ascending order, such that the smallest city is at the top and the biggest city is at the bottom of the result. Note that the sorting on `state` and `city` is implicitly performed against the group ID fields (which Spring Data MongoDB handled).\n. Use a `group` operation again to group the intermediate result by `state`. Note that `state` again implicitly references a group ID field. We select the name and the population count of the biggest and smallest city with calls to the `last(…)` and `first(...)` operators, respectively, in the `project` operation.\n. Select the `state` field from the previous `group` operation. Note that `state` again implicitly references a group ID field. Because we do not want an implicitly generated ID to appear, we exclude the ID from the previous operation by using `and(previousOperation()).exclude()`. Because we want to populate the nested `City` structures in our output class, we have to emit appropriate sub-documents by using the nested method.\n. Sort the resulting list of `StateStats` by their state name in ascending order in the `sort` operation.\n\nNote that we derive the name of the input collection from the `ZipInfo` class passed as the first parameter to the `newAggregation` method.\n\n[[mongo.aggregation.examples.example3]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 2", "heading_level": 4, "file_order": 20, "section_index": 11, "content_hash": "4d73cc5933e22ae83eac8fac40a0fcfeb49f0b66ff5e09e9b21897f41db44fdf", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:32c2322e35ebbf572cc71cfff68e0265f05c3417647f3d93154e7c41cee1b4f6", "content": "This example is based on the https://docs.mongodb.org/manual/tutorial/aggregation-examples/#states-with-populations-over-10-million[States with Populations Over 10 Million] example from the MongoDB Aggregation Framework documentation. We added additional sorting to produce stable results with different MongoDB versions. Here we want to return all states with a population greater than 10 million, using the aggregation framework. This example demonstrates grouping, sorting, and matching (filtering).\n\n[source,java]\n----\nclass StateStats {\n @Id String id;\n String state;\n @Field(\"totalPop\") int totalPopulation;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nTypedAggregation<ZipInfo> agg = newAggregation(ZipInfo.class,\n group(\"state\").sum(\"population\").as(\"totalPop\"),\n sort(ASC, previousOperation(), \"totalPop\"),\n match(where(\"totalPop\").gte(10 * 1000 * 1000))\n);\n\nAggregationResults<StateStats> result = mongoTemplate.aggregate(agg, StateStats.class);\nList<StateStats> stateStatsList = result.getMappedResults();\n----\n\nThe preceding listings use the following algorithm:\n\n. Group the input collection by the `state` field and calculate the sum of the `population` field and store the result in the new field `\"totalPop\"`.\n. Sort the intermediate result by the id-reference of the previous group operation in addition to the `\"totalPop\"` field in ascending order.\n. Filter the intermediate result by using a `match` operation which accepts a `Criteria` query as an argument.\n\nNote that we derive the name of the input collection from the `ZipInfo` class passed as first parameter to the `newAggregation` method.\n\n[[mongo.aggregation.examples.example4]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 3", "heading_level": 4, "file_order": 20, "section_index": 12, "content_hash": "32c2322e35ebbf572cc71cfff68e0265f05c3417647f3d93154e7c41cee1b4f6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:005286518af2f188ed0698b3341612df7d5d7b149c7640d8cf0ec2544538b301", "content": "This example demonstrates the use of simple arithmetic operations in the projection operation.\n\n[source,java]\n----\nclass Product {\n String id;\n String name;\n double netPrice;\n int spaceUnits;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nTypedAggregation<Product> agg = newAggregation(Product.class,\n project(\"name\", \"netPrice\")\n .and(\"netPrice\").plus(1).as(\"netPricePlus1\")\n .and(\"netPrice\").minus(1).as(\"netPriceMinus1\")\n .and(\"netPrice\").multiply(1.19).as(\"grossPrice\")\n .and(\"netPrice\").divide(2).as(\"netPriceDiv2\")\n .and(\"spaceUnits\").mod(2).as(\"spaceUnitsMod2\")\n);\n\nAggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);\nList<Document> resultList = result.getMappedResults();\n----\n\nNote that we derive the name of the input collection from the `Product` class passed as first parameter to the `newAggregation` method.\n\n[[mongo.aggregation.examples.example5]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 4", "heading_level": 4, "file_order": 20, "section_index": 13, "content_hash": "005286518af2f188ed0698b3341612df7d5d7b149c7640d8cf0ec2544538b301", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:e984192c3cb1966867389a385c45b3dda2695d28daf0827464f9e6db1ac445b3", "content": "This example demonstrates the use of simple arithmetic operations derived from SpEL Expressions in the projection operation.\n\n[source,java]\n----\nclass Product {\n String id;\n String name;\n double netPrice;\n int spaceUnits;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nTypedAggregation<Product> agg = newAggregation(Product.class,\n project(\"name\", \"netPrice\")\n .andExpression(\"netPrice + 1\").as(\"netPricePlus1\")\n .andExpression(\"netPrice - 1\").as(\"netPriceMinus1\")\n .andExpression(\"netPrice / 2\").as(\"netPriceDiv2\")\n .andExpression(\"netPrice * 1.19\").as(\"grossPrice\")\n .andExpression(\"spaceUnits % 2\").as(\"spaceUnitsMod2\")\n .andExpression(\"(netPrice * 0.8 + 1.2) * 1.19\").as(\"grossPriceIncludingDiscountAndCharge\")\n\n);\n\nAggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);\nList<Document> resultList = result.getMappedResults();\n----\n\n[[mongo.aggregation.examples.example6]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 5", "heading_level": 4, "file_order": 20, "section_index": 14, "content_hash": "e984192c3cb1966867389a385c45b3dda2695d28daf0827464f9e6db1ac445b3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:ee843cd3aa170036d736b0ebc537828f80e707a15f6507ba99345c847dbc7057", "content": "This example demonstrates the use of complex arithmetic operations derived from SpEL Expressions in the projection operation.\n\nNote: The additional parameters passed to the `addExpression` method can be referenced with indexer expressions according to their position. In this example, we reference the first parameter of the parameters array with `[0]`. When the SpEL expression is transformed into a MongoDB aggregation framework expression, external parameter expressions are replaced with their respective values.\n\n[source,java]\n----\nclass Product {\n String id;\n String name;\n double netPrice;\n int spaceUnits;\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\ndouble shippingCosts = 1.2;\n\nTypedAggregation<Product> agg = newAggregation(Product.class,\n project(\"name\", \"netPrice\")\n .andExpression(\"(netPrice * (1-discountRate) + [0]) * (1+taxRate)\", shippingCosts).as(\"salesPrice\")\n);\n\nAggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);\nList<Document> resultList = result.getMappedResults();\n----\n\nNote that we can also refer to other fields of the document within the SpEL expression.\n\n[[mongo.aggregation.examples.example7]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 6", "heading_level": 4, "file_order": 20, "section_index": 15, "content_hash": "ee843cd3aa170036d736b0ebc537828f80e707a15f6507ba99345c847dbc7057", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:f74692b9dd085c51e8a64ce39ba6e97d5e3b1188c2b95aaca5240ec51a8f2e12", "content": "This example uses conditional projection. It is derived from the https://docs.mongodb.com/manual/reference/operator/aggregation/cond/[$cond reference documentation].\n\n[source,java]\n----\npublic class InventoryItem {\n\n @Id int id;\n String item;\n String description;\n int qty;\n}\n\npublic class InventoryItemProjection {\n\n @Id int id;\n String item;\n String description;\n int qty;\n int discount\n}\n----\n\n[source,java]\n----\nimport static org.springframework.data.mongodb.core.aggregation.Aggregation.*;\n\nTypedAggregation<InventoryItem> agg = newAggregation(InventoryItem.class,\n project(\"item\").and(\"discount\")\n .applyCondition(ConditionalOperator.newBuilder().when(Criteria.where(\"qty\").gte(250))\n .then(30)\n .otherwise(20))\n .and(ifNull(\"description\", \"Unspecified\")).as(\"description\")\n);\n\nAggregationResults<InventoryItemProjection> result = mongoTemplate.aggregate(agg, \"inventory\", InventoryItemProjection.class);\nList<InventoryItemProjection> stateStatsList = result.getMappedResults();\n----\n\nThis one-step aggregation uses a projection operation with the `inventory` collection. We project the `discount` field by using a conditional operation for all inventory items that have a `qty` greater than or equal to `250`. A second conditional projection is performed for the `description` field. We apply the `Unspecified` description to all items that either do not have a `description` field or items that have a `null` description.\n\nAs of MongoDB 3.6, it is possible to exclude fields from the projection by using a conditional expression.\n\n.Conditional aggregation projection\n====\n[source,java]\n----\nTypedAggregation<Book> agg = Aggregation.newAggregation(Book.class,\n project(\"title\")\n .and(ConditionalOperators.when(ComparisonOperators.valueOf(\"author.middle\") <1>\n .equalToValue(\"\")) <2>\n .then(\"$$REMOVE\") <3>\n .otherwiseValueOf(\"author.middle\") <4>\n )\n\t.as(\"author.middle\"));\n----\n<1> If the value of the field `author.middle`\n<2> does not contain a value,\n<3> then use https://docs.mongodb.com/manual/reference/aggregation-variables/#variable.REMOVE[``$$REMOVE``] to exclude the field.\n<4> Otherwise, add the field value of `author.middle`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc", "title": "aggregation-framework", "heading": "Aggregation Framework Example 7", "heading_level": 4, "file_order": 20, "section_index": 16, "content_hash": "f74692b9dd085c51e8a64ce39ba6e97d5e3b1188c2b95aaca5240ec51a8f2e12", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aggregation-framework.adoc"}}
{"id": "sha256:78cee0e2b69579fc3b4a531317ae473eb1f62fc6360197e5b2a01e0c21b99d88", "content": "include::{commons}@data-commons::page$aot.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aot.adoc", "title": "aot", "heading": "aot", "heading_level": 1, "file_order": 21, "section_index": 0, "content_hash": "78cee0e2b69579fc3b4a531317ae473eb1f62fc6360197e5b2a01e0c21b99d88", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aot.adoc"}}
{"id": "sha256:034182fdd68ba713c5a1b65d3ab6cc906043e8ab886012dfa8be7193322cd549", "content": "[[aot.repositories.mongodb]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aot.adoc", "title": "aot", "heading": "MongoDB Specific Ahead Of Time Features", "heading_level": 2, "file_order": 21, "section_index": 1, "content_hash": "034182fdd68ba713c5a1b65d3ab6cc906043e8ab886012dfa8be7193322cd549", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aot.adoc"}}
{"id": "sha256:c99907bc5f436cf11fc2d6dfa5f8340a489004aedd84a8b1660d3789c5d1cb6f", "content": "With Spring Data MongoDb we generally support query methods that are not backed by an xref:repositories/custom-implementations.adoc[implementation fragment], and don't require, with a few limitations detailed below.\n\n[NOTE]\n====\nReactive Repository interfaces using Project Reactor, Kotlin Coroutines et. al. are not supported.\n====\n\n**Supported Features**\n\n* Derived `find`, `count`, `exists` and `delete` methods\n* Query methods annotated with `@Query` (excluding those containing SpEL)\n* Methods annotated with `@Aggregation`, `@Update`, and `@VectorSearch`\n* `@Hint`, `@Meta`, and `@ReadPreference` support\n* `Page`, `Slice`, and `Optional` return types\n* DTO & Interface Projections\n\n**Limitations**\n\n* `@Meta.flags` is not evaluated.\n* Limited `Collation` detection.\n* No support for in-clauses with pattern matching / case insensitivity.\n* Custom Collection return types (e.g. `io.vavr.collection`, `org.eclipse.collections`) are not yet supported.\n\n**Excluded methods**\n\n* `CrudRepository` and other base interface methods\n* Querydsl and Query by Example methods\n* Query Methods obtaining MQL from a file\n\n[TIP]\n====\nConsider using `Pattern` instead of `String` as parameter type when working with derived queries using the `LIKE` keyword.\n[source,java]\n----\nList<Person> findByLastnameLike(Pattern lastname);\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/aot.adoc", "title": "aot", "heading": "MongoDB Ahead of Time Repositories", "heading_level": 3, "file_order": 21, "section_index": 2, "content_hash": "c99907bc5f436cf11fc2d6dfa5f8340a489004aedd84a8b1660d3789c5d1cb6f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/aot.adoc"}}
{"id": "sha256:b5aec234c22db94bd21fe9b94509966630796363e05ce19bba0337c884a09428", "content": "[[mongo.auditing]]\n\nSince Spring Data MongoDB 1.4, auditing can be enabled by annotating a configuration class with the `@EnableMongoAuditing` annotation, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\n@EnableMongoAuditing\nclass Config {\n\n @Bean\n public AuditorAware<AuditableUser> myAuditorProvider() {\n return new AuditorAwareImpl();\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\n@EnableReactiveMongoAuditing\nclass Config {\n\n @Bean\n public ReactiveAuditorAware<AuditableUser> myAuditorProvider() {\n return new ReactiveAuditorAwareImpl();\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<mongo:auditing mapping-context-ref=\"customMappingContext\" auditor-aware-ref=\"yourAuditorAwareImpl\"/>\n----\n======\n\nIf you expose a bean of type `AuditorAware` / `ReactiveAuditorAware` to the `ApplicationContext`, the auditing infrastructure picks it up automatically and uses it to determine the current user to be set on domain types.\nIf you have multiple implementations registered in the `ApplicationContext`, you can select the one to be used by explicitly setting the `auditorAwareRef` attribute of `@EnableMongoAuditing`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/auditing.adoc", "title": "auditing", "heading": "auditing", "heading_level": 1, "file_order": 22, "section_index": 0, "content_hash": "b5aec234c22db94bd21fe9b94509966630796363e05ce19bba0337c884a09428", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/auditing.adoc"}}
{"id": "sha256:3e606a2e5b9ff487df9a253493b12a505ceda0605af54984f21216d7bd0c6b8a", "content": "[[change-streams]]\n\nAs of MongoDB 3.6, https://docs.mongodb.com/manual/changeStreams/[Change Streams] let applications get notified about changes without having to tail the oplog.\n\nNOTE: Change Stream support is only possible for replica sets or for a sharded cluster.\n\nChange Streams can be consumed with both, the imperative and the reactive MongoDB Java driver. It is highly recommended to use the reactive variant, as it is less resource-intensive. However, if you cannot use the reactive API, you can still obtain change events by using the messaging concept that is already prevalent in the Spring ecosystem.\n\nIt is possible to watch both on a collection as well as database level, whereas the database level variant publishes\nchanges from all collections within the database. When subscribing to a database change stream, make sure to use a\n suitable type for the event type as conversion might not apply correctly across different entity types.\nIn doubt, use `Document`.\n\n[[change-streams-with-messagelistener]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/change-streams.adoc", "title": "change-streams", "heading": "change-streams", "heading_level": 1, "file_order": 23, "section_index": 0, "content_hash": "3e606a2e5b9ff487df9a253493b12a505ceda0605af54984f21216d7bd0c6b8a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/change-streams.adoc"}}
{"id": "sha256:5273d32ccfd11bcb998c7fb0dd4e06b98707f3a2116d7e096ea9e1072ef57a06", "content": "Listening to a https://docs.mongodb.com/manual/tutorial/change-streams-example/[Change Stream by using a Sync Driver] creates a long running, blocking task that needs to be delegated to a separate component.\nIn this case, we need to first create a javadoc:org.springframework.data.mongodb.core.messaging.MessageListenerContainer[] which will be the main entry point for running the specific `SubscriptionRequest` tasks.\nSpring Data MongoDB already ships with a default implementation that operates on `MongoTemplate` and is capable of creating and running `Task` instances for a javadoc:org.springframework.data.mongodb.core.messaging.ChangeStreamRequest[].\n\nThe following example shows how to use Change Streams with `MessageListener` instances:\n\n.Change Streams with `MessageListener` instances\n====\n[source,java]\n----\nMessageListenerContainer container = new DefaultMessageListenerContainer(template);\ncontainer.start(); <1>\n\nMessageListener<ChangeStreamDocument<Document>, User> listener = System.out::println; <2>\nChangeStreamRequestOptions options = new ChangeStreamRequestOptions(\"db\", \"user\", ChangeStreamOptions.empty()); <3>\n\nSubscription subscription = container.register(new ChangeStreamRequest<>(listener, options), User.class); <4>\n\ncontainer.stop(); <5>\n----\n<1> Starting the container initializes the resources and starts `Task` instances for already registered `SubscriptionRequest` instances. Requests added after startup are ran immediately.\n<2> Define the listener called when a `Message` is received. The `Message#getBody()` is converted to the requested domain type. Use `Document` to receive raw results without conversion.\n<3> Set the collection to listen to and provide additional options through `ChangeStreamOptions`.\n<4> Register the request. The returned `Subscription` can be used to check the current `Task` state and cancel it to free resources.\n<5> Do not forget to stop the container once you are sure you no longer need it. Doing so stops all running `Task` instances within the container.\n====\n\n`DefaultMessageListenerContainer` implements `SmartLifecycle` and will by default be automatically started when registered as a bean in the Application Context.\n\n[NOTE]\n====\nErrors while processing are passed on to an `org.springframework.util.ErrorHandler`. If not stated otherwise a log appending `ErrorHandler` gets applied by default. +\nPlease use `register(request, body, errorHandler)` to provide additional functionality.\n====\n\n[[reactive-change-streams]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/change-streams.adoc", "title": "change-streams", "heading": "Change Streams with `MessageListener`", "heading_level": 2, "file_order": 23, "section_index": 1, "content_hash": "5273d32ccfd11bcb998c7fb0dd4e06b98707f3a2116d7e096ea9e1072ef57a06", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/change-streams.adoc"}}
{"id": "sha256:7bbb4d3bf64beabd84ea83780c49bb25f827d9602ecb140f3da74f32a0e483ec", "content": "Subscribing to Change Streams with the reactive API is a more natural approach to work with streams. Still, the essential building blocks, such as `ChangeStreamOptions`, remain the same. The following example shows how to use Change Streams emitting ``ChangeStreamEvent``s:\n\n.Change Streams emitting `ChangeStreamEvent`\n====\n[source,java]\n----\nFlux<ChangeStreamEvent<User>> flux = reactiveTemplate.changeStream(User.class) <1>\n .watchCollection(\"people\")\n .filter(where(\"age\").gte(38)) <2>\n .listen(); <3>\n----\n<1> The event target type the underlying document should be converted to. Leave this out to receive raw results without conversion.\n<2> Use an aggregation pipeline or just a query `Criteria` to filter events.\n<3> Obtain a `Flux` of change stream events. The `ChangeStreamEvent#getBody()` is converted to the requested domain type from (2).\n====\n\n[[resuming-change-streams]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/change-streams.adoc", "title": "change-streams", "heading": "Reactive Change Streams", "heading_level": 2, "file_order": 23, "section_index": 2, "content_hash": "7bbb4d3bf64beabd84ea83780c49bb25f827d9602ecb140f3da74f32a0e483ec", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/change-streams.adoc"}}
{"id": "sha256:5e59ddfcade6be2907a3edec7e0fb76f97ef821443e4d0496dbe266f331af774", "content": "Change Streams can be resumed and resume emitting events where you left. To resume the stream, you need to supply either a resume\ntoken or the last known server time (in UTC). Use javadoc:org.springframework.data.mongodb.core.ChangeStreamOptions[] to set the value accordingly.\n\nThe following example shows how to set the resume offset using server time:\n\n.Resume a Change Stream\n====\n[source,java]\n----\nFlux<ChangeStreamEvent<User>> resumed = template.changeStream(User.class)\n .watchCollection(\"people\")\n .resumeAt(Instant.now().minusSeconds(1)) <1>\n .listen();\n----\n<1> You may obtain the server time of an `ChangeStreamEvent` through the `getTimestamp` method or use the `resumeToken`\nexposed through `getResumeToken`.\n====\n\nTIP: In some cases an `Instant` might not be a precise enough measure when resuming a Change Stream. Use a MongoDB native\nhttps://docs.mongodb.com/manual/reference/bson-types/#timestamps[BsonTimestamp] for that purpose.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/change-streams.adoc", "title": "change-streams", "heading": "Resuming Change Streams", "heading_level": 2, "file_order": 23, "section_index": 3, "content_hash": "5e59ddfcade6be2907a3edec7e0fb76f97ef821443e4d0496dbe266f331af774", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/change-streams.adoc"}}
{"id": "sha256:89224e4a1dd395841fb4e5d2c857c6a91cd0c93bba81e59935074a656bb96bcb", "content": "[[mongo.sessions]]\n\nAs of version 3.6, MongoDB supports the concept of sessions.\nThe use of sessions enables MongoDB's https://docs.mongodb.com/manual/core/read-isolation-consistency-recency/#causal-consistency[Causal Consistency] model, which guarantees running operations in an order that respects their causal relationships.\nThose are split into `ServerSession` instances and `ClientSession` instances.\nIn this section, when we speak of a session, we refer to `ClientSession`.\n\nWARNING: Operations within a client session are not isolated from operations outside the session.\n\nBoth `MongoOperations` and `ReactiveMongoOperations` provide gateway methods for tying a `ClientSession` to the operations.\n`MongoCollection` and `MongoDatabase` use session proxy objects that implement MongoDB's collection and database interfaces, so you need not add a session on each call.\nThis means that a potential call to `MongoCollection#find()` is delegated to `MongoCollection#find(ClientSession)`.\n\nNOTE: Methods such as `(Reactive)MongoOperations#getCollection` return native MongoDB Java Driver gateway objects (such as `MongoCollection`) that themselves offer dedicated methods for `ClientSession`.\nThese methods are *NOT* session-proxied.\nYou should provide the `ClientSession` where needed when interacting directly with a `MongoCollection` or `MongoDatabase` and not through one of the `#execute` callbacks on `MongoOperations`.\n\n[[mongo.sessions.sync]]\n[[mongo.sessions.reactive]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "client-session-transactions", "heading_level": 1, "file_order": 24, "section_index": 0, "content_hash": "89224e4a1dd395841fb4e5d2c857c6a91cd0c93bba81e59935074a656bb96bcb", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:f00c6716d1ec8a3e5f80134de68b3d1c8ca875e9d963768cdf9dffcd5d2cbc40", "content": "The following example shows the usage of a session:\n\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nClientSessionOptions sessionOptions = ClientSessionOptions.builder()\n .causallyConsistent(true)\n .build();\n\nClientSession session = client.startSession(sessionOptions); <1>\n\ntemplate.withSession(() -> session)\n .execute(action -> {\n\n Query query = query(where(\"name\").is(\"Durzo Blint\"));\n Person durzo = action.findOne(query, Person.class); <2>\n\n Person azoth = new Person(\"Kylar Stern\");\n azoth.setMaster(durzo);\n\n action.insert(azoth); <3>\n\n return azoth;\n });\n\nsession.close() <4>\n----\n\n<1> Obtain a new session from the server.\n<2> Use `MongoOperation` methods as before.\nThe `ClientSession` gets applied automatically.\n<3> Make sure to close the `ClientSession`.\n<4> Close the session.\n\nWARNING: When dealing with `DBRef` instances, especially lazily loaded ones, it is essential to *not* close the `ClientSession` before all data is loaded.\nOtherwise, lazy fetch fails.\n====\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nClientSessionOptions sessionOptions = ClientSessionOptions.builder()\n.causallyConsistent(true)\n.build();\n\nPublisher<ClientSession> session = client.startSession(sessionOptions); <1>\n\ntemplate.withSession(session)\n.execute(action -> {\n\n Query query = query(where(\"name\").is(\"Durzo Blint\"));\n return action.findOne(query, Person.class)\n .flatMap(durzo -> {\n\n Person azoth = new Person(\"Kylar Stern\");\n azoth.setMaster(durzo);\n\n return action.insert(azoth); <2>\n });\n }, ClientSession::close) <3>\n .subscribe(); <4>\n----\n\n<1> Obtain a `Publisher` for new session retrieval.\n<2> Use `ReactiveMongoOperation` methods as before.\nThe `ClientSession` is obtained and applied automatically.\n<3> Make sure to close the `ClientSession`.\n<4> Nothing happens until you subscribe.\nSee https://projectreactor.io/docs/core/release/reference/#reactive.subscribe[the Project Reactor Reference Guide] for details.\n\nBy using a `Publisher` that provides the actual session, you can defer session acquisition to the point of actual subscription.\nStill, you need to close the session when done, so as to not pollute the server with stale sessions.\nUse the `doFinally` hook on `execute` to call `ClientSession#close()` when you no longer need the session.\nIf you prefer having more control over the session itself, you can obtain the `ClientSession` through the driver and provide it through a `Supplier`.\n\nNOTE: Reactive use of `ClientSession` is limited to Template API usage.\nThere's currently no session integration with reactive repositories.\n====\n======\n\n[[mongo.transactions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "ClientSession support", "heading_level": 2, "file_order": 24, "section_index": 1, "content_hash": "f00c6716d1ec8a3e5f80134de68b3d1c8ca875e9d963768cdf9dffcd5d2cbc40", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:7cf9c598517b75e5cf39d01ffb991da1f73c756a6ce3d4c32c09a797c83bfcc2", "content": "As of version 4, MongoDB supports https://www.mongodb.com/transactions[Transactions].\nTransactions are built on top of xref:mongodb/client-session-transactions.adoc[Sessions] and, consequently, require an active `ClientSession`.\n\nNOTE: Unless you specify a `MongoTransactionManager` within your application context, transaction support is *DISABLED*.\nYou can use `setSessionSynchronization(ALWAYS)` to participate in ongoing non-native MongoDB transactions.\n\nTo get full programmatic control over transactions, you may want to use the session callback on `MongoOperations`.\n\nThe following example shows programmatic transaction control:\n\n.Programmatic transactions\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nClientSession session = client.startSession(options); <1>\n\ntemplate.withSession(session)\n .execute(action -> {\n\n session.startTransaction(); <2>\n\n try {\n\n Step step = // ...;\n action.insert(step);\n\n process(step);\n\n action.update(Step.class).apply(Update.set(\"state\", // ...\n\n session.commitTransaction(); <3>\n\n } catch (RuntimeException e) {\n session.abortTransaction(); <4>\n }\n }, ClientSession::close) <5>\n----\n\n<1> Obtain a new `ClientSession`.\n<2> Start the transaction.\n<3> If everything works out as expected, commit the changes.\n<4> Something broke, so roll back everything.\n<5> Do not forget to close the session when done.\n\nThe preceding example lets you have full control over transactional behavior while using the session scoped `MongoOperations` instance within the callback to ensure the session is passed on to every server call.\nTo avoid some of the overhead that comes with this approach, you can use a `TransactionTemplate` to take away some of the noise of manual transaction flow.\n====\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<DeleteResult> result = Mono\n .from(client.startSession()) <1>\n\n .flatMap(session -> {\n session.startTransaction(); <2>\n\n return Mono.from(collection.deleteMany(session, ...)) <3>\n\n .onErrorResume(e -> Mono.from(session.abortTransaction()).then(Mono.error(e))) <4>\n\n .flatMap(val -> Mono.from(session.commitTransaction()).then(Mono.just(val))) <5>\n\n .doFinally(signal -> session.close()); <6>\n });\n----\n\n<1> First we obviously need to initiate the session.\n<2> Once we have the `ClientSession` at hand, start the transaction.\n<3> Operate within the transaction by passing on the `ClientSession` to the operation.\n<4> If the operations completes exceptionally, we need to stop the transaction and preserve the error.\n<5> Or of course, commit the changes in case of success.\nStill preserving the operations result.\n<6> Lastly, we need to make sure to close the session.\n\nThe culprit of the above operation is in keeping the main flows `DeleteResult` instead of the transaction outcome published via either `commitTransaction()` or `abortTransaction()`, which leads to a rather complicated setup.\n\nNOTE: Unless you specify a `ReactiveMongoTransactionManager` within your application context, transaction support is *DISABLED*.\nYou can use `setSessionSynchronization(ALWAYS)` to participate in ongoing non-native MongoDB transactions.\n====\n======\n\n[[mongo.transactions.transaction-template]]\n[[mongo.transactions.reactive-operator]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "MongoDB Transactions", "heading_level": 2, "file_order": 24, "section_index": 2, "content_hash": "7cf9c598517b75e5cf39d01ffb991da1f73c756a6ce3d4c32c09a797c83bfcc2", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:e3f125d13a3df4df3a868133cd51af6917d11aa71dad103f41d87d8e2569aaaa", "content": "Spring Data MongoDB transactions support both `TransactionTemplate` and `TransactionalOperator`.\n\n.Transactions with `TransactionTemplate` / `TransactionalOperator`\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\ntemplate.setSessionSynchronization(ALWAYS); <1>\n\nTransactionTemplate txTemplate = new TransactionTemplate(anyTxManager); <2>\n\ntxTemplate.execute(new TransactionCallbackWithoutResult() {\n\n @Override\n protected void doInTransactionWithoutResult(TransactionStatus status) { <3>\n\n Step step = // ...;\n template.insert(step);\n\n process(step);\n\n template.update(Step.class).apply(Update.set(\"state\", // ...\n }\n});\n----\n\n<1> Enable transaction synchronization during Template API configuration.\n<2> Create the `TransactionTemplate` using the provided `PlatformTransactionManager`.\n<3> Within the callback the `ClientSession` and transaction are already registered.\n\nCAUTION: Changing state of `MongoTemplate` during runtime (as you might think would be possible in item 1 of the preceding listing) can cause threading and visibility issues.\n====\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ntemplate.setSessionSynchronization(ALWAYS); <1>\n\nTransactionalOperator rxtx = TransactionalOperator.create(anyTxManager,\n new DefaultTransactionDefinition()); <2>\n\nStep step = // ...;\ntemplate.insert(step);\n\nMono<Void> process(step)\n .then(template.update(Step.class).apply(Update.set(\"state\", …))\n .as(rxtx::transactional) <3>\n .then();\n----\n\n<1> Enable transaction synchronization for Transactional participation.\n<2> Create the `TransactionalOperator` using the provided `ReactiveTransactionManager`.\n<3> `TransactionalOperator.transactional(…)` provides transaction management for all upstream operations.\n====\n======\n\n[[mongo.transactions.tx-manager]]\n[[mongo.transactions.reactive-tx-manager]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "Transactions with TransactionTemplate / TransactionalOperator", "heading_level": 2, "file_order": 24, "section_index": 3, "content_hash": "e3f125d13a3df4df3a868133cd51af6917d11aa71dad103f41d87d8e2569aaaa", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:6032c8f3a5292346ef4bd61afb1c2270c4447223488fe8b85275058e2326ace2", "content": "`MongoTransactionManager` / `ReactiveMongoTransactionManager` is the gateway to the well known Spring transaction support.\nIt lets applications use link:{springDocsUrl}/data-access.html#transaction[the managed transaction features of Spring].\nThe `MongoTransactionManager` binds a `ClientSession` to the thread whereas the `ReactiveMongoTransactionManager` is using the `ReactorContext` for this.\n`MongoTemplate` detects the session and operates on these resources which are associated with the transaction accordingly.\n`MongoTemplate` can also participate in other, ongoing transactions.\nThe following example shows how to create and use transactions with a `MongoTransactionManager`:\n\n.Transactions with `MongoTransactionManager` / `ReactiveMongoTransactionManager`\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\nstatic class Config extends AbstractMongoClientConfiguration {\n\n @Bean\n MongoTransactionManager transactionManager(MongoDatabaseFactory dbFactory) { <1>\n return new MongoTransactionManager(dbFactory);\n }\n\n @Bean\n MongoTemplate mongoTemplate(MongoDatabaseFactory dbFactory) { <1>\n return new MongoTemplate(dbFactory);\n }\n\n // ...\n}\n\n@Component\npublic class StateService {\n\n @Transactional\n void someBusinessFunction(Step step) { <2>\n\n template.insert(step);\n\n process(step);\n\n template.update(Step.class).apply(Update.set(\"state\", // ...\n };\n});\n\n----\n\n<1> Register `MongoTransactionManager` in the application context.\nAlso, make sure to use the same `MongoDatabaseFactory` when creating `MongoTemplate` to participate in transactions in the scope of the same `MongoDatabaseFactory`.\n<2> Mark methods as transactional.\n\nNOTE: `@Transactional(readOnly = true)` advises `MongoTransactionManager` to also start a transaction that adds the\n`ClientSession` to outgoing requests.\n====\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\npublic class Config extends AbstractReactiveMongoConfiguration {\n\n @Bean\n ReactiveMongoTransactionManager transactionManager(ReactiveMongoDatabaseFactory factory) { <1>\n return new ReactiveMongoTransactionManager(factory);\n }\n\n @Bean\n ReactiveMongoTemplate reactiveMongoTemplate(ReactiveMongoDatabaseFactory dbFactory) { <1>\n return new ReactiveMongoTemplate(dbFactory);\n }\n\n // ...\n}\n\n@Service\npublic class StateService {\n\n @Transactional\n Mono<UpdateResult> someBusinessFunction(Step step) { <2>\n\n return template.insert(step)\n .then(process(step))\n .then(template.update(Step.class).apply(Update.set(\"state\", …));\n };\n});\n\n----\n\n<1> Register `ReactiveMongoTransactionManager` in the application context.\nAlso, make sure to use the same `ReactiveMongoDatabaseFactory` when creating `ReactiveMongoTemplate` to participate in transactions in the scope of the same `ReactiveMongoDatabaseFactory`.\n<2> Mark methods as transactional.\n\nNOTE: `@Transactional(readOnly = true)` advises `ReactiveMongoTransactionManager` to also start a transaction that adds the `ClientSession` to outgoing requests.\n====\n======\n\n[[mongo.transaction.options]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "Transactions with MongoTransactionManager & ReactiveMongoTransactionManager", "heading_level": 2, "file_order": 24, "section_index": 4, "content_hash": "6032c8f3a5292346ef4bd61afb1c2270c4447223488fe8b85275058e2326ace2", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:0c8072e5a2a238c25a029a163a5a1c577f6e0beaf11358320f74748ebd044ba5", "content": "Transactional service methods can require specific transaction options to run a transaction.\nSpring Data MongoDB's transaction managers support evaluation of transaction labels such as `@Transactional(label = { \"mongo:readConcern=available\" })`.\n\nBy default, the label namespace using the `mongo:` prefix is evaluated by `MongoTransactionOptionsResolver` that is configured by default.\nTransaction labels are provided by `TransactionAttribute` and available to programmatic transaction control through `TransactionTemplate` and `TransactionalOperator`.\nDue to their declarative nature, `@Transactional(label = …)` provides a good starting point that also can serve as documentation.\n\nCurrently, the following options are supported:\n\nMax Commit Time::\n\nControls the maximum execution time on the server for the commitTransaction operation.\nThe format of the value corresponds with ISO-8601 duration format as used with `Duration.parse(…)`.\n+\nUsage:\n`mongo:maxCommitTime=PT1S`\n\nRead Concern::\n\nSets the read concern for the transaction.\n+\nUsage:\n`mongo:readConcern=LOCAL|MAJORITY|LINEARIZABLE|SNAPSHOT|AVAILABLE`\n\nRead Preference::\n\nSets the read preference for the transaction.\n+\nUsage:\n`mongo:readPreference=PRIMARY|SECONDARY|SECONDARY_PREFERRED|PRIMARY_PREFERRED|NEAREST`\n\nWrite Concern::\n\nSets the write concern for the transaction.\n+\nUsage:\n`mongo:writeConcern=ACKNOWLEDGED|W1|W2|W3|UNACKNOWLEDGED|JOURNALED|MAJORITY`\n\nNOTE: Nested transactions that join the outer transaction do not affect the initial transaction options as the transaction is already started.\nTransaction options are only applied when a new transaction is started.\n\n[[mongo.transactions.behavior]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "Controlling MongoDB-specific Transaction Options", "heading_level": 3, "file_order": 24, "section_index": 5, "content_hash": "0c8072e5a2a238c25a029a163a5a1c577f6e0beaf11358320f74748ebd044ba5", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:3349476bf2e30738dfa4a101179f5599cce9d62e90d7fbeed6f3bf6885b0e526", "content": "Inside transactions, MongoDB server has a slightly different behavior.\n\n*Connection Settings*\n\nThe MongoDB drivers offer a dedicated replica set name configuration option turing the driver into auto-detection mode.\nThis option helps identify the primary replica set nodes and command routing during a transaction.\n\nNOTE: Make sure to add `replicaSet` to the MongoDB URI.\nPlease refer to https://docs.mongodb.com/manual/reference/connection-string/#connections-connection-options[connection string options] for further details.\n\n*Collection Operations*\n\nMongoDB does *not* support collection operations, such as collection creation, within a transaction.\nThis also affects the on the fly collection creation that happens on first usage.\nTherefore, make sure to have all required structures in place.\n\n*Transient Errors*\n\nMongoDB can add special labels to errors raised during transactional operations.\nThose may indicate transient failures that might vanish by merely retrying the operation.\nWe highly recommend https://github.com/spring-projects/spring-retry[Spring Retry] for those purposes.\nNevertheless, one may override `MongoTransactionManager#doCommit(MongoTransactionObject)` to implement a https://docs.mongodb.com/manual/core/transactions/#retry-commit-operation[Retry Commit Operation]\nbehavior as outlined in the MongoDB reference manual.\n\n*Count*\n\nMongoDB `count` operates upon collection statistics which may not reflect the actual situation within a transaction.\nThe server responds with _error 50851_ when issuing a `count` command inside a multi-document transaction.\nOnce `MongoTemplate` detects an active transaction, all exposed `count()` methods are converted and delegated to the aggregation framework using `$match` and `$count` operators, preserving `Query` settings, such as `collation`.\n\nRestrictions apply when using geo commands inside of the aggregation count helper.\nThe following operators cannot be used and must be replaced with a different operator:\n\n* `$where` -> `$expr`\n* `$near` -> `$geoWithin` with `$center`\n* `$nearSphere` -> `$geoWithin` with `$centerSphere`\n\nQueries using `Criteria.near(…)` and `Criteria.nearSphere(…)` must be rewritten to `Criteria.within(…)` respective `Criteria.withinSphere(…)`.\nSame applies for the `near` query keyword in repository query methods that must be changed to `within`.\nSee also MongoDB JIRA ticket https://jira.mongodb.org/browse/DRIVERS-518[DRIVERS-518] for further reference.\n\nThe following snippet shows `count` usage inside the session-bound closure:\n\n====\n[source,javascript]\n----\nsession.startTransaction();\n\ntemplate.withSession(session)\n .execute(ops -> {\n return ops.count(query(where(\"state\").is(\"active\")), Step.class)\n });\n----\n====\n\nThe snippet above materializes in the following command:\n\n====\n[source,javascript]\n----\ndb.collection.aggregate(\n [\n { $match: { state: \"active\" } },\n { $count: \"totalEntityCount\" }\n ]\n)\n----\n====\n\ninstead of:\n\n====\n[source,javascript]\n----\ndb.collection.find( { state: \"active\" } ).count()\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc", "title": "client-session-transactions", "heading": "Special behavior inside transactions", "heading_level": 2, "file_order": 24, "section_index": 6, "content_hash": "3349476bf2e30738dfa4a101179f5599cce9d62e90d7fbeed6f3bf6885b0e526", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/client-session-transactions.adoc"}}
{"id": "sha256:97fb58a7696d5d15d3774764ea40be9c9dcd184e0d893cd6bd6b70f3e49ec624", "content": "[[mongo.collation]]\n\nSince version 3.4, MongoDB supports collations for collection and index creation and various query operations.\nCollations define string comparison rules based on the http://userguide.icu-project.org/collation/concepts[ICU collations].\nA collation document consists of various properties that are encapsulated in `Collation`, as the following listing shows:\n\n====\n[source,java]\n----\nCollation collation = Collation.of(\"fr\") <1>\n\n .strength(ComparisonLevel.secondary() <2>\n .includeCase())\n\n .numericOrderingEnabled() <3>\n\n .alternate(Alternate.shifted().punct()) <4>\n\n .forwardDiacriticSort() <5>\n\n .normalizationEnabled(); <6>\n----\n<1> `Collation` requires a locale for creation. This can be either a string representation of the locale, a `Locale` (considering language, country, and variant) or a `CollationLocale`. The locale is mandatory for creation.\n<2> Collation strength defines comparison levels that denote differences between characters. You can configure various options (case-sensitivity, case-ordering, and others), depending on the selected strength.\n<3> Specify whether to compare numeric strings as numbers or as strings.\n<4> Specify whether the collation should consider whitespace and punctuation as base characters for purposes of comparison.\n<5> Specify whether strings with diacritics sort from back of the string, such as with some French dictionary ordering.\n<6> Specify whether to check whether text requires normalization and whether to perform normalization.\n====\n\nCollations can be used to create collections and indexes. If you create a collection that specifies a collation, the\ncollation is applied to index creation and queries unless you specify a different collation. A collation is valid for a\nwhole operation and cannot be specified on a per-field basis.\n\nLike other metadata, collations can be be derived from the domain type via the `collation` attribute of the `@Document`\nannotation and will be applied directly when running queries, creating collections or indexes.\n\nNOTE: Annotated collations will not be used when a collection is auto created by MongoDB on first interaction. This would\nrequire additional store interaction delaying the entire process. Please use `MongoOperations.createCollection` for those cases.\n\n[source,java]\n----\nCollation french = Collation.of(\"fr\");\nCollation german = Collation.of(\"de\");\n\ntemplate.createCollection(Person.class, CollectionOptions.just(collation));\n\ntemplate.indexOps(Person.class).ensureIndex(new Index(\"name\", Direction.ASC).collation(german));\n----\n\nNOTE: MongoDB uses simple binary comparison if no collation is specified (`Collation.simple()`).\n\nUsing collations with collection operations is a matter of specifying a `Collation` instance in your query or operation options, as the following two examples show:\n\n.Using collation with `find`\n====\n[source,java]\n----\nCollation collation = Collation.of(\"de\");\n\nQuery query = new Query(Criteria.where(\"firstName\").is(\"Amél\")).collation(collation);\n\nList<Person> results = template.find(query, Person.class);\n----\n====\n\n.Using collation with `aggregate`\n====\n[source,java]\n----\nCollation collation = Collation.of(\"de\");\n\nAggregationOptions options = AggregationOptions.builder().collation(collation).build();\n\nAggregation aggregation = newAggregation(\n project(\"tags\"),\n unwind(\"tags\"),\n group(\"tags\")\n .count().as(\"count\")\n).withOptions(options);\n\nAggregationResults<TagCount> results = template.aggregate(aggregation, \"tags\", TagCount.class);\n----\n====\n\nWARNING: Indexes are only used if the collation used for the operation matches the index collation.\n\nxref:mongodb/repositories/repositories.adoc[MongoDB Repositories] support `Collations` via the `collation` attribute of the `@Query` annotation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/collation.adoc", "title": "collation", "heading": "collation", "heading_level": 1, "file_order": 25, "section_index": 0, "content_hash": "97fb58a7696d5d15d3774764ea40be9c9dcd184e0d893cd6bd6b70f3e49ec624", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/collation.adoc"}}
{"id": "sha256:62ac01a3f4aff186453ddcbcd1928a29b5b6a27d9f2b156b7c732f001ab80140", "content": "[[mongodb-connectors]]\n\nOne of the first tasks when using MongoDB and Spring is to create a `MongoClient` object using the IoC container.\nThere are two main ways to do this, either by using Java-based bean metadata or by using XML-based bean metadata.\n\nNOTE: For those not familiar with how to configure the Spring container using Java-based bean metadata instead of XML-based metadata, see the high-level introduction in the reference docs https://docs.spring.io/spring/docs/3.2.x/spring-framework-reference/html/new-in-3.0.html#new-java-configuration[here] as well as the detailed documentation https://docs.spring.io/spring-framework/docs/{springVersion}/reference/html/core.html#beans-java-instantiating-container[here].\n\n[[mongo.mongo-java-config]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/configuration.adoc", "title": "configuration", "heading": "configuration", "heading_level": 1, "file_order": 26, "section_index": 0, "content_hash": "62ac01a3f4aff186453ddcbcd1928a29b5b6a27d9f2b156b7c732f001ab80140", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/configuration.adoc"}}
{"id": "sha256:218e126e66d4e97bddb1c87259352b5aecf1039147155ffc530ff99a87910ba1", "content": "The following example shows an example to register an instance of a `MongoClient`:\n\n.Registering `MongoClient`\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\npublic class AppConfig {\n\n /*\n * Use the standard Mongo driver API to create a com.mongodb.client.MongoClient instance.\n */\n public @Bean com.mongodb.client.MongoClient mongoClient() {\n return com.mongodb.client.MongoClients.create(\"mongodb://localhost:27017\");\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\npublic class AppConfig {\n\n /*\n * Use the standard Mongo driver API to create a com.mongodb.client.MongoClient instance.\n */\n public @Bean com.mongodb.reactivestreams.client.MongoClient mongoClient() {\n return com.mongodb.reactivestreams.client.MongoClients.create(\"mongodb://localhost:27017\");\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"third\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxmlns:mongo=\"http://www.springframework.org/schema/data/mongo\"\nxsi:schemaLocation=\n\"\nhttp://www.springframework.org/schema/data/mongo https://www.springframework.org/schema/data/mongo/spring-mongo.xsd\nhttp://www.springframework.org/schema/beans\nhttps://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n <!-- Default bean name is 'mongo' -->\n <mongo:mongo-client host=\"localhost\" port=\"27017\"/>\n\n</beans>\n----\n======\n\nThis approach lets you use the standard `MongoClient` instance, with the container using Spring's `MongoClientFactoryBean`/`ReactiveMongoClientFactoryBean`.\nAs compared to instantiating a `MongoClient` instance directly, the `FactoryBean` has the added advantage of also providing the container with an `ExceptionTranslator` implementation that translates MongoDB exceptions to exceptions in Spring's portable `DataAccessException` hierarchy for data access classes annotated with the `@Repository` annotation.\nThis hierarchy and the use of `@Repository` is described in link:{springDocsUrl}/data-access.html[Spring's DAO support features].\n\nThe following example shows an example of a Java-based bean metadata that supports exception translation on `@Repository` annotated classes:\n\n.Registering a `MongoClient` via `MongoClientFactoryBean` / `ReactiveMongoClientFactoryBean`\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\npublic class AppConfig {\n\n /*\n * Factory bean that creates the com.mongodb.client.MongoClient instance\n */\n public @Bean MongoClientFactoryBean mongo() {\n MongoClientFactoryBean mongo = new MongoClientFactoryBean();\n mongo.setHost(\"localhost\");\n return mongo;\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\npublic class AppConfig {\n\n /*\n * Factory bean that creates the com.mongodb.reactivestreams.client.MongoClient instance\n */\n public @Bean ReactiveMongoClientFactoryBean mongo() {\n ReactiveMongoClientFactoryBean mongo = new ReactiveMongoClientFactoryBean();\n mongo.setHost(\"localhost\");\n return mongo;\n }\n}\n----\n======\n\nTo access the `MongoClient` object created by the `FactoryBean` in other `@Configuration` classes or your own classes, use a `private @Autowired MongoClient mongoClient;` field.\n\n[[mongo.mongo-db-factory]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/configuration.adoc", "title": "configuration", "heading": "Registering a Mongo Instance", "heading_level": 2, "file_order": 26, "section_index": 1, "content_hash": "218e126e66d4e97bddb1c87259352b5aecf1039147155ffc530ff99a87910ba1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/configuration.adoc"}}
{"id": "sha256:9c0fef02e5c1e7f6400363537dcd0750fcef3d4397384bd3fcbec433685a40aa", "content": "While `MongoClient` is the entry point to the MongoDB driver API, connecting to a specific MongoDB database instance requires additional information, such as the database name and an optional username and password.\nWith that information, you can obtain a `MongoDatabase` object and access all the functionality of a specific MongoDB database instance.\nSpring provides the `org.springframework.data.mongodb.core.MongoDatabaseFactory` & `org.springframework.data.mongodb.core.ReactiveMongoDatabaseFactory` interfaces, shown in the following listing, to bootstrap connectivity to the database:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface MongoDatabaseFactory {\n\n MongoDatabase getDatabase() throws DataAccessException;\n\n MongoDatabase getDatabase(String dbName) throws DataAccessException;\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface ReactiveMongoDatabaseFactory {\n\n Mono<MongoDatabase> getDatabase() throws DataAccessException;\n\n Mono<MongoDatabase> getDatabase(String dbName) throws DataAccessException;\n}\n----\n======\n\nThe following sections show how you can use the container with either Java-based or XML-based metadata to configure an instance of the `MongoDatabaseFactory` interface.\nIn turn, you can use the `MongoDatabaseFactory` / `ReactiveMongoDatabaseFactory` instance to configure `MongoTemplate` / `ReactiveMongoTemplate`.\n\nInstead of using the IoC container to create an instance of the template, you can use them in standard Java code, as follows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic class MongoApplication {\n\n public static void main(String[] args) throws Exception {\n\n MongoOperations mongoOps = new MongoTemplate(new SimpleMongoClientDatabaseFactory(MongoClients.create(), \"database\"));\n\n // ...\n }\n}\n----\nThe code in bold highlights the use of `SimpleMongoClientDbFactory` and is the only difference between the listing shown in the xref:mongodb/getting-started.adoc[getting started section].\nUse `SimpleMongoClientDbFactory` when choosing `com.mongodb.client.MongoClient` as the entrypoint of choice.\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic class ReactiveMongoApplication {\n\n public static void main(String[] args) throws Exception {\n\n ReactiveMongoOperations mongoOps = new MongoTemplate(new SimpleReactiveMongoDatabaseFactory(MongoClients.create(), \"database\"));\n\n // ...\n }\n}\n----\n======\n\n[[mongo.mongo-db-factory-java]]\n[[mongo.mongo-db-factory.config]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/configuration.adoc", "title": "configuration", "heading": "The MongoDatabaseFactory Interface", "heading_level": 2, "file_order": 26, "section_index": 2, "content_hash": "9c0fef02e5c1e7f6400363537dcd0750fcef3d4397384bd3fcbec433685a40aa", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/configuration.adoc"}}
{"id": "sha256:b384a35bf595de49d07773e8875651a9df039314fc5560a44efd9ce0de36e1f5", "content": "To register a `MongoDatabaseFactory`/ `ReactiveMongoDatabaseFactory` instance with the container, you write code much like what was highlighted in the previous section.\nThe following listing shows a simple example:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\npublic class MongoConfiguration {\n\n @Bean\n public MongoDatabaseFactory mongoDatabaseFactory() {\n return new SimpleMongoClientDatabaseFactory(MongoClients.create(), \"database\");\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\npublic class ReactiveMongoConfiguration {\n\n @Bean\n public ReactiveMongoDatabaseFactory mongoDatabaseFactory() {\n return new SimpleReactiveMongoDatabaseFactory(MongoClients.create(), \"database\");\n }\n}\n----\n======\n\nMongoDB Server generation 3 changed the authentication model when connecting to the DB.\nTherefore, some of the configuration options available for authentication are no longer valid.\nYou should use the `MongoClient`-specific options for setting credentials through `MongoCredential` to provide authentication data, as shown in the following example:\n\n[tabs]\n======\nJava::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\npublic class MongoAppConfig extends AbstractMongoClientConfiguration {\n\n @Override\n public String getDatabaseName() {\n return \"database\";\n }\n\n @Override\n protected void configureClientSettings(Builder builder) {\n\n builder\n .credential(MongoCredential.createCredential(\"name\", \"db\", \"pwd\".toCharArray()))\n .applyToClusterSettings(settings -> {\n settings.hosts(singletonList(new ServerAddress(\"127.0.0.1\", 27017)));\n });\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<mongo:db-factory dbname=\"database\" />\n----\nUsername and password credentials used in XML-based configuration must be URL-encoded when these contain reserved characters, such as `:`, `%`, `@`, or `,`.\nThe following example shows encoded credentials:\n`m0ng0@dmin:mo_res:bw6},Qsdxx@admin@database` -> `m0ng0%40dmin:mo_res%3Abw6%7D%2CQsdxx%40admin@database`\nSee https://tools.ietf.org/html/rfc3986#section-2.2[section 2.2 of RFC 3986] for further details.\n======\n\nIf you need to configure additional options on the `com.mongodb.client.MongoClient` instance that is used to create a `SimpleMongoClientDbFactory`, you can refer to an existing bean as shown in the following example. To show another common usage pattern, the following listing shows the use of a property placeholder, which lets you parametrize the configuration and the creation of a `MongoTemplate`:\n\n[tabs]\n======\nJava::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\n@PropertySource(\"classpath:/com/myapp/mongodb/config/mongo.properties\")\npublic class MongoAppConfig extends AbstractMongoClientConfiguration {\n\n @Autowired\n Environment env;\n\n @Override\n public String getDatabaseName() {\n return \"database\";\n }\n\n @Override\n protected void configureClientSettings(Builder builder) {\n\n builder.applyToClusterSettings(settings -> {\n settings.hosts(singletonList(\n new ServerAddress(env.getProperty(\"mongo.host\"), env.getProperty(\"mongo.port\", Integer.class))));\n });\n\n builder.applyToConnectionPoolSettings(settings -> {\n\n settings.maxConnectionLifeTime(env.getProperty(\"mongo.pool-max-life-time\", Integer.class), TimeUnit.MILLISECONDS)\n .minSize(env.getProperty(\"mongo.pool-min-size\", Integer.class))\n .maxSize(env.getProperty(\"mongo.pool-max-size\", Integer.class))\n .maintenanceFrequency(10, TimeUnit.MILLISECONDS)\n .maintenanceInitialDelay(11, TimeUnit.MILLISECONDS)\n .maxConnectionIdleTime(30, TimeUnit.SECONDS)\n .maxWaitTime(15, TimeUnit.MILLISECONDS);\n });\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<context:property-placeholder location=\"classpath:/com/myapp/mongodb/config/mongo.properties\"/>\n\n<mongo:mongo-client host=\"${mongo.host}\" port=\"${mongo.port}\">\n <mongo:client-settings connection-pool-max-connection-life-time=\"${mongo.pool-max-life-time}\"\n connection-pool-min-size=\"${mongo.pool-min-size}\"\n connection-pool-max-size=\"${mongo.pool-max-size}\"\n connection-pool-maintenance-frequency=\"10\"\n connection-pool-maintenance-initial-delay=\"11\"\n connection-pool-max-connection-idle-time=\"30\"\n connection-pool-max-wait-time=\"15\" />\n</mongo:mongo-client>\n\n<mongo:db-factory dbname=\"database\" mongo-ref=\"mongoClient\"/>\n\n<bean id=\"anotherMongoTemplate\" class=\"org.springframework.data.mongodb.core.MongoTemplate\">\n <constructor-arg name=\"mongoDbFactory\" ref=\"mongoDbFactory\"/>\n</bean>\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/configuration.adoc", "title": "configuration", "heading": "Registering a `MongoDatabaseFactory` / `ReactiveMongoDatabaseFactory`", "heading_level": 2, "file_order": 26, "section_index": 3, "content_hash": "b384a35bf595de49d07773e8875651a9df039314fc5560a44efd9ce0de36e1f5", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/configuration.adoc"}}
{"id": "sha256:20df09e36210b30c4ab13d0b10b0f6e37f553c0ee3df45d1807624cdc3363231", "content": "[[mongo-template.type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc", "title": "converters-type-mapping", "heading": "converters-type-mapping", "heading_level": 1, "file_order": 27, "section_index": 0, "content_hash": "20df09e36210b30c4ab13d0b10b0f6e37f553c0ee3df45d1807624cdc3363231", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc"}}
{"id": "sha256:45562fa780017a7966c8884ac6029b0dae995c1a767f44eb01072a29e80ab753", "content": "MongoDB collections can contain documents that represent instances of a variety of types.\nThis feature can be useful if you store a hierarchy of classes or have a class with a property of type `Object`.In the latter case, the values held inside that property have to be read in correctly when retrieving the object.Thus, we need a mechanism to store type information alongside the actual document.\n\nTo achieve that, the `MappingMongoConverter` uses a `MongoTypeMapper` abstraction with `DefaultMongoTypeMapper` as its main implementation.Its default behavior to store the fully qualified classname under `_class` inside the document.Type hints are written for top-level documents as well as for every value (if it is a complex type and a subtype of the declared property type).The following example (with a JSON representation at the end) shows how the mapping works:\n\n.Type mapping\n====\n[source,java]\n----\nclass Sample {\n Contact value;\n}\n\nabstract class Contact { … }\n\nclass Person extends Contact { … }\n\nSample sample = new Sample();\nsample.value = new Person();\n\nmongoTemplate.save(sample);\n\n{\n \"value\" : { \"_class\" : \"com.acme.Person\" },\n \"_class\" : \"com.acme.Sample\"\n}\n----\n====\n\nSpring Data MongoDB stores the type information as the last field for the actual root class as well as for the nested type (because it is complex and a subtype of `Contact`).So, if you now use `mongoTemplate.findAll(Object.class, \"sample\")`, you can find out that the document stored is a `Sample` instance.You can also find out that the value property is actually a `Person`.\n\n[[customizing-type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc", "title": "converters-type-mapping", "heading": "Type Mapping", "heading_level": 2, "file_order": 27, "section_index": 1, "content_hash": "45562fa780017a7966c8884ac6029b0dae995c1a767f44eb01072a29e80ab753", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc"}}
{"id": "sha256:a358fe0c00c5093b912a3d10de048ba7ecf126d5cf33431393fb5e373a9efea1", "content": "If you want to avoid writing the entire Java class name as type information but would rather like to use a key, you can use the `@TypeAlias` annotation on the entity class.If you need to customize the mapping even more, have a look at the `TypeInformationMapper` interface.An instance of that interface can be configured at the `DefaultMongoTypeMapper`, which can, in turn, be configured on `MappingMongoConverter`.The following example shows how to define a type alias for an entity:\n\n.Defining a type alias for an Entity\n====\n[source,java]\n----\n@TypeAlias(\"pers\")\nclass Person {\n\n}\n----\n====\n\nNote that the resulting document contains `pers` as the value in the `_class` Field.\n\n[WARNING]\n====\nType aliases only work if the mapping context is aware of the actual type.\nThe required entity metadata is determined either on first save or has to be provided via the configurations initial entity set.\nBy default, the configuration class scans the base package for potential candidates.\n\n[source,java]\n----\n@Configuration\nclass AppConfig extends AbstractMongoClientConfiguration {\n\n @Override\n protected Set<Class<?>> getInitialEntitySet() {\n return Collections.singleton(Person.class);\n }\n\n // ...\n}\n----\n====\n\n[[configuring-custom-type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc", "title": "converters-type-mapping", "heading": "Customizing Type Mapping", "heading_level": 3, "file_order": 27, "section_index": 2, "content_hash": "a358fe0c00c5093b912a3d10de048ba7ecf126d5cf33431393fb5e373a9efea1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc"}}
{"id": "sha256:1ba27ae973a6bac68851eb56c3049d6f2444c347ac790f7df0e2d09525c1feac", "content": "The following example shows how to configure a custom `MongoTypeMapper` in `MappingMongoConverter`:\n\n[source,java]\n----\nclass CustomMongoTypeMapper extends DefaultMongoTypeMapper {\n //implement custom type mapping here\n}\n----\n\n.Configuring a custom `MongoTypeMapper`\n====\n.Java\n[source,java,role=\"primary\"]\n----\n@Configuration\nclass SampleMongoConfiguration extends AbstractMongoClientConfiguration {\n\n @Override\n protected String getDatabaseName() {\n return \"database\";\n }\n\n @Bean\n @Override\n public MappingMongoConverter mappingMongoConverter(MongoDatabaseFactory databaseFactory,\n MongoCustomConversions customConversions, MongoMappingContext mappingContext) {\n MappingMongoConverter mmc = super.mappingMongoConverter();\n mmc.setTypeMapper(customTypeMapper());\n return mmc;\n }\n\n @Bean\n public MongoTypeMapper customTypeMapper() {\n return new CustomMongoTypeMapper();\n }\n}\n----\n\n.XML\n[source,xml,role=\"secondary\"]\n----\n<mongo:mapping-converter type-mapper-ref=\"customMongoTypeMapper\"/>\n\n<bean name=\"customMongoTypeMapper\" class=\"com.acme.CustomMongoTypeMapper\"/>\n----\n====\n\nNote that the preceding example extends the `AbstractMongoClientConfiguration` class and overrides the bean definition of the `MappingMongoConverter` where we configured our custom `MongoTypeMapper`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc", "title": "converters-type-mapping", "heading": "Configuring Custom Type Mapping", "heading_level": 3, "file_order": 27, "section_index": 3, "content_hash": "1ba27ae973a6bac68851eb56c3049d6f2444c347ac790f7df0e2d09525c1feac", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/converters-type-mapping.adoc"}}
{"id": "sha256:b0eb876b19e1f7a815124844023ba6e77d3725d06decac15322e6cdf348a9f3b", "content": "TODO: add the following section somewhere\n\n[[mongo.geo-json.jackson-modules]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/geo-json.adoc", "title": "geo-json", "heading": "geo-json", "heading_level": 1, "file_order": 28, "section_index": 0, "content_hash": "b0eb876b19e1f7a815124844023ba6e77d3725d06decac15322e6cdf348a9f3b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/geo-json.adoc"}}
{"id": "sha256:38464997213a6700ba12e5045254c93209aa276b03139565294af532ccda4301", "content": "By using the <<core.web>>, Spring Data registers additional Jackson ``Modules``s to the `ObjectMapper` for de-/serializing common Spring Data domain types.\nPlease refer to the <<core.web.basic.jackson-mappers>> section to learn more about the infrastructure setup of this feature.\n\nThe MongoDB module additionally registers ``JsonDeserializer``s for the following GeoJSON types via its `GeoJsonConfiguration` exposing the `GeoJsonModule`.\n----\norg.springframework.data.mongodb.core.geo.GeoJsonPoint\norg.springframework.data.mongodb.core.geo.GeoJsonMultiPoint\norg.springframework.data.mongodb.core.geo.GeoJsonLineString\norg.springframework.data.mongodb.core.geo.GeoJsonMultiLineString\norg.springframework.data.mongodb.core.geo.GeoJsonPolygon\norg.springframework.data.mongodb.core.geo.GeoJsonMultiPolygon\n----\n\n[NOTE]\n====\nThe `GeoJsonModule` only registers ``JsonDeserializer``s! +\nTo equip the `ObjectMapper` with a symmetric set of ``JsonSerializer``s you need to either manually configure those for the `ObjectMapper` or provide a custom `SpringDataJacksonModules` configuration exposing `GeoJsonModule.serializers()` as a Spring Bean.\n\n[source,java]\n----\nclass GeoJsonConfiguration implements SpringDataJacksonModules {\n\n\t@Bean\n\tpublic Module geoJsonSerializers() {\n return GeoJsonModule.serializers();\n\t}\n}\n----\n====\n\n[WARNING]\n====\nThe next major version (`4.0`) will register both, ``JsonDeserializer``s and ``JsonSerializer``s for GeoJSON types by default.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/geo-json.adoc", "title": "geo-json", "heading": "GeoJSON Jackson Modules", "heading_level": 2, "file_order": 28, "section_index": 1, "content_hash": "38464997213a6700ba12e5045254c93209aa276b03139565294af532ccda4301", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/geo-json.adoc"}}
{"id": "sha256:7cc918c9b6969b6d2fbfb0b05649ce7d741fb59c91a9c3d872f9a4175c36f5c9", "content": "[[mongodb-getting-started]]\n\nAn easy way to bootstrap setting up a working environment is to create a Spring-based project via https://start.spring.io/#!type=maven-project&dependencies=data-mongodb[start.spring.io] or create a Spring project in https://spring.io/tools[Spring Tools].\n\n[[mongo.examples-repo]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/getting-started.adoc", "title": "getting-started", "heading": "getting-started", "heading_level": 1, "file_order": 29, "section_index": 0, "content_hash": "7cc918c9b6969b6d2fbfb0b05649ce7d741fb59c91a9c3d872f9a4175c36f5c9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/getting-started.adoc"}}
{"id": "sha256:6d5397d42dfc46f0ea18b51aa9a32114e0b769fd0ccfa282a765c3303aac6b01", "content": "The GitHub https://github.com/spring-projects/spring-data-examples[spring-data-examples repository] hosts several examples that you can download and play around with to get a feel for how the library works.\n\n[[mongodb.hello-world]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/getting-started.adoc", "title": "getting-started", "heading": "Examples Repository", "heading_level": 2, "file_order": 29, "section_index": 1, "content_hash": "6d5397d42dfc46f0ea18b51aa9a32114e0b769fd0ccfa282a765c3303aac6b01", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/getting-started.adoc"}}
{"id": "sha256:ad5b915f41116bd1293df39f2d7b889268ed5647d8e8ecf343365eb0ab53c1c0", "content": "First, you need to set up a running MongoDB server. Refer to the https://docs.mongodb.org/manual/core/introduction/[MongoDB Quick Start guide] for an explanation on how to startup a MongoDB instance.\nOnce installed, starting MongoDB is typically a matter of running the following command: `/bin/mongod`\n\nThen you can create a `Person` class to persist:\n\n====\n[source,java]\n----\npackage org.springframework.data.mongodb.example;\n\npublic class Person {\n\n\tprivate String id;\n\tprivate String name;\n\tprivate int age;\n\n\tpublic Person(String name, int age) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t}\n\n\tpublic String getId() {\n\t\treturn id;\n\t}\n\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Person [id=\" + id + \", name=\" + name + \", age=\" + age + \"]\";\n\t}\n}\n----\n====\n\nYou also need a main application to run:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npackage org.springframework.data.mongodb.example;\n\nimport static org.springframework.data.mongodb.core.query.Criteria.*;\n\nimport org.springframework.data.mongodb.core.MongoOperations;\nimport org.springframework.data.mongodb.core.MongoTemplate;\n\nimport com.mongodb.client.MongoClients;\n\npublic class MongoApplication {\n\n\tpublic static void main(String[] args) throws Exception {\n\n\t\tMongoOperations mongoOps = new MongoTemplate(MongoClients.create(), \"database\");\n\t\tmongoOps.insert(new Person(\"Joe\", 34));\n\n\t\tSystem.out.println(mongoOps.query(Person.class).matching(where(\"name\").is(\"Joe\")).firstValue());\n\n\t\tmongoOps.dropCollection(\"person\");\n\t}\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npackage org.springframework.data.mongodb.example;\n\nimport static org.springframework.data.mongodb.core.query.Criteria.*;\n\nimport org.springframework.data.mongodb.core.ReactiveMongoOperations;\nimport org.springframework.data.mongodb.core.ReactiveMongoTemplate;\n\nimport com.mongodb.reactivestreams.client.MongoClients;\n\npublic class ReactiveMongoApplication {\n\n\tpublic static void main(String[] args) throws Exception {\n\n\t\tReactiveMongoOperations mongoOps = new ReactiveMongoTemplate(MongoClients.create(), \"database\");\n\n\t\tmongoOps.insert(new Person(\"Joe\", 34))\n\t\t\t.then(mongoOps.query(Person.class).matching(where(\"name\").is(\"Joe\")).first())\n\t\t\t.doOnNext(System.out::println)\n\t\t\t.block();\n\n\t\tmongoOps.dropCollection(\"person\").block();\n\t}\n}\n----\n======\n\nWhen you run the main program, the preceding examples produce the following output:\n\n[source]\n----\n10:01:32,265 DEBUG o.s.data.mongodb.core.MongoTemplate - insert Document containing fields: [_class, age, name] in collection: Person\n10:01:32,765 DEBUG o.s.data.mongodb.core.MongoTemplate - findOne using query: { \"name\" : \"Joe\"} in db.collection: database.Person\nPerson [id=4ddbba3c0be56b7e1b210166, name=Joe, age=34]\n10:01:32,984 DEBUG o.s.data.mongodb.core.MongoTemplate - Dropped collection [database.person]\n----\n\nEven in this simple example, there are few things to notice:\n\n* You can instantiate the central helper class of Spring Mongo, xref:mongodb/template-api.adoc[`MongoTemplate`], by using the standard or reactive `MongoClient` object and the name of the database to use.\n* The mapper works against standard POJO objects without the need for any additional metadata (though you can optionally provide that information. See xref:mongodb/mapping/mapping.adoc[here]).\n* Conventions are used for handling the `id` field, converting it to be an `ObjectId` when stored in the database.\n* Mapping conventions can use field access. Notice that the `Person` class has only getters.\n* If the constructor argument names match the field names of the stored document, they are used to instantiate the object", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/getting-started.adoc", "title": "getting-started", "heading": "Hello World", "heading_level": 2, "file_order": 29, "section_index": 2, "content_hash": "ad5b915f41116bd1293df39f2d7b889268ed5647d8e8ecf343365eb0ab53c1c0", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/getting-started.adoc"}}
{"id": "sha256:e4db358715170119c94b76f56d5cd3ed96bacaf7530880ba1255a206fc990e61", "content": "[[mongo.jmx]]\n\n[NOTE]\n====\nJMX support has been removed in 5.0. +\nWe recommend switching to Spring Boot https://docs.spring.io/spring-boot/reference/actuator/endpoints.html[Actuator Endpoints] and expose those over JMX if needed.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/jmx.adoc", "title": "jmx", "heading": "jmx", "heading_level": 1, "file_order": 30, "section_index": 0, "content_hash": "e4db358715170119c94b76f56d5cd3ed96bacaf7530880ba1255a206fc990e61", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/jmx.adoc"}}
{"id": "sha256:4d75004febb7cc062cf000ff6d0e4e1312c613cf6d035c7e843c84883872832b", "content": "[[mongodb.mapping-usage.events]]\n\nThe MongoDB mapping framework includes several `org.springframework.context.ApplicationEvent` events that your application can respond to by registering special beans in the `ApplicationContext`.\nBeing based on Spring's `ApplicationContext` event infrastructure enables other products, such as Spring Integration, to easily receive these events, as they are a well known eventing mechanism in Spring-based applications.\n\nEntity lifecycle events can be costly and you may notice a change in the performance profile when loading large result sets.\nYou can disable lifecycle events on the javadoc:org.springframework.data.mongodb.core.MongoTemplate#setEntityLifecycleEventsEnabled(boolean)[Template API].\n\nTo intercept an object before it goes through the conversion process (which turns your domain object into a `org.bson.Document`), you can register a subclass of `AbstractMongoEventListener` that overrides the `onBeforeConvert` method.\nWhen the event is dispatched, your listener is called and passed the domain object before it goes into the converter.\nThe following example shows how to do so:\n\n====\n[source,java]\n----\npublic class BeforeConvertListener extends AbstractMongoEventListener<Person> {\n @Override\n public void onBeforeConvert(BeforeConvertEvent<Person> event) {\n ... does some auditing manipulation, set timestamps, whatever ...\n }\n}\n----\n====\n\nTo intercept an object before it goes into the database, you can register a subclass of javadoc:org.springframework.data.mongodb.core.mapping.event.AbstractMongoEventListener[] that overrides the `onBeforeSave` method. When the event is dispatched, your listener is called and passed the domain object and the converted `com.mongodb.Document`. The following example shows how to do so:\n\n====\n[source,java]\n----\npublic class BeforeSaveListener extends AbstractMongoEventListener<Person> {\n @Override\n public void onBeforeSave(BeforeSaveEvent<Person> event) {\n … change values, delete them, whatever …\n }\n}\n----\n====\n\nDeclaring these beans in your Spring ApplicationContext causes them to be invoked whenever the event is dispatched.\n\n.Callbacks on `AbstractMappingEventListener`:\n[%collapsible]\n====\n* `onBeforeConvert`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations before the object is converted to a `Document` by a `MongoConverter`.\n* `onBeforeSave`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations *before* inserting or saving the `Document` in the database.\n* `onAfterSave`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations *after* inserting or saving the `Document` in the database.\n* `onAfterLoad`: Called in `MongoTemplate` `find`, `findAndRemove`, `findOne`, and `getCollection` methods after the `Document` has been retrieved from the database.\n* `onAfterConvert`: Called in `MongoTemplate` `find`, `findAndRemove`, `findOne`, and `getCollection` methods after the `Document` has been retrieved from the database was converted to a POJO.\n====\n\nNOTE: Lifecycle events are only emitted for root level types.\nComplex types used as properties within a document root are not subject to event publication unless they are document references annotated with `@DBRef`.\n\nWARNING: Lifecycle events depend on an `ApplicationEventMulticaster`, which in case of the `SimpleApplicationEventMulticaster` can be configured with a `TaskExecutor`, and therefore gives no guarantees when an Event is processed.\n\ninclude::{commons}@data-commons::page$entity-callbacks.adoc[leveloffset=+1]\n\n[[mongo.entity-callbacks]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc", "title": "lifecycle-events", "heading": "lifecycle-events", "heading_level": 1, "file_order": 31, "section_index": 0, "content_hash": "4d75004febb7cc062cf000ff6d0e4e1312c613cf6d035c7e843c84883872832b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc"}}
{"id": "sha256:6762d02079749d0d0d8ff2677e6c289f6cf48f98977135e43197781493949a2b", "content": "Spring Data MongoDB uses the `EntityCallback` API for its auditing support and reacts on the following callbacks.\n\n.Supported Entity Callbacks\n[%header,cols=\"4\"]\n|===\n| Callback\n| Method\n| Description\n| Order\n\n| `ReactiveBeforeConvertCallback`\n`BeforeConvertCallback`\n| `onBeforeConvert(T entity, String collection)`\n| Invoked before a domain object is converted to `org.bson.Document`.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| `ReactiveAfterConvertCallback`\n`AfterConvertCallback`\n| `onAfterConvert(T entity, org.bson.Document target, String collection)`\n| Invoked after a domain object is loaded. +\nCan modify the domain object after reading it from a `org.bson.Document`.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| `ReactiveAuditingEntityCallback`\n`AuditingEntityCallback`\n| `onBeforeConvert(Object entity, String collection)`\n| Marks an auditable entity _created_ or _modified_\n| 100\n\n| `ReactiveBeforeSaveCallback`\n`BeforeSaveCallback`\n| `onBeforeSave(T entity, org.bson.Document target, String collection)`\n| Invoked before a domain object is saved. +\nCan modify the target, to be persisted, `Document` containing all mapped entity information.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| `ReactiveAfterSaveCallback`\n`AfterSaveCallback`\n| `onAfterSave(T entity, org.bson.Document target, String collection)`\n| Invoked before a domain object is saved. +\nCan modify the domain object, to be returned after save, `Document` containing all mapped entity information.\n| `Ordered.LOWEST_PRECEDENCE`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc", "title": "lifecycle-events", "heading": "Store specific EntityCallbacks", "heading_level": 2, "file_order": 31, "section_index": 1, "content_hash": "6762d02079749d0d0d8ff2677e6c289f6cf48f98977135e43197781493949a2b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc"}}
{"id": "sha256:3e80dd7c59f8164e146827603de086a7b14d127a4e04b070202812556ffacbbe", "content": "Spring Data MongoDB supports Bean Validation for MongoDB entities annotated with https://beanvalidation.org/[https://xxx][Jakarta Validation annotations].\n\nYou can enable Bean Validation by registering `ValidatingEntityCallback` respectively `ReactiveValidatingEntityCallback` for reactive driver usage in your Spring `ApplicationContext` as shown in the following example:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\nclass Config {\n\n @Bean\n public ValidatingEntityCallback validatingEntityCallback(Validator validator) {\n return new ValidatingEntityCallback(validator);\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\nclass Config {\n\n @Bean\n public ReactiveValidatingEntityCallback validatingEntityCallback(Validator validator) {\n return new ReactiveValidatingEntityCallback(validator);\n }\n}\n----\n======\n\nIf you're using both, imperative and reactive, then you can enable also both callbacks.\n\nNOTE: When using XML-based configuration, historically, `ValidatingMongoEventListener` is registered through our namespace handlers when configuring `<mongo:mapping-converter>`.\nIf you want to use the newer Entity Callback variant, make sure to not use `<mongo:mapping-converter>`, otherwise you'll end up with both, the `ValidatingMongoEventListener` and the `ValidatingEntityCallback` being registered.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc", "title": "lifecycle-events", "heading": "Bean Validation", "heading_level": 3, "file_order": 31, "section_index": 2, "content_hash": "3e80dd7c59f8164e146827603de086a7b14d127a4e04b070202812556ffacbbe", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/lifecycle-events.adoc"}}
{"id": "sha256:9be9c42a7fcc9e1bb1d607ea0f9d1c8a2a9061b2a6dc883f010aa43a3967e762", "content": "[[mongo.encryption]]\n\nClient Side Encryption is a feature that encrypts data in your application before it is sent to MongoDB.\nWe recommend you get familiar with the concepts, ideally from the https://www.mongodb.com/docs/manual/core/security-in-use-encryption/[MongoDB Documentation] to learn more about its capabilities and restrictions before you continue applying Encryption through Spring Data.\n\n[NOTE]\n====\nMake sure to set the drivers `com.mongodb.AutoEncryptionSettings` to use client-side encryption.\nMongoDB does not support encryption for all field types.\nSpecific data types require deterministic encryption to preserve equality comparison functionality.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "mongo-encryption", "heading_level": 1, "file_order": 32, "section_index": 0, "content_hash": "9be9c42a7fcc9e1bb1d607ea0f9d1c8a2a9061b2a6dc883f010aa43a3967e762", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:2f342df60916fe9e34c4b206fe0724c459e84d076f2bb5f018ad6f8b8387d817", "content": "Choosing CSFLE gives you full flexibility and allows you to use different keys for a single field, eg. in a one key per tenant scenario. +\nPlease make sure to consult the https://www.mongodb.com/docs/manual/core/csfle/[MongoDB CSFLE Documentation] before you continue reading.\n\n[[mongo.encryption.automatic]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Client Side Field Level Encryption (CSFLE)", "heading_level": 2, "file_order": 32, "section_index": 1, "content_hash": "2f342df60916fe9e34c4b206fe0724c459e84d076f2bb5f018ad6f8b8387d817", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:72e1e7c9e2366bb9957fb0f4908b2b4190103b4fdf9e251310e5e77ccbda647c", "content": "MongoDB supports https://www.mongodb.com/docs/manual/core/csfle/[Client-Side Field Level Encryption] out of the box using the MongoDB driver with its Automatic Encryption feature.\nAutomatic Encryption requires a xref:mongodb/mapping/mapping-schema.adoc[JSON Schema] that allows to perform encrypted read and write operations without the need to provide an explicit en-/decryption step.\n\nPlease refer to the xref:mongodb/mapping/mapping-schema.adoc#mongo.jsonSchema.encrypted-fields[JSON Schema] section for more information on defining a JSON Schema that holds encryption information.\n\nTo use a `MongoJsonSchema`, you must supply it together with `AutoEncryptionSettings` which can be done e.g., via a `MongoClientSettingsBuilderCustomizer`.\n\n[source,java]\n----\n@Bean\nMongoClientSettingsBuilderCustomizer customizer(MappingContext mappingContext) {\n return (builder) -> {\n\n // ... keyVaultCollection, kmsProvider, ...\n\n MongoJsonSchemaCreator schemaCreator = MongoJsonSchemaCreator.create(mappingContext);\n MongoJsonSchema patientSchema = schemaCreator\n .filter(MongoJsonSchemaCreator.encryptedOnly())\n .createSchemaFor(Patient.class);\n\n AutoEncryptionSettings autoEncryptionSettings = AutoEncryptionSettings.builder()\n .keyVaultNamespace(keyVaultCollection)\n .kmsProviders(kmsProviders)\n .extraOptions(extraOpts)\n .schemaMap(Collections.singletonMap(\"db.patient\", patientSchema.schemaDocument().toBsonDocument()))\n .build();\n\n builder.autoEncryptionSettings(autoEncryptionSettings);\n };\n}\n----\n\n[[mongo.encryption.explicit]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Automatic Encryption (CSFLE)", "heading_level": 3, "file_order": 32, "section_index": 2, "content_hash": "72e1e7c9e2366bb9957fb0f4908b2b4190103b4fdf9e251310e5e77ccbda647c", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:edf3d1366525a41429712161c4057cf7e338c9be5a63c0bb67127e0f36c19914", "content": "Explicit encryption uses the MongoDB driver's encryption library (`org.mongodb:mongodb-crypt`) to perform encryption and decryption tasks.\nThe `@ExplicitEncrypted` annotation is a combination of the `@Encrypted` annotation used for xref:mongodb/mapping/mapping-schema.adoc#mongo.jsonSchema.encrypted-fields[JSON Schema creation] and a xref:mongodb/mapping/property-converters.adoc[Property Converter].\nIn other words, `@ExplicitEncrypted` uses existing building blocks to combine them for simplified explicit encryption support.\n\n[NOTE]\n====\nFields annotated with `@ExplicitEncrypted` are always encrypted as whole.\nConsider the following example:\n\n[source,java]\n----\n@ExplicitEncrypted(…)\nString simpleValue; <1>\n\n@ExplicitEncrypted(…)\nAddress address; <2>\n\n@ExplicitEncrypted(…)\nList<...> list; <3>\n\n@ExplicitEncrypted(…)\nMap<..., ...> mapOfString; <4>\n----\n\n<1> Encrypts the value of the simple type such as a `String` if not `null`.\n<2> Encrypts the entire `Address` object and all its nested fields as `Document`.\nTo only encrypt parts of the `Address`, like `Address#street` the `street` field within `Address` needs to be annotated with `@ExplicitEncrypted`.\n<3> ``Collection``-like fields are encrypted as single value and not per entry.\n<4> ``Map``-like fields are encrypted as single value and not as a key/value entry.\n====\n\nClient-Side Field Level Encryption allows you to choose between a deterministic and a randomized algorithm. Depending on the https://www.mongodb.com/docs/v5.0/reference/security-client-side-automatic-json-schema/#std-label-field-level-encryption-json-schema/[chosen algorithm], https://www.mongodb.com/docs/manual/core/csfle/reference/supported-operations/[different operations] may be supported.\nTo pick a certain algorithm use `@ExplicitEncrypted(algorithm)`, see `EncryptionAlgorithms` for algorithm constants.\nPlease read the https://www.mongodb.com/docs/manual/core/csfle/fundamentals/encryption-algorithms[Encryption Types] manual for more information on algorithms and their usage.\n\nTo perform the actual encryption we require a Data Encryption Key (DEK).\nPlease refer to the https://www.mongodb.com/docs/manual/core/csfle/quick-start/#create-a-data-encryption-key[MongoDB Documentation] for more information on how to set up key management and create a Data Encryption Key.\nThe DEK can be referenced directly via its `id` or a defined _alternative name_.\nThe `@EncryptedField` annotation only allows referencing a DEK via an alternative name.\nIt is possible to provide an `EncryptionKeyResolver`, which will be discussed later, to any DEK.\n\n.Reference the Data Encryption Key\n====\n[source,java]\n----\n@EncryptedField(algorithm=…, altKeyName = \"secret-key\") <1>\nString ssn;\n----\n\n[source,java]\n----\n@EncryptedField(algorithm=…, altKeyName = \"/name\") <2>\nString ssn;\n----\n\n<1> Use the DEK stored with the alternative name `secret-key`.\n<2> Uses a field reference that will read the actual field value and use that for key lookup.\nAlways requires the full document to be present for save operations.\nFields cannot be used in queries/aggregations.\n====\n\nBy default, the `@ExplicitEncrypted(value=…)` attribute references a `MongoEncryptionConverter`.\nIt is possible to change the default implementation and exchange it with any `PropertyValueConverter` implementation by providing the according type reference.\nTo learn more about custom `PropertyValueConverters` and the required configuration, please refer to the xref:mongodb/mapping/property-converters.adoc[Property Converters - Mapping specific fields] section.\n\n[[mongo.encryption.queryable]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Explicit Encryption (CSFLE)", "heading_level": 3, "file_order": 32, "section_index": 3, "content_hash": "edf3d1366525a41429712161c4057cf7e338c9be5a63c0bb67127e0f36c19914", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:794b522f0fd3a4e7b3cf29fa1220aadf1e628330880bff2ca68d405e26ce65b8", "content": "Choosing QE enables you to run different types of queries, like _range_ or _equality_, against encrypted fields. +\nPlease make sure to consult the https://www.mongodb.com/docs/manual/core/queryable-encryption/[MongoDB QE Documentation] before you continue reading to learn more about QE features and limitations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Queryable Encryption (QE)", "heading_level": 2, "file_order": 32, "section_index": 4, "content_hash": "794b522f0fd3a4e7b3cf29fa1220aadf1e628330880bff2ca68d405e26ce65b8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:297e80c36d08833a80dcd5abc751b6b7fa1ead80cdf51686c101b28258d4e12a", "content": "Queryable Encryption requires upfront declaration of certain aspects allowed within an actual query against an encrypted field.\nThe information covers the algorithm in use as well as allowed query types along with their attributes and must be provided when creating the collection.\n\n`MongoOperations#createCollection(...)` can be used to do the initial setup for collections utilizing QE.\nThe configuration for QE via Spring Data uses the same building blocks (a xref:mongodb/mapping/mapping-schema.adoc#mongo.jsonSchema.encrypted-fields[JSON Schema creation]) as CSFLE, converting the schema/properties into the configuration format required by MongoDB.\n\nYou can configure Queryable Encryption either manually or in a derived way:\n\n**Manual setup**\n\nManual setup gives you full control over how encrypted fields are declared and how collections are created.\nIt's useful when you need to explicitly manage data keys, encryption algorithms, and field mappings.\n\n** ✅ Full control over encryption configuration\n** ✅ Explicitly manage data keys and algorithms\n** ✅ Allows for complex encryption scenarios\n** ✅ Explicit configuration avoids the risk of surprises (e.g. missing configuration because of improper annotations or class-path scanning)\n** ⚠️ An Explicit Field Configuration can diverge from the domain model and you must keep it in sync with the domain model\n\n**Derived setup**\n\nDerived setup relies on annotations in your domain model and automatically generates the required encrypted field configuration from it.\nThis is simpler and recommended for typical Spring applications where your data model is already annotated.\n\n** ✅ Domain model-driven configuration\n** ✅ Easy to set up and maintain\n** ⚠️ Might not cover all complex scenarios\n** ⚠️ Risk of surprises (e.g. missing configuration for documents based on subtypes because of improper annotations or class-path scanning)\n\n[tabs]\n======\nManual Collection Setup::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n\nBsonBinary pinDK = clientEncryption.createDataKey(\"local\", new com.mongodb.client.model.vault.DataKeyOptions());\nBsonBinary ssnDK = clientEncryption.createDataKey(\"local\", new com.mongodb.client.model.vault.DataKeyOptions());\nBsonBinary ageDK = clientEncryption.createDataKey(\"local\", new com.mongodb.client.model.vault.DataKeyOptions());\nBsonBinary signDK = clientEncryption.createDataKey(\"local\", new com.mongodb.client.model.vault.DataKeyOptions());\n\nCollectionOptions collectionOptions = CollectionOptions.encryptedCollection(options -> options\n .encrypted(string(\"pin\"), pinDK)\n .queryable(encrypted(string(\"ssn\")).algorithm(\"Indexed\").keyId(ssnDK.asUuid()), equality().contention(0))\n .queryable(encrypted(int32(\"age\")).algorithm(\"Range\").keyId(ageDK.asUuid()), range().contention(8).min(0).max(150))\n .queryable(encrypted(int64(\"address.sign\")).algorithm(\"Range\").keyId(signDK.asUuid()), range().contention(2).min(-10L).max(10L))\n);\n\nmongoTemplate.createCollection(Patient.class, collectionOptions); <1>\n----\n<1> Using the template to create the collection may prevent capturing generated keyIds. In this case render the `Document` from the options and use the `createEncryptedCollection(...)` method via the encryption library.\n====\n\nDerived Collection Setup::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nclass Patient {\n\n @Id String id; <1>\n\n Address address; <1>\n\n @Encrypted(algorithm = \"Unindexed\")\n String pin; <2>\n\n @Encrypted(algorithm = \"Indexed\")\n @Queryable(queryType = \"equality\", contentionFactor = 0)\n String ssn; <3>\n\n @RangeEncrypted(contentionFactor = 8, rangeOptions = \"{ 'min' : 0, 'max' : 150 }\")\n Integer age; <4>\n\n @RangeEncrypted(contentionFactor = 0L,\n rangeOptions = \"{\\\"min\\\": {\\\"$numberDouble\\\": \\\"0.3\\\"}, \\\"max\\\": {\\\"$numberDouble\\\": \\\"2.5\\\"}, \\\"precision\\\": 2 }\")\n double height; <5>\n}\n\nMongoJsonSchema patientSchema = MongoJsonSchemaCreator.create(mappingContext)\n .filter(MongoJsonSchemaCreator.encryptedOnly())\n .createSchemaFor(Patient.class);\n\nDocument encryptedFields = CollectionOptions.encryptedCollection(patientSchema)\n .getEncryptedFieldsOptions()\n .map(CollectionOptions.EncryptedFieldsOptions::toDocument)\n .orElseThrow();\n\ntemplate.execute(db -> clientEncryption.createEncryptedCollection(db, template.getCollectionName(Patient.class), new CreateCollectionOptions()\n .encryptedFields(encryptedFields), new CreateEncryptedCollectionParams(\"local\"))); <1>\n\n----\n\n<1> `id` and `address` are not encrypted.\nThose fields can be queried normally.\n<2> `pin` is encrypted but does not support queries.\n<3> `ssn` is encrypted and allows equality queries.\n<4> `age` is encrypted and allows range queries between `0` and `150`.\n<5> `height` is encrypted and allows range queries between `0.3` and `2.5`.\n\nThe `Queryable` annotation allows to define allowed query types for encrypted fields.\n`@RangeEncrypted` is a combination of `@Encrypted` and `@Queryable` for fields allowing `range` queries.\nIt is possible to create custom annotations out of the provided ones.\n====\n\nMongoDB Collection Info::\n+\n====\n[source,json,indent=0,subs=\"verbatim,quotes\",role=\"thrid\"]\n----\n{\n name: 'patient',\n type: 'collection',\n options: {\n encryptedFields: {\n escCollection: 'enxcol_.test.esc',\n ecocCollection: 'enxcol_.test.ecoc',\n fields: [\n {\n keyId: ...,\n path: 'ssn',\n bsonType: 'string',\n queries: [ { queryType: 'equality', contention: Long('0') } ]\n },\n {\n keyId: ...,\n path: 'age',\n bsonType: 'int',\n queries: [ { queryType: 'range', contention: Long('8'), min: 0, max: 150 } ]\n },\n {\n keyId: ...,\n path: 'pin',\n bsonType: 'string'\n },\n {\n keyId: ...,\n path: 'address.sign',\n bsonType: 'long',\n queries: [ { queryType: 'range', contention: Long('2'), min: Long('-10'), max: Long('10') } ]\n }\n ]\n }\n }\n}\n----\n====\n======\n\n[NOTE]\n====\n- It is not possible to use both QE and CSFLE within the same collection.\n- It is not possible to query a `range` indexed field with an `equality` operator.\n- It is not possible to query an `equality` indexed field with a `range` operator.\n- It is not possible to set `bypassAutoEncrytion(true)`.\n- It is not possible to use self maintained encryption keys via `@Encrypted` in combination with Queryable Encryption.\n- Contention is only optional on the server side, the clients requires you to set the value (Default us `8`).\n- Additional options for eg. `min` and `max` need to match the actual field type. Make sure to use `$numberLong` etc. to ensure target types when parsing bson String.\n- Queryable Encryption will an extra field `__safeContent__` to each of your documents.\nUnless explicitly excluded the field will be loaded into memory when retrieving results.\n- For a complete example, see:\nhttps://github.com/mongodb-developer/spring-data-queryable-encryption[spring-data-queryable-encryption]\n====\n\n[[mongo.encryption.queryable.automatic]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Collection Setup", "heading_level": 3, "file_order": 32, "section_index": 5, "content_hash": "297e80c36d08833a80dcd5abc751b6b7fa1ead80cdf51686c101b28258d4e12a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:5921283d5c590eb788e88b67a61a3e2fd1251ca3e65ba3ad2f61d225c4e00171", "content": "MongoDB supports Queryable Encryption out of the box using the MongoDB driver with its Automatic Encryption feature.\nAutomatic Encryption requires a xref:mongodb/mapping/mapping-schema.adoc[JSON Schema] that allows to perform encrypted read and write operations without the need to provide an explicit en-/decryption step.\n\nAll you need to do is create the collection according to the MongoDB documentation.\nYou may utilize techniques to create the required configuration outlined in the section above.\n\n[[mongo.encryption.queryable.manual]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Automatic Encryption (QE)", "heading_level": 3, "file_order": 32, "section_index": 6, "content_hash": "5921283d5c590eb788e88b67a61a3e2fd1251ca3e65ba3ad2f61d225c4e00171", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:5089f8ec8e524a61fd4cf5b0332dce9802491a9741ddbdaa5b75d7df0b4c743d", "content": "Explicit encryption uses the MongoDB driver's encryption library (`org.mongodb:mongodb-crypt`) to perform encryption and decryption tasks based on the meta information provided by annotation within the domain model.\n\n[NOTE]\n====\nThere is no official support for using Explicit Queryable Encryption.\nThe audacious user may combine `@Encrypted` and `@Queryable` with `@ValueConverter(MongoEncryptionConverter.class)` at their own risk.\n====\n\n[[mongo.encryption.explicit-setup]]\n[[mongo.encryption.converter-setup]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "Explicit Encryption (QE)", "heading_level": 3, "file_order": 32, "section_index": 7, "content_hash": "5089f8ec8e524a61fd4cf5b0332dce9802491a9741ddbdaa5b75d7df0b4c743d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:bc014695034a970bc82aef03dd4df81308f49598b2ce7fcfea24c634d6e9461c", "content": "The converter setup for `MongoEncryptionConverter` requires a few steps as several components are involved.\nThe bean setup consists of the following:\n\n1. The `ClientEncryption` engine\n2. A `MongoEncryptionConverter` instance configured with `ClientEncryption` and a `EncryptionKeyResolver`.\n3. A `PropertyValueConverterFactory` that uses the registered `MongoEncryptionConverter` bean.\n\nThe `EncryptionKeyResolver` uses an `EncryptionContext` providing access to the property allowing for dynamic DEK resolution.\n\n.Sample MongoEncryptionConverter Configuration\n====\n[source,java]\n----\nclass Config extends AbstractMongoClientConfiguration {\n\n @Autowired ApplicationContext appContext;\n\n @Bean\n ClientEncryption clientEncryption() { <1>\n ClientEncryptionSettings encryptionSettings = ClientEncryptionSettings.builder();\n // …\n\n return ClientEncryptions.create(encryptionSettings);\n }\n\n @Bean\n MongoEncryptionConverter encryptingConverter(ClientEncryption clientEncryption) {\n\n Encryption<BsonValue, BsonBinary> encryption = MongoClientEncryption.just(clientEncryption);\n EncryptionKeyResolver keyResolver = EncryptionKeyResolver.annotated((ctx) -> …); <2>\n\n return new MongoEncryptionConverter(encryption, keyResolver); <3>\n }\n\n @Override\n protected void configureConverters(MongoConverterConfigurationAdapter adapter) {\n\n adapter\n .registerPropertyValueConverterFactory(PropertyValueConverterFactory.beanFactoryAware(appContext)); <4>\n }\n}\n----\n\n<1> Set up a `Encryption` engine using `com.mongodb.client.vault.ClientEncryption`.\nThe instance is stateful and must be closed after usage.\nSpring takes care of this because `ClientEncryption` is ``Closeable``.\n<2> Set up an annotation-based `EncryptionKeyResolver` to determine the `EncryptionKey` from annotations.\n<3> Create the `MongoEncryptionConverter`.\n<4> Enable for a `PropertyValueConverter` lookup from the `BeanFactory`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc", "title": "mongo-encryption", "heading": "MongoEncryptionConverter Setup", "heading_level": 2, "file_order": 32, "section_index": 8, "content_hash": "bc014695034a970bc82aef03dd4df81308f49598b2ce7fcfea24c634d6e9461c", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-encryption.adoc"}}
{"id": "sha256:468f0d36f767023acfd8e77d0c5a69499467ad47e6ec2c13d38aefe77068cf02", "content": "[[mongo.group]]\n\nAs an alternative to using Map-Reduce to perform data aggregation, you can use the https://www.mongodb.org/display/DOCS/Aggregation#Aggregation-Group[`group` operation] which feels similar to using SQL's group by query style, so it may feel more approachable vs. using Map-Reduce. Using the group operations does have some limitations, for example it is not supported in a shared environment and it returns the full result set in a single BSON object, so the result should be small, less than 10,000 keys.\n\nSpring provides integration with MongoDB's group operation by providing methods on MongoOperations to simplify the creation and running of group operations.\nIt can convert the results of the group operation to a POJO and also integrates with Spring's {spring-framework-docs}/core/resources.html[Resource abstraction] abstraction.\nThis will let you place your JavaScript files on the file system, classpath, http server or any other Spring Resource implementation and then reference the JavaScript resources via an easy URI style syntax, e.g. 'classpath:reduce.js;.\nExternalizing JavaScript code in files if often preferable to embedding them as Java strings in your code.\nNote that you can still pass JavaScript code as Java strings if you prefer.\n\n[[mongo.group.example]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-group.adoc", "title": "mongo-group", "heading": "mongo-group", "heading_level": 1, "file_order": 33, "section_index": 0, "content_hash": "468f0d36f767023acfd8e77d0c5a69499467ad47e6ec2c13d38aefe77068cf02", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-group.adoc"}}
{"id": "sha256:6c588306c804f76595d34419213cb3a5168831b0d82943ba0a4908e51ebffcf5", "content": "In order to understand how group operations work the following example is used, which is somewhat artificial. For a more realistic example consult the book 'MongoDB - The definitive guide'. A collection named `group_test_collection` created with the following rows.\n\n[source]\n----\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f1\"), \"x\" : 1 }\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f2\"), \"x\" : 1 }\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f3\"), \"x\" : 2 }\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f4\"), \"x\" : 3 }\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f5\"), \"x\" : 3 }\n{ \"_id\" : ObjectId(\"4ec1d25d41421e2015da64f6\"), \"x\" : 3 }\n----\n\nWe would like to group by the only field in each row, the `x` field and aggregate the number of times each specific value of `x` occurs. To do this we need to create an initial document that contains our count variable and also a reduce function which will increment it each time it is encountered. The Java code to run the group operation is shown below\n\n[source,java]\n----\nGroupByResults<XObject> results = mongoTemplate.group(\"group_test_collection\",\n GroupBy.key(\"x\").initialDocument(\"{ count: 0 }\").reduceFunction(\"function(doc, prev) { prev.count += 1 }\"),\n XObject.class);\n----\n\nThe first argument is the name of the collection to run the group operation over, the second is a fluent API that specifies properties of the group operation via a `GroupBy` class. In this example we are using just the `intialDocument` and `reduceFunction` methods. You can also specify a key-function, as well as a finalizer as part of the fluent API. If you have multiple keys to group by, you can pass in a comma separated list of keys.\n\nThe raw results of the group operation is a JSON document that looks like this\n\n[source]\n----\n{\n \"retval\" : [ { \"x\" : 1.0 , \"count\" : 2.0} ,\n { \"x\" : 2.0 , \"count\" : 1.0} ,\n { \"x\" : 3.0 , \"count\" : 3.0} ] ,\n \"count\" : 6.0 ,\n \"keys\" : 3 ,\n \"ok\" : 1.0\n}\n----\n\nThe document under the \"retval\" field is mapped onto the third argument in the group method, in this case XObject which is shown below.\n\n[source,java]\n----\npublic class XObject {\n\n private float x;\n\n private float count;\n\n public float getX() {\n return x;\n }\n\n public void setX(float x) {\n this.x = x;\n }\n\n public float getCount() {\n return count;\n }\n\n public void setCount(float count) {\n this.count = count;\n }\n\n @Override\n public String toString() {\n return \"XObject [x=\" + x + \" count = \" + count + \"]\";\n }\n}\n----\n\nYou can also obtain the raw result as a `Document` by calling the method `getRawResults` on the `GroupByResults` class.\n\nThere is an additional method overload of the group method on `MongoOperations` which lets you specify a `Criteria` object for selecting a subset of the rows. An example which uses a `Criteria` object, with some syntax sugar using static imports, as well as referencing a key-function and reduce function javascript files via a Spring Resource string is shown below.\n\n[source]\n----\nimport static org.springframework.data.mongodb.core.mapreduce.GroupBy.keyFunction;\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\n\nGroupByResults<XObject> results = mongoTemplate.group(where(\"x\").gt(0),\n \"group_test_collection\",\n keyFunction(\"classpath:keyFunction.js\").initialDocument(\"{ count: 0 }\").reduceFunction(\"classpath:groupReduce.js\"), XObject.class);\n----\n\ninclude:../:aggregation-framework.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-group.adoc", "title": "mongo-group", "heading": "Example Usage", "heading_level": 2, "file_order": 33, "section_index": 1, "content_hash": "6c588306c804f76595d34419213cb3a5168831b0d82943ba0a4908e51ebffcf5", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-group.adoc"}}
{"id": "sha256:b542a48019cb852831e74a23f591549cfd26a8fbe2e8e140422848e0a96bbc41", "content": "[[mongo.mapreduce]]\n\nYou can query MongoDB by using Map-Reduce, which is useful for batch processing, for data aggregation, and for when the query language does not fulfill your needs.\n\nSpring provides integration with MongoDB's Map-Reduce by providing methods on `MongoOperations` to simplify the creation and running of Map-Reduce operations.It can convert the results of a Map-Reduce operation to a POJO and integrates with Spring's link:{springDocsUrl}/core.html#resources[Resource abstraction].This lets you place your JavaScript files on the file system, classpath, HTTP server, or any other Spring Resource implementation and then reference the JavaScript resources through an easy URI style syntax -- for example, `classpath:reduce.js;`.Externalizing JavaScript code in files is often preferable to embedding them as Java strings in your code.Note that you can still pass JavaScript code as Java strings if you prefer.\n\n[[mongo.mapreduce.example]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-mapreduce.adoc", "title": "mongo-mapreduce", "heading": "mongo-mapreduce", "heading_level": 1, "file_order": 34, "section_index": 0, "content_hash": "b542a48019cb852831e74a23f591549cfd26a8fbe2e8e140422848e0a96bbc41", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-mapreduce.adoc"}}
{"id": "sha256:4bafb1008626c27e3262a5d9f4c9220f39fa281a58e97ac3c7d40b5d66615aea", "content": "To understand how to perform Map-Reduce operations, we use an example from the book, _MongoDB - The Definitive Guide_ footnote:[Kristina Chodorow. _MongoDB - The Definitive Guide_. O'Reilly Media, 2013].In this example, we create three documents that have the values [a,b], [b,c], and [c,d], respectively.The values in each document are associated with the key, 'x', as the following example shows (assume these documents are in a collection named `jmr1`):\n\n[source]\n----\n{ \"_id\" : ObjectId(\"4e5ff893c0277826074ec533\"), \"x\" : [ \"a\", \"b\" ] }\n{ \"_id\" : ObjectId(\"4e5ff893c0277826074ec534\"), \"x\" : [ \"b\", \"c\" ] }\n{ \"_id\" : ObjectId(\"4e5ff893c0277826074ec535\"), \"x\" : [ \"c\", \"d\" ] }\n----\n\nThe following map function counts the occurrence of each letter in the array for each document:\n\n[source,java]\n----\nfunction () {\n for (var i = 0; i < this.x.length; i++) {\n emit(this.x[i], 1);\n }\n}\n----\n\nThe follwing reduce function sums up the occurrence of each letter across all the documents:\n\n[source,java]\n----\nfunction (key, values) {\n var sum = 0;\n for (var i = 0; i < values.length; i++)\n sum += values[i];\n return sum;\n}\n----\n\nRunning the preceding functions result in the following collection:\n\n[source]\n----\n{ \"_id\" : \"a\", \"value\" : 1 }\n{ \"_id\" : \"b\", \"value\" : 2 }\n{ \"_id\" : \"c\", \"value\" : 2 }\n{ \"_id\" : \"d\", \"value\" : 1 }\n----\n\nAssuming that the map and reduce functions are located in `map.js` and `reduce.js` and bundled in your jar so they are available on the classpath, you can run a Map-Reduce operation as follows:\n\n[source,java]\n----\nMapReduceResults<ValueObject> results = mongoOperations.mapReduce(\"jmr1\", \"classpath:map.js\", \"classpath:reduce.js\", ValueObject.class);\nfor (ValueObject valueObject : results) {\n System.out.println(valueObject);\n}\n----\n\nThe preceding exmaple produces the following output:\n\n[source]\n----\nValueObject [id=a, value=1.0]\nValueObject [id=b, value=2.0]\nValueObject [id=c, value=2.0]\nValueObject [id=d, value=1.0]\n----\n\nThe `MapReduceResults` class implements `Iterable` and provides access to the raw output and timing and count statistics.The following listing shows the `ValueObject` class:\n\n[source,java]\n----\npublic class ValueObject {\n\n private String id;\n private float value;\n\n public String getId() {\n return id;\n }\n\n public float getValue() {\n return value;\n }\n\n public void setValue(float value) {\n this.value = value;\n }\n\n @Override\n public String toString() {\n return \"ValueObject [id=\" + id + \", value=\" + value + \"]\";\n }\n}\n----\n\nBy default, the output type of `INLINE` is used so that you need not specify an output collection.To specify additional Map-Reduce options, use an overloaded method that takes an additional `MapReduceOptions` argument.The class `MapReduceOptions` has a fluent API, so adding additional options can be done in a compact syntax.The following example sets the output collection to `jmr1_out` (note that setting only the output collection assumes a default output type of `REPLACE`):\n\n[source,java]\n----\nMapReduceResults<ValueObject> results = mongoOperations.mapReduce(\"jmr1\", \"classpath:map.js\", \"classpath:reduce.js\",\n new MapReduceOptions().outputCollection(\"jmr1_out\"), ValueObject.class);\n----\n\nThere is also a static import (`import static org.springframework.data.mongodb.core.mapreduce.MapReduceOptions.options;`) that can be used to make the syntax slightly more compact, as the following example shows:\n\n[source,java]\n----\nMapReduceResults<ValueObject> results = mongoOperations.mapReduce(\"jmr1\", \"classpath:map.js\", \"classpath:reduce.js\",\n options().outputCollection(\"jmr1_out\"), ValueObject.class);\n----\n\nYou can also specify a query to reduce the set of data that is fed into the Map-Reduce operation.The following example removes the document that contains [a,b] from consideration for Map-Reduce operations:\n\n[source,java]\n----\nQuery query = new Query(where(\"x\").ne(new String[] { \"a\", \"b\" }));\nMapReduceResults<ValueObject> results = mongoOperations.mapReduce(query, \"jmr1\", \"classpath:map.js\", \"classpath:reduce.js\",\n options().outputCollection(\"jmr1_out\"), ValueObject.class);\n----\n\nNote that you can specify additional limit and sort values on the query, but you cannot skip values.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-mapreduce.adoc", "title": "mongo-mapreduce", "heading": "Example Usage", "heading_level": 2, "file_order": 34, "section_index": 1, "content_hash": "4bafb1008626c27e3262a5d9f4c9220f39fa281a58e97ac3c7d40b5d66615aea", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-mapreduce.adoc"}}
{"id": "sha256:74ae60a73656f5fd37106e825ec5008e140d4ad1fca46d9653223b5d8107995b", "content": "[[mongo.search]]\n\nMongoDB enables users to do keyword or lexical search as well as vector search data using dedicated search indexes.\n\n[[mongo.search.vector]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc", "title": "mongo-search-indexes", "heading": "mongo-search-indexes", "heading_level": 1, "file_order": 35, "section_index": 0, "content_hash": "74ae60a73656f5fd37106e825ec5008e140d4ad1fca46d9653223b5d8107995b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc"}}
{"id": "sha256:2550e600a2970921e55a662ce778a038396451d6b81f6416bb64567f83251355", "content": "MongoDB Vector Search uses the `$vectorSearch` aggregation stage to run queries against specialized indexes.\nPlease refer to the MongoDB documentation to learn more about requirements and restrictions of `vectorSearch` indexes.\n\n[[mongo.search.vector.index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc", "title": "mongo-search-indexes", "heading": "Vector Search", "heading_level": 2, "file_order": 35, "section_index": 1, "content_hash": "2550e600a2970921e55a662ce778a038396451d6b81f6416bb64567f83251355", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc"}}
{"id": "sha256:1ee3cda7c858ad3a2640a37d06e99be9207ade289e0603ddaa6405f0e0ee5816", "content": "`SearchIndexOperationsProvider` implemented by `MongoTemplate` are the entrypoint to `SearchIndexOperations` offering various methods for managing vector indexes.\n\nThe following snippet shows how to create a vector index for a collection\n\n.Create a Vector Index\n[tabs]\n======\nJava::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nVectorIndex index = new VectorIndex(\"vector_index\")\n .addVector(\"plotEmbedding\", vector -> vector.dimensions(1536).similarity(COSINE)) <1>\n .addFilter(\"year\"); <2>\n\nmongoTemplate.searchIndexOps(Movie.class) <3>\n .createIndex(index);\n----\n<1> A vector index may cover multiple vector embeddings that can be added via the `addVector` method.\n<2> Vector indexes can contain additional fields to narrow down search results when running queries.\n<3> Obtain `SearchIndexOperations` bound to the `Movie` type which is used for field name mapping.\n====\n\nMongo Shell::\n+\n====\n[source,console,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ndb.movie.createSearchIndex(\"movie\", \"vector_index\",\n {\n \"fields\": [\n {\n \"type\": \"vector\",\n \"numDimensions\": 1536,\n \"path\": \"plot_embedding\", <1>\n \"similarity\": \"cosine\"\n },\n {\n \"type\": \"filter\",\n \"path\": \"year\"\n }\n ]\n }\n)\n----\n<1> Field name `plotEmbedding` got mapped to `plot_embedding` considering a `@Field(name = \"...\")` annotation.\n====\n======\n\nOnce created, vector indexes are not immediately ready to use although the `exists` check returns `true`.\nThe actual status of a search index can be obtained via `SearchIndexOperations#status(...)`.\nThe `READY` state indicates the index is ready to accept queries.\n\n[[mongo.search.vector.query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc", "title": "mongo-search-indexes", "heading": "Managing Vector Indexes", "heading_level": 3, "file_order": 35, "section_index": 2, "content_hash": "1ee3cda7c858ad3a2640a37d06e99be9207ade289e0603ddaa6405f0e0ee5816", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc"}}
{"id": "sha256:783e316820ae2e4ad2d48cd50be0e9643507d634961a2b38ad16d2431d5cbcfe", "content": "Vector indexes can be queried by issuing an aggregation using a `VectorSearchOperation` via `MongoOperations` as shown in the following example\n\n.Query a Vector Index\n[tabs]\n======\nJava::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nVectorSearchOperation search = VectorSearchOperation.search(\"vector_index\") <1>\n .path(\"plotEmbedding\") <2>\n .vector( ... )\n .numCandidates(150)\n .limit(10)\n .withSearchScore(\"score\"); <3>\n\nAggregationResults<MovieWithSearchScore> results = mongoTemplate\n .aggregate(newAggregation(Movie.class, search), MovieWithSearchScore.class);\n----\n<1> Provide the name of the vector index to query since a collection may hold multiple ones.\n<2> The name of the path used for comparison.\n<3> Optionally add the search score with given name to the result document.\n====\n\nMongo Shell::\n+\n====\n[source,console,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ndb.embedded_movies.aggregate([\n {\n \"$vectorSearch\": {\n \"index\": \"vector_index\",\n \"path\": \"plot_embedding\", <1>\n \"queryVector\": [ ... ],\n \"numCandidates\": 150,\n \"limit\": 10\n }\n },\n {\n \"$addFields\": {\n \"score\": { $meta: \"vectorSearchScore\" }\n }\n }\n])\n----\n<1> Field name `plotEmbedding` got mapped to `plot_embedding` considering a `@Field(name = \"...\")` annotation.\n====\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc", "title": "mongo-search-indexes", "heading": "Querying Vector Indexes", "heading_level": 3, "file_order": 35, "section_index": 3, "content_hash": "783e316820ae2e4ad2d48cd50be0e9643507d634961a2b38ad16d2431d5cbcfe", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-search-indexes.adoc"}}
{"id": "sha256:ba745b00d4bb75fe597c255e45bf7193ae8292bb8e0a1e7d0a8ac3a5016cb625", "content": "[[mongo.server-side-scripts]]\n\n[WARNING]\n====\nhttps://docs.mongodb.com/master/release-notes/4.2-compatibility/[MongoDB 4.2] removed support for the `eval` command used\nby `ScriptOperations`. +\nThere is no replacement for the removed functionality.\n====\n\nMongoDB allows running JavaScript functions on the server by either directly sending the script or calling a stored one. `ScriptOperations` can be accessed through `MongoTemplate` and provides basic abstraction for `JavaScript` usage. The following example shows how to us the `ScriptOperations` class:\n\n====\n[source,java]\n----\nScriptOperations scriptOps = template.scriptOps();\n\nExecutableMongoScript echoScript = new ExecutableMongoScript(\"function(x) { return x; }\");\nscriptOps.execute(echoScript, \"directly execute script\"); <1>\n\nscriptOps.register(new NamedMongoScript(\"echo\", echoScript)); <2>\nscriptOps.call(\"echo\", \"execute script via name\"); <3>\n----\n<1> Run the script directly without storing the function on server side.\n<2> Store the script using 'echo' as its name. The given name identifies the script and allows calling it later.\n<3> Run the script with name 'echo' using the provided parameters.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/mongo-server-side-scripts.adoc", "title": "mongo-server-side-scripts", "heading": "mongo-server-side-scripts", "heading_level": 1, "file_order": 36, "section_index": 0, "content_hash": "ba745b00d4bb75fe597c255e45bf7193ae8292bb8e0a1e7d0a8ac3a5016cb625", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/mongo-server-side-scripts.adoc"}}
{"id": "sha256:8ec797d6dc13e5a47a72f831d63838e8d60180252c66a9e3921d4d896a159f04", "content": "include::{commons}@data-commons::page$property-paths.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/property-paths.adoc", "title": "property-paths", "heading": "property-paths", "heading_level": 1, "file_order": 37, "section_index": 0, "content_hash": "8ec797d6dc13e5a47a72f831d63838e8d60180252c66a9e3921d4d896a159f04", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/property-paths.adoc"}}
{"id": "sha256:e5fe2277f0515d4070d87d628d2115f86c98e38a835a998f153fa3cd610133be", "content": "[[sharding]]\n\nMongoDB supports large data sets via sharding, a method for distributing data across multiple database servers.\nPlease refer to the https://docs.mongodb.com/manual/sharding/[MongoDB Documentation] to learn how to set up a sharded cluster, its requirements and limitations.\n\nSpring Data MongoDB uses the `@Sharded` annotation to identify entities stored in sharded collections as shown below.\n\n====\n[source,java]\n----\n@Document(\"users\")\n@Sharded(shardKey = { \"country\", \"userId\" }) <1>\npublic class User {\n\n\t@Id\n\tLong id;\n\n\t@Field(\"userid\")\n\tString userId;\n\n\tString country;\n}\n----\n<1> The properties of the shard key get mapped to the actual field names.\n====\n\n[[sharding.sharded-collections]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/sharding.adoc", "title": "sharding", "heading": "sharding", "heading_level": 1, "file_order": 38, "section_index": 0, "content_hash": "e5fe2277f0515d4070d87d628d2115f86c98e38a835a998f153fa3cd610133be", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/sharding.adoc"}}
{"id": "sha256:ce9680edb29bbb88ced2b824de3740ab7b04bb76a9e7b488888a0652a092e83d", "content": "Spring Data MongoDB does not auto set up sharding for collections nor indexes required for it.\nThe snippet below shows how to do so using the MongoDB client API.\n\n====\n[source,java]\n----\nMongoDatabase adminDB = template.getMongoDbFactory()\n .getMongoDatabase(\"admin\"); <1>\n\nadminDB.runCommand(new Document(\"enableSharding\", \"db\")); <2>\n\nDocument shardCmd = new Document(\"shardCollection\", \"db.users\") <3>\n\t.append(\"key\", new Document(\"country\", 1).append(\"userid\", 1)); <4>\n\nadminDB.runCommand(shardCmd);\n----\n<1> Sharding commands need to be run against the _admin_ database.\n<2> Enable sharding for a specific database if necessary.\n<3> Shard a collection within the database having sharding enabled.\n<4> Specify the shard key.\nThis example uses range based sharding.\n====\n\n[[sharding.shard-key]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/sharding.adoc", "title": "sharding", "heading": "Sharded Collections", "heading_level": 2, "file_order": 38, "section_index": 1, "content_hash": "ce9680edb29bbb88ced2b824de3740ab7b04bb76a9e7b488888a0652a092e83d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/sharding.adoc"}}
{"id": "sha256:a40ddcf2e8aa1c75d473d4daeb6a6acc174b0f143980a1bb23ccc6f54f11af2a", "content": "The shard key consists of a single or multiple properties that must exist in every document in the target collection.\nIt is used to distribute documents across shards.\n\nAdding the `@Sharded` annotation to an entity enables Spring Data MongoDB to apply best effort optimisations required for sharded scenarios.\nThis means essentially adding required shard key information, if not already present, to `replaceOne` filter queries when upserting entities.\nThis may require an additional server round trip to determine the actual value of the current shard key.\n\nTIP: By setting `@Sharded(immutableKey = true)` Spring Data does not attempt to check if an entity shard key was changed.\n\nPlease see the https://docs.mongodb.com/manual/reference/method/db.collection.replaceOne/#upsert[MongoDB Documentation] for further details.\nThe following list contains which operations are eligible for shard key auto-inclusion:\n\n* `(Reactive)CrudRepository.save(…)`\n* `(Reactive)CrudRepository.saveAll(…)`\n* `(Reactive)MongoTemplate.save(…)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/sharding.adoc", "title": "sharding", "heading": "Shard Key Handling", "heading_level": 2, "file_order": 38, "section_index": 2, "content_hash": "a40ddcf2e8aa1c75d473d4daeb6a6acc174b0f143980a1bb23ccc6f54f11af2a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/sharding.adoc"}}
{"id": "sha256:29d6f70597eb7fe9e1a01e295f0dee1ad30de0995ab27b3d43492fcc148a46ef", "content": "[[tailable-cursors]]\n\nBy default, MongoDB automatically closes a cursor when the client exhausts all results supplied by the cursor.\nClosing a cursor on exhaustion turns a stream into a finite stream. For https://docs.mongodb.com/manual/core/capped-collections/[capped collections],\nyou can use a https://docs.mongodb.com/manual/core/tailable-cursors/[Tailable Cursor] that remains open after the client\nconsumed all initially returned data.\n\nTIP: Capped collections can be created with `MongoOperations.createCollection`. To do so, provide the required `CollectionOptions.empty().capped()...`.\n\nTailable cursors can be consumed with both, the imperative and the reactive MongoDB API. It is highly recommended to use the\nreactive variant, as it is less resource-intensive. However, if you cannot use the reactive API, you can still use a messaging\nconcept that is already prevalent in the Spring ecosystem.\n\n[[tailable-cursors.sync]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc", "title": "tailable-cursors", "heading": "tailable-cursors", "heading_level": 1, "file_order": 39, "section_index": 0, "content_hash": "29d6f70597eb7fe9e1a01e295f0dee1ad30de0995ab27b3d43492fcc148a46ef", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc"}}
{"id": "sha256:4bba95bdc9cd5fc0ab5f0f8e882c9d00946188c84b3813276c1c9e2bc698fa31", "content": "Listening to a capped collection using a Sync Driver creates a long running, blocking task that needs to be delegated to\na separate component. In this case, we need to first create a `MessageListenerContainer`, which will be the main entry point\nfor running the specific `SubscriptionRequest`. Spring Data MongoDB already ships with a default implementation that\noperates on `MongoTemplate` and is capable of creating and running `Task` instances for a `TailableCursorRequest`.\n\nThe following example shows how to use tailable cursors with `MessageListener` instances:\n\n.Tailable Cursors with `MessageListener` instances\n====\n[source,java]\n----\nMessageListenerContainer container = new DefaultMessageListenerContainer(template);\ncontainer.start(); <1>\n\nMessageListener<Document, User> listener = System.out::println; <2>\n\nTailableCursorRequest request = TailableCursorRequest.builder()\n .collection(\"orders\") <3>\n .filter(query(where(\"value\").lt(100))) <4>\n .publishTo(listener) <5>\n .build();\n\ncontainer.register(request, User.class); <6>\n\ncontainer.stop(); <7>\n----\n<1> Starting the container intializes the resources and starts `Task` instances for already registered `SubscriptionRequest` instances. Requests added after startup are ran immediately.\n<2> Define the listener called when a `Message` is received. The `Message#getBody()` is converted to the requested domain type. Use `Document` to receive raw results without conversion.\n<3> Set the collection to listen to.\n<4> Provide an optional filter for documents to receive.\n<5> Set the message listener to publish incoming ``Message``s to.\n<6> Register the request. The returned `Subscription` can be used to check the current `Task` state and cancel it to free resources.\n<7> Do not forget to stop the container once you are sure you no longer need it. Doing so stops all running `Task` instances within the container.\n====\n\n[[tailable-cursors.reactive]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc", "title": "tailable-cursors", "heading": "Tailable Cursors with `MessageListener`", "heading_level": 2, "file_order": 39, "section_index": 1, "content_hash": "4bba95bdc9cd5fc0ab5f0f8e882c9d00946188c84b3813276c1c9e2bc698fa31", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc"}}
{"id": "sha256:bf8ce796e8537185e3c72cd514f4302b09ac8fd36c6f84b5bfc047468a09c379", "content": "Using tailable cursors with a reactive data types allows construction of infinite streams. A tailable cursor remains open until it is closed externally. It emits data as new documents arrive in a capped collection.\n\nTailable cursors may become dead, or invalid, if either the query returns no match or the cursor returns the document at the \"`end`\" of the collection and the application then deletes that document. The following example shows how to create and use an infinite stream query:\n\n.Infinite Stream queries with ReactiveMongoOperations\n====\n[source,java]\n----\nFlux<Person> stream = template.tail(query(where(\"name\").is(\"Joe\")), Person.class);\n\nDisposable subscription = stream.doOnNext(person -> System.out.println(person)).subscribe();\n\nsubscription.dispose();\n----\n====\n\nSpring Data MongoDB Reactive repositories support infinite streams by annotating a query method with `@Tailable`. This works for methods that return `Flux` and other reactive types capable of emitting multiple elements, as the following example shows:\n\n.Infinite Stream queries with ReactiveMongoRepository\n====\n[source,java]\n----\n\npublic interface PersonRepository extends ReactiveMongoRepository<Person, String> {\n\n @Tailable\n Flux<Person> findByFirstname(String firstname);\n\n}\n\nFlux<Person> stream = repository.findByFirstname(\"Joe\");\n\nDisposable subscription = stream.doOnNext(System.out::println).subscribe();\n\nsubscription.dispose();\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc", "title": "tailable-cursors", "heading": "Reactive Tailable Cursors", "heading_level": 2, "file_order": 39, "section_index": 2, "content_hash": "bf8ce796e8537185e3c72cd514f4302b09ac8fd36c6f84b5bfc047468a09c379", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/tailable-cursors.adoc"}}
{"id": "sha256:ebc8a8508e531a75e6e89555a327d9aebbac6e6655e4f6c7f45fbae926809aaf", "content": "[[mongo-template]]\n\nThe javadoc:org.springframework.data.mongodb.core.MongoTemplate[] and its javadoc:org.springframework.data.mongodb.core.ReactiveMongoTemplate[reactive] counterpart class, located in the `org.springframework.data.mongodb.core` package, is the central class of Spring's MongoDB support and provides a rich feature set for interacting with the database.\nThe template offers convenience operations to create, update, delete, and query MongoDB documents and provides a mapping between your domain objects and MongoDB documents.\n\nNOTE: Once configured, `MongoTemplate` is thread-safe and can be reused across multiple instances.\n\n[[mongo-template.convenience-methods]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "template-api", "heading_level": 1, "file_order": 40, "section_index": 0, "content_hash": "ebc8a8508e531a75e6e89555a327d9aebbac6e6655e4f6c7f45fbae926809aaf", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:d87865b2c4c34b545bc603c63c69d1a3b6a2e4a3906baa9ccabb3b570227ac32", "content": "The javadoc:org.springframework.data.mongodb.core.MongoTemplate[] class implements the interface javadoc:org.springframework.data.mongodb.core.MongoOperations[].\nIn as much as possible, the methods on `MongoOperations` are named after methods available on the MongoDB driver `Collection` object, to make the API familiar to existing MongoDB developers who are used to the driver API.\nFor example, you can find methods such as `find`, `findAndModify`, `findAndReplace`, `findOne`, `insert`, `remove`, `save`, `update`, and `updateMulti`.\nThe design goal was to make it as easy as possible to transition between the use of the base MongoDB driver and `MongoOperations`.\nA major difference between the two APIs is that `MongoOperations` can be passed domain objects instead of `Document`.\nAlso, `MongoOperations` has fluent APIs for `Query`, `Criteria`, and `Update` operations instead of populating a `Document` to specify the parameters for those operations.\n\nFor more information please refer to the xref:mongodb/template-crud-operations.adoc[CRUD] and xref:mongodb/template-query-operations.adoc[Query] sections of the documentation.\n\nNOTE: The preferred way to reference the operations on `MongoTemplate` instance is through its interface, `MongoOperations`.\n\n[[mongo-template.execute-callbacks]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "Convenience Methods", "heading_level": 2, "file_order": 40, "section_index": 1, "content_hash": "d87865b2c4c34b545bc603c63c69d1a3b6a2e4a3906baa9ccabb3b570227ac32", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:14958c014dcecc84e5ec30599d06b2bf5614a5c980114f919dd47fc4e039d5ed", "content": "`MongoTemplate` offers many convenience methods to help you easily perform common tasks.\nHowever, if you need to directly access the MongoDB driver API, you can use one of several `Execute` callback methods.\nThe `execute` callbacks gives you a reference to either a `MongoCollection` or a `MongoDatabase` object.\n\n* `<T> T` *execute* `(Class<?> entityClass, CollectionCallback<T> action)`: Runs the given `CollectionCallback` for the entity collection of the specified class.\n\n* `<T> T` *execute* `(String collectionName, CollectionCallback<T> action)`: Runs the given `CollectionCallback` on the collection of the given name.\n\n* `<T> T` *execute* `(DbCallback<T> action)`: Runs a DbCallback, translating any exceptions as necessary.\nSpring Data MongoDB provides support for the Aggregation Framework introduced to MongoDB in version 2.2.\n\n* `<T> T` *execute* `(String collectionName, DbCallback<T> action)`: Runs a `DbCallback` on the collection of the given name translating any exceptions as necessary.\n\n* `<T> T` *executeInSession* `(DbCallback<T> action)`: Runs the given `DbCallback` within the same connection to the database so as to ensure consistency in a write-heavy environment where you may read the data that you wrote.\n\nThe following example uses the javadoc:org.springframework.data.mongodb.core.CollectionCallback[] to return information about an index:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nboolean hasIndex = template.execute(\"geolocation\", collection ->\n Streamable.of(collection.listIndexes(org.bson.Document.class))\n .stream()\n .map(document -> document.get(\"name\"))\n .anyMatch(\"location_2d\"::equals)\n);\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<Boolean> hasIndex = template.execute(\"geolocation\", collection ->\n Flux.from(collection.listIndexes(org.bson.Document.class))\n .map(document -> document.get(\"name\"))\n .filterWhen(name -> Mono.just(\"location_2d\".equals(name)))\n .map(it -> Boolean.TRUE)\n .single(Boolean.FALSE)\n ).next();\n----\n======\n\n[[mongo-template.fluent-api]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "Execute Callbacks", "heading_level": 2, "file_order": 40, "section_index": 2, "content_hash": "14958c014dcecc84e5ec30599d06b2bf5614a5c980114f919dd47fc4e039d5ed", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:a09b96afdcd0e29ea1ef56b7a5467445f03a7c36c3d8b4a216f5f955828fab2b", "content": "Being the central component when it comes to more low-level interaction with MongoDB `MongoTemplate` offers a wide range of methods covering needs from collection creation, index creation, and CRUD operations to more advanced functionality, such as Map-Reduce and aggregations.\nYou can find multiple overloads for each method.\nMost of them cover optional or nullable parts of the API.\n\n`FluentMongoOperations` provides a more narrow interface for the common methods of `MongoOperations` and provides a more readable, fluent API.\nThe entry points (`insert(…)`, `find(…)`, `update(…)`, and others) follow a natural naming schema based on the operation to be run.\nMoving on from the entry point, the API is designed to offer only context-dependent methods that lead to a terminating method that invokes the actual `MongoOperations` counterpart -- the `all` method in the case of the following example:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nList<Jedi> all = template.query(SWCharacter.class) <1>\n .inCollection(\"star-wars\") <2>\n .as(Jedi.class) <3>\n .matching(query(where(\"jedi\").is(true))) <4>\n .all();\n----\n\n<1> The type used to map fields used in the query to.\n<2> The collection name to use if not defined on the domain type.\n<3> Result type if not using the original domain type.\n<4> The lookup query.\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nFlux<Jedi> all = template.query(SWCharacter.class)\n .inCollection(\"star-wars\")\n .as(Jedi.class)\n .matching(query(where(\"jedi\").is(true)))\n .all();\n----\n======\n\nNOTE: Using projections allows `MongoTemplate` to optimize result mapping by limiting the actual response to fields required by the projection target type.\nThis applies as long as the javadoc:org.springframework.data.mongodb.core.query.Query[] itself does not contain any field restriction and the target type is a closed interface or DTO projection.\n\nWARNING: Projections must not be applied to xref:mongodb/mapping/document-references.adoc[DBRefs].\n\nYou can switch between retrieving a single entity and retrieving multiple entities as a `List` or a `Stream` through the terminating methods: `first()`, `one()`, `all()`, or `stream()`.\n\nResults can be contextually post-processed by using a `QueryResultConverter` that has access to both the raw result `Document` and the already mapped object by calling `map(...)` as outlined below.\n\n[source,java]\n====\n----\nList<Optional<Jedi>> result = template.query(Person.class)\n .as(Jedi.class)\n .matching(query(where(\"firstname\").is(\"luke\")))\n .map((document, reader) -> Optional.of(reader.get()))\n .all();\n----\n====\n\nWhen writing a geo-spatial query with `near(NearQuery)`, the number of terminating methods is altered to include only the methods that are valid for running a `geoNear` command in MongoDB (fetching entities as a `GeoResult` within `GeoResults`), as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nGeoResults<Jedi> results = template.query(SWCharacter.class)\n .as(Jedi.class)\n .near(alderaan) // NearQuery.near(-73.9667, 40.78).maxDis…\n .all();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nFlux<GeoResult<Jedi>> results = template.query(SWCharacter.class)\n .as(Jedi.class)\n .near(alderaan) // NearQuery.near(-73.9667, 40.78).maxDis…\n .all();\n----\n======\n\n[[mongo-template.exception-translation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "Fluent API", "heading_level": 2, "file_order": 40, "section_index": 3, "content_hash": "a09b96afdcd0e29ea1ef56b7a5467445f03a7c36c3d8b4a216f5f955828fab2b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:223e37c6f2ac5d5d5e4b741c49a75ac6e4ef3f8f70556bedecb948cc8cadfd6e", "content": "The Spring framework provides exception translation for a wide variety of database and mapping technologies.\nThis has traditionally been for JDBC and JPA.\nThe Spring support for MongoDB extends this feature to the MongoDB Database by providing an implementation of the `org.springframework.dao.support.PersistenceExceptionTranslator` interface.\n\nThe motivation behind mapping to Spring's link:{springDocsUrl}/data-access.html#dao-exceptions[consistent data access exception hierarchy] is that you are then able to write portable and descriptive exception handling code without resorting to coding against MongoDB error codes.\nAll of Spring's data access exceptions are inherited from the root `DataAccessException` class so that you can be sure to catch all database related exception within a single try-catch block.\nNote that not all exceptions thrown by the MongoDB driver inherit from the `MongoException` class.\nThe inner exception and message are preserved so that no information is lost.\n\nSome of the mappings performed by the javadoc:org.springframework.data.mongodb.core.MongoExceptionTranslator[] are `com.mongodb.Network` to `DataAccessResourceFailureException` and `MongoException` error codes 1003, 12001, 12010, 12011, and 12012 to `InvalidDataAccessApiUsageException`.\nLook into the implementation for more details on the mapping.\n\nException Translation can be configured by setting a customized javadoc:org.springframework.data.mongodb.core.MongoExceptionTranslator[] on your `MongoDatabaseFactory` or its reactive variant.\nYou might also want to set the exception translator on the corresponding `MongoClientFactoryBean`.\n\n.Configuring `MongoExceptionTranslator`\n====\n[source,java]\n----\nConnectionString uri = new ConnectionString(\"mongodb://username:password@localhost/database\");\nSimpleMongoClientDatabaseFactory mongoDbFactory = new SimpleMongoClientDatabaseFactory(uri);\nmongoDbFactory.setExceptionTranslator(myCustomExceptionTranslator);\n----\n====\n\nA motivation to customize exception can be MongoDB's behavior during transactions where some failures (such as write conflicts) can become transient and where a retry could lead to a successful operation.\nIn such a case, you could wrap exceptions with a specific MongoDB label and apply a different exception translation stragegy.\n\n[[mongo-template.type-mapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "Exception Translation", "heading_level": 2, "file_order": 40, "section_index": 4, "content_hash": "223e37c6f2ac5d5d5e4b741c49a75ac6e4ef3f8f70556bedecb948cc8cadfd6e", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:dbcbacc68a719ad3d2e3b5714d1d6e6880a6a91da8632448eaf00a9e80352aeb", "content": "The mapping between MongoDB documents and domain classes is done by delegating to an implementation of the javadoc:org.springframework.data.mongodb.core.convert.MongoConverter[] interface.\nSpring provides javadoc:org.springframework.data.mongodb.core.convert.MappingMongoConverter[], but you can also write your own converter.\nWhile the `MappingMongoConverter` can use additional metadata to specify the mapping of objects to documents, it can also convert objects that contain no additional metadata by using some conventions for the mapping of IDs and collection names.\nThese conventions, as well as the use of mapping annotations, are explained in the xref:mongodb/mapping/mapping.adoc[Mapping] chapter.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-api.adoc", "title": "template-api", "heading": "Domain Type Mapping", "heading_level": 2, "file_order": 40, "section_index": 5, "content_hash": "dbcbacc68a719ad3d2e3b5714d1d6e6880a6a91da8632448eaf00a9e80352aeb", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-api.adoc"}}
{"id": "sha256:f18dfe7c8fa6b6159085f9e14fe3d845ec489814d29aafb3e10e81c685435d2c", "content": "[[mongo-template.index-and-collections]]\n\n`MongoTemplate` and `ReactiveMongoTemplate` provide methods for managing indexes and collections.\nThese methods are collected into a helper interface called `IndexOperations` respectively `ReactiveIndexOperations`.\nYou can access these operations by calling the `indexOps` method and passing in either the collection name or the `java.lang.Class` of your entity (the collection name is derived from the `.class`, either by name or from annotation metadata).\n\nThe following listing shows the `IndexOperations` interface:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface IndexOperations {\n\n String ensureIndex(IndexDefinition indexDefinition);\n\n void alterIndex(String name, IndexOptions options);\n\n void dropIndex(String name);\n\n void dropAllIndexes();\n\n List<IndexInfo> getIndexInfo();\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic interface ReactiveIndexOperations {\n\n Mono<String> ensureIndex(IndexDefinition indexDefinition);\n\n Mono<Void> alterIndex(String name, IndexOptions options);\n\n Mono<Void> dropIndex(String name);\n\n Mono<Void> dropAllIndexes();\n\n Flux<IndexInfo> getIndexInfo();\n----\n======\n\n[[mongo-template.index-and-collections.index]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-collection-management.adoc", "title": "template-collection-management", "heading": "template-collection-management", "heading_level": 1, "file_order": 41, "section_index": 0, "content_hash": "f18dfe7c8fa6b6159085f9e14fe3d845ec489814d29aafb3e10e81c685435d2c", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-collection-management.adoc"}}
{"id": "sha256:b3bd00431eaf8259b440cc4e947e127e9f62b77b02c21e80b141288f3f855edd", "content": "You can create an index on a collection to improve query performance by using the MongoTemplate class, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\ntemplate.indexOps(Person.class)\n .ensureIndex(new Index().on(\"name\",Order.ASCENDING));\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<String> createIndex = template.indexOps(Person.class)\n .ensureIndex(new Index().on(\"name\",Order.ASCENDING));\n----\n======\n\n`ensureIndex` makes sure that an index for the provided IndexDefinition exists for the collection.\n\nYou can create standard, geospatial, and text indexes by using the `IndexDefinition`, `GeoSpatialIndex` and `TextIndexDefinition` classes.\nFor example, given the `Venue` class defined in a previous section, you could declare a geospatial query, as the following example shows:\n\n[source,java]\n----\ntemplate.indexOps(Venue.class)\n .ensureIndex(new GeospatialIndex(\"location\"));\n----\n\nNOTE: `Index` and `GeospatialIndex` support configuration of xref:mongodb/template-query-operations.adoc#mongo.query.collation[collations].\n\n[[mongo-template.index-and-collections.access]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-collection-management.adoc", "title": "template-collection-management", "heading": "Methods for Creating an Index", "heading_level": 2, "file_order": 41, "section_index": 1, "content_hash": "b3bd00431eaf8259b440cc4e947e127e9f62b77b02c21e80b141288f3f855edd", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-collection-management.adoc"}}
{"id": "sha256:c5ec7f4ee1f0f60d0d589bf9d03b5daed3996877ea83b833d4401cc4e9afcf41", "content": "The `IndexOperations` interface has the `getIndexInfo` method that returns a list of `IndexInfo` objects.\nThis list contains all the indexes defined on the collection. The following example defines an index on the `Person` class that has an `age` property:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\ntemplate.indexOps(Person.class)\n .ensureIndex(new Index().on(\"age\", Order.DESCENDING).unique());\n\nList<IndexInfo> indexInfoList = template.indexOps(Person.class)\n .getIndexInfo();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<String> ageIndex = template.indexOps(Person.class)\n .ensureIndex(new Index().on(\"age\", Order.DESCENDING).unique());\n\nFlux<IndexInfo> indexInfo = ageIndex.then(template.indexOps(Person.class)\n .getIndexInfo());\n----\n======\n\n[[mongo-template.index-and-collections.collection]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-collection-management.adoc", "title": "template-collection-management", "heading": "Accessing Index Information", "heading_level": 2, "file_order": 41, "section_index": 2, "content_hash": "c5ec7f4ee1f0f60d0d589bf9d03b5daed3996877ea83b833d4401cc4e9afcf41", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-collection-management.adoc"}}
{"id": "sha256:ce0744399a76e0f4c0276951d00220d6d31294bf2a4dee18324e330e42c8d46a", "content": "The following example shows how to create a collection:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nMongoCollection<Document> collection = null;\nif (!template.getCollectionNames().contains(\"MyNewCollection\")) {\n collection = mongoTemplate.createCollection(\"MyNewCollection\");\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMongoCollection<Document> collection = template.getCollectionNames().collectList()\n .flatMap(collectionNames -> {\n if(!collectionNames.contains(\"MyNewCollection\")) {\n return template.createCollection(\"MyNewCollection\");\n }\n return template.getMongoDatabase().map(db -> db.getCollection(\"MyNewCollection\"));\n });\n----\n======\n\nNOTE: Collection creation allows customization with `CollectionOptions` and supports xref:mongodb/collation.adoc[collations].\n\n.Methods to interact with MongoCollections\n[%collapsible]\n====\n* *getCollectionNames*: Returns a set of collection names.\n* *collectionExists*: Checks to see if a collection with a given name exists.\n* *createCollection*: Creates an uncapped collection.\n* *dropCollection*: Drops the collection.\n* *getCollection*: Gets a collection by name, creating it if it does not exist.\n====\n\n[[time-series]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-collection-management.adoc", "title": "template-collection-management", "heading": "Methods for Working with a Collection", "heading_level": 2, "file_order": 41, "section_index": 3, "content_hash": "ce0744399a76e0f4c0276951d00220d6d31294bf2a4dee18324e330e42c8d46a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-collection-management.adoc"}}
{"id": "sha256:6696ea50df95b96ce16866956f733ee276d2526101a5a227e2e8c16b6a554fdd", "content": "MongoDB 5.0 introduced https://docs.mongodb.com/manual/core/timeseries-collections/[Time Series] collections that are optimized to efficiently store documents over time such as measurements or events.\nThose collections need to be created as such before inserting any data.\nCollections can be created by either running the `createCollection` command, defining time series collection options or extracting options from a `@TimeSeries` annotation as shown in the examples below.\n\n.Create a Time Series Collection\n====\n.Create a Time Series via the MongoDB Driver\n[source,java]\n----\ntemplate.execute(db -> {\n\n com.mongodb.client.model.CreateCollectionOptions options = new CreateCollectionOptions();\n options.timeSeriesOptions(new TimeSeriesOptions(\"timestamp\"));\n\n db.createCollection(\"weather\", options);\n return \"OK\";\n});\n----\n\n.Create a Time Series Collection with `CollectionOptions`\n[source,java]\n----\ntemplate.createCollection(\"weather\", CollectionOptions.timeSeries(\"timestamp\"));\n----\n\n.Create a Time Series Collection derived from an Annotation\n[source,java]\n----\n@TimeSeries(collection=\"weather\", timeField = \"timestamp\")\npublic class Measurement {\n\n String id;\n Instant timestamp;\n // ...\n}\n\ntemplate.createCollection(Measurement.class);\n----\n====\n\nThe snippets above can easily be transferred to the reactive API offering the very same methods.\nMake sure to properly _subscribe_ to the returned publishers.\n\n[TIP]\n====\nYou can use the `@TimeSeries#expireAfter` option to have MongoDB automatically remove expired buckets.\nThe attribute allows different timeout formats like `10s`, `3h`,... as well as expression (`#{@mySpringBean.timeout}`) and property placeholder (`${my.property.timeout}`) syntax.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-collection-management.adoc", "title": "template-collection-management", "heading": "Time Series", "heading_level": 2, "file_order": 41, "section_index": 4, "content_hash": "6696ea50df95b96ce16866956f733ee276d2526101a5a227e2e8c16b6a554fdd", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-collection-management.adoc"}}
{"id": "sha256:d20e3f76939e0a16cd8bc975e74d6d517365552f33bd08e70f177c91debe695b", "content": "[[mongo-template.instantiating]]\n\nYou can use the following configuration to create and register an instance of `MongoTemplate`, as the following example shows:\n\n.Registering a `MongoClient` object and enabling Spring's exception translation support\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Configuration\nclass ApplicationConfiguration {\n\n @Bean\n MongoClient mongoClient() {\n return MongoClients.create(\"mongodb://localhost:27017\");\n }\n\n @Bean\n MongoOperations mongoTemplate(MongoClient mongoClient) {\n return new MongoTemplate(mongoClient, \"geospatial\");\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Configuration\nclass ReactiveApplicationConfiguration {\n\n @Bean\n MongoClient mongoClient() {\n return MongoClients.create(\"mongodb://localhost:27017\");\n }\n\n @Bean\n ReactiveMongoOperations mongoTemplate(MongoClient mongoClient) {\n return new ReactiveMongoTemplate(mongoClient, \"geospatial\");\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"third\"]\n----\n<mongo:mongo-client host=\"localhost\" port=\"27017\" />\n\n<bean id=\"mongoTemplate\" class=\"org.springframework.data.mongodb.core.MongoTemplate\">\n <constructor-arg ref=\"mongoClient\" />\n <constructor-arg name=\"databaseName\" value=\"geospatial\" />\n</bean>\n----\n======\n\nThere are several overloaded constructors of javadoc:org.springframework.data.mongodb.core.MongoTemplate[] and javadoc:org.springframework.data.mongodb.core.ReactiveMongoTemplate[]:\n\n* `MongoTemplate(MongoClient mongo, String databaseName)`: Takes the `MongoClient` object and the default database name to operate against.\n* `MongoTemplate(MongoDatabaseFactory mongoDbFactory)`: Takes a MongoDbFactory object that encapsulated the `MongoClient` object, database name, and username and password.\n* `MongoTemplate(MongoDatabaseFactory mongoDbFactory, MongoConverter mongoConverter)`: Adds a `MongoConverter` to use for mapping.\n\nOther optional properties that you might like to set when creating a `MongoTemplate` / `ReactiveMongoTemplate` are the default `WriteResultCheckingPolicy`, `WriteConcern`, `ReadPreference` and others listed below.\n\n[[mongo-template.read-preference]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "template-config", "heading_level": 1, "file_order": 42, "section_index": 0, "content_hash": "d20e3f76939e0a16cd8bc975e74d6d517365552f33bd08e70f177c91debe695b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:ce2c4142c002597ad4491b2175843545bf40ee42b9b63094c6b851a54f4db0e4", "content": "The default read preference applied to read operations if no other preference was defined via the xref:mongodb/template-query-operations.adoc#mongo.query.read-preference[Query].\n\n[[mongo-template.writeresultchecking]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "Default Read Preference", "heading_level": 2, "file_order": 42, "section_index": 1, "content_hash": "ce2c4142c002597ad4491b2175843545bf40ee42b9b63094c6b851a54f4db0e4", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:38041ca617b0d3c1b221e5636430ad337e37d3d0279d922315520ff4b00b7b04", "content": "When in development, it is handy to either log or throw an exception if the `com.mongodb.WriteResult` returned from any MongoDB operation contains an error. It is quite common to forget to do this during development and then end up with an application that looks like it runs successfully when, in fact, the database was not modified according to your expectations. You can set the `WriteResultChecking` property of `MongoTemplate` to one of the following values: `EXCEPTION` or `NONE`, to either throw an `Exception` or do nothing, respectively. The default is to use a `WriteResultChecking` value of `NONE`.\n\n[[mongo-template.writeconcern]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "WriteResultChecking Policy", "heading_level": 2, "file_order": 42, "section_index": 2, "content_hash": "38041ca617b0d3c1b221e5636430ad337e37d3d0279d922315520ff4b00b7b04", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:26b1ec10f59311350720633d912976cd7b48af9185976dca641dbe740327233b", "content": "If it has not yet been specified through the driver at a higher level (such as `com.mongodb.client.MongoClient`), you can set the `com.mongodb.WriteConcern` property that the `MongoTemplate` uses for write operations. If the `WriteConcern` property is not set, it defaults to the one set in the MongoDB driver's DB or Collection setting.\n\n[[mongo-template.writeconcernresolver]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "Default WriteConcern", "heading_level": 2, "file_order": 42, "section_index": 3, "content_hash": "26b1ec10f59311350720633d912976cd7b48af9185976dca641dbe740327233b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:b6af84e06f425cb999cabcdd3fa2053d71caea2cb7100d1dc3d0138e4ff03c64", "content": "For more advanced cases where you want to set different `WriteConcern` values on a per-operation basis (for remove, update, insert, and save operations), a strategy interface called `WriteConcernResolver` can be configured on `MongoTemplate`. Since `MongoTemplate` is used to persist POJOs, the `WriteConcernResolver` lets you create a policy that can map a specific POJO class to a `WriteConcern` value. The following listing shows the `WriteConcernResolver` interface:\n\n[source,java]\n----\npublic interface WriteConcernResolver {\n WriteConcern resolve(MongoAction action);\n}\n----\n\nYou can use the `MongoAction` argument to determine the `WriteConcern` value or use the value of the Template itself as a default.\n`MongoAction` contains the collection name being written to, the `java.lang.Class` of the POJO, the converted `Document`, the operation (`REMOVE`, `UPDATE`, `INSERT`, `INSERT_LIST`, or `SAVE`), and a few other pieces of contextual information.\nThe following example shows two sets of classes getting different `WriteConcern` settings:\n\n[source,java]\n----\npublic class MyAppWriteConcernResolver implements WriteConcernResolver {\n\n @Override\n public WriteConcern resolve(MongoAction action) {\n if (action.getEntityType().getSimpleName().contains(\"Audit\")) {\n return WriteConcern.ACKNOWLEDGED;\n } else if (action.getEntityType().getSimpleName().contains(\"Metadata\")) {\n return WriteConcern.JOURNALED;\n }\n return action.getDefaultWriteConcern();\n }\n}\n----\n\n[[mongo-template.entity-lifecycle-events]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "WriteConcernResolver", "heading_level": 2, "file_order": 42, "section_index": 4, "content_hash": "b6af84e06f425cb999cabcdd3fa2053d71caea2cb7100d1dc3d0138e4ff03c64", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:0ff40dea952943e47c0120765fd167e138d708446e17f9223250d62152ca799d", "content": "The template publishes xref:mongodb/lifecycle-events.adoc#mongodb.mapping-usage.events[lifecycle events].\nIn case there are no listeners present, this feature can be disabled.\n\n[source,java]\n----\n@Bean\nMongoOperations mongoTemplate(MongoClient mongoClient) {\n MongoTemplate template = new MongoTemplate(mongoClient, \"geospatial\");\n\ttemplate.setEntityLifecycleEventsEnabled(false);\n\t// ...\n}\n----\n\n[[mongo-template.entity-callbacks-config]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "Publish entity lifecycle events", "heading_level": 2, "file_order": 42, "section_index": 5, "content_hash": "0ff40dea952943e47c0120765fd167e138d708446e17f9223250d62152ca799d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:b175a5380c1c770849e5604489c678a54ff9504d8672fe0f67fb3b4dd54ad3ea", "content": "Nest to lifecycle events the template invokes xref:mongodb/lifecycle-events.adoc#mongo.entity-callbacks[EntityCallbacks] which can be (if not auto configured) set via the template API.\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n@Bean\nMongoOperations mongoTemplate(MongoClient mongoClient) {\n MongoTemplate template = new MongoTemplate(mongoClient, \"...\");\n\ttemplate.setEntityCallbacks(EntityCallbacks.create(...));\n\t// ...\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n@Bean\nReactiveMongoOperations mongoTemplate(MongoClient mongoClient) {\n ReactiveMongoTemplate template = new ReactiveMongoTemplate(mongoClient, \"...\");\n\ttemplate.setEntityCallbacks(ReactiveEntityCallbacks.create(...));\n\t// ...\n}\n----\n======\n\n[[mongo-template.count-documents-config]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "Configure EntityCallbacks", "heading_level": 2, "file_order": 42, "section_index": 6, "content_hash": "b175a5380c1c770849e5604489c678a54ff9504d8672fe0f67fb3b4dd54ad3ea", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:40df6bf73520d2d1937cb1859d6adfe621fa867014e8aec8eb25b0827533b0c8", "content": "By setting `MongoTemplate#useEstimatedCount(...)` to `true` _MongoTemplate#count(...)_ operations, that use an empty filter query, will be delegated to `estimatedCount`, as long as there is no transaction active and the template is not bound to a xref:mongodb/client-session-transactions.adoc[session].\nPlease refer to the xref:mongodb/template-document-count.adoc#mongo.query.count[Counting Documents] section for more information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-config.adoc", "title": "template-config", "heading": "Document count configuration", "heading_level": 2, "file_order": 42, "section_index": 7, "content_hash": "40df6bf73520d2d1937cb1859d6adfe621fa867014e8aec8eb25b0827533b0c8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-config.adoc"}}
{"id": "sha256:6621073124d4981ed54e1bfc19579856e0042c227351e17efa095adefc1efa6d", "content": "[[mongo-template.save-update-remove]]\n\n`MongoTemplate` / `ReactiveMongoTemplatge` let you save, update, and delete your domain objects and map those objects to documents stored in MongoDB.\nThe API signatures of the imperative and reactive API are mainly the same only differing in their return types.\nWhile the synchronous API uses `void`, single `Object` and `List` the reactive counterpart consists of `Mono<Void>`, `Mono<Object>` and `Flux`.\n\nConsider the following class:\n\n[source,java]\n----\npublic class Person {\n\n\tprivate String id;\n\tprivate String name;\n\tprivate int age;\n\n\tpublic Person(String name, int age) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t}\n\n\tpublic String getId() {\n\t\treturn id;\n\t}\n\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Person [id=\" + id + \", name=\" + name + \", age=\" + age + \"]\";\n\t}\n}\n----\n\nGiven the `Person` class in the preceding example, you can save, update and delete the object, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic class MongoApplication {\n\n private static final Log log = LogFactory.getLog(MongoApplication.class);\n\n public static void main(String[] args) {\n\n MongoOperations template = new MongoTemplate(new SimpleMongoClientDbFactory(MongoClients.create(), \"database\"));\n\n Person p = new Person(\"Joe\", 34);\n\n // Insert is used to initially store the object into the database.\n template.insert(p);\n log.info(\"Insert: \" + p);\n\n // Find\n p = template.findById(p.getId(), Person.class);\n log.info(\"Found: \" + p);\n\n // Update\n template.updateFirst(query(where(\"name\").is(\"Joe\")), update(\"age\", 35), Person.class);\n p = template.findOne(query(where(\"name\").is(\"Joe\")), Person.class);\n log.info(\"Updated: \" + p);\n\n // Delete\n template.remove(p);\n\n // Check that deletion worked\n List<Person> people = template.findAll(Person.class);\n log.info(\"Number of people = : \" + people.size());\n\n template.dropCollection(Person.class);\n }\n}\n----\n\nThe preceding example would produce the following log output (including debug messages from `MongoTemplate`):\n\n[source]\n----\nDEBUG apping.MongoPersistentEntityIndexCreator: 80 - Analyzing class class org.spring.example.Person for index information.\nDEBUG work.data.mongodb.core.MongoTemplate: 632 - insert Document containing fields: [_class, age, name] in collection: person\nINFO org.spring.example.MongoApp: 30 - Insert: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=34]\nDEBUG work.data.mongodb.core.MongoTemplate:1246 - findOne using query: { \"_id\" : { \"$oid\" : \"4ddc6e784ce5b1eba3ceaf5c\"}} in db.collection: database.person\nINFO org.spring.example.MongoApp: 34 - Found: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=34]\nDEBUG work.data.mongodb.core.MongoTemplate: 778 - calling update using query: { \"name\" : \"Joe\"} and update: { \"$set\" : { \"age\" : 35}} in collection: person\nDEBUG work.data.mongodb.core.MongoTemplate:1246 - findOne using query: { \"name\" : \"Joe\"} in db.collection: database.person\nINFO org.spring.example.MongoApp: 39 - Updated: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=35]\nDEBUG work.data.mongodb.core.MongoTemplate: 823 - remove using query: { \"id\" : \"4ddc6e784ce5b1eba3ceaf5c\"} in collection: person\nINFO org.spring.example.MongoApp: 46 - Number of people = : 0\nDEBUG work.data.mongodb.core.MongoTemplate: 376 - Dropped collection [database.person]\n----\n====\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\npublic class ReactiveMongoApplication {\n\n private static final Logger log = LoggerFactory.getLogger(ReactiveMongoApplication.class);\n\n public static void main(String[] args) throws Exception {\n\n CountDownLatch latch = new CountDownLatch(1);\n\n ReactiveMongoTemplate template = new ReactiveMongoTemplate(MongoClients.create(), \"database\");\n\n template.insert(new Person(\"Joe\", 34)).doOnNext(person -> log.info(\"Insert: \" + person))\n .flatMap(person -> template.findById(person.getId(), Person.class))\n .doOnNext(person -> log.info(\"Found: \" + person))\n .zipWith(person -> template.updateFirst(query(where(\"name\").is(\"Joe\")), update(\"age\", 35), Person.class))\n .flatMap(tuple -> template.remove(tuple.getT1())).flatMap(deleteResult -> template.findAll(Person.class))\n .count().doOnSuccess(count -> {\n log.info(\"Number of people: \" + count);\n latch.countDown();\n })\n\n .subscribe();\n\n latch.await();\n }\n}\n----\n======\n\n`MongoConverter` caused implicit conversion between a `String` and an `ObjectId` stored in the database by recognizing (through convention) the `Id` property name.\n\nThe preceding example is meant to show the use of save, update, and remove operations on `MongoTemplate` / `ReactiveMongoTemplate` and not to show complex mapping functionality.\nThe query syntax used in the preceding example is explained in more detail in the section \"`xref:mongodb/template-query-operations.adoc[Querying Documents]`\".\n\nIMPORTANT: MongoDB requires that you have an `_id` field for all documents. Please refer to the xref:mongodb/template-crud-operations.adoc[ID handling] section for details on the special treatment of this field.\n\nIMPORTANT: MongoDB collections can contain documents that represent instances of a variety of types. Please refer to the xref:mongodb/converters-type-mapping.adoc[type mapping] for details.\n\n[[mongo-template.save-insert]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "template-crud-operations", "heading_level": 1, "file_order": 43, "section_index": 0, "content_hash": "6621073124d4981ed54e1bfc19579856e0042c227351e17efa095adefc1efa6d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:4704c5db033db0c1fcf884909c4ca29ab638b21e27d72b77f27c0136c79b5734", "content": "There are several convenient methods on `MongoTemplate` for saving and inserting your objects.\nTo have more fine-grained control over the conversion process, you can register Spring converters with the `MappingMongoConverter` -- for example `Converter<Person, Document>` and `Converter<Document, Person>`.\n\nNOTE: The difference between insert and save operations is that a save operation performs an insert if the object is not already present.\n\nThe simple case of using the save operation is to save a POJO.\nIn this case, the collection name is determined by name (not fully qualified) of the class.\nYou may also call the save operation with a specific collection name. You can use mapping metadata to override the collection in which to store the object.\n\nWhen inserting or saving, if the `Id` property is not set, the assumption is that its value will be auto-generated by the database.\nConsequently, for auto-generation of an `ObjectId` to succeed, the type of the `Id` property or field in your class must be a `String`, an `ObjectId`, or a `BigInteger`.\n\nThe following example shows how to save a document and retrieving its contents:\n\n.Inserting and retrieving documents using the MongoTemplate\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport static org.springframework.data.mongodb.core.query.Criteria.query;\n\ntemplate.insert(new Person(\"Bob\", 33));\n\nPerson person = template.query(Person.class)\n .matching(query(where(\"age\").is(33)))\n .oneValue();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport static org.springframework.data.mongodb.core.query.Criteria.query;\n\nMono<Person> person = mongoTemplate.insert(new Person(\"Bob\", 33))\n .then(mongoTemplate.query(Person.class)\n .matching(query(where(\"age\").is(33)))\n .one());\n----\n======\n\nThe following insert and save operations are available:\n\n* `void` *save* `(Object objectToSave)`: Save the object to the default collection.\n* `void` *save* `(Object objectToSave, String collectionName)`: Save the object to the specified collection.\n\nA similar set of insert operations is also available:\n\n* `void` *insert* `(Object objectToSave)`: Insert the object to the default collection.\n* `void` *insert* `(Object objectToSave, String collectionName)`: Insert the object to the specified collection.\n\n[[mongo-template.id-handling]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Insert / Save", "heading_level": 2, "file_order": 43, "section_index": 1, "content_hash": "4704c5db033db0c1fcf884909c4ca29ab638b21e27d72b77f27c0136c79b5734", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:c64b4132f6a0460a9193f37b09126cecaff8af1cc52302b796a13ffdb123da74", "content": "MongoDB requires that you have an `_id` field for all documents.\nIf you do not provide one, the driver assigns an `ObjectId` with a generated value without considering your domain model as the server isn't aware of your identifier type.\nWhen you use the `MappingMongoConverter`, certain rules govern how properties from the Java class are mapped to this `_id` field:\n\n. A property or field annotated with `@Id` (`org.springframework.data.annotation.Id`) maps to the `_id` field.\n. A property or field without an annotation but named `id` maps to the `_id` field.\n\nThe following outlines what type conversion, if any, is done on the property mapped to the `_id` document field when using the `MappingMongoConverter` (the default for `MongoTemplate`).\n\n. If possible, an `id` property or field declared as a `String` in the Java class is converted to and stored as an `ObjectId` by using a Spring `Converter<String, ObjectId>`. Valid conversion rules are delegated to the MongoDB Java driver. If it cannot be converted to an `ObjectId`, then the value is stored as a string in the database.\n. An `id` property or field declared as `Date` is converted to and stored as `ObjectId`.\n. An `id` property or field declared as `BigInteger` in the Java class is converted to and stored as an `ObjectId` by using a Spring `Converter<BigInteger, ObjectId>`.\n\nIf no field or property specified in the previous sets of rules is present in the Java class, an implicit `_id` file is generated by the driver but not mapped to a property or field of the Java class.\n\nWhen querying and updating, `MongoTemplate` uses the converter that corresponds to the preceding rules for saving documents so that field names and types used in your queries can match what is in your domain classes.\n\nSome environments require a customized approach to map `Id` values such as data stored in MongoDB that did not run through the Spring Data mapping layer. Documents can contain `_id` values that can be represented either as `ObjectId` or as `String`.\nReading documents from the store back to the domain type works just fine. Querying for documents via their `id` can be cumbersome due to the implicit `ObjectId` conversion. Therefore documents cannot be retrieved that way.\nFor those cases `@MongoId` provides more control over the actual id mapping attempts.\n\n.`@MongoId` mapping\n====\n[source,java]\n----\npublic class PlainStringId {\n @MongoId String id; <1>\n}\n\npublic class PlainObjectId {\n @MongoId ObjectId id; <2>\n}\n\npublic class StringToObjectId {\n @MongoId(FieldType.OBJECT_ID) String id; <3>\n}\n----\n<1> The id is treated as `String` without further conversion.\n<2> The id is treated as `ObjectId`.\n<3> The id is treated as `ObjectId` if the given `String` is a valid `ObjectId` hex, otherwise as `String`. Corresponds to `@Id` usage.\n====\n\n[[mongo-template.save-insert.collection]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "How the `_id` Field is Handled in the Mapping Layer", "heading_level": 3, "file_order": 43, "section_index": 2, "content_hash": "c64b4132f6a0460a9193f37b09126cecaff8af1cc52302b796a13ffdb123da74", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:347ae30f62c04677eab242fd1909b0b6d90852dbd6f3b702b0395a06ff89b955", "content": "There are two ways to manage the collection name that is used for the documents.\nThe default collection name that is used is the class name changed to start with a lower-case letter.\nSo a `com.test.Person` class is stored in the `person` collection.\nYou can customize this by providing a different collection name with the `@Document` annotation.\nYou can also override the collection name by providing your own collection name as the last parameter for the selected `MongoTemplate` method calls.\n\n[[mongo-template.save-insert.individual]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Into Which Collection Are My Documents Saved?", "heading_level": 3, "file_order": 43, "section_index": 3, "content_hash": "347ae30f62c04677eab242fd1909b0b6d90852dbd6f3b702b0395a06ff89b955", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:570d4067d184038bb0139f1043aeac2f1a9b7052e9deeab849b801268ac3c60a", "content": "The MongoDB driver supports inserting a collection of documents in a single operation.\nThe following methods in the `MongoOperations` interface support this functionality:\n\n* *insert*: Inserts an object. If there is an existing document with the same `id`, an error is generated.\n* *insertAll*: Takes a `Collection` of objects as the first parameter. This method inspects each object and inserts it into the appropriate collection, based on the rules specified earlier.\n* *save*: Saves the object, overwriting any object that might have the same `id`.\n\n[[mongo-template.save-insert.batch]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Inserting or Saving Individual Objects", "heading_level": 3, "file_order": 43, "section_index": 4, "content_hash": "570d4067d184038bb0139f1043aeac2f1a9b7052e9deeab849b801268ac3c60a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:355c0c2ff038c7f70b9839b19c4d02e195a44bf26fe42270c7930489f358c438", "content": "The MongoDB driver supports inserting a collection of documents in one operation.\nThe following methods in the `MongoOperations` interface support this functionality via `insert` or a dedicated `BulkOperations` interface.\n\n.Batch Insert\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nCollection<Person> inserted = template.insert(List.of(...), Person.class);\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nFlux<Person> inserted = template.insert(List.of(...), Person.class);\n----\n======\n\n.Bulk Insert\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nBulkWriteResult result = template.bulkOps(BulkMode.ORDERED, Person.class)\n .insert(List.of(...))\n .execute();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<BulkWriteResult> result = template.bulkOps(BulkMode.ORDERED, Person.class)\n .insert(List.of(...))\n .execute();\n----\n======\n\n[NOTE]\n====\nServer performance of batch and bulk is identical.\nHowever bulk operations do not publish xref:mongodb/lifecycle-events.adoc[lifecycle events].\n====\n\n[IMPORTANT]\n====\nAny `@Version` property that has not been set prior to calling insert will be auto initialized with `1` (in case of a simple type like `int`) or `0` for wrapper types (eg. `Integer`). +\nRead more in the see xref:mongodb/template-crud-operations.adoc#mongo-template.optimistic-locking[Optimistic Locking] section.\n====\n\n[[mongodb-template-update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Inserting Several Objects in a Batch", "heading_level": 3, "file_order": 43, "section_index": 5, "content_hash": "355c0c2ff038c7f70b9839b19c4d02e195a44bf26fe42270c7930489f358c438", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:55f6397410d1da4392240b0ba4860a0ff527d4274d2e627f84d85ac70717c431", "content": "For updates, you can update the first document found by using `MongoOperation.updateFirst` or you can update all documents that were found to match the query by using the `MongoOperation.updateMulti` method or `all` on the fluent API.\nThe following example shows an update of all `SAVINGS` accounts where we are adding a one-time $50.00 bonus to the balance by using the `$inc` operator:\n\n.Updating documents by using the `MongoTemplate` / `ReactiveMongoTemplate`\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport org.springframework.data.mongodb.core.query.Update;\n\nUpdateResult result = template.update(Account.class)\n .matching(where(\"accounts.accountType\").is(Type.SAVINGS))\n .apply(new Update().inc(\"accounts.$.balance\", 50.00))\n .all();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport org.springframework.data.mongodb.core.query.Update;\n\nMono<UpdateResult> result = template.update(Account.class)\n .matching(where(\"accounts.accountType\").is(Type.SAVINGS))\n .apply(new Update().inc(\"accounts.$.balance\", 50.00))\n .all();\n----\n======\n\nIn addition to the `Query` discussed earlier, we provide the update definition by using an `Update` object.\nThe `Update` class has methods that match the update modifiers available for MongoDB.\nMost methods return the `Update` object to provide a fluent style for the API.\n\n[IMPORTANT]\n====\n`@Version` properties if not included in the `Update` will be automatically incremented.\nRead more in the see xref:mongodb/template-crud-operations.adoc#mongo-template.optimistic-locking[Optimistic Locking] section.\n====\n\n[[mongodb-template-update.methods]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Update", "heading_level": 2, "file_order": 43, "section_index": 6, "content_hash": "55f6397410d1da4392240b0ba4860a0ff527d4274d2e627f84d85ac70717c431", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:9ef135ad8309d7535289789ea89bb249a220e5f0c72907cec65ecf3d38fdd5be", "content": "* *updateFirst*: Updates the first document that matches the query document criteria with the updated document.\n* *updateMulti*: Updates all objects that match the query document criteria with the updated document.\n\nWARNING: `updateFirst` does not support ordering for MongoDB Versions below 8.0. Running one of the older versions, please use xref:mongodb/template-crud-operations.adoc#mongo-template.find-and-upsert[findAndModify] to apply `Sort`.\n\nNOTE: Index hints for the update operation can be provided via `Query.withHint(...)`.\n\n[[mongodb-template-update.update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Methods for Running Updates for Documents", "heading_level": 3, "file_order": 43, "section_index": 7, "content_hash": "9ef135ad8309d7535289789ea89bb249a220e5f0c72907cec65ecf3d38fdd5be", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:904f614eac322f29bd7fcafd988de187f08bf12083ca49359d69375e4dfbe2e8", "content": "You can use a little \"'syntax sugar'\" with the `Update` class, as its methods are meant to be chained together.\nAlso, you can kick-start the creation of a new `Update` instance by using `public static Update update(String key, Object value)` and using static imports.\n\nThe `Update` class contains the following methods:\n\n* `Update` *addToSet* `(String key, Object value)` Update using the `$addToSet` update modifier\n* `Update` *currentDate* `(String key)` Update using the `$currentDate` update modifier\n* `Update` *currentTimestamp* `(String key)` Update using the `$currentDate` update modifier with `$type` `timestamp`\n* `Update` *inc* `(String key, Number inc)` Update using the `$inc` update modifier\n* `Update` *max* `(String key, Object max)` Update using the `$max` update modifier\n* `Update` *min* `(String key, Object min)` Update using the `$min` update modifier\n* `Update` *multiply* `(String key, Number multiplier)` Update using the `$mul` update modifier\n* `Update` *pop* `(String key, Update.Position pos)` Update using the `$pop` update modifier\n* `Update` *pull* `(String key, Object value)` Update using the `$pull` update modifier\n* `Update` *pullAll* `(String key, Object[] values)` Update using the `$pullAll` update modifier\n* `Update` *push* `(String key, Object value)` Update using the `$push` update modifier\n* `Update` *pushAll* `(String key, Object[] values)` Update using the `$pushAll` update modifier\n* `Update` *rename* `(String oldName, String newName)` Update using the `$rename` update modifier\n* `Update` *set* `(String key, Object value)` Update using the `$set` update modifier\n* `Update` *setOnInsert* `(String key, Object value)` Update using the `$setOnInsert` update modifier\n* `Update` *unset* `(String key)` Update using the `$unset` update modifier\n\nSome update modifiers, such as `$push` and `$addToSet`, allow nesting of additional operators.\n\n[source,java]\n----\nnew Update().push(\"category\").each(\"spring\", \"data\")\n\nnew Update().push(\"key\").atPosition(Position.FIRST).each(Arrays.asList(\"Arya\", \"Arry\", \"Weasel\"));\n\nnew Update().push(\"key\").slice(5).each(Arrays.asList(\"Arya\", \"Arry\", \"Weasel\"));\n\nnew Update().addToSet(\"values\").each(\"spring\", \"data\", \"mongodb\");\n----\n\n[[mongo-template.aggregation-update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Methods in the `Update` Class", "heading_level": 3, "file_order": 43, "section_index": 8, "content_hash": "904f614eac322f29bd7fcafd988de187f08bf12083ca49359d69375e4dfbe2e8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:ec7c3c215ef580bed35616677e51005e0840aa8a6e8538ab787cc52bd0fd9471", "content": "Update methods exposed by `MongoOperations` and `ReactiveMongoOperations` also accept an xref:mongodb/aggregation-framework.adoc[Aggregation Pipeline] via `AggregationUpdate`.\nUsing `AggregationUpdate` allows leveraging https://docs.mongodb.com/manual/reference/method/db.collection.update/#update-with-aggregation-pipeline[MongoDB 4.2 aggregations] in an update operation.\nUsing aggregations in an update allows updating one or more fields by expressing multiple stages and multiple conditions with a single operation.\n\nThe update can consist of the following stages:\n\n* `AggregationUpdate.set(...).toValue(...)` -> `$set : { ... }`\n* `AggregationUpdate.unset(...)` -> `$unset : [ ... ]`\n* `AggregationUpdate.replaceWith(...)` -> `$replaceWith : { ... }`\n\n.Update Aggregation\n====\n[source,java]\n----\nAggregationUpdate update = Aggregation.newUpdate()\n .set(\"average\").toValue(ArithmeticOperators.valueOf(\"tests\").avg()) <1>\n .set(\"grade\").toValue(ConditionalOperators.switchCases( <2>\n when(valueOf(\"average\").greaterThanEqualToValue(90)).then(\"A\"),\n when(valueOf(\"average\").greaterThanEqualToValue(80)).then(\"B\"),\n when(valueOf(\"average\").greaterThanEqualToValue(70)).then(\"C\"),\n when(valueOf(\"average\").greaterThanEqualToValue(60)).then(\"D\"))\n .defaultTo(\"F\")\n );\n\ntemplate.update(Student.class) <3>\n .apply(update)\n .all(); <4>\n----\n[source,javascript]\n----\ndb.students.update( <3>\n { },\n [\n { $set: { average : { $avg: \"$tests\" } } }, <1>\n { $set: { grade: { $switch: { <2>\n branches: [\n { case: { $gte: [ \"$average\", 90 ] }, then: \"A\" },\n { case: { $gte: [ \"$average\", 80 ] }, then: \"B\" },\n { case: { $gte: [ \"$average\", 70 ] }, then: \"C\" },\n { case: { $gte: [ \"$average\", 60 ] }, then: \"D\" }\n ],\n default: \"F\"\n } } } }\n ],\n { multi: true } <4>\n)\n----\n<1> The 1st `$set` stage calculates a new field _average_ based on the average of the _tests_ field.\n<2> The 2nd `$set` stage calculates a new field _grade_ based on the _average_ field calculated by the first aggregation stage.\n<3> The pipeline is run on the _students_ collection and uses `Student` for the aggregation field mapping.\n<4> Apply the update to all matching documents in the collection.\n====\n\n[[mongo-template.upserts]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Aggregation Pipeline Updates", "heading_level": 3, "file_order": 43, "section_index": 9, "content_hash": "ec7c3c215ef580bed35616677e51005e0840aa8a6e8538ab787cc52bd0fd9471", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:c97493d433d31fcf0b7ba6f381459d032dc4116e2c91efc3678519bfc21550be", "content": "Related to performing an `updateFirst` operation, you can also perform an `upsert` operation, which will perform an insert if no document is found that matches the query.\nThe document that is inserted is a combination of the query document and the update document.\nThe following example shows how to use the `upsert` method:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nUpdateResult result = template.update(Person.class)\n .matching(query(where(\"ssn\").is(1111).and(\"firstName\").is(\"Joe\").and(\"Fraizer\").is(\"Update\"))\n .apply(update(\"address\", addr))\n .upsert();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nMono<UpdateResult> result = template.update(Person.class)\n .matching(query(where(\"ssn\").is(1111).and(\"firstName\").is(\"Joe\").and(\"Fraizer\").is(\"Update\"))\n .apply(update(\"address\", addr))\n .upsert();\n----\n======\n\nWARNING: `upsert` does not support ordering. Please use xref:mongodb/template-crud-operations.adoc#mongo-template.find-and-upsert[findAndModify] to apply `Sort`.\n\n[IMPORTANT]\n====\n`@Version` properties if not included in the `Update` will be automatically initialized.\nRead more in the see xref:mongodb/template-crud-operations.adoc#mongo-template.optimistic-locking[Optimistic Locking] section.\n====\n\n[[mongo-template.replace]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Upsert", "heading_level": 2, "file_order": 43, "section_index": 10, "content_hash": "c97493d433d31fcf0b7ba6f381459d032dc4116e2c91efc3678519bfc21550be", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:7c85699c396d2718ac725ae72150bf23503c63bc60bcd7060b40c3f2b9c07252", "content": "The various `replace` methods available via `MongoTemplate` allow to override the first matching Document.\nIf no match is found a new one can be upserted (as outlined in the previous section) by providing `ReplaceOptions` with according configuration.\n\n====\n.Replace one\n[source,java]\n----\nPerson tom = template.insert(new Person(\"Motte\", 21)); <1>\nQuery query = Query.query(Criteria.where(\"firstName\").is(tom.getFirstName())); <2>\ntom.setFirstname(\"Tom\"); <3>\ntemplate.replace(query, tom, ReplaceOptions.none()); <4>\n----\n<1> Insert a new document.\n<2> The query used to identify the single document to replace.\n<3> Set up the replacement document which must hold either the same `_id` as the existing or no `_id` at all.\n<4> Run the replace operation.\n.Replace one with upsert\n[source,java]\n----\nPerson tom = new Person(\"id-123\", \"Tom\", 21) <1>\nQuery query = Query.query(Criteria.where(\"firstName\").is(tom.getFirstName()));\ntemplate.replace(query, tom, ReplaceOptions.replaceOptions().upsert()); <2>\n----\n<1> The `_id` value needs to be present for upsert, otherwise MongoDB will create a new potentially with the domain type incompatible `ObjectId`.\nAs MongoDB is not aware of your domain type, any `@Field(targetType)` hints are not considered and the resulting `ObjectId` might be not compatible with your domain model.\n<2> Use `upsert` to insert a new document if no match is found\n====\n\n[WARNING]\n====\nIt is not possible to change the `_id` of existing documents with a replace operation.\nOn `upsert` MongoDB uses 2 ways of determining the new id for the entry:\n* The `_id` is used within the query as in `{\"_id\" : 1234 }`\n* The `_id` is present in the replacement document.\nIf no `_id` is provided in either way, MongoDB will create a new `ObjectId` for the document.\nThis may lead to mapping and data lookup malfunctions if the used domain types `id` property has a different type like e.g. `Long`.\n====\n\n[[mongo-template.find-and-upsert]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Replacing Documents in a Collection", "heading_level": 3, "file_order": 43, "section_index": 11, "content_hash": "7c85699c396d2718ac725ae72150bf23503c63bc60bcd7060b40c3f2b9c07252", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:dc4338b521904d90b4db5677c0449d9304f90c6713d4a5c49e5e9e49a71ab92a", "content": "The `findAndModify(…)` method on `MongoCollection` can update a document and return either the old or newly updated document in a single operation.\n`MongoTemplate` provides four `findAndModify` overloaded methods that take `Query` and `Update` classes and converts from `Document` to your POJOs:\n\n[source,java]\n----\n<T> T findAndModify(Query query, Update update, Class<T> entityClass);\n\n<T> T findAndModify(Query query, Update update, Class<T> entityClass, String collectionName);\n\n<T> T findAndModify(Query query, Update update, FindAndModifyOptions options, Class<T> entityClass);\n\n<T> T findAndModify(Query query, Update update, FindAndModifyOptions options, Class<T> entityClass, String collectionName);\n----\n\nThe following example inserts a few `Person` objects into the container and performs a `findAndUpdate` operation:\n\n[source,java]\n----\ntemplate.insert(new Person(\"Tom\", 21));\ntemplate.insert(new Person(\"Dick\", 22));\ntemplate.insert(new Person(\"Harry\", 23));\n\nQuery query = new Query(Criteria.where(\"firstName\").is(\"Harry\"));\nUpdate update = new Update().inc(\"age\", 1);\n\nPerson oldValue = template.update(Person.class)\n .matching(query)\n .apply(update)\n .findAndModifyValue(); // oldValue.age == 23\n\nPerson newValue = template.query(Person.class)\n .matching(query)\n .findOneValue(); // newValye.age == 24\n\nPerson newestValue = template.update(Person.class)\n .matching(query)\n .apply(update)\n .withOptions(FindAndModifyOptions.options().returnNew(true)) // Now return the newly updated document when updating\n .findAndModifyValue(); // newestValue.age == 25\n----\n\nThe `FindAndModifyOptions` method lets you set the options of `returnNew`, `upsert`, and `remove`.\nAn example extending from the previous code snippet follows:\n\n[source,java]\n----\nPerson upserted = template.update(Person.class)\n .matching(new Query(Criteria.where(\"firstName\").is(\"Mary\")))\n .apply(update)\n .withOptions(FindAndModifyOptions.options().upsert(true).returnNew(true))\n .findAndModifyValue()\n----\n\n[IMPORTANT]\n====\n`@Version` properties if not included in the `Update` will be automatically incremented.\nRead more in the see xref:mongodb/template-crud-operations.adoc#mongo-template.optimistic-locking[Optimistic Locking] section.\n====\n\n[[mongo-template.find-and-replace]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Find and Modify", "heading_level": 2, "file_order": 43, "section_index": 12, "content_hash": "dc4338b521904d90b4db5677c0449d9304f90c6713d4a5c49e5e9e49a71ab92a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:134868b51d24ef5aff58c77e3f5a3dc71cc0dea3a303a09273bd19a23a586ab0", "content": "The most straight forward method of replacing an entire `Document` is via its `id` using the `save` method.\nHowever this might not always be feasible.\n`findAndReplace` offers an alternative that allows to identify the document to replace via a simple query.\n\n.Find and Replace Documents\n====\n[source,java]\n----\nOptional<User> result = template.update(Person.class) <1>\n .matching(query(where(\"firstame\").is(\"Tom\"))) <2>\n .replaceWith(new Person(\"Dick\"))\n .withOptions(FindAndReplaceOptions.options().upsert()) <3>\n .as(User.class) <4>\n .findAndReplace(); <5>\n----\n<1> Use the fluent update API with the domain type given for mapping the query and deriving the collection name or just use `MongoOperations#findAndReplace`.\n<2> The actual match query mapped against the given domain type. Provide `sort`, `fields` and `collation` settings via the query.\n<3> Additional optional hook to provide options other than the defaults, like `upsert`.\n<4> An optional projection type used for mapping the operation result. If none given the initial domain type is used.\n<5> Trigger the actual processing. Use `findAndReplaceValue` to obtain the nullable result instead of an `Optional`.\n====\n\nIMPORTANT: Please note that the replacement must not hold an `id` itself as the `id` of the existing `Document` will be\ncarried over to the replacement by the store itself. Also keep in mind that `findAndReplace` will only replace the first\ndocument matching the query criteria depending on a potentially given sort order.\n\n[[mongo-template.delete]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Find and Replace", "heading_level": 2, "file_order": 43, "section_index": 13, "content_hash": "134868b51d24ef5aff58c77e3f5a3dc71cc0dea3a303a09273bd19a23a586ab0", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:69b6be88f2570a3e7008ccd301e8f816772d0002161ba8d9ccfe83656d0b4448", "content": "You can use one of five overloaded methods to remove an object from the database:\n\n====\n[source,java]\n----\ntemplate.remove(tywin, \"GOT\"); <1>\n\ntemplate.remove(query(where(\"lastname\").is(\"lannister\")), \"GOT\"); <2>\n\ntemplate.remove(new Query().limit(3), \"GOT\"); <3>\n\ntemplate.findAllAndRemove(query(where(\"lastname\").is(\"lannister\"), \"GOT\"); <4>\n\ntemplate.findAllAndRemove(new Query().limit(3), \"GOT\"); <5>\n----\n<1> Remove a single entity specified by its `_id` from the associated collection.\n<2> Remove all documents that match the criteria of the query from the `GOT` collection.\n<3> Remove the first three documents in the `GOT` collection. Unlike <2>, the documents to remove are identified by their `_id`, running the given query, applying `sort`, `limit`, and `skip` options first, and then removing all at once in a separate step.\n<4> Remove all documents matching the criteria of the query from the `GOT` collection. Unlike <3>, documents do not get deleted in a batch but one by one.\n<5> Remove the first three documents in the `GOT` collection. Unlike <3>, documents do not get deleted in a batch but one by one.\n====\n\n[[mongo-template.optimistic-locking]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Delete", "heading_level": 2, "file_order": 43, "section_index": 14, "content_hash": "69b6be88f2570a3e7008ccd301e8f816772d0002161ba8d9ccfe83656d0b4448", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:3cb3ae98de9adb87ff11984dc8a3f0c59247198b89614422c70cd3b033745194", "content": "The `@Version` annotation provides syntax similar to that of JPA in the context of MongoDB and makes sure updates are only applied to documents with a matching version.\nTherefore, the actual value of the version property is added to the update query in such a way that the update does not have any effect if another operation altered the document in the meantime.\nIn that case, an `OptimisticLockingFailureException` is thrown.\nThe following example shows these features:\n\n====\n[source,java]\n----\n@Document\nclass Person {\n\n @Id String id;\n String firstname;\n String lastname;\n @Version Long version;\n}\n\nPerson daenerys = template.insert(new Person(\"Daenerys\")); <1>\n\nPerson tmp = template.findOne(query(where(\"id\").is(daenerys.getId())), Person.class); <2>\n\ndaenerys.setLastname(\"Targaryen\");\ntemplate.save(daenerys); <3>\n\ntemplate.save(tmp); // throws OptimisticLockingFailureException <4>\n----\n<1> Intially insert document. `version` is set to `0`.\n<2> Load the just inserted document. `version` is still `0`.\n<3> Update the document with `version = 0`. Set the `lastname` and bump `version` to `1`.\n<4> Try to update the previously loaded document that still has `version = 0`. The operation fails with an `OptimisticLockingFailureException`, as the current `version` is `1`.\n====\n\nOnly certain CRUD operations on `MongoTemplate` do consider and alter version properties. Please consult `MongoOperations` java doc for detailed information.\n\nNOTE: Optimistic Locking requires write acknowledgement (a write result response) by the server. Using `WriteConcern.UNACKNOWLEDGED` can lead to silently swallowed `OptimisticLockingFailureException`.\n\nNOTE: As of Version 2.2 `MongoOperations` also includes the `@Version` property when removing an entity from the database.\nTo remove a `Document` without version check use `MongoOperations#remove(Query,...)` instead of `MongoOperations#remove(Object)`.\n\nNOTE: As of Version 2.2 repositories check for the outcome of acknowledged deletes when removing versioned entities.\nAn `OptimisticLockingFailureException` is raised if a versioned entity cannot be deleted through `CrudRepository.delete(Object)`. In such case, the version was changed or the object was deleted in the meantime. Use `CrudRepository.deleteById(ID)` to bypass optimistic locking functionality and delete objects regardless of their version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc", "title": "template-crud-operations", "heading": "Optimistic Locking", "heading_level": 2, "file_order": 43, "section_index": 15, "content_hash": "3cb3ae98de9adb87ff11984dc8a3f0c59247198b89614422c70cd3b033745194", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-crud-operations.adoc"}}
{"id": "sha256:d4d3633325b624619bb10bee0e18ab675e393446b146e612a87b45b01476b7d4", "content": "[[mongo.query.count]]\n\nThe template API offers various methods to count the number of documents matching a given criteria.\nOne of them outlined below.\n\n====\n[source,java]\n----\ntemplate.query(Person.class)\n .matching(query(where(\"firstname\").is(\"luke\")))\n .count();\n----\n====\n\nIn pre-3.x versions of SpringData MongoDB the count operation used MongoDBs internal collection statistics.\nWith the introduction of xref:mongodb/client-session-transactions.adoc#mongo.transactions[MongoDB Transactions] this was no longer possible because statistics would not correctly reflect potential changes during a transaction requiring an aggregation-based count approach.\nSo in version 2.x `MongoOperations.count()` would use the collection statistics if no transaction was in progress, and the aggregation variant if so.\n\nAs of Spring Data MongoDB 3.x any `count` operation uses regardless the existence of filter criteria the aggregation-based count approach via MongoDBs `countDocuments`.\nIf the application is fine with the limitations of working upon collection statistics `MongoOperations.estimatedCount()` offers an alternative.\n\n[TIP]\n====\nBy setting `MongoTemplate#useEstimatedCount(...)` to `true` _MongoTemplate#count(...)_ operations, that use an empty filter query, will be delegated to `estimatedCount`, as long as there is no transaction active and the template is not bound to a xref:mongodb/client-session-transactions.adoc[session].\nIt will still be possible to obtain exact numbers via `MongoTemplate#exactCount`, but may speed up things.\n====\n\n[NOTE]\n====\nMongoDBs native `countDocuments` method and the `$match` aggregation, do not support `$near` and `$nearSphere` but require `$geoWithin` along with `$center` or `$centerSphere` which does not support `$minDistance` (see https://jira.mongodb.org/browse/SERVER-37043).\n\nTherefore a given `Query` will be rewritten for `count` operations using `Reactive`-/`MongoTemplate` to bypass the issue like shown below.\n\n[source,javascript]\n----\n{ location : { $near : [-73.99171, 40.738868], $maxDistance : 1.1 } } <1>\n{ location : { $geoWithin : { $center: [ [-73.99171, 40.738868], 1.1] } } } <2>\n\n{ location : { $near : [-73.99171, 40.738868], $minDistance : 0.1, $maxDistance : 1.1 } } <3>\n{$and :[ { $nor :[ { location :{ $geoWithin :{ $center :[ [-73.99171, 40.738868 ], 0.01] } } } ]}, { location :{ $geoWithin :{ $center :[ [-73.99171, 40.738868 ], 1.1] } } } ] } <4>\n----\n<1> Count source query using `$near`.\n<2> Rewritten query now using `$geoWithin` with `$center`.\n<3> Count source query using `$near` with `$minDistance` and `$maxDistance`.\n<4> Rewritten query now a combination of `$nor` `$geowithin` critierias to work around unsupported `$minDistance`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-document-count.adoc", "title": "template-document-count", "heading": "template-document-count", "heading_level": 1, "file_order": 44, "section_index": 0, "content_hash": "d4d3633325b624619bb10bee0e18ab675e393446b146e612a87b45b01476b7d4", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-document-count.adoc"}}
{"id": "sha256:fcf47de1e5c59b62db1aee4276b5b3f66f59cf0fa712c1fa3bac62bcc1d45bf6", "content": "[[gridfs]]\n\nMongoDB supports storing binary files inside its filesystem, GridFS.\nSpring Data MongoDB provides a javadoc:org.springframework.data.mongodb.gridfs.GridFsOperations[] and javadoc:org.springframework.data.mongodb.gridfs.ReactiveGridFsOperations[] interface as well as the corresponding implementation, `GridFsTemplate` and `ReactiveGridFsTemplate`, to let you interact with the filesystem.\nYou can set up a template instance by handing it a `MongoDatabaseFactory`/`ReactiveMongoDatabaseFactory` as well as a `MongoConverter`, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nclass GridFsConfiguration extends AbstractMongoClientConfiguration {\n\n // … further configuration omitted\n\n @Bean\n public GridFsTemplate gridFsTemplate() {\n return new GridFsTemplate(mongoDbFactory(), mappingMongoConverter());\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nclass ReactiveGridFsConfiguration extends AbstractReactiveMongoConfiguration {\n\n // … further configuration omitted\n\n @Bean\n public ReactiveGridFsTemplate reactiveGridFsTemplate() {\n return new ReactiveGridFsTemplate(reactiveMongoDbFactory(), mappingMongoConverter());\n }\n}\n----\n\nXML::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxmlns:mongo=\"http://www.springframework.org/schema/data/mongo\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/data/mongo\nhttps://www.springframework.org/schema/data/mongo/spring-mongo.xsd\nhttp://www.springframework.org/schema/beans\nhttps://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n <mongo:db-factory id=\"mongoDbFactory\" dbname=\"database\" />\n <mongo:mapping-converter id=\"converter\" />\n\n <bean class=\"org.springframework.data.mongodb.gridfs.GridFsTemplate\">\n <constructor-arg ref=\"mongoDbFactory\" />\n <constructor-arg ref=\"converter\" />\n </bean>\n\n</beans>\n----\n======\n\nThe template can now be injected and used to perform storage and retrieval operations, as the following example shows:\n\n.Using GridFS to store files\n[tabs]\n======\nImperative::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nclass GridFsClient {\n\n @Autowired\n GridFsOperations operations;\n\n @Test\n public void storeFileToGridFs() {\n\n FileMetadata metadata = new FileMetadata();\n // populate metadata\n Resource file = … // lookup File or Resource\n\n operations.store(file.getInputStream(), \"filename.txt\", metadata);\n }\n}\n----\nThe `store(…)` operations take an `InputStream`, a filename, and (optionally) metadata information about the file to store.\nThe metadata can be an arbitrary object, which will be marshaled by the `MongoConverter` configured with the `GridFsTemplate`.\nAlternatively, you can also provide a `Document`.\n====\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nclass ReactiveGridFsClient {\n\n @Autowired\n ReactiveGridFsTemplate operations;\n\n @Test\n public Mono<ObjectId> storeFileToGridFs() {\n\n FileMetadata metadata = new FileMetadata();\n // populate metadata\n Publisher<DataBuffer> file = … // lookup File or Resource\n\n return operations.store(file, \"filename.txt\", metadata);\n }\n}\n----\nThe `store(…)` operations take an `Publisher<DataBuffer>`, a filename, and (optionally) metadata information about the file to store.\nThe metadata can be an arbitrary object, which will be marshaled by the `MongoConverter` configured with the `ReactiveGridFsTemplate`.\nAlternatively, you can also provide a `Document`.\n\nThe MongoDB's driver uses `AsyncInputStream` and `AsyncOutputStream` interfaces to exchange binary streams.\nSpring Data MongoDB adapts these interfaces to `Publisher<DataBuffer>`.\nRead more about `DataBuffer` in {spring-framework-docs}/core/databuffer-codec.html[Spring's reference documentation].\n====\n======\n\nYou can read files from the filesystem through either the `find(…)` or the `getResources(…)` methods.\nLet's have a look at the `find(…)` methods first.\nYou can either find a single file or multiple files that match a `Query`.\nYou can use the `GridFsCriteria` helper class to define queries.\nIt provides static factory methods to encapsulate default metadata fields (such as `whereFilename()` and `whereContentType()`) or a custom one through `whereMetaData()`.\nThe following example shows how to use the template to query for files:\n\n.Using GridFsTemplate to query for files\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nclass GridFsClient {\n\n @Autowired\n GridFsOperations operations;\n\n @Test\n public void findFilesInGridFs() {\n GridFSFindIterable result = operations.find(query(whereFilename().is(\"filename.txt\")));\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nclass ReactiveGridFsClient {\n\n @Autowired\n ReactiveGridFsTemplate operations;\n\n @Test\n public Flux<GridFSFile> findFilesInGridFs() {\n return operations.find(query(whereFilename().is(\"filename.txt\")))\n }\n}\n----\n======\n\nNOTE: Currently, MongoDB does not support defining sort criteria when retrieving files from GridFS. For this reason, any sort criteria defined on the `Query` instance handed into the `find(…)` method are disregarded.\n\nThe other option to read files from the GridFs is to use the methods introduced by the `ResourcePatternResolver` interface.\nThey allow handing an Ant path into the method and can thus retrieve files matching the given pattern.\nThe following example shows how to use `GridFsTemplate` to read files:\n\n.Using GridFsTemplate to read files\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nclass GridFsClient {\n\n @Autowired\n GridFsOperations operations;\n\n public GridFsResources[] readFilesFromGridFs() {\n return operations.getResources(\"*.txt\");\n }\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nclass ReactiveGridFsClient {\n\n @Autowired\n ReactiveGridFsOperations operations;\n\n public Flux<ReactiveGridFsResource> readFilesFromGridFs() {\n return operations.getResources(\"*.txt\");\n }\n}\n----\n======\n\n`GridFsOperations` extends `ResourcePatternResolver` and lets the `GridFsTemplate` (for example) to be plugged into an `ApplicationContext` to read Spring Config files from MongoDB database.\n\nNOTE: By default, `GridFsTemplate` obtains `GridFSBucket` once upon the first GridFS interaction.\nAfter that, the template instance reuses the cached bucket.\nTo use different buckets, from the same Template instance use the constructor accepting `Supplier<GridFSBucket>`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-gridfs.adoc", "title": "template-gridfs", "heading": "template-gridfs", "heading_level": 1, "file_order": 45, "section_index": 0, "content_hash": "fcf47de1e5c59b62db1aee4276b5b3f66f59cf0fa712c1fa3bac62bcc1d45bf6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-gridfs.adoc"}}
{"id": "sha256:8da296cebfdbfa0ce4070649f9e901edf096da1ea377c9c1b7443910f00bafa2", "content": "[[mongo.query]]\n\nYou can use the `Query` and `Criteria` classes to express your queries.\nThey have method names that mirror the native MongoDB operator names, such as `lt`, `lte`, `is`, and others.\nThe `Query` and `Criteria` classes follow a fluent API style so that you can chain together multiple method criteria and queries while having easy-to-understand code.\nTo improve readability, static imports let you avoid using the 'new' keyword for creating `Query` and `Criteria` instances.\nYou can also use `BasicQuery` to create `Query` instances from plain JSON Strings, as shown in the following example:\n\n.Creating a Query instance from a plain JSON String\n====\n[source,java]\n----\nBasicQuery query = new BasicQuery(\"{ age : { $lt : 50 }, accounts.balance : { $gt : 1000.00 }}\");\nList<Person> result = mongoTemplate.find(query, Person.class);\n----\n====\n\n[[mongodb-template-query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "template-query-operations", "heading_level": 1, "file_order": 46, "section_index": 0, "content_hash": "8da296cebfdbfa0ce4070649f9e901edf096da1ea377c9c1b7443910f00bafa2", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:3eb4229528193d646d0446d17bee21b45b19479961810f6bafce5aa14828b894", "content": "Earlier, we saw how to retrieve a single document by using the `findOne` and `findById` methods on `MongoTemplate`.\nThese methods return a single domain object right way or using a reactive API a `Mono` emitting a single element.\nWe can also query for a collection of documents to be returned as a list of domain objects.\nAssuming that we have a number of `Person` objects with name and age stored as documents in a collection and that each person has an embedded account document with a balance, we can now run a query using the following code:\n\n.Querying for documents using the MongoTemplate\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport static org.springframework.data.mongodb.core.query.Query.query;\n\nList<Person> result = template.query(Person.class)\n .matching(query(where(\"age\").lt(50).and(\"accounts.balance\").gt(1000.00d)))\n .all();\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nimport static org.springframework.data.mongodb.core.query.Criteria.where;\nimport static org.springframework.data.mongodb.core.query.Query.query;\n\nFlux<Person> result = template.query(Person.class)\n .matching(query(where(\"age\").lt(50).and(\"accounts.balance\").gt(1000.00d)))\n .all();\n----\n======\n\nAll find methods take a `Query` object as a parameter.\nThis object defines the criteria and options used to perform the query.\nThe criteria are specified by using a `Criteria` object that has a static factory method named `where` to instantiate a new `Criteria` object.\nWe recommend using static imports for `org.springframework.data.mongodb.core.query.Criteria.where` and `Query.query` to make the query more readable.\n\nThe query should return a `List` or `Flux` of `Person` objects that meet the specified criteria.\nThe rest of this section lists the methods of the `Criteria` and `Query` classes that correspond to the operators provided in MongoDB.\nMost methods return the `Criteria` object, to provide a fluent style for the API.\n\n[[mongodb-template-query.criteria]]\n.Methods of the Criteria Class\n[%collapsible]\n====\nThe `Criteria` class provides the following methods, all of which correspond to operators in MongoDB:\n\n* `Criteria` *all* `(Object o)` Creates a criterion using the `$all` operator\n* `Criteria` *and* `(String key)` Adds a chained `Criteria` with the specified `key` to the current `Criteria` and returns the newly created one\n* `Criteria` *andOperator* `(Criteria... criteria)` Creates an and query using the `$and` operator for all of the provided criteria (requires MongoDB 2.0 or later)\n* `Criteria` *andOperator* `(Collection<Criteria> criteria)` Creates an and query using the `$and` operator for all of the provided criteria (requires MongoDB 2.0 or later)\n* `Criteria` *elemMatch* `(Criteria c)` Creates a criterion using the `$elemMatch` operator\n* `Criteria` *exists* `(boolean b)` Creates a criterion using the `$exists` operator\n* `Criteria` *gt* `(Object o)` Creates a criterion using the `$gt` operator\n* `Criteria` *gte* `(Object o)` Creates a criterion using the `$gte` operator\n* `Criteria` *in* `(Object... o)` Creates a criterion using the `$in` operator for a varargs argument.\n* `Criteria` *in* `(Collection<?> collection)` Creates a criterion using the `$in` operator using a collection\n* `Criteria` *is* `(Object o)` Creates a criterion using field matching (`{ key:value }`). If the specified value is a document, the order of the fields and exact equality in the document matters.\n* `Criteria` *lt* `(Object o)` Creates a criterion using the `$lt` operator\n* `Criteria` *lte* `(Object o)` Creates a criterion using the `$lte` operator\n* `Criteria` *mod* `(Number value, Number remainder)` Creates a criterion using the `$mod` operator\n* `Criteria` *ne* `(Object o)` Creates a criterion using the `$ne` operator\n* `Criteria` *nin* `(Object... o)` Creates a criterion using the `$nin` operator\n* `Criteria` *norOperator* `(Criteria... criteria)` Creates an nor query using the `$nor` operator for all of the provided criteria\n* `Criteria` *norOperator* `(Collection<Criteria> criteria)` Creates an nor query using the `$nor` operator for all of the provided criteria\n* `Criteria` *not* `()` Creates a criterion using the `$not` meta operator which affects the clause directly following\n* `Criteria` *orOperator* `(Criteria... criteria)` Creates an or query using the `$or` operator for all of the provided criteria\n* `Criteria` *orOperator* `(Collection<Criteria> criteria)` Creates an or query using the `$or` operator for all of the provided criteria\n* `Criteria` *regex* `(String re)` Creates a criterion using a `$regex`\n* `Criteria` *sampleRate* `(double sampleRate)` Creates a criterion using the `$sampleRate` operator\n* `Criteria` *size* `(int s)` Creates a criterion using the `$size` operator\n* `Criteria` *type* `(int t)` Creates a criterion using the `$type` operator\n* `Criteria` *matchingDocumentStructure* `(MongoJsonSchema schema)` Creates a criterion using the `$jsonSchema` operator for xref:mongodb/mapping/mapping-schema.adoc[JSON schema criteria]. `$jsonSchema` can only be applied on the top level of a query and not property specific. Use the `properties` attribute of the schema to match against nested fields.\n* `Criteria` *bits()* is the gateway to https://docs.mongodb.com/manual/reference/operator/query-bitwise/[MongoDB bitwise query operators] like `$bitsAllClear`.\n\nThe Criteria class also provides the following methods for geospatial queries.\n\n* `Criteria` *within* `(Circle circle)` Creates a geospatial criterion using `$geoWithin $center` operators.\n* `Criteria` *within* `(Box box)` Creates a geospatial criterion using a `$geoWithin $box` operation.\n* `Criteria` *withinSphere* `(Circle circle)` Creates a geospatial criterion using `$geoWithin $center` operators.\n* `Criteria` *near* `(Point point)` Creates a geospatial criterion using a `$near` operation\n* `Criteria` *nearSphere* `(Point point)` Creates a geospatial criterion using `$nearSphere$center` operations. This is only available for MongoDB 1.7 and higher.\n* `Criteria` *minDistance* `(double minDistance)` Creates a geospatial criterion using the `$minDistance` operation, for use with $near.\n* `Criteria` *maxDistance* `(double maxDistance)` Creates a geospatial criterion using the `$maxDistance` operation, for use with $near.\n====\n\nThe `Query` class has some additional methods that allow to select certain fields as well as to limit and sort the result.\n\n[[mongodb-template-query.query]]\n.Methods of the Query class\n[%collapsible]\n====\n* `Query` *addCriteria* `(Criteria criteria)` used to add additional criteria to the query\n* `Field` *fields* `()` used to define fields to be included in the query results\n* `Query` *limit* `(int limit)` used to limit the size of the returned results to the provided limit (used for paging)\n* `Query` *skip* `(int skip)` used to skip the provided number of documents in the results (used for paging)\n* `Query` *with* `(Sort sort)` used to provide sort definition for the results\n* `Query` *with* `(ScrollPosition position)` used to provide a scroll position (Offset- or Keyset-based pagination) to start or resume a `Scroll`\n====\n\n[[mongo-template.query.result-projection]]\n\nThe template API allows direct usage of result projections that enable you to map queries against a given domain type while projecting the operation result onto another one as outlined below.\n\n[source,java]\n----\nclass\n\ntemplate.query(SWCharacter.class)\n .as(Jedi.class)\n----\n\nFor more information on result projections please refer to the xref:repositories/projections.adoc[Projections] section of the documentation.\n\n[[mongo-template.querying.field-selection]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Querying Documents in a Collection", "heading_level": 2, "file_order": 46, "section_index": 1, "content_hash": "3eb4229528193d646d0446d17bee21b45b19479961810f6bafce5aa14828b894", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:dcf10e2e6abfbdf67ae16e76b504855b434214f96e62ad8d9df0f93dec53ab38", "content": "MongoDB supports https://docs.mongodb.com/manual/tutorial/project-fields-from-query-results/[projecting fields] returned by a query.\nA projection can include and exclude fields (the `_id` field is always included unless explicitly excluded) based on their name.\n\n.Selecting result fields\n====\n[source,java]\n----\npublic class Person {\n\n @Id String id;\n String firstname;\n\n @Field(\"last_name\")\n String lastname;\n\n Address address;\n}\n\nquery.fields().include(\"lastname\"); <1>\n\nquery.fields().exclude(\"id\").include(\"lastname\") <2>\n\nquery.fields().include(\"address\") <3>\n\nquery.fields().include(\"address.city\") <4>\n----\n<1> Result will contain both `_id` and `last_name` via `{ \"last_name\" : 1 }`.\n<2> Result will only contain the `last_name` via `{ \"_id\" : 0, \"last_name\" : 1 }`.\n<3> Result will contain the `_id` and entire `address` object via `{ \"address\" : 1 }`.\n<4> Result will contain the `_id` and and `address` object that only contains the `city` field via `{ \"address.city\" : 1 }`.\n====\n\nStarting with MongoDB 4.4 you can use aggregation expressions for field projections as shown below:\n\n.Computing result fields using expressions\n====\n[source,java]\n----\nquery.fields()\n .project(MongoExpression.create(\"'$toUpper' : '$last_name'\")) <1>\n .as(\"last_name\"); <2>\n\nquery.fields()\n .project(StringOperators.valueOf(\"lastname\").toUpper()) <3>\n .as(\"last_name\");\n\nquery.fields()\n .project(AggregationSpELExpression.expressionOf(\"toUpper(lastname)\")) <4>\n .as(\"last_name\");\n----\n<1> Use a native expression. The used field name must refer to field names within the database document.\n<2> Assign the field name to which the expression result is projected. The resulting field name is not mapped against the domain model.\n<3> Use an `AggregationExpression`. Other than native `MongoExpression`, field names are mapped to the ones used in the domain model.\n<4> Use SpEL along with an `AggregationExpression` to invoke expression functions. Field names are mapped to the ones used in the domain model.\n====\n\n`@Query(fields=\"…\")` allows usage of expression field projections at `Repository` level as described in xref:mongodb/repositories/repositories.adoc#mongodb.repositories.queries.json-based[MongoDB JSON-based Query Methods and Field Restriction].\n\n[[mongo.query.additional-query-options]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Selecting fields", "heading_level": 2, "file_order": 46, "section_index": 2, "content_hash": "dcf10e2e6abfbdf67ae16e76b504855b434214f96e62ad8d9df0f93dec53ab38", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:342133011675bd13f7035468960c3dac82c3185913548ae4c1e9e20ff5c1de39", "content": "MongoDB offers various ways of applying meta information, like a comment or a batch size, to a query.Using the `Query` API\ndirectly there are several methods for those options.\n\n[[mongo.query.hints]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Additional Query Options", "heading_level": 2, "file_order": 46, "section_index": 3, "content_hash": "342133011675bd13f7035468960c3dac82c3185913548ae4c1e9e20ff5c1de39", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:45326d76b5bf06a90b3005da4ce542ba98908ecb1b0a9f80316ab75c95e44717", "content": "Index hints can be applied in two ways, using the index name or its field definition.\n\n====\n[source,java]\n----\ntemplate.query(Person.class)\n .matching(query(\"...\").withHint(\"index-to-use\"));\n\ntemplate.query(Person.class)\n .matching(query(\"...\").withHint(\"{ firstname : 1 }\"));\n----\n====\n\n[[mongo.query.cursor-size]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Hints", "heading_level": 3, "file_order": 46, "section_index": 4, "content_hash": "45326d76b5bf06a90b3005da4ce542ba98908ecb1b0a9f80316ab75c95e44717", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:b66837917e8b2c415ccc8e64942e437684083240d45d2a7dd36c8f0975adb1c6", "content": "The cursor batch size defines the number of documents to return in each response batch.\n====\n[source,java]\n----\nQuery query = query(where(\"firstname\").is(\"luke\"))\n .cursorBatchSize(100)\n----\n====\n\n[[mongo.query.collation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Cursor Batch Size", "heading_level": 3, "file_order": 46, "section_index": 5, "content_hash": "b66837917e8b2c415ccc8e64942e437684083240d45d2a7dd36c8f0975adb1c6", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:0b6bbfffed6756788920defa3c36cbb983da27e886bd1d3dcbd7d60b97e33374", "content": "Using collations with collection operations is a matter of specifying a `Collation` instance in your query or operation options, as the following two examples show:\n\n====\n[source,java]\n----\nCollation collation = Collation.of(\"de\");\n\nQuery query = new Query(Criteria.where(\"firstName\").is(\"Amél\"))\n .collation(collation);\n\nList<Person> results = template.find(query, Person.class);\n----\n====\n\n[[mongo.query.read-preference]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Collations", "heading_level": 3, "file_order": 46, "section_index": 6, "content_hash": "0b6bbfffed6756788920defa3c36cbb983da27e886bd1d3dcbd7d60b97e33374", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:aceec85fda96f30aefdd944035e259ceee183f6fe7b8f3f9e898d1c27a8a0e35", "content": "The `ReadPreference` to use can be set directly on the `Query` object to be run as outlined below.\n\n====\n[source,java]\n----\ntemplate.find(Person.class)\n .matching(query(where(...)).withReadPreference(ReadPreference.secondary()))\n .all();\n----\n====\n\nNOTE: The preference set on the `Query` instance will supersede the default `ReadPreference` of `MongoTemplate`.\n\n[[mongo.query.comment]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Read Preference", "heading_level": 3, "file_order": 46, "section_index": 7, "content_hash": "aceec85fda96f30aefdd944035e259ceee183f6fe7b8f3f9e898d1c27a8a0e35", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:f22331ea3d0ae46de99b92e879d4361f14c22e57e78ca4e48a4fba60d525f152", "content": "Queries can be equipped with comments which makes them easier to look up in server logs.\n\n====\n[source,java]\n----\ntemplate.find(Person.class)\n .matching(query(where(...)).comment(\"Use the force luke!\"))\n .all();\n----\n====\n\n[[mongo-template.query.distinct]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Comments", "heading_level": 3, "file_order": 46, "section_index": 8, "content_hash": "f22331ea3d0ae46de99b92e879d4361f14c22e57e78ca4e48a4fba60d525f152", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:1e4c0ea150d27212c6ebce15950cf8e2cbf7655da1380dee96e78e7c3b0decee", "content": "MongoDB provides an operation to obtain distinct values for a single field by using a query from the resulting documents.\nResulting values are not required to have the same data type, nor is the feature limited to simple types.\nFor retrieval, the actual result type does matter for the sake of conversion and typing. The following example shows how to query for distinct values:\n\n.Retrieving distinct values\n====\n[source,java]\n----\ntemplate.query(Person.class) <1>\n .distinct(\"lastname\") <2>\n .all(); <3>\n----\n<1> Query the `Person` collection.\n<2> Select distinct values of the `lastname` field. The field name is mapped according to the domain types property declaration, taking potential `@Field` annotations into account.\n<3> Retrieve all distinct values as a `List` of `Object` (due to no explicit result type being specified).\n====\n\nRetrieving distinct values into a `Collection` of `Object` is the most flexible way, as it tries to determine the property value of the domain type and convert results to the desired type or mapping `Document` structures.\n\nSometimes, when all values of the desired field are fixed to a certain type, it is more convenient to directly obtain a correctly typed `Collection`, as shown in the following example:\n\n.Retrieving strongly typed distinct values\n====\n[source,java]\n----\ntemplate.query(Person.class) <1>\n .distinct(\"lastname\") <2>\n .as(String.class) <3>\n .all(); <4>\n----\n<1> Query the collection of `Person`.\n<2> Select distinct values of the `lastname` field. The fieldname is mapped according to the domain types property declaration, taking potential `@Field` annotations into account.\n<3> Retrieved values are converted into the desired target type -- in this case, `String`. It is also possible to map the values to a more complex type if the stored field contains a document.\n<4> Retrieve all distinct values as a `List` of `String`. If the type cannot be converted into the desired target type, this method throws a `DataAccessException`.\n====\n\n[[mongo.geospatial]]\n+= GeoSpatial Queries\n\nMongoDB supports GeoSpatial queries through the use of operators such as `$near`, `$within`, `geoWithin`, and `$nearSphere`. Methods specific to geospatial queries are available on the `Criteria` class. There are also a few shape classes (`Box`, `Circle`, and `Point`) that are used in conjunction with geospatial related `Criteria` methods.\n\nNOTE: Using GeoSpatial queries requires attention when used within MongoDB transactions, see xref:mongodb/client-session-transactions.adoc#mongo.transactions.behavior[Special behavior inside transactions].\n\nTo understand how to perform GeoSpatial queries, consider the following `Venue` class (taken from the integration tests and relying on the rich `MappingMongoConverter`):\n\n.Venue.java\n[%collapsible]\n====\n[source,java]\n----\n@Document(collection=\"newyork\")\npublic class Venue {\n\n @Id\n private String id;\n private String name;\n private double[] location;\n\n @PersistenceCreator\n Venue(String name, double[] location) {\n super();\n this.name = name;\n this.location = location;\n }\n\n public Venue(String name, double x, double y) {\n super();\n this.name = name;\n this.location = new double[] { x, y };\n }\n\n public String getName() {\n return name;\n }\n\n public double[] getLocation() {\n return location;\n }\n\n @Override\n public String toString() {\n return \"Venue [id=\" + id + \", name=\" + name + \", location=\"\n + Arrays.toString(location) + \"]\";\n }\n}\n----\n====\n\nTo find locations within a `Circle`, you can use the following query:\n\n[source,java]\n----\nCircle circle = new Circle(-73.99171, 40.738868, 0.01);\nList<Venue> venues =\n template.find(new Query(Criteria.where(\"location\").within(circle)), Venue.class);\n----\n\nTo find venues within a `Circle` using spherical coordinates, you can use the following query:\n\n[source,java]\n----\nCircle circle = new Circle(-73.99171, 40.738868, 0.003712240453784);\nList<Venue> venues =\n template.find(new Query(Criteria.where(\"location\").withinSphere(circle)), Venue.class);\n----\n\nTo find venues within a `Box`, you can use the following query:\n\n[source,java]\n----\nBox box = new Box(new Point(-73.99756, 40.73083), new Point(-73.988135, 40.741404));\nList<Venue> venues =\n template.find(new Query(Criteria.where(\"location\").within(box)), Venue.class);\n----\n\nTo find venues near a `Point`, you can use the following queries:\n\n[source,java]\n----\nPoint point = new Point(-73.99171, 40.738868);\nList<Venue> venues =\n template.find(new Query(Criteria.where(\"location\").near(point).maxDistance(0.01)), Venue.class);\n----\n\n[source,java]\n----\nPoint point = new Point(-73.99171, 40.738868);\nList<Venue> venues =\n template.find(new Query(Criteria.where(\"location\").near(point).minDistance(0.01).maxDistance(100)), Venue.class);\n----\n\nTo find venues near a `Point` using spherical coordinates, you can use the following query:\n\n[source,java]\n----\nPoint point = new Point(-73.99171, 40.738868);\nList<Venue> venues =\n template.find(new Query(\n Criteria.where(\"location\").nearSphere(point).maxDistance(0.003712240453784)),\n Venue.class);\n----\n\n[[mongo.geo-near]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Query Distinct Values", "heading_level": 2, "file_order": 46, "section_index": 9, "content_hash": "1e4c0ea150d27212c6ebce15950cf8e2cbf7655da1380dee96e78e7c3b0decee", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:5ce64c266c5024caaf533bb8c7f768a732af88ffc9329b5cf50b696ae9d1a941", "content": "[WARNING]\n====\n*Changed in 2.2!* +\nhttps://docs.mongodb.com/master/release-notes/4.2-compatibility/[MongoDB 4.2] removed support for the\n`geoNear` command which had been previously used to run the `NearQuery`.\n\nSpring Data MongoDB 2.2 `MongoOperations#geoNear` uses the `$geoNear` https://docs.mongodb.com/manual/reference/operator/aggregation/geoNear/[aggregation]\ninstead of the `geoNear` command to run a `NearQuery`.\n\nThe calculated distance (the `dis` when using a geoNear command) previously returned within a wrapper type now is embedded\ninto the resulting document.\nIf the given domain type already contains a property with that name, the calculated distance\nis named `calculated-distance` with a potentially random postfix.\n\nTarget types may contain a property named after the returned distance to (additionally) read it back directly into the domain type as shown below.\n\n[source,java]\n----\nGeoResults<VenueWithDistanceField> = template.query(Venue.class) <1>\n .as(VenueWithDistanceField.class) <2>\n .near(NearQuery.near(new GeoJsonPoint(-73.99, 40.73), KILOMETERS))\n .all();\n----\n<1> Domain type used to identify the target collection and potential query mapping.\n<2> Target type containing a `dis` field of type `Number`.\n====\n\nMongoDB supports querying the database for geo locations and calculating the distance from a given origin at the same time. With geo-near queries, you can express queries such as \"find all restaurants in the surrounding 10 miles\". To let you do so, `MongoOperations` provides `geoNear(…)` methods that take a `NearQuery` as an argument (as well as the already familiar entity type and collection), as shown in the following example:\n\n[source,java]\n----\nPoint location = new Point(-73.99171, 40.738868);\nNearQuery query = NearQuery.near(location).maxDistance(new Distance(10, Metrics.MILES));\n\nGeoResults<Restaurant> = operations.geoNear(query, Restaurant.class);\n----\n\nWe use the `NearQuery` builder API to set up a query to return all `Restaurant` instances surrounding the given `Point` out to 10 miles.\nThe `Metrics` enum used here actually implements an interface so that other metrics could be plugged into a distance as well.\nA `Metric` is backed by a multiplier to transform the distance value of the given metric into native distances.\nThe sample shown here would consider the 10 to be miles. Using one of the built-in metrics (miles and kilometers) automatically triggers the spherical flag to be set on the query.\nIf you want to avoid that, pass plain `double` values into `maxDistance(…)`.\nFor more information, see the Javadoc of javadoc:org.springframework.data.mongodb.core.query.NearQuery[] and `Distance`.\n\nThe geo-near operations return a `GeoResults` wrapper object that encapsulates `GeoResult` instances.\nWrapping `GeoResults` allows accessing the average distance of all results.\nA single `GeoResult` object carries the entity found plus its distance from the origin.\n\n[[mongo.geo-json]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Geo-near Queries", "heading_level": 2, "file_order": 46, "section_index": 10, "content_hash": "5ce64c266c5024caaf533bb8c7f768a732af88ffc9329b5cf50b696ae9d1a941", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:65b29d15acda048ee708ba5ea38e2ccc92c6f38738a489560c3e148422358b3b", "content": "MongoDB supports https://geojson.org/[GeoJSON] and simple (legacy) coordinate pairs for geospatial data. Those formats can both be used for storing as well as querying data. See the https://docs.mongodb.org/manual/core/2dsphere/#geospatial-indexes-store-geojson/[MongoDB manual on GeoJSON support] to learn about requirements and restrictions.\n\n[[mongo.geo-json.domain.classes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "GeoJSON Support", "heading_level": 2, "file_order": 46, "section_index": 11, "content_hash": "65b29d15acda048ee708ba5ea38e2ccc92c6f38738a489560c3e148422358b3b", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:d4a6561c444b15b0818c61b523fe730e468a08abc3528e110ceed3567a2440c1", "content": "Usage of https://geojson.org/[GeoJSON] types in domain classes is straightforward. The `org.springframework.data.mongodb.core.geo` package contains types such as `GeoJsonPoint`, `GeoJsonPolygon`, and others. These types are extend the existing `org.springframework.data.geo` types. The following example uses a javadoc:org.springframework.data.mongodb.core.geo.GeoJsonPoint[]:\n\n====\n[source,java]\n----\npublic class Store {\n\n\tString id;\n\n\t/**\n * { \"type\" : \"Point\", \"coordinates\" : [ x, y ] }\n */\n\tGeoJsonPoint location;\n}\n----\n====\n\n[TIP]\n====\nIf the `coordinates` of a GeoJSON object represent _latitude_ and _longitude_ pairs, the _longitude_ goes first followed by _latitude_. +\n`GeoJsonPoint` therefore treats `getX()` as _longitude_ and `getY()` as _latitude_.\n====\n\n[[mongo.geo-json.query-methods]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "GeoJSON Types in Domain Classes", "heading_level": 2, "file_order": 46, "section_index": 12, "content_hash": "d4a6561c444b15b0818c61b523fe730e468a08abc3528e110ceed3567a2440c1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:e4d24218ac84536c419b8d411301f6b0810611e90ba3099d589777ff43b70526", "content": "Using GeoJSON types as repository query parameters forces usage of the `$geometry` operator when creating the query, as the following example shows:\n\n====\n[source,java]\n----\npublic interface StoreRepository extends CrudRepository<Store, String> {\n\n\tList<Store> findByLocationWithin(Polygon polygon); <1>\n\n}\n\n/*\n * {\n * \"location\": {\n * \"$geoWithin\": {\n * \"$geometry\": {\n * \"type\": \"Polygon\",\n * \"coordinates\": [\n * [\n * [-73.992514,40.758934],\n * [-73.961138,40.760348],\n * [-73.991658,40.730006],\n * [-73.992514,40.758934]\n * ]\n * ]\n * }\n * }\n * }\n * }\n */\nrepo.findByLocationWithin( <2>\n new GeoJsonPolygon(\n new Point(-73.992514, 40.758934),\n new Point(-73.961138, 40.760348),\n new Point(-73.991658, 40.730006),\n new Point(-73.992514, 40.758934))); <3>\n\n/*\n * {\n * \"location\" : {\n * \"$geoWithin\" : {\n * \"$polygon\" : [ [-73.992514,40.758934] , [-73.961138,40.760348] , [-73.991658,40.730006] ]\n * }\n * }\n * }\n */\nrepo.findByLocationWithin( <4>\n new Polygon(\n new Point(-73.992514, 40.758934),\n new Point(-73.961138, 40.760348),\n new Point(-73.991658, 40.730006)));\n----\n<1> Repository method definition using the commons type allows calling it with both the GeoJSON and the legacy format.\n<2> Use GeoJSON type to make use of `$geometry` operator.\n<3> Note that GeoJSON polygons need to define a closed ring.\n<4> Use the legacy format `$polygon` operator.\n====\n\n[[mongo.geo-json.metrics]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "GeoJSON Types in Repository Query Methods", "heading_level": 2, "file_order": 46, "section_index": 13, "content_hash": "e4d24218ac84536c419b8d411301f6b0810611e90ba3099d589777ff43b70526", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:686a79ec0922f3cc141e74bf3b193f3cd61180ecb0fa96a7490c7304f3d28638", "content": "Then MongoDB `$geoNear` operator allows usage of a GeoJSON Point or legacy coordinate pairs.\n\n====\n[source,java]\n----\nNearQuery.near(new Point(-73.99171, 40.738868))\n----\n[source,json]\n----\n{\n \"$geoNear\": {\n //...\n \"near\": [-73.99171, 40.738868]\n }\n}\n----\n====\n====\n[source,java]\n----\nNearQuery.near(new GeoJsonPoint(-73.99171, 40.738868))\n----\n[source,json]\n----\n{\n \"$geoNear\": {\n //...\n \"near\": { \"type\": \"Point\", \"coordinates\": [-73.99171, 40.738868] }\n }\n}\n\n----\n====\n\nThough syntactically different the server is fine accepting both no matter what format the target Document within the collection\nis using.\n\nWARNING: There is a huge difference in the distance calculation. Using the legacy format operates\nupon _Radians_ on an Earth like sphere, whereas the GeoJSON format uses _Meters_.\n\nTo avoid a serious headache make sure to set the `Metric` to the desired unit of measure which ensures the\ndistance to be calculated correctly.\n\nIn other words:\n\n====\nAssume you've got 5 Documents like the ones below:\n[source,json]\n----\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a5\"),\n \"name\" : \"Penn Station\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.99408, 40.75057 ] }\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a6\"),\n \"name\" : \"10gen Office\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.99171, 40.738868 ] }\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a9\"),\n \"name\" : \"City Bakery \",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796aa\"),\n \"name\" : \"Splash Bar\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796ab\"),\n \"name\" : \"Momofuku Milk Bar\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.985839, 40.731698 ] }\n}\n----\n====\n\nFetching all Documents within a 400 Meter radius from `[-73.99171, 40.738868]` would look like this using\nGeoJSON:\n\n.GeoNear with GeoJSON\n====\n[source,json]\n----\n{\n \"$geoNear\": {\n \"maxDistance\": 400, <1>\n \"num\": 10,\n \"near\": { type: \"Point\", coordinates: [-73.99171, 40.738868] },\n \"spherical\":true, <2>\n \"key\": \"location\",\n \"distanceField\": \"distance\"\n }\n}\n----\nReturning the following 3 Documents:\n[source,json]\n----\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a6\"),\n \"name\" : \"10gen Office\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.99171, 40.738868 ] }\n \"distance\" : 0.0 <3>\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a9\"),\n \"name\" : \"City Bakery \",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n \"distance\" : 69.3582262492474 <3>\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796aa\"),\n \"name\" : \"Splash Bar\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n \"distance\" : 69.3582262492474 <3>\n}\n----\n<1> Maximum distance from center point in _Meters_.\n<2> GeoJSON always operates upon a sphere.\n<3> Distance from center point in _Meters_.\n====\n\nNow, when using legacy coordinate pairs one operates upon _Radians_ as discussed before. So we use `Metrics#KILOMETERS\nwhen constructing the `$geoNear` command. The `Metric` makes sure the distance multiplier is set correctly.\n\n.GeoNear with Legacy Coordinate Pairs\n====\n[source,json]\n----\n{\n \"$geoNear\": {\n \"maxDistance\": 0.0000627142377, <1>\n \"distanceMultiplier\": 6378.137, <2>\n \"num\": 10,\n \"near\": [-73.99171, 40.738868],\n \"spherical\":true, <3>\n \"key\": \"location\",\n \"distanceField\": \"distance\"\n }\n}\n----\nReturning the 3 Documents just like the GeoJSON variant:\n[source,json]\n----\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a6\"),\n \"name\" : \"10gen Office\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.99171, 40.738868 ] }\n \"distance\" : 0.0 <4>\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796a9\"),\n \"name\" : \"City Bakery \",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n \"distance\" : 0.0693586286032982 <4>\n}\n{\n \"_id\" : ObjectId(\"5c10f3735d38908db52796aa\"),\n \"name\" : \"Splash Bar\",\n \"location\" : { \"type\" : \"Point\", \"coordinates\" : [ -73.992491, 40.738673 ] }\n \"distance\" : 0.0693586286032982 <4>\n}\n----\n<1> Maximum distance from center point in _Radians_.\n<2> The distance multiplier so we get _Kilometers_ as resulting distance.\n<3> Make sure we operate on a 2d_sphere index.\n<4> Distance from center point in _Kilometers_ - take it times 1000 to match _Meters_ of the GeoJSON variant.\n====\n\n[[mongo.textsearch]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Metrics and Distance calculation", "heading_level": 2, "file_order": 46, "section_index": 14, "content_hash": "686a79ec0922f3cc141e74bf3b193f3cd61180ecb0fa96a7490c7304f3d28638", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:a75c8b0c78863d8baf15339b3a4a3d47daf878f15429b9386b5bd9f35b101330", "content": "Since version 2.6 of MongoDB, you can run full-text queries by using the `$text` operator. Methods and operations specific to full-text queries are available in `TextQuery` and `TextCriteria`. When doing full text search, see the https://docs.mongodb.org/manual/reference/operator/query/text/#behavior[MongoDB reference] for its behavior and limitations.\n\nBefore you can actually use full-text search, you must set up the search index correctly.\nSee xref:mongodb/mapping/mapping.adoc#mapping-usage-indexes.text-index[Text Index] for more detail on how to create index structures.\nThe following example shows how to set up a full-text search:\n\n[source,javascript]\n----\ndb.foo.createIndex(\n{\n title : \"text\",\n content : \"text\"\n},\n{\n weights : {\n title : 3\n }\n}\n)\n----\n\nA query searching for `coffee cake` can be defined and run as follows:\n\n.Full Text Query\n====\n[source,java]\n----\nQuery query = TextQuery\n .queryText(new TextCriteria().matchingAny(\"coffee\", \"cake\"));\n\nList<Document> page = template.find(query, Document.class);\n----\n====\n\nTo sort results by relevance according to the `weights` use `TextQuery.sortByScore`.\n\n.Full Text Query - Sort by Score\n====\n[source,java]\n----\nQuery query = TextQuery\n .queryText(new TextCriteria().matchingAny(\"coffee\", \"cake\"))\n .sortByScore() <1>\n .includeScore(); <2>\n\nList<Document> page = template.find(query, Document.class);\n----\n<1> Use the score property for sorting results by relevance which triggers `.sort({'score': {'$meta': 'textScore'}})`.\n<2> Use `TextQuery.includeScore()` to include the calculated relevance in the resulting `Document`.\n====\n\nYou can exclude search terms by prefixing the term with `-` or by using `notMatching`, as shown in the following example (note that the two lines have the same effect and are thus redundant):\n\n[source,java]\n----\nTextQuery.queryText(new TextCriteria().matching(\"coffee\").matching(\"-cake\"));\nTextQuery.queryText(new TextCriteria().matching(\"coffee\").notMatching(\"cake\"));\n----\n\n`TextCriteria.matching` takes the provided term as is.\nTherefore, you can define phrases by putting them between double quotation marks (for example, `\\\"coffee cake\\\")` or using by `TextCriteria.phrase.`\nThe following example shows both ways of defining a phrase:\n\n[source,java]\n----\nTextQuery.queryText(new TextCriteria().matching(\"\\\"coffee cake\\\"\"));\nTextQuery.queryText(new TextCriteria().phrase(\"coffee cake\"));\n----\n\nYou can set flags for `$caseSensitive` and `$diacriticSensitive` by using the corresponding methods on `TextCriteria`.\nNote that these two optional flags have been introduced in MongoDB 3.2 and are not included in the query unless explicitly set.\n\n[[mongo.query-by-example]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Full-text Search", "heading_level": 2, "file_order": 46, "section_index": 15, "content_hash": "a75c8b0c78863d8baf15339b3a4a3d47daf878f15429b9386b5bd9f35b101330", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:999131104de71bcdef0d5c52ada73d1f1dbb957264d48d954ef762bf7bd3602f", "content": "xref:mongodb/repositories/query-methods.adoc#query-by-example[Query by Example] can be used on the Template API level run example queries.\n\nThe following snipped shows how to query by example:\n\n.Typed Example Query\n[source,java]\n----\nPerson probe = new Person();\nprobe.lastname = \"stark\";\n\nExample example = Example.of(probe);\n\nQuery query = new Query(new Criteria().alike(example));\nList<Person> result = template.find(query, Person.class);\n----\n\nBy default `Example` is strictly typed. This means that the mapped query has an included type match, restricting it to probe assignable types.\nFor example, when sticking with the default type key (`_class`), the query has restrictions such as (`_class : { $in : [ com.acme.Person] }`).\n\nBy using the `UntypedExampleMatcher`, it is possible to bypass the default behavior and skip the type restriction. So, as long as field names match, nearly any domain type can be used as the probe for creating the reference, as the following example shows:\n\n.Untyped Example Query\n====\n[source, java]\n----\n\nclass JustAnArbitraryClassWithMatchingFieldName {\n @Field(\"lastname\") String value;\n}\n\nJustAnArbitraryClassWithMatchingFieldNames probe = new JustAnArbitraryClassWithMatchingFieldNames();\nprobe.value = \"stark\";\n\nExample example = Example.of(probe, UntypedExampleMatcher.matching());\n\nQuery query = new Query(new Criteria().alike(example));\nList<Person> result = template.find(query, Person.class);\n----\n====\n\n[NOTE]\n====\nWhen including `null` values in the `ExampleSpec`, Spring Data Mongo uses embedded document matching instead of dot notation property matching.\nDoing so forces exact document matching for all property values and the property order in the embedded document.\n====\n\n[NOTE]\n====\n`UntypedExampleMatcher` is likely the right choice for you if you are storing different entities within a single collection or opted out of writing type hints.\n\nAlso, keep in mind that using `@TypeAlias` requires eager initialization of the `MappingContext`. To do so, configure `initialEntitySet` to to ensure proper alias resolution for read operations.\n====\n\nSpring Data MongoDB provides support for different matching options:\n\n.`StringMatcher` options\n[%collapsible]\n====\n[cols=\"1,2\", options=\"header\"]\n|===\n| Matching\n| Logical result\n\n| `DEFAULT` (case-sensitive)\n| `{\"firstname\" : firstname}`\n\n| `DEFAULT` (case-insensitive)\n| `{\"firstname\" : { $regex: firstname, $options: 'i'}}`\n\n| `EXACT` (case-sensitive)\n| `{\"firstname\" : { $regex: /^firstname$/}}`\n\n| `EXACT` (case-insensitive)\n| `{\"firstname\" : { $regex: /^firstname$/, $options: 'i'}}`\n\n| `STARTING` (case-sensitive)\n| `{\"firstname\" : { $regex: /^firstname/}}`\n\n| `STARTING` (case-insensitive)\n| `{\"firstname\" : { $regex: /^firstname/, $options: 'i'}}`\n\n| `ENDING` (case-sensitive)\n| `{\"firstname\" : { $regex: /firstname$/}}`\n\n| `ENDING` (case-insensitive)\n| `{\"firstname\" : { $regex: /firstname$/, $options: 'i'}}`\n\n| `CONTAINING` (case-sensitive)\n| `{\"firstname\" : { $regex: /.\\*firstname.*/}}`\n\n| `CONTAINING` (case-insensitive)\n| `{\"firstname\" : { $regex: /.\\*firstname.*/, $options: 'i'}}`\n\n| `REGEX` (case-sensitive)\n| `{\"firstname\" : { $regex: /firstname/}}`\n\n| `REGEX` (case-insensitive)\n| `{\"firstname\" : { $regex: /firstname/, $options: 'i'}}`\n\n|===\n====\n\n[[mongo.jsonSchema.query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Query by Example", "heading_level": 2, "file_order": 46, "section_index": 16, "content_hash": "999131104de71bcdef0d5c52ada73d1f1dbb957264d48d954ef762bf7bd3602f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:03f363fe56000940b436e52126229c71484578cb2171f101f9279e906fa5d5aa", "content": "You can use a schema to query any collection for documents that match a given structure defined by a JSON schema, as the following example shows:\n\n.Query for Documents matching a `$jsonSchema`\n====\n[source,java]\n----\nMongoJsonSchema schema = MongoJsonSchema.builder().required(\"firstname\", \"lastname\").build();\n\ntemplate.find(query(matchingDocumentStructure(schema)), Person.class);\n----\n====\n\nPlease refer to the xref:mongodb/mapping/mapping-schema.adoc[JSON Schema] section to learn more about the schema support in Spring Data MongoDB.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/template-query-operations.adoc", "title": "template-query-operations", "heading": "Query a collection for matching JSON Schema", "heading_level": 2, "file_order": 46, "section_index": 17, "content_hash": "03f363fe56000940b436e52126229c71484578cb2171f101f9279e906fa5d5aa", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/template-query-operations.adoc"}}
{"id": "sha256:a2f9509dfd2c32d3a8616e2e042c1c3d553f244456720de793748b7b19ababa5", "content": "include::{commons}@data-commons::page$value-expressions.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb/value-expressions.adoc", "title": "value-expressions", "heading": "value-expressions", "heading_level": 1, "file_order": 47, "section_index": 0, "content_hash": "a2f9509dfd2c32d3a8616e2e042c1c3d553f244456720de793748b7b19ababa5", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb/value-expressions.adoc"}}
{"id": "sha256:6f716313cd2ca967bf3b7158766dc615f08c2fc96f066561f060f9342d6cf044", "content": "[[observability-conventions]]\n\nBelow you can find a list of all `GlobalObservationConvention` and `ObservationConvention` declared by this project.\n\n.ObservationConvention implementations\n|===\n|ObservationConvention Class Name | Applicable ObservationContext Class Name\n|`org.springframework.data.mongodb.observability.DefaultMongoHandlerObservationConvention`|`MongoHandlerContext`\n|`org.springframework.data.mongodb.observability.MongoHandlerObservationConvention`|`MongoHandlerContext`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/conventions.adoc", "title": "conventions", "heading": "conventions", "heading_level": 1, "file_order": 48, "section_index": 0, "content_hash": "6f716313cd2ca967bf3b7158766dc615f08c2fc96f066561f060f9342d6cf044", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/conventions.adoc"}}
{"id": "sha256:4feb8299ae4e8d84a034725ffd797abed6e2853103ef97ff86aa091102d866dd", "content": "[[observability-metrics]]\n\nBelow you can find a list of all metrics declared by this project.\n\n[[observability-metrics-mongodb-command-observation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/metrics.adoc", "title": "metrics", "heading": "metrics", "heading_level": 1, "file_order": 49, "section_index": 0, "content_hash": "4feb8299ae4e8d84a034725ffd797abed6e2853103ef97ff86aa091102d866dd", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/metrics.adoc"}}
{"id": "sha256:2fb9a88b9240822ee4dc61bec052d6e6175009cb8c8d764769dfe0ff17d62011", "content": "____\nTimer created around a MongoDB command execution.\n____\n\n**Metric name** `spring.data.mongodb.command`. **Type** `timer`.\n\n**Metric name** `spring.data.mongodb.command.active`. **Type** `long task timer`.\n\nIMPORTANT: KeyValues that are added after starting the Observation might be missing from the *.active metrics.\n\nIMPORTANT: Micrometer internally uses `nanoseconds` for the baseunit. However, each backend determines the actual baseunit. (i.e. Prometheus uses seconds)\n\nFully qualified name of the enclosing class `org.springframework.data.mongodb.observability.MongoObservation`.\n\n.Low cardinality Keys\n[cols=\"a,a\"]\n|===\n|Name | Description\n|`db.mongodb.collection` _(required)_|MongoDB collection name.\n|`db.name` _(required)_|MongoDB database name.\n|`db.operation` _(required)_|MongoDB command value.\n|`db.system` _(required)_|MongoDB database system.\n|`net.peer.name` _(required)_|Name of the database host.\n|`net.peer.port` _(required)_|Logical remote port number.\n|`net.sock.peer.addr` _(required)_|Mongo peer address.\n|`net.sock.peer.port` _(required)_|Mongo peer port.\n|`net.transport` _(required)_|Network transport.\n|`spring.data.mongodb.cluster_id` _(required)_|MongoDB cluster identifier.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/metrics.adoc", "title": "metrics", "heading": "Mongodb Command Observation", "heading_level": 2, "file_order": 49, "section_index": 1, "content_hash": "2fb9a88b9240822ee4dc61bec052d6e6175009cb8c8d764769dfe0ff17d62011", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/metrics.adoc"}}
{"id": "sha256:de0567b0f6adb27b5d18f6b74b576ec3351a3ef09dc588348d31c4e36bf7aac0", "content": "[[mongodb.observability]]\n\n[NOTE]\n====\nMongoDB Java Driver 5.7+ comes with observability directly built in.\nWe recommend switching to the driver native `ObservabilitySettings`, which can be configured as outlined below:\n[source,java]\n----\n@Bean\nMongoClientSettingsBuilderCustomizer mongoDbObservabilitySettings(ObservationRegistry registry) {\n return (clientSettingsBuilder) -> {\n clientSettingsBuilder.observabilitySettings(ObservabilitySettings.micrometerBuilder()\n .observationRegistry(observationRegistry)\n .build());\n };\n}\n----\nIn the light of driver native observability support, the types within the Spring Data provided _org.springframework.data.mongodb.observability_ package will not see further development and are subject to deprecation/removal in subsequent releases.\n====\n\nTo use Spring Data MongoDB's flavor of Observability you must:\n\n. opt into Spring Data MongoDB's configuration settings by customizing `MongoClientSettings` through either your `@SpringBootApplication` class or one of your configuration classes.\n+\n.Registering MongoDB Micrometer customizer setup\n====\n[source,java]\n----\n@Bean\nMongoClientSettingsBuilderCustomizer mongoMetricsSynchronousContextProvider(ObservationRegistry registry) {\n return (clientSettingsBuilder) -> {\n clientSettingsBuilder.contextProvider(ContextProviderFactory.create(registry))\n .addCommandListener(new MongoObservationCommandListener(registry));\n };\n}\n----\n====\n+\n. Your project must include *Spring Boot Actuator*.\n. Disable Spring Boot's autoconfigured MongoDB command listener and enable tracing manually by adding the following properties to your `application.properties`\n+\n.Custom settings to apply\n====\n[source]\n----\n# Disable Spring Boot's autoconfigured tracing\nmanagement.metrics.mongo.command.enabled=false\n# Enable it manually\nmanagement.tracing.enabled=true\n----\nBe sure to add any other relevant settings needed to configure the tracer you are using based upon Micrometer's reference documentation.\n====\n\nThis should do it! You are now running with Spring Data MongoDB's usage of Spring Observability's `Observation` API.\nSee also https://opentelemetry.io/docs/reference/specification/trace/semantic_conventions/database/#mongodb[OpenTelemetry Semantic Conventions] for further reference.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/observability.adoc", "title": "observability", "heading": "observability", "heading_level": 1, "file_order": 50, "section_index": 0, "content_hash": "de0567b0f6adb27b5d18f6b74b576ec3351a3ef09dc588348d31c4e36bf7aac0", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/observability.adoc"}}
{"id": "sha256:5d4a7f04f32ff50a84c7dc0ce6c911955b6b44bbd4258ec6d4deb478f6594b55", "content": "[[observability-spans]]\n\nBelow you can find a list of all spans declared by this project.\n\n[[observability-spans-mongodb-command-observation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/spans.adoc", "title": "spans", "heading": "spans", "heading_level": 1, "file_order": 51, "section_index": 0, "content_hash": "5d4a7f04f32ff50a84c7dc0ce6c911955b6b44bbd4258ec6d4deb478f6594b55", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/spans.adoc"}}
{"id": "sha256:e8e07f48f4ad87e6917fbbbc2cea74a37fab1cb1816b0ec1a7f495d905f084f8", "content": "> Timer created around a MongoDB command execution.\n\n**Span name** `spring.data.mongodb.command`.\n\nFully qualified name of the enclosing class `org.springframework.data.mongodb.observability.MongoObservation`.\n\n.Tag Keys\n|===\n|Name | Description\n|`db.mongodb.collection` _(required)_|MongoDB collection name.\n|`db.name` _(required)_|MongoDB database name.\n|`db.operation` _(required)_|MongoDB command value.\n|`db.system` _(required)_|MongoDB database system.\n|`net.peer.name` _(required)_|Name of the database host.\n|`net.peer.port` _(required)_|Logical remote port number.\n|`net.sock.peer.addr` _(required)_|Mongo peer address.\n|`net.sock.peer.port` _(required)_|Mongo peer port.\n|`net.transport` _(required)_|Network transport.\n|`spring.data.mongodb.cluster_id` _(required)_|MongoDB cluster identifier.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/observability/spans.adoc", "title": "spans", "heading": "Mongodb Command Observation Span", "heading_level": 2, "file_order": 51, "section_index": 1, "content_hash": "e8e07f48f4ad87e6917fbbbc2cea74a37fab1cb1816b0ec1a7f495d905f084f8", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/observability/spans.adoc"}}
{"id": "sha256:428de6c77121a512a9b98e2107e2132900685f6e491b627d36874700d2897038", "content": "include::{commons}@data-commons::page$repositories/core-concepts.adoc[]\n\n[[mongodb.entity-persistence.state-detection-strategies]]\ninclude::{commons}@data-commons::page$is-new-state-detection.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/core-concepts.adoc", "title": "core-concepts", "heading": "core-concepts", "heading_level": 1, "file_order": 52, "section_index": 0, "content_hash": "428de6c77121a512a9b98e2107e2132900685f6e491b627d36874700d2897038", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/core-concepts.adoc"}}
{"id": "sha256:81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "content": "include::{commons}@data-commons::page$repositories/core-domain-events.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/core-domain-events.adoc", "title": "core-domain-events", "heading": "core-domain-events", "heading_level": 1, "file_order": 53, "section_index": 0, "content_hash": "81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/core-domain-events.adoc"}}
{"id": "sha256:07d4718e8044ac8e0c79ef5c75307d7e40c77fdc7db24dfbea78bba85bffebe9", "content": "[[core.extensions]]\n\nThis section documents a set of Spring Data extensions that enable Spring Data usage in a variety of contexts.\nCurrently, most of the integration is targeted towards Spring MVC.\n\ninclude::{commons}@data-commons::page$repositories/core-extensions-querydsl.adoc[leveloffset=1]\n\n[[mongodb.repositories.queries.type-safe]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/core-extensions.adoc", "title": "core-extensions", "heading": "core-extensions", "heading_level": 1, "file_order": 54, "section_index": 0, "content_hash": "07d4718e8044ac8e0c79ef5c75307d7e40c77fdc7db24dfbea78bba85bffebe9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/core-extensions.adoc"}}
{"id": "sha256:f6ed4b68ae95535c22e0ad6837c85644a2bf8986d34b0e965f9f774a9a5c78ee", "content": "MongoDB repository and its reactive counterpart integrates with the http://www.querydsl.com/[Querydsl] project, which provides a way to perform type-safe queries.\n\n[quote,Querydsl Team]\nInstead of writing queries as inline strings or externalizing them into XML files they are constructed via a fluent API.\n\nIt provides the following features:\n\n* Code completion in the IDE (all properties, methods, and operations can be expanded in your favorite Java IDE).\n* Almost no syntactically invalid queries allowed (type-safe on all levels).\n* Domain types and properties can be referenced safely -- no strings involved!\n* Adapts better to refactoring changes in domain types.\n* Incremental query definition is easier.\n\nSee the http://www.querydsl.com/static/querydsl/latest/reference/html/[Querydsl documentation] for how to bootstrap your environment for APT-based code generation using Maven or Ant.\n\nQueryDSL lets you write queries such as the following:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\nQPerson person = QPerson.person;\nList<Person> result = repository.findAll(person.address.zipCode.eq(\"C0123\"));\n\nPage<Person> page = repository.findAll(person.lastname.contains(\"a\"),\n PageRequest.of(0, 2, Direction.ASC, \"lastname\"));\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\nQPerson person = QPerson.person;\n\nFlux<Person> result = repository.findAll(person.address.zipCode.eq(\"C0123\"));\n----\n======\n\n`QPerson` is a class that is generated by the Java annotation processor.\nSee xref:#mongodb.repositories.queries.type-safe.apt[Setting up Annotation Processing] for how to set up Annotation Processing with your Build System.\nIt is a `Predicate` that lets you write type-safe queries.\nNotice that there are no strings in the query other than the `C0123` value.\n\nYou can use the generated `Predicate` class by using the `QuerydslPredicateExecutor` / `ReactiveQuerydslPredicateExecutor` interface, which the following listing shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\npublic interface QuerydslPredicateExecutor<T> {\n\n Optional<T> findOne(Predicate predicate);\n\n List<T> findAll(Predicate predicate);\n\n List<T> findAll(Predicate predicate, Sort sort);\n\n List<T> findAll(Predicate predicate, OrderSpecifier<?>... orders);\n\n Page<T> findAll(Predicate predicate, Pageable pageable);\n\n List<T> findAll(OrderSpecifier<?>... orders);\n\n long count(Predicate predicate);\n\n boolean exists(Predicate predicate);\n\n <S extends T, R> R findBy(Predicate predicate, Function<FluentQuery.FetchableFluentQuery<S>, R> queryFunction);\n}\n----\n\nReactive::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ninterface ReactiveQuerydslPredicateExecutor<T> {\n\n Mono<T> findOne(Predicate predicate);\n\n Flux<T> findAll(Predicate predicate);\n\n Flux<T> findAll(Predicate predicate, Sort sort);\n\n Flux<T> findAll(Predicate predicate, OrderSpecifier<?>... orders);\n\n Flux<T> findAll(OrderSpecifier<?>... orders);\n\n Mono<Long> count(Predicate predicate);\n\n Mono<Boolean> exists(Predicate predicate);\n\n <S extends T, R, P extends Publisher<R>> P findBy(Predicate predicate,\n Function<FluentQuery.ReactiveFluentQuery<S>, P> queryFunction);\n}\n----\n======\n\nTo use this in your repository implementation, add it to the list of repository interfaces from which your interface inherits, as the following example shows:\n\n[tabs]\n======\nImperative::\n+\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\ninterface PersonRepository extends MongoRepository<Person, String>, QuerydslPredicateExecutor<Person> {\n\n // additional query methods go here\n}\n----\n\nReactive::\n+\n====\n[source,java,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\n\ninterface PersonRepository extends ReactiveMongoRepository<Person, String>, ReactiveQuerydslPredicateExecutor<Person> {\n\n // additional query methods go here\n}\n----\n\nNOTE: Please note that joins (DBRef's) are not supported with Reactive MongoDB support.\n====\n======\n\n[[mongodb.repositories.queries.type-safe.apt]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/core-extensions.adoc", "title": "core-extensions", "heading": "Type-safe Query Methods with Querydsl", "heading_level": 3, "file_order": 54, "section_index": 1, "content_hash": "f6ed4b68ae95535c22e0ad6837c85644a2bf8986d34b0e965f9f774a9a5c78ee", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/core-extensions.adoc"}}
{"id": "sha256:24bb8ca8167ad2502d884a67e208f0938b5908977c74bd2670bd715b1bc15241", "content": "To use Querydsl with Spring Data MongoDB, you need to set up annotation processing in your build system that generates the `Q` classes.\nWhile you could write the `Q` classes by hand, it is recommended to use the Querydsl annotation processor to generate them for you to keep your `Q` classes in sync with your domain model.\n\nSpring Data MongoDB ships with an annotation processor javadoc:org.springframework.data.mongodb.repository.support.MongoAnnotationProcessor[] that isn't registered by default.\nTypically, annotation processors are registered through Java's service loader via `META-INF/services/javax.annotation.processing.Processor` that also activates these once you have them on the class path.\nMost Spring Data users do not use Querydsl, so it does not make sense to require additional mandatory dependencies for projects that would not benefit from Querydsl.\nHence, you need to activate annotation processing in your build system.\n\nThe following example shows how to set up annotation processing by mentioning dependencies and compiler config changes in Maven and Gradle:\n\n[tabs]\n======\nMaven::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\",role=\"primary\"]\n----\n<dependencies>\n <dependency>\n <groupId>org.springframework.data</groupId>\n <artifactId>spring-data-mongodb</artifactId>\n </dependency>\n\n <dependency>\n <groupId>com.querydsl</groupId>\n <artifactId>querydsl-mongodb</artifactId>\n <version>${querydslVersion}</version>\n\n <!-- Recommended: Exclude the mongo-java-driver to avoid version conflicts -->\n <exclusions>\n <exclusion>\n <groupId>org.mongodb</groupId>\n <artifactId>mongo-java-driver</artifactId>\n </exclusion>\n </exclusions>\n </dependency>\n\n <dependency>\n <groupId>com.querydsl</groupId>\n <artifactId>querydsl-apt</artifactId>\n <version>${querydslVersion}</version>\n <classifier>jakarta</classifier>\n <scope>provided</scope>\n </dependency>\n</dependencies>\n\n<build>\n <plugins>\n <plugin>\n <groupId>org.apache.maven.plugins</groupId>\n <artifactId>maven-compiler-plugin</artifactId>\n <configuration>\n <annotationProcessors>\n <annotationProcessor>\n org.springframework.data.mongodb.repository.support.MongoAnnotationProcessor\n </annotationProcessor>\n </annotationProcessors>\n\n <!-- Recommended: Some IDE's might require this configuration to include generated sources for IDE usage -->\n <generatedTestSourcesDirectory>target/generated-test-sources</generatedTestSourcesDirectory>\n <generatedSourcesDirectory>target/generated-sources</generatedSourcesDirectory>\n </configuration>\n </plugin>\n </plugins>\n</build>\n----\n\nGradle::\n+\n====\n[source,groovy,indent=0,subs=\"verbatim,quotes\",role=\"secondary\"]\n----\ndependencies {\n implementation 'com.querydsl:querydsl-mongodb:${querydslVersion}'\n\n annotationProcessor 'com.querydsl:querydsl-apt:${querydslVersion}:jakarta'\n annotationProcessor 'org.springframework.data:spring-data-mongodb'\n\n testAnnotationProcessor 'com.querydsl:querydsl-apt:${querydslVersion}:jakarta'\n testAnnotationProcessor 'org.springframework.data:spring-data-mongodb'\n}\n\ntasks.withType(JavaCompile).configureEach {\n options.compilerArgs += [\n \"-processor\",\n \"org.springframework.data.mongodb.repository.support.MongoAnnotationProcessor\"]\n}\n----\n====\n======\n\nNote that the setup above shows the simplest usage omitting any other options or dependencies that your project might require.\nThis way of configuring annotation processing disables Java's annotation processor scanning because MongoDB requires specifying `-processor` by class name.\nIf you're using other annotation processors, you need to add them to the list of `-processor`/`annotationProcessors` as well.\n\ninclude::{commons}@data-commons::page$repositories/core-extensions-web.adoc[leveloffset=1]\n\ninclude::{commons}@data-commons::page$repositories/core-extensions-populators.adoc[leveloffset=1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/core-extensions.adoc", "title": "core-extensions", "heading": "Setting up Annotation Processing", "heading_level": 3, "file_order": 54, "section_index": 2, "content_hash": "24bb8ca8167ad2502d884a67e208f0938b5908977c74bd2670bd715b1bc15241", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/core-extensions.adoc"}}
{"id": "sha256:bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "content": "include::{commons}@data-commons::page$repositories/create-instances.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/create-instances.adoc", "title": "create-instances", "heading": "create-instances", "heading_level": 1, "file_order": 55, "section_index": 0, "content_hash": "bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/create-instances.adoc"}}
{"id": "sha256:bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "content": "include::{commons}@data-commons::page$repositories/custom-implementations.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/custom-implementations.adoc", "title": "custom-implementations", "heading": "custom-implementations", "heading_level": 1, "file_order": 56, "section_index": 0, "content_hash": "bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/custom-implementations.adoc"}}
{"id": "sha256:661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "content": "include::{commons}@data-commons::page$repositories/definition.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/definition.adoc", "title": "definition", "heading": "definition", "heading_level": 1, "file_order": 57, "section_index": 0, "content_hash": "661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/definition.adoc"}}
{"id": "sha256:8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "content": "include::{commons}@data-commons::page$repositories/null-handling.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/null-handling.adoc", "title": "null-handling", "heading": "null-handling", "heading_level": 1, "file_order": 58, "section_index": 0, "content_hash": "8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/null-handling.adoc"}}
{"id": "sha256:b1ab502dfbb4de90badfd51ab0e14c133bcd5da94da7c060695bf8c92dfb3132", "content": "[[mongodb.projections]]\ninclude::{commons}@data-commons::page$repositories/projections.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/projections.adoc", "title": "projections", "heading": "projections", "heading_level": 1, "file_order": 59, "section_index": 0, "content_hash": "b1ab502dfbb4de90badfd51ab0e14c133bcd5da94da7c060695bf8c92dfb3132", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/projections.adoc"}}
{"id": "sha256:9322ad3383c4d0a0b4198931ed5c4d6a7224c6a0034cba94c192e0057ec96c02", "content": "include::{commons}@data-commons::query-by-example.adoc[]\n\n[[query-by-example.running]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/query-by-example.adoc", "title": "query-by-example", "heading": "query-by-example", "heading_level": 1, "file_order": 60, "section_index": 0, "content_hash": "9322ad3383c4d0a0b4198931ed5c4d6a7224c6a0034cba94c192e0057ec96c02", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/query-by-example.adoc"}}
{"id": "sha256:4f11ae00b5c9ef3673874b33828834ff51a26b0d6fe3d2dcf5c214b6c78223f0", "content": "The following example shows how to query by example when using a repository (of `Person` objects, in this case):\n\n.Query by Example using a repository\n====\n[source, java]\n----\npublic interface PersonRepository extends QueryByExampleExecutor<Person> {\n\n}\n\npublic class PersonService {\n\n @Autowired PersonRepository personRepository;\n\n public List<Person> findPeople(Person probe) {\n return personRepository.findAll(Example.of(probe));\n }\n}\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/query-by-example.adoc", "title": "query-by-example", "heading": "Running an Example", "heading_level": 2, "file_order": 60, "section_index": 1, "content_hash": "4f11ae00b5c9ef3673874b33828834ff51a26b0d6fe3d2dcf5c214b6c78223f0", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/query-by-example.adoc"}}
{"id": "sha256:7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "content": "include::{commons}@data-commons::page$repositories/query-keywords-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc", "title": "query-keywords-reference", "heading": "query-keywords-reference", "heading_level": 1, "file_order": 61, "section_index": 0, "content_hash": "7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc"}}
{"id": "sha256:2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "content": "include::{commons}@data-commons::page$repositories/query-methods-details.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/query-methods-details.adoc", "title": "query-methods-details", "heading": "query-methods-details", "heading_level": 1, "file_order": 62, "section_index": 0, "content_hash": "2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/query-methods-details.adoc"}}
{"id": "sha256:8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "content": "include::{commons}@data-commons::page$repositories/query-return-types-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc", "title": "query-return-types-reference", "heading": "query-return-types-reference", "heading_level": 1, "file_order": 63, "section_index": 0, "content_hash": "8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc"}}
{"id": "sha256:a4a587c275b84271f8ed24b683f16d5630c9d82edd577d43e53ede40025e2bf1", "content": "[[spring-data-mongodb-reference-documentation]]\n\n_Spring Data MongoDB provides support for the MongoDB database.\nIt uses familiar Spring concepts such as a template classes for core API usage and lightweight repository style data access to ease development of applications with a consistent programming model._\n\n[horizontal]\nxref:mongodb.adoc[MongoDB] :: MongoDB support and connectivity\nxref:repositories.adoc[Repositories] :: Mongo Repositories\nxref:observability/observability.adoc[Observability] :: Observability Integration\nxref:kotlin.adoc[Kotlin] :: Kotlin support\nhttps://github.com/spring-projects/spring-data-commons/wiki[Wiki] :: What's New, Upgrade Notes, Supported Versions, additional cross-version information.\n\nMark Pollack; Thomas Risberg; Oliver Gierke; Costin Leau; Jon Brisbin; Thomas Darimont; Christoph Strobl; Mark Paluch; Jay Bryant\n\n(C) 2008-{copyright-year} VMware Inc.\n\nCopies of this document may be made for your own use and for distribution to others, provided that you do not charge any fee for such copies and further provided that each copy contains this Copyright Notice, whether distributed in print or electronically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 64, "section_index": 0, "content_hash": "a4a587c275b84271f8ed24b683f16d5630c9d82edd577d43e53ede40025e2bf1", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/index.adoc"}}
{"id": "sha256:7ea6ef941532b479cba6ee5ca2f2f8dafc3373a9e29b7a6348efb81ee0c2cde3", "content": "include::{commons}@data-commons::page$kotlin.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/kotlin.adoc", "title": "kotlin", "heading": "kotlin", "heading_level": 1, "file_order": 65, "section_index": 0, "content_hash": "7ea6ef941532b479cba6ee5ca2f2f8dafc3373a9e29b7a6348efb81ee0c2cde3", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/kotlin.adoc"}}
{"id": "sha256:e38ff286eb17875a7a40d00528b9b2f6b3323431267dd0830c57c555e64973c9", "content": "[[mongodb.migration]]\n\nThis section contains version-specific migration guides explaining how to upgrade between two versions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/migration-guides.adoc", "title": "migration-guides", "heading": "migration-guides", "heading_level": 1, "file_order": 66, "section_index": 0, "content_hash": "e38ff286eb17875a7a40d00528b9b2f6b3323431267dd0830c57c555e64973c9", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/migration-guides.adoc"}}
{"id": "sha256:3d3c3c2654671c9960f0e8298238025b7c43b3353870a443fc6a33f3f3e5e86a", "content": "[[mongodb.core]]\n\nSpring Data support for MongoDB contains a wide range of features:\n\n* xref:mongodb/template-config.adoc[Spring configuration support] with Java-based `@Configuration` classes or an XML namespace for a Mongo driver instance and replica sets.\n* xref:mongodb/template-api.adoc[`MongoTemplate` helper class] that increases productivity when performing common Mongo operations.\nIncludes integrated object mapping between documents and POJOs.\n* xref:mongodb/template-api.adoc#mongo-template.exception-translation[Exception translation] into Spring's portable Data Access Exception hierarchy.\n* Feature-rich xref:mongodb/mapping/mapping.adoc[Object Mapping] integrated with Spring's Conversion Service.\n* xref:mongodb/mapping/mapping.adoc#mapping-usage-annotations[Annotation-based mapping metadata] that is extensible to support other metadata formats.\n* xref:mongodb/lifecycle-events.adoc[Persistence and mapping lifecycle events].\n* xref:mongodb/template-query-operations.adoc[Java-based Query, Criteria, and Update DSLs].\n* Automatic implementation of xref:repositories.adoc[Repository interfaces], including support for custom query methods.\n* xref:repositories/core-extensions.adoc#mongodb.repositories.queries.type-safe[QueryDSL integration] to support type-safe queries.\n* xref:mongodb/client-session-transactions.adoc[Multi-Document Transactions].\n* xref:mongodb/template-query-operations.adoc#mongo.geo-json[GeoSpatial integration].\n* xref:mongodb/mongo-search-indexes.adoc#mongo.search.vector[Vector Index] and declarative xref:mongodb/repositories/vector-search.adoc[Vector Search] support.\n* xref:mongodb/aot.adoc[Ahead Of Time (AOT)] optimizations.\n\nFor most tasks, you should use `MongoTemplate` or the Repository support, which both leverage the rich mapping functionality.\n`MongoTemplate` is the place to look for accessing functionality such as incrementing counters or ad-hoc CRUD operations.\n`MongoTemplate` also provides callback methods so that it is easy for you to get the low-level API artifacts, such as `com.mongodb.client.MongoDatabase`, to communicate directly with MongoDB.\nThe goal with naming conventions on various API artifacts is to copy those in the base MongoDB Java driver so you can easily map your existing knowledge onto the Spring APIs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/mongodb.adoc", "title": "mongodb", "heading": "mongodb", "heading_level": 1, "file_order": 67, "section_index": 0, "content_hash": "3d3c3c2654671c9960f0e8298238025b7c43b3353870a443fc6a33f3f3e5e86a", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/mongodb.adoc"}}
{"id": "sha256:43f17af2c49cc7df968f964ef98d085dc37381828a8904728ed1f580349c7994", "content": "[[requirements]]\n\nThe Spring Data MongoDB 5.x binaries require JDK level 17 and above and https://spring.io/docs[Spring Framework] {springVersion} and above.\n\n[[compatibility.matrix]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "preface", "heading_level": 1, "file_order": 68, "section_index": 0, "content_hash": "43f17af2c49cc7df968f964ef98d085dc37381828a8904728ed1f580349c7994", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:819a2360ca2ef07fd6996ff1629d9a9d87b0a26e2c317eab3d4f226b3e2ca74f", "content": "[TIP]\n====\nPlease visit https://spring.io/projects/spring-data-mongodb#support[OSS Support] for detailed Spring Data support timelines. +\nFor the MongoDB Server Support Policy please refer to the https://www.mongodb.com/legal/support-policy/lifecycles[MongoDB Software Lifecycle Schedule].\n====\n\nThe following compatibility matrix summarizes Spring Data versions and their required minimum MongoDB client version.\nDatabase versions show server generations that pass the Spring Data test suite, older server versions might have difficulties dealing with new/changed commands.\nYou may use newer server versions unless your application uses functionality that is affected by xref:preface.adoc#compatibility.changes[changes in the MongoDB server].\nSee also the https://www.mongodb.com/docs/drivers/java/sync/current/compatibility/[official MongoDB driver compatibility matrix] for driver- and server version compatibility.\n\n====\n[cols=\"h,m,m,m\", options=\"header\"]\n|===\n\n|Spring Data Release Train\n|Spring Data MongoDB\n|Minimum Driver Version\n|Tested Database Versions\n\n|2026.0\n|5.1.x\n|5.6.x\n|6.x to 8.x\n\n|2025.1\n|5.0.x\n|5.6.x\n|6.x to 8.x\n\n|2025.0\n|4.5.x\n|5.5.x\n|6.x to 8.x\n\n|2024.1\n|4.4.x\n|5.2.x\n|4.4.x to 8.x\n\n|2024.0\n|4.3.x\n|4.11.x & 5.x\n|4.4.x to 7.x\n\n|===\n====\n\n[[compatibility.changes]]\n[[compatibility.changes-4.4]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Compatibility Matrix", "heading_level": 2, "file_order": 68, "section_index": 1, "content_hash": "819a2360ca2ef07fd6996ff1629d9a9d87b0a26e2c317eab3d4f226b3e2ca74f", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:ad6d6a70e44bcdad35b46c75fe095ad64e46308ef73af314e9118f09adb79f76", "content": "* Fields list must not contain text search score property when no `$text` criteria present. See also https://docs.mongodb.com/manual/reference/operator/query/text/[`$text` operator]\n* Sort must not be an empty document when running map reduce.\n\n[[compatibility.changes-4.2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Relevant Changes in MongoDB 4.4", "heading_level": 3, "file_order": 68, "section_index": 2, "content_hash": "ad6d6a70e44bcdad35b46c75fe095ad64e46308ef73af314e9118f09adb79f76", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:aba981f774bb831c66f19284902784d2aa727d2c66612054667c8e97191ff630", "content": "* Removal of `geoNear` command. See also https://docs.mongodb.com/manual/release-notes/4.2-compatibility/#remove-support-for-the-geonear-command[Removal of `geoNear`]\n* Removal of `eval` command. See also https://docs.mongodb.com/manual/release-notes/4.2-compatibility/#remove-support-for-the-eval-command[Removal of `eval`]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/preface.adoc", "title": "preface", "heading": "Relevant Changes in MongoDB 4.2", "heading_level": 3, "file_order": 68, "section_index": 3, "content_hash": "aba981f774bb831c66f19284902784d2aa727d2c66612054667c8e97191ff630", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/preface.adoc"}}
{"id": "sha256:fddd614948eb9c384fb320c1c63d12883214d5153cf1b0d399fde8cc5900be23", "content": "[[mongodb.repositories]]\n\nThis chapter explains the basic foundations of Spring Data repositories and MongoDB specifics.\nBefore continuing to the MongoDB specifics, make sure you have a sound understanding of the basic concepts.\n\nThe goal of the Spring Data repository abstraction is to significantly reduce the amount of boilerplate code required to implement data access layers for various persistence stores.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-mongodb", "path": "antora/modules/ROOT/pages/repositories.adoc", "title": "repositories", "heading": "repositories", "heading_level": 1, "file_order": 69, "section_index": 0, "content_hash": "fddd614948eb9c384fb320c1c63d12883214d5153cf1b0d399fde8cc5900be23", "source_url": "https://github.com/spring-projects/spring-data-mongodb/blob/9d10a5fb14ba4d7402367c7f89816fb26d6c0c66/src/main/antora/modules/ROOT/pages/repositories.adoc"}}
