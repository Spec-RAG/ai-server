{"id": "sha256:ca2c4df7ea67fbe0a0c3f458704b2e55bdfdd16d393ed83abb977f3a384f4e34", "content": "ElevenLabs provides natural-sounding speech synthesis software using deep learning. Its AI audio models generate realistic, versatile, and contextually-aware speech, voices, and sound effects across 32 languages. The ElevenLabs Text-to-Speech API enables users to bring any book, article, PDF, newsletter, or text to life with ultra-realistic AI narration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Introduction", "heading_level": 2, "file_order": 0, "section_index": 0, "content_hash": "ca2c4df7ea67fbe0a0c3f458704b2e55bdfdd16d393ed83abb977f3a384f4e34", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:bc30e5bca3db0f48dd8fedd9ec1e94fd018fcc1e08c7900408319003bc81afd1", "content": ". Create an ElevenLabs account and obtain an API key. You can sign up at the https://elevenlabs.io/sign-up[ElevenLabs signup page]. Your API key can be found on your profile page after logging in.\n. Add the `spring-ai-elevenlabs` dependency to your project's build file. For more information, refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Prerequisites", "heading_level": 2, "file_order": 0, "section_index": 1, "content_hash": "bc30e5bca3db0f48dd8fedd9ec1e94fd018fcc1e08c7900408319003bc81afd1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:daeb14f647cad5287af523a64ac9791a6551c0ef9331c93724d7f593da29d206", "content": "Spring AI provides Spring Boot auto-configuration for the ElevenLabs Text-to-Speech Client.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-elevenlabs</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-elevenlabs'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Auto-configuration", "heading_level": 2, "file_order": 0, "section_index": 2, "content_hash": "daeb14f647cad5287af523a64ac9791a6551c0ef9331c93724d7f593da29d206", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:541279c926350f61597a47d4d41186baa099bd253e7baaf51c579a741525f3d5", "content": "The prefix `spring.ai.elevenlabs` is used as the property prefix for *all* ElevenLabs related configurations (both connection and TTS specific settings). This is defined in `ElevenLabsConnectionProperties`.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.elevenlabs.base-url | The base URL for the ElevenLabs API. | https://api.elevenlabs.io\n| spring.ai.elevenlabs.api-key | Your ElevenLabs API key. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Connection Properties", "heading_level": 3, "file_order": 0, "section_index": 3, "content_hash": "541279c926350f61597a47d4d41186baa099bd253e7baaf51c579a741525f3d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:55f894e771f1df990a6f39c7f5ad8f40f6d8af6b5adcb2693b0b685c0c2ed6d8", "content": "[NOTE]\n====\nEnabling and disabling of the audio speech auto-configurations are now configured via top level properties with the prefix `spring.ai.model.audio.speech`.\n\nTo enable, spring.ai.model.audio.speech=elevenlabs (It is enabled by default)\n\nTo disable, spring.ai.model.audio.speech=none (or any value which doesn't match elevenlabs)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.elevenlabs.tts` is used as the property prefix to configure the ElevenLabs Text-to-Speech client, specifically. This is defined in `ElevenLabsSpeechProperties`.\n\n[cols=\"3,5,2\"]\n|====\n| Property | Description | Default\n\n| spring.ai.model.audio.speech | Enable Audio Speech Model | elevenlabs\n| spring.ai.elevenlabs.tts.options.model-id | The ID of the model to use. | eleven_turbo_v2_5\n| spring.ai.elevenlabs.tts.options.voice-id | The ID of the voice to use. This is the *voice ID*, not the voice name. | 9BWtsMINqrJLrRacOk9x\n| spring.ai.elevenlabs.tts.options.output-format | The output format for the generated audio. See xref:#output-formats[Output Formats] below. | mp3_22050_32\n|====\n\nNOTE: The base URL and API key can also be configured *specifically* for TTS using `spring.ai.elevenlabs.tts.base-url` and `spring.ai.elevenlabs.tts.api-key`. However, it is generally recommended to use the global `spring.ai.elevenlabs` prefix for simplicity, unless you have a specific reason to use different credentials for different ElevenLabs services. The more specific `tts` properties will override the global ones.\n\nTIP: All properties prefixed with `spring.ai.elevenlabs.tts.options` can be overridden at runtime.\n\n[[output-formats]]\n.Available Output Formats\n[cols=\"1,1\"]\n|====\n| Enum Value | Description\n| MP3_22050_32 | MP3, 22.05 kHz, 32 kbps\n| MP3_44100_32 | MP3, 44.1 kHz, 32 kbps\n| MP3_44100_64 | MP3, 44.1 kHz, 64 kbps\n| MP3_44100_96 | MP3, 44.1 kHz, 96 kbps\n| MP3_44100_128 | MP3, 44.1 kHz, 128 kbps\n| MP3_44100_192 | MP3, 44.1 kHz, 192 kbps\n| PCM_8000 | PCM, 8 kHz\n| PCM_16000 | PCM, 16 kHz\n| PCM_22050 | PCM, 22.05 kHz\n| PCM_24000 | PCM, 24 kHz\n| PCM_44100 | PCM, 44.1 kHz\n| PCM_48000 | PCM, 48 kHz\n| ULAW_8000 | µ-law, 8 kHz\n| ALAW_8000 | A-law, 8 kHz\n| OPUS_48000_32 | Opus, 48 kHz, 32 kbps\n| OPUS_48000_64 | Opus, 48 kHz, 64 kbps\n| OPUS_48000_96 | Opus, 48 kHz, 96 kbps\n| OPUS_48000_128 | Opus, 48 kHz, 128 kbps\n| OPUS_48000_192 | Opus, 48 kHz, 192 kbps\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Configuration Properties", "heading_level": 3, "file_order": 0, "section_index": 4, "content_hash": "55f894e771f1df990a6f39c7f5ad8f40f6d8af6b5adcb2693b0b685c0c2ed6d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:249f3d1c04901c6ec19594ef2fd9d528e7518f82797086f600caa3c7ff68ca5e", "content": "The `ElevenLabsTextToSpeechOptions` class provides options to use when making a text-to-speech request. On start-up, the options specified by `spring.ai.elevenlabs.tts` are used, but you can override these at runtime. The following options are available:\n\n* `modelId`: The ID of the model to use.\n* `voiceId`: The ID of the voice to use.\n* `outputFormat`: The output format of the generated audio.\n* `voiceSettings`: An object containing voice settings such as `stability`, `similarityBoost`, `style`, `useSpeakerBoost`, and `speed`.\n* `enableLogging`: A boolean to enable or disable logging.\n* `languageCode`: The language code of the input text (e.g., \"en\" for English).\n* `pronunciationDictionaryLocators`: A list of pronunciation dictionary locators.\n* `seed`: A seed for random number generation, for reproducibility.\n* `previousText`: Text before the main text, for context in multi-turn conversations.\n* `nextText`: Text after the main text, for context in multi-turn conversations.\n* `previousRequestIds`: Request IDs from previous turns in a conversation.\n* `nextRequestIds`: Request IDs for subsequent turns in a conversation.\n* `applyTextNormalization`: Apply text normalization (\"auto\", \"on\", or \"off\").\n* `applyLanguageTextNormalization`: Apply language text normalization.\n\nFor example:\n\n[source,java]\n----\nElevenLabsTextToSpeechOptions speechOptions = ElevenLabsTextToSpeechOptions.builder()\n .model(\"eleven_multilingual_v2\")\n .voiceId(\"your_voice_id\")\n .outputFormat(ElevenLabsApi.OutputFormat.MP3_44100_128.getValue())\n .build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"Hello, this is a text-to-speech example.\", speechOptions);\nTextToSpeechResponse response = elevenLabsTextToSpeechModel.call(speechPrompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Runtime Options [[speech-options]]", "heading_level": 2, "file_order": 0, "section_index": 5, "content_hash": "249f3d1c04901c6ec19594ef2fd9d528e7518f82797086f600caa3c7ff68ca5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:b28663cbd2317167642ccd93b575a6c4511d453cf9e52795663c7a01caa5645f", "content": "You can customize the voice output by providing `VoiceSettings` in the options. This allows you to control properties like stability and similarity.\n\n[source,java]\n----\nvar voiceSettings = new ElevenLabsApi.SpeechRequest.VoiceSettings(0.75f, 0.75f, 0.0f, true);\n\nElevenLabsTextToSpeechOptions speechOptions = ElevenLabsTextToSpeechOptions.builder()\n .model(\"eleven_multilingual_v2\")\n .voiceId(\"your_voice_id\")\n .voiceSettings(voiceSettings)\n .build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"This is a test with custom voice settings!\", speechOptions);\nTextToSpeechResponse response = elevenLabsTextToSpeechModel.call(speechPrompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Using Voice Settings", "heading_level": 3, "file_order": 0, "section_index": 6, "content_hash": "b28663cbd2317167642ccd93b575a6c4511d453cf9e52795663c7a01caa5645f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:f8b9c155f2aabd0c0e969ca175a12ea4bc71af334bf95d5afbdf59ec6ee77839", "content": "Add the `spring-ai-elevenlabs` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-elevenlabs</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-elevenlabs'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `ElevenLabsTextToSpeechModel`:\n\n[source,java]\n----\nElevenLabsApi elevenLabsApi = ElevenLabsApi.builder()\n .apiKey(System.getenv(\"ELEVEN_LABS_API_KEY\"))\n .build();\n\nElevenLabsTextToSpeechModel elevenLabsTextToSpeechModel = ElevenLabsTextToSpeechModel.builder()\n\t.elevenLabsApi(elevenLabsApi)\n\t.defaultOptions(ElevenLabsTextToSpeechOptions.builder()\n .model(\"eleven_turbo_v2_5\")\n .voiceId(\"your_voice_id\") // e.g. \"9BWtsMINqrJLrRacOk9x\"\n .outputFormat(\"mp3_44100_128\")\n .build())\n\t.build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"Hello, this is a text-to-speech example.\");\nTextToSpeechResponse response = elevenLabsTextToSpeechModel.call(speechPrompt);\n\nbyte[] responseAsBytes = response.getResult().getOutput();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Manual Configuration", "heading_level": 2, "file_order": 0, "section_index": 7, "content_hash": "f8b9c155f2aabd0c0e969ca175a12ea4bc71af334bf95d5afbdf59ec6ee77839", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:23679eba282f981e5f31b7399010718e7d639e0335ff6875254506402eb9cacf", "content": "The ElevenLabs Speech API supports real-time audio streaming using chunk transfer encoding. This allows audio playback to begin before the entire audio file is generated.\n\n[source,java]\n----\nElevenLabsApi elevenLabsApi = ElevenLabsApi.builder()\n .apiKey(System.getenv(\"ELEVEN_LABS_API_KEY\"))\n .build();\n\nElevenLabsTextToSpeechModel elevenLabsTextToSpeechModel = ElevenLabsTextToSpeechModel.builder()\n\t.elevenLabsApi(elevenLabsApi)\n\t.build();\n\nElevenLabsTextToSpeechOptions streamingOptions = ElevenLabsTextToSpeechOptions.builder()\n .model(\"eleven_turbo_v2_5\")\n .voiceId(\"your_voice_id\")\n .outputFormat(\"mp3_44100_128\")\n .build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"Today is a wonderful day to build something people love!\", streamingOptions);\n\nFlux<TextToSpeechResponse> responseStream = elevenLabsTextToSpeechModel.stream(speechPrompt);\n\nresponseStream.subscribe(speechResponse -> {\n byte[] audioChunk = speechResponse.getResult().getOutput();\n // Play the audioChunk\n});\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Streaming Real-time Audio", "heading_level": 2, "file_order": 0, "section_index": 8, "content_hash": "23679eba282f981e5f31b7399010718e7d639e0335ff6875254506402eb9cacf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:377a1ecc98d709806c6772b2c6b5be46f48d1a84b1deb4bea2523e548938e2f9", "content": "The ElevenLabs Voices API allows you to retrieve information about available voices, their settings, and default voice settings. You can use this API to discover the `voiceId`s to use in your speech requests.\n\nTo use the Voices API, you'll need to create an instance of `ElevenLabsVoicesApi`:\n\n[source,java]\n----\nElevenLabsVoicesApi voicesApi = ElevenLabsVoicesApi.builder()\n .apiKey(System.getenv(\"ELEVEN_LABS_API_KEY\"))\n .build();\n----\n\nYou can then use the following methods:\n\n* `getVoices()`: Retrieves a list of all available voices.\n* `getDefaultVoiceSettings()`: Gets the default settings for voices.\n* `getVoiceSettings(String voiceId)`: Returns the settings for a specific voice.\n* `getVoice(String voiceId)`: Returns metadata about a specific voice.\n\nExample:\n\n[source,java]\n----\nResponseEntity<ElevenLabsVoicesApi.Voices> voicesResponse = voicesApi.getVoices();\nList<ElevenLabsVoicesApi.Voice> voices = voicesResponse.getBody().voices();\n\nResponseEntity<ElevenLabsVoicesApi.VoiceSettings> defaultSettingsResponse = voicesApi.getDefaultVoiceSettings();\nElevenLabsVoicesApi.VoiceSettings defaultSettings = defaultSettingsResponse.getBody();\n\nResponseEntity<ElevenLabsVoicesApi.VoiceSettings> voiceSettingsResponse = voicesApi.getVoiceSettings(voiceId);\nElevenLabsVoicesApi.VoiceSettings voiceSettings = voiceSettingsResponse.getBody();\n\nResponseEntity<ElevenLabsVoicesApi.Voice> voiceDetailsResponse = voicesApi.getVoice(voiceId);\nElevenLabsVoicesApi.Voice voiceDetails = voiceDetailsResponse.getBody();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Voices API", "heading_level": 2, "file_order": 0, "section_index": 9, "content_hash": "377a1ecc98d709806c6772b2c6b5be46f48d1a84b1deb4bea2523e548938e2f9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:ea25d189f5d15732c785f3507a89c3e0e779fd90f29ae7e6199578473ac1c4ed", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-elevenlabs/src/test/java/org/springframework/ai/elevenlabs/ElevenLabsTextToSpeechModelIT.java[ElevenLabsTextToSpeechModelIT.java] test provides some general examples of how to use the library.\n* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-elevenlabs/src/test/java/org/springframework/ai/elevenlabs/api/ElevenLabsApiIT.java[ElevenLabsApiIT.java] test provides examples of using the low-level `ElevenLabsApi`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc", "title": "ElevenLabs Text-to-Speech (TTS)", "heading": "Example Code", "heading_level": 2, "file_order": 0, "section_index": 10, "content_hash": "ea25d189f5d15732c785f3507a89c3e0e779fd90f29ae7e6199578473ac1c4ed", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/elevenlabs-speech.adoc"}}
{"id": "sha256:e00c0181e567c955a3d8e7ea9f97280df2bf87474b1f5eea2a91db511d467cc3", "content": "The Audio API provides a speech endpoint based on OpenAI's TTS (text-to-speech) model, enabling users to:\n\n- Narrate a written blog post.\n- Produce spoken audio in multiple languages.\n- Give real-time audio output using streaming.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Introduction", "heading_level": 2, "file_order": 1, "section_index": 0, "content_hash": "e00c0181e567c955a3d8e7ea9f97280df2bf87474b1f5eea2a91db511d467cc3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:1b1bf25cd24c0ec80f743e480a050b3878165491f6c1722541997a0e783152d3", "content": ". Create an OpenAI account and obtain an API key. You can sign up at the https://platform.openai.com/signup[OpenAI signup page] and generate an API key on the https://platform.openai.com/account/api-keys[API Keys page].\n. Add the `spring-ai-openai` dependency to your project's build file. For more information, refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Prerequisites", "heading_level": 2, "file_order": 1, "section_index": 1, "content_hash": "1b1bf25cd24c0ec80f743e480a050b3878165491f6c1722541997a0e783152d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:47623285aae9f67698710f1667b45cadd52dec406a23a7495295466a08f8d62a", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Text-to-Speech Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Auto-configuration", "heading_level": 2, "file_order": 1, "section_index": 2, "content_hash": "47623285aae9f67698710f1667b45cadd52dec406a23a7495295466a08f8d62a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:ee64147b98f66f5d4a209e02c68e3a8339cb18f4ff2181d9eca4c389e3363e17", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.openai.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project is used for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), optionally, you can specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Connection Properties", "heading_level": 3, "file_order": 1, "section_index": 3, "content_hash": "ee64147b98f66f5d4a209e02c68e3a8339cb18f4ff2181d9eca4c389e3363e17", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:28310b63299c062828f9a15d62990a9e49d38af243dd861e7a58bdd05d92612a", "content": "[NOTE]\n====\nEnabling and disabling of the audio speech auto-configurations are now configured via top level properties with the prefix `spring.ai.model.audio.speech`.\n\nTo enable, spring.ai.model.audio.speech=openai (It is enabled by default)\n\nTo disable, spring.ai.model.audio.speech=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.audio.speech` is used as the property prefix that lets you configure the OpenAI Text-to-Speech client.\n\n[cols=\"3,5,2\"]\n|====\n| Property | Description | Default\n\n| spring.ai.model.audio.speech | Enable Audio Speech Model | openai\n| spring.ai.openai.audio.speech.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.audio.speech.api-key | The API Key | -\n| spring.ai.openai.audio.speech.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.audio.speech.project-id | Optionally, you can specify which project is used for an API request. | -\n| spring.ai.openai.audio.speech.speech-path | The API endpoint path for audio speech generation. Useful for OpenAI-compatible APIs with different endpoint structures. | /v1/audio/speech\n| spring.ai.openai.audio.speech.options.model | ID of the model to use for generating the audio. Available models: `gpt-4o-mini-tts` (default, optimized for speed and cost), `gpt-4o-tts` (higher quality), `tts-1` (legacy, optimized for speed), or `tts-1-hd` (legacy, optimized for quality). | gpt-4o-mini-tts\n| spring.ai.openai.audio.speech.options.voice | The voice to use for synthesis. For OpenAI's TTS API, One of the available voices for the chosen model: alloy, echo, fable, onyx, nova, and shimmer. | alloy\n| spring.ai.openai.audio.speech.options.response-format | The format of the audio output. Supported formats are mp3, opus, aac, flac, wav, and pcm. | mp3\n| spring.ai.openai.audio.speech.options.speed | The speed of the voice synthesis. The acceptable range is from 0.25 (slowest) to 4.0 (fastest). | 1.0\n|====\n\nNOTE: You can override the common `spring.ai.openai.base-url`, `spring.ai.openai.api-key`, `spring.ai.openai.organization-id` and `spring.ai.openai.project-id` properties.\nThe `spring.ai.openai.audio.speech.base-url`, `spring.ai.openai.audio.speech.api-key`, `spring.ai.openai.audio.speech.organization-id` and `spring.ai.openai.audio.speech.project-id` properties if set take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.audio.speech.options` can be overridden at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Configuration Properties", "heading_level": 3, "file_order": 1, "section_index": 4, "content_hash": "28310b63299c062828f9a15d62990a9e49d38af243dd861e7a58bdd05d92612a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:aba96545554019917f44b3db4c4c16e522e81b396271430ae1c19366f9646282", "content": "For OpenAI-compatible APIs (such as LocalAI, Ollama with OpenAI compatibility, or custom proxies) that use different endpoint paths, you can configure the speech path:\n\n[source,properties]\n----\nspring.ai.openai.audio.speech.speech-path=/custom/path/to/speech\n----\n\nThis is particularly useful when:\n\n* Using API gateways or proxies that modify standard OpenAI paths\n* Working with OpenAI-compatible services that implement different URL structures\n* Testing against mock endpoints with custom paths\n* Deploying in environments with path-based routing requirements", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Custom API Paths", "heading_level": 3, "file_order": 1, "section_index": 5, "content_hash": "aba96545554019917f44b3db4c4c16e522e81b396271430ae1c19366f9646282", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:acaa8c80f95585398c728764acd4d18ba5358961f16a01a47d2902b182872cae", "content": "The `OpenAiAudioSpeechOptions` class provides the options to use when making a text-to-speech request.\nOn start-up, the options specified by `spring.ai.openai.audio.speech` are used but you can override these at runtime.\n\nThe `OpenAiAudioSpeechOptions` class implements the `TextToSpeechOptions` interface, providing both portable and OpenAI-specific configuration options.\n\nFor example:\n\n[source,java]\n----\nOpenAiAudioSpeechOptions speechOptions = OpenAiAudioSpeechOptions.builder()\n .model(\"gpt-4o-mini-tts\")\n .voice(OpenAiAudioApi.SpeechRequest.Voice.ALLOY)\n .responseFormat(OpenAiAudioApi.SpeechRequest.AudioResponseFormat.MP3)\n .speed(1.0)\n .build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"Hello, this is a text-to-speech example.\", speechOptions);\nTextToSpeechResponse response = openAiAudioSpeechModel.call(speechPrompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Runtime Options [[speech-options]]", "heading_level": 2, "file_order": 1, "section_index": 6, "content_hash": "acaa8c80f95585398c728764acd4d18ba5358961f16a01a47d2902b182872cae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:61309251ec72cf7c74b84511652804d102c41e0d2512990bc38b8c163ae3104f", "content": "Add the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `OpenAiAudioSpeechModel`:\n\n[source,java]\n----\nvar openAiAudioApi = new OpenAiAudioApi()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar openAiAudioSpeechModel = new OpenAiAudioSpeechModel(openAiAudioApi);\n\nvar speechOptions = OpenAiAudioSpeechOptions.builder()\n .responseFormat(OpenAiAudioApi.SpeechRequest.AudioResponseFormat.MP3)\n .speed(1.0)\n .model(OpenAiAudioApi.TtsModel.GPT_4_O_MINI_TTS.value)\n .build();\n\nvar speechPrompt = new TextToSpeechPrompt(\"Hello, this is a text-to-speech example.\", speechOptions);\nTextToSpeechResponse response = openAiAudioSpeechModel.call(speechPrompt);\n\nOpenAiAudioSpeechResponseMetadata metadata = (OpenAiAudioSpeechResponseMetadata) response.getMetadata();\n\nbyte[] responseAsBytes = response.getResult().getOutput();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Manual Configuration", "heading_level": 2, "file_order": 1, "section_index": 7, "content_hash": "61309251ec72cf7c74b84511652804d102c41e0d2512990bc38b8c163ae3104f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:4d13caf0dc898989ea26854778e6c7a2059ea2988b2428fd477459b134091b20", "content": "The Speech API provides support for real-time audio streaming using chunk transfer encoding. This means that the audio is able to be played before the full file has been generated and made accessible.\n\nThe `OpenAiAudioSpeechModel` implements the `StreamingTextToSpeechModel` interface, providing both standard and streaming capabilities.\n\n[source,java]\n----\nvar openAiAudioApi = new OpenAiAudioApi()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar openAiAudioSpeechModel = new OpenAiAudioSpeechModel(openAiAudioApi);\n\nOpenAiAudioSpeechOptions speechOptions = OpenAiAudioSpeechOptions.builder()\n .voice(OpenAiAudioApi.SpeechRequest.Voice.ALLOY)\n .speed(1.0)\n .responseFormat(OpenAiAudioApi.SpeechRequest.AudioResponseFormat.MP3)\n .model(OpenAiAudioApi.TtsModel.GPT_4_O_MINI_TTS.value)\n .build();\n\nTextToSpeechPrompt speechPrompt = new TextToSpeechPrompt(\"Today is a wonderful day to build something people love!\", speechOptions);\n\nFlux<TextToSpeechResponse> responseStream = openAiAudioSpeechModel.stream(speechPrompt);\n\nFlux<byte[]> audioByteStream = openAiAudioSpeechModel.stream(\"Hello, world!\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Streaming Real-time Audio", "heading_level": 2, "file_order": 1, "section_index": 8, "content_hash": "4d13caf0dc898989ea26854778e6c7a2059ea2988b2428fd477459b134091b20", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:a4a058284afb6c48d2951eaf406418f24e9d552795c7a7b2c323353831ff9915", "content": "If you're upgrading from the deprecated `SpeechModel` and `SpeechPrompt` classes, this guide provides detailed instructions for migrating to the new shared interfaces.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Migration Guide", "heading_level": 2, "file_order": 1, "section_index": 9, "content_hash": "a4a058284afb6c48d2951eaf406418f24e9d552795c7a7b2c323353831ff9915", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:88dfbba6eda5b71ac0548cd584f6fb6ba13e5da90531e686c1408715ec71c861", "content": "This migration includes the following breaking changes:\n\n1. **Removed Classes**: Six deprecated classes have been removed from `org.springframework.ai.openai.audio.speech` package\n2. **Package Changes**: Core TTS classes moved to `org.springframework.ai.audio.tts` package\n3. **Type Changes**: The `speed` parameter changed from `Float` to `Double` across all OpenAI TTS components\n4. **Interface Hierarchy**: `TextToSpeechModel` now extends `StreamingTextToSpeechModel`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Breaking Changes Summary", "heading_level": 3, "file_order": 1, "section_index": 10, "content_hash": "88dfbba6eda5b71ac0548cd584f6fb6ba13e5da90531e686c1408715ec71c861", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:ccb6008d54fcc30b3756bd116f8c77c7489fd40f9afadcf401c608891d871ceb", "content": "[cols=\"1,1\"]\n|====\n| Deprecated (Removed) | New Interface\n\n| `SpeechModel`\n| `TextToSpeechModel`\n\n| `StreamingSpeechModel`\n| `StreamingTextToSpeechModel`\n\n| `SpeechPrompt`\n| `TextToSpeechPrompt`\n\n| `SpeechResponse`\n| `TextToSpeechResponse`\n\n| `SpeechMessage`\n| `TextToSpeechMessage`\n\n| `Speech` (in `org.springframework.ai.openai.audio.speech`)\n| `Speech` (in `org.springframework.ai.audio.tts`)\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Class Mapping Reference", "heading_level": 3, "file_order": 1, "section_index": 11, "content_hash": "ccb6008d54fcc30b3756bd116f8c77c7489fd40f9afadcf401c608891d871ceb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:012108825f23c1c5110d809e70971c1e48b998abb31c330ffc567db0cd63de6f", "content": "Replace all imports from the old `org.springframework.ai.openai.audio.speech` package with the new shared interfaces:\n\n[source,text]\n----\nFind: import org.springframework.ai.openai.audio.speech.SpeechModel;\nReplace: import org.springframework.ai.audio.tts.TextToSpeechModel;\n\nFind: import org.springframework.ai.openai.audio.speech.StreamingSpeechModel;\nReplace: import org.springframework.ai.audio.tts.StreamingTextToSpeechModel;\n\nFind: import org.springframework.ai.openai.audio.speech.SpeechPrompt;\nReplace: import org.springframework.ai.audio.tts.TextToSpeechPrompt;\n\nFind: import org.springframework.ai.openai.audio.speech.SpeechResponse;\nReplace: import org.springframework.ai.audio.tts.TextToSpeechResponse;\n\nFind: import org.springframework.ai.openai.audio.speech.SpeechMessage;\nReplace: import org.springframework.ai.audio.tts.TextToSpeechMessage;\n\nFind: import org.springframework.ai.openai.audio.speech.Speech;\nReplace: import org.springframework.ai.audio.tts.Speech;\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Step 1: Update Imports", "heading_level": 4, "file_order": 1, "section_index": 12, "content_hash": "012108825f23c1c5110d809e70971c1e48b998abb31c330ffc567db0cd63de6f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:0a91c588c41ccd1161dc194ef83a3593fcc717e189a46b215d1f6d4fcccfad2d", "content": "Replace all type references in your code:\n\n[source,text]\n----\nFind: SpeechModel\nReplace: TextToSpeechModel\n\nFind: StreamingSpeechModel\nReplace: StreamingTextToSpeechModel\n\nFind: SpeechPrompt\nReplace: TextToSpeechPrompt\n\nFind: SpeechResponse\nReplace: TextToSpeechResponse\n\nFind: SpeechMessage\nReplace: TextToSpeechMessage\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Step 2: Update Type References", "heading_level": 4, "file_order": 1, "section_index": 13, "content_hash": "0a91c588c41ccd1161dc194ef83a3593fcc717e189a46b215d1f6d4fcccfad2d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:d002d8b3ad3ecc15dbfb8f979a8fa9211819108e62f1c852565357b8d1c57fa5", "content": "The `speed` parameter has changed from `Float` to `Double`. Update all occurrences:\n\n[source,text]\n----\nFind: .speed(1.0f)\nReplace: .speed(1.0)\n\nFind: .speed(0.5f)\nReplace: .speed(0.5)\n\nFind: Float speed\nReplace: Double speed\n----\n\nIf you have serialized data or configuration files with Float values, you'll need to update those as well:\n\n[source,json]\n----\n{\n \"speed\": 1.0\n}\n\n{\n \"speed\": 1.0\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Step 3: Update Speed Parameter (Float → Double)", "heading_level": 4, "file_order": 1, "section_index": 14, "content_hash": "d002d8b3ad3ecc15dbfb8f979a8fa9211819108e62f1c852565357b8d1c57fa5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:d4fa6d2ec7dabb1ab5784e6b87ee04bea3820668721454ec8baad9d2472b93ca", "content": "If you have Spring Boot auto-configuration or manual bean definitions:\n\n[source,java]\n----\n@Bean\npublic SpeechModel speechModel(OpenAiAudioApi audioApi) {\n return new OpenAiAudioSpeechModel(audioApi);\n}\n\n@Bean\npublic TextToSpeechModel textToSpeechModel(OpenAiAudioApi audioApi) {\n return new OpenAiAudioSpeechModel(audioApi);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Step 4: Update Bean Declarations", "heading_level": 4, "file_order": 1, "section_index": 15, "content_hash": "d4fa6d2ec7dabb1ab5784e6b87ee04bea3820668721454ec8baad9d2472b93ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:24a80f50eb778a635e11c572b8b3f9f9ca1452698f6b4356f8db2e5a98d7bc6c", "content": "**Before (deprecated):**\n[source,java]\n----\nimport org.springframework.ai.openai.audio.speech.*;\n\n@Service\npublic class OldNarrationService {\n\n private final SpeechModel speechModel;\n\n public OldNarrationService(SpeechModel speechModel) {\n this.speechModel = speechModel;\n }\n\n public byte[] createNarration(String text) {\n SpeechPrompt prompt = new SpeechPrompt(text);\n SpeechResponse response = speechModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----\n\n**After (using shared interfaces):**\n[source,java]\n----\nimport org.springframework.ai.audio.tts.*;\nimport org.springframework.ai.openai.OpenAiAudioSpeechModel;\n\n@Service\npublic class NarrationService {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public NarrationService(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n public byte[] createNarration(String text) {\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text);\n TextToSpeechResponse response = textToSpeechModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Example 1: Basic Text-to-Speech Conversion", "heading_level": 4, "file_order": 1, "section_index": 16, "content_hash": "24a80f50eb778a635e11c572b8b3f9f9ca1452698f6b4356f8db2e5a98d7bc6c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:1ceba83b35422c2f457e0c7d8935e2f91973683f10ed9e39a75d4b0023f78d50", "content": "**Before (deprecated):**\n[source,java]\n----\nimport org.springframework.ai.openai.audio.speech.*;\nimport org.springframework.ai.openai.api.OpenAiAudioApi;\n\nSpeechModel model = new OpenAiAudioSpeechModel(audioApi);\n\nOpenAiAudioSpeechOptions options = OpenAiAudioSpeechOptions.builder()\n .model(\"tts-1\")\n .voice(OpenAiAudioApi.SpeechRequest.Voice.NOVA)\n .speed(1.0f) // Float value\n .responseFormat(OpenAiAudioApi.SpeechRequest.AudioResponseFormat.MP3)\n .build();\n\nSpeechPrompt prompt = new SpeechPrompt(\"Hello, world!\", options);\nSpeechResponse response = model.call(prompt);\nbyte[] audio = response.getResult().getOutput();\n----\n\n**After (using shared interfaces):**\n[source,java]\n----\nimport org.springframework.ai.audio.tts.*;\nimport org.springframework.ai.openai.OpenAiAudioSpeechModel;\nimport org.springframework.ai.openai.OpenAiAudioSpeechOptions;\nimport org.springframework.ai.openai.api.OpenAiAudioApi;\n\nTextToSpeechModel model = new OpenAiAudioSpeechModel(audioApi);\n\nOpenAiAudioSpeechOptions options = OpenAiAudioSpeechOptions.builder()\n .model(\"tts-1\")\n .voice(OpenAiAudioApi.SpeechRequest.Voice.NOVA)\n .speed(1.0) // Double value\n .responseFormat(OpenAiAudioApi.SpeechRequest.AudioResponseFormat.MP3)\n .build();\n\nTextToSpeechPrompt prompt = new TextToSpeechPrompt(\"Hello, world!\", options);\nTextToSpeechResponse response = model.call(prompt);\nbyte[] audio = response.getResult().getOutput();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Example 2: Text-to-Speech with Custom Options", "heading_level": 4, "file_order": 1, "section_index": 17, "content_hash": "1ceba83b35422c2f457e0c7d8935e2f91973683f10ed9e39a75d4b0023f78d50", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:f9d4a7d84d4d458662249ed15717620345641a393c82c7b82df9625d0901f50d", "content": "**Before (deprecated):**\n[source,java]\n----\nimport org.springframework.ai.openai.audio.speech.*;\nimport reactor.core.publisher.Flux;\n\nStreamingSpeechModel model = new OpenAiAudioSpeechModel(audioApi);\nSpeechPrompt prompt = new SpeechPrompt(\"Stream this text\");\n\nFlux<SpeechResponse> stream = model.stream(prompt);\nstream.subscribe(response -> {\n byte[] audioChunk = response.getResult().getOutput();\n // Process audio chunk\n});\n----\n\n**After (using shared interfaces):**\n[source,java]\n----\nimport org.springframework.ai.audio.tts.*;\nimport org.springframework.ai.openai.OpenAiAudioSpeechModel;\nimport reactor.core.publisher.Flux;\n\nTextToSpeechModel model = new OpenAiAudioSpeechModel(audioApi);\nTextToSpeechPrompt prompt = new TextToSpeechPrompt(\"Stream this text\");\n\nFlux<TextToSpeechResponse> stream = model.stream(prompt);\nstream.subscribe(response -> {\n byte[] audioChunk = response.getResult().getOutput();\n // Process audio chunk\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Example 3: Streaming Text-to-Speech", "heading_level": 4, "file_order": 1, "section_index": 18, "content_hash": "f9d4a7d84d4d458662249ed15717620345641a393c82c7b82df9625d0901f50d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:008b85df15139f519517da2ead1caea6ab82d884fa501ef28584dafca9e94ee3", "content": "**Before (deprecated):**\n[source,java]\n----\n@RestController\npublic class OldSpeechController {\n\n private final SpeechModel speechModel;\n\n @Autowired\n public OldSpeechController(SpeechModel speechModel) {\n this.speechModel = speechModel;\n }\n\n @PostMapping(\"/narrate\")\n public ResponseEntity<byte[]> narrate(@RequestBody String text) {\n SpeechPrompt prompt = new SpeechPrompt(text);\n SpeechResponse response = speechModel.call(prompt);\n return ResponseEntity.ok()\n .contentType(MediaType.parseMediaType(\"audio/mpeg\"))\n .body(response.getResult().getOutput());\n }\n}\n----\n\n**After (using shared interfaces):**\n[source,java]\n----\n@RestController\npublic class SpeechController {\n\n private final TextToSpeechModel textToSpeechModel;\n\n @Autowired\n public SpeechController(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n @PostMapping(\"/narrate\")\n public ResponseEntity<byte[]> narrate(@RequestBody String text) {\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text);\n TextToSpeechResponse response = textToSpeechModel.call(prompt);\n return ResponseEntity.ok()\n .contentType(MediaType.parseMediaType(\"audio/mpeg\"))\n .body(response.getResult().getOutput());\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Example 4: Dependency Injection with Spring Boot", "heading_level": 4, "file_order": 1, "section_index": 19, "content_hash": "008b85df15139f519517da2ead1caea6ab82d884fa501ef28584dafca9e94ee3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:2dae6d1b3ecf2a40326d837f7dda7b719fbfa9d3b73796f02ea4bbc255aa31da", "content": "The Spring Boot auto-configuration properties remain the same. No changes are required to your `application.properties` or `application.yml` files.\n\nHowever, if you have explicit bean references or qualifiers, update them:\n\n[source,java]\n----\n@Qualifier(\"speechModel\")\n\n@Qualifier(\"textToSpeechModel\")\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Spring Boot Configuration Changes", "heading_level": 3, "file_order": 1, "section_index": 20, "content_hash": "2dae6d1b3ecf2a40326d837f7dda7b719fbfa9d3b73796f02ea4bbc255aa31da", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:32c0510f018b46affc63247b0ffeae6c5bf5b6a228e74ef7b592ebbb647aeeb8", "content": "- **Portability**: Write code once, switch between OpenAI, ElevenLabs, or other TTS providers easily\n- **Consistency**: Same patterns as ChatModel and other Spring AI abstractions\n- **Type Safety**: Improved type hierarchy with proper interface implementations\n- **Future-Proof**: New TTS providers will automatically work with your existing code\n- **Standardization**: Consistent `Double` type for speed parameter across all TTS providers", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Benefits of the Migration", "heading_level": 3, "file_order": 1, "section_index": 21, "content_hash": "32c0510f018b46affc63247b0ffeae6c5bf5b6a228e74ef7b592ebbb647aeeb8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:d8798efc8586c2d8520a0a98a8c6988a2621b5f92d1a00f5fdaaba65498c6310", "content": "**Error:**\n[source]\n----\nerror: cannot find symbol SpeechModel\n----\n\n**Solution:** Update your imports as described in Step 1, changing `SpeechModel` to `TextToSpeechModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Issue 1: Compilation Error - Cannot Find Symbol SpeechModel", "heading_level": 4, "file_order": 1, "section_index": 22, "content_hash": "d8798efc8586c2d8520a0a98a8c6988a2621b5f92d1a00f5fdaaba65498c6310", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:20959d957694e39b57382543ab8286840b19a5c7366630951a8940554730167a", "content": "**Error:**\n[source]\n----\nerror: incompatible types: float cannot be converted to Double\n----\n\n**Solution:** Remove the `f` suffix from floating-point literals (e.g., change `1.0f` to `1.0`).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Issue 2: Type Mismatch - Float Cannot Be Converted to Double", "heading_level": 4, "file_order": 1, "section_index": 23, "content_hash": "20959d957694e39b57382543ab8286840b19a5c7366630951a8940554730167a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:9b2a6888ebe92c6cd05d33b6a3f0cb600ae9161562ce42b983c75b3cb529ddc9", "content": "**Error:**\n[source]\n----\nNoSuchBeanDefinitionException: No qualifying bean of type 'SpeechModel'\n----\n\n**Solution:** Update your dependency injection to use `TextToSpeechModel` instead of `SpeechModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Issue 3: Bean Creation Error at Runtime", "heading_level": 4, "file_order": 1, "section_index": 24, "content_hash": "9b2a6888ebe92c6cd05d33b6a3f0cb600ae9161562ce42b983c75b3cb529ddc9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:f38235cefacfdd2182883f081ad047355bf14432be53e61d45b9c97ec81e6f44", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/audio/speech/OpenAiSpeechModelIT.java[OpenAiSpeechModelIT.java] test provides some general examples of how to use the library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc", "title": "OpenAI Text-to-Speech (TTS)", "heading": "Example Code", "heading_level": 2, "file_order": 1, "section_index": 25, "content_hash": "f38235cefacfdd2182883f081ad047355bf14432be53e61d45b9c97ec81e6f44", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech/openai-speech.adoc"}}
{"id": "sha256:230a36c0b41e9f46c4ce9c88cfbc325611b84f1a91368fe494b00968aa24d93d", "content": "Spring AI supports https://learn.microsoft.com/en-us/azure/ai-services/openai/whisper-quickstart?tabs=command-line%2Cpython-new&pivots=rest-api[Azure Whisper model].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Azure OpenAI Transcriptions", "heading_level": 1, "file_order": 2, "section_index": 0, "content_hash": "230a36c0b41e9f46c4ce9c88cfbc325611b84f1a91368fe494b00968aa24d93d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:fd81deb8ffc9093fc116c24da5da6366debee21cb0d156fddfccc51fd9bfbd72", "content": "Obtain your Azure OpenAI `endpoint` and `api-key` from the Azure OpenAI Service section on the link:https://portal.azure.com[Azure Portal].\nSpring AI defines a configuration property named `spring.ai.azure.openai.api-key` that you should set to the value of the `API Key` obtained from Azure.\nThere is also a configuration property named `spring.ai.azure.openai.endpoint` that you should set to the endpoint URL obtained when provisioning your model in Azure.\nExporting an environment variable is one way to set that configuration property:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Prerequisites", "heading_level": 2, "file_order": 2, "section_index": 1, "content_hash": "fd81deb8ffc9093fc116c24da5da6366debee21cb0d156fddfccc51fd9bfbd72", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:045982e42431d8ec8de771e7045923642e72d797fb8471da10ef1e85096e10f0", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure OpenAI Transcription Generation Client.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Auto-configuration", "heading_level": 2, "file_order": 2, "section_index": 2, "content_hash": "045982e42431d8ec8de771e7045923642e72d797fb8471da10ef1e85096e10f0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:c7b1aa95952a6a586bc1b11f81c3eba711566d30f1e6448bfe44bb26a1bc8019", "content": "[NOTE]\n====\nEnabling and disabling of the audio transcription auto-configurations are now configured via top level properties with the prefix `spring.ai.model.audio.transcription`.\n\nTo enable, spring.ai.model.audio.transcription=azure-openai (It is enabled by default)\n\nTo disable, spring.ai.model.audio.transcription=none (or any value which doesn't match azure-openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.audio.transcription` is used as the property prefix that lets you configure the retry mechanism for the OpenAI image model.\n\n[cols=\"3,5,2\"]\n|====\n| Property | Description | Default\n\n| spring.ai.azure.openai.audio.transcription.enabled (Removed and no longer valid) | Enable Azure OpenAI transcription model. | true\n| spring.ai.model.audio.transcription | Enable Azure OpenAI transcription model. | azure-openai\n| spring.ai.azure.openai.audio.transcription.options.model | ID of the model to use. Only whisper is currently available. | whisper\n| spring.ai.azure.openai.audio.transcription.options.deployment-name | The deployment name under which the model is deployed. |\n| spring.ai.azure.openai.audio.transcription.options.response-format | The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. | json\n| spring.ai.azure.openai.audio.transcription.options.prompt | An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. |\n| spring.ai.azure.openai.audio.transcription.options.language | The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. |\n| spring.ai.azure.openai.audio.transcription.options.temperature | The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. | 0\n| spring.ai.azure.openai.audio.transcription.options.timestamp-granularities | The timestamp granularities to populate for this transcription. response_format must be set verbose_json to use timestamp granularities. Either or both of these options are supported: word, or segment. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency. | segment\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Transcription Properties", "heading_level": 3, "file_order": 2, "section_index": 3, "content_hash": "c7b1aa95952a6a586bc1b11f81c3eba711566d30f1e6448bfe44bb26a1bc8019", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:3b1097ddc83692513825206e3b755ef8f961d4b1820602a579edc902e1d94f80", "content": "The `AzureOpenAiAudioTranscriptionOptions` class provides the options to use when making a transcription.\nOn start-up, the options specified by `spring.ai.azure.openai.audio.transcription` are used, but you can override these at runtime.\n\nFor example:\n\n[source,java]\n----\nAzureOpenAiAudioTranscriptionOptions.TranscriptResponseFormat responseFormat = AzureOpenAiAudioTranscriptionOptions.TranscriptResponseFormat.VTT;\n\nAzureOpenAiAudioTranscriptionOptions transcriptionOptions = AzureOpenAiAudioTranscriptionOptions.builder()\n .language(\"en\")\n .prompt(\"Ask not this, but ask that\")\n .temperature(0f)\n .responseFormat(this.responseFormat)\n .build();\nAudioTranscriptionPrompt transcriptionRequest = new AudioTranscriptionPrompt(audioFile, this.transcriptionOptions);\nAudioTranscriptionResponse response = azureOpenAiTranscriptionModel.call(this.transcriptionRequest);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Runtime Options", "heading_level": 2, "file_order": 2, "section_index": 4, "content_hash": "3b1097ddc83692513825206e3b755ef8f961d4b1820602a579edc902e1d94f80", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:24c7186b345a6fb6a4cf031299d9cd6826a720763678ecb78180f3b82dc6b783", "content": "Add the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `AzureOpenAiAudioTranscriptionModel`\n\n[source,java]\n----\nvar openAIClient = new OpenAIClientBuilder()\n .credential(new AzureKeyCredential(System.getenv(\"AZURE_OPENAI_API_KEY\")))\n .endpoint(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n .buildClient();\n\nvar azureOpenAiAudioTranscriptionModel = new AzureOpenAiAudioTranscriptionModel(this.openAIClient, null);\n\nvar transcriptionOptions = AzureOpenAiAudioTranscriptionOptions.builder()\n .responseFormat(TranscriptResponseFormat.TEXT)\n .temperature(0f)\n .build();\n\nvar audioFile = new FileSystemResource(\"/path/to/your/resource/speech/jfk.flac\");\n\nAudioTranscriptionPrompt transcriptionRequest = new AudioTranscriptionPrompt(this.audioFile, this.transcriptionOptions);\nAudioTranscriptionResponse response = this.azureOpenAiAudioTranscriptionModel.call(this.transcriptionRequest);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc", "title": "Azure OpenAI Transcriptions", "heading": "Manual Configuration", "heading_level": 2, "file_order": 2, "section_index": 5, "content_hash": "24c7186b345a6fb6a4cf031299d9cd6826a720763678ecb78180f3b82dc6b783", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/azure-openai-transcriptions.adoc"}}
{"id": "sha256:7c1c0f6b955f92f656216992b7780d429140a97fedb5299afe965c6424510962", "content": "Spring AI supports https://platform.openai.com/docs/api-reference/audio/createTranscription[OpenAI's Transcription model].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "OpenAI Transcriptions", "heading_level": 2, "file_order": 3, "section_index": 0, "content_hash": "7c1c0f6b955f92f656216992b7780d429140a97fedb5299afe965c6424510962", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:181a87968f7b0d998b5fbe7156fd400271afb2689099cc186fb84fa16c46bb9d", "content": "You will need to create an API key with OpenAI to access ChatGPT models.\nCreate an account at https://platform.openai.com/signup[OpenAI signup page] and generate the token on the https://platform.openai.com/account/api-keys[API Keys page].\nThe Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from openai.com.\nExporting an environment variable is one way to set that configuration property:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Prerequisites", "heading_level": 2, "file_order": 3, "section_index": 1, "content_hash": "181a87968f7b0d998b5fbe7156fd400271afb2689099cc186fb84fa16c46bb9d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:dbfcede932cbc792453fdd498adf75b46a2a7d79d4901e11d0a906274b01dd03", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Transcription Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Auto-configuration", "heading_level": 2, "file_order": 3, "section_index": 2, "content_hash": "dbfcede932cbc792453fdd498adf75b46a2a7d79d4901e11d0a906274b01dd03", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:31e7e8c78d92d0225d6e38af3cefc82a949f20dd3a411744127aeafbc30a779e", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.openai.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project is used for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), optionally, you can specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Connection Properties", "heading_level": 4, "file_order": 3, "section_index": 3, "content_hash": "31e7e8c78d92d0225d6e38af3cefc82a949f20dd3a411744127aeafbc30a779e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:a3567b2fb7b339b2d28fd1b28cc68f3072b112b928961f4fa0d77fbcdf0086a5", "content": "[NOTE]\n====\nEnabling and disabling of the audio transcription auto-configurations are now configured via top level properties with the prefix `spring.ai.model.audio.transcription`.\n\nTo enable, spring.ai.model.audio.transcription=openai (It is enabled by default)\n\nTo disable, spring.ai.model.audio.transcription=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.audio.transcription` is used as the property prefix that lets you configure the retry mechanism for the OpenAI transcription model.\n\n[cols=\"3,5,2\"]\n|====\n| Property | Description | Default\n\n| spring.ai.model.audio.transcription | Enable OpenAI Audio Transcription Model | openai\n| spring.ai.openai.audio.transcription.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.audio.transcription.api-key | The API Key | -\n| spring.ai.openai.audio.transcription.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.audio.transcription.project-id | Optionally, you can specify which project is used for an API request. | -\n| spring.ai.openai.audio.transcription.transcription-path | The API endpoint path for audio transcription. Useful for OpenAI-compatible APIs with different endpoint structures. | /v1/audio/transcriptions\n| spring.ai.openai.audio.transcription.options.model | ID of the model to use for transcription. Available models: `gpt-4o-transcribe` (speech-to-text powered by GPT-4o), `gpt-4o-mini-transcribe` (speech-to-text powered by GPT-4o mini), or `whisper-1` (general-purpose speech recognition model, default). | whisper-1\n| spring.ai.openai.audio.transcription.options.response-format | The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. | json\n| spring.ai.openai.audio.transcription.options.prompt | An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language. |\n| spring.ai.openai.audio.transcription.options.language | The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency. |\n| spring.ai.openai.audio.transcription.options.temperature | The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit. | 0\n| spring.ai.openai.audio.transcription.options.timestamp_granularities | The timestamp granularities to populate for this transcription. response_format must be set verbose_json to use timestamp granularities. Either or both of these options are supported: word, or segment. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency. | segment\n|====\n\nNOTE: You can override the common `spring.ai.openai.base-url`, `spring.ai.openai.api-key`, `spring.ai.openai.organization-id` and `spring.ai.openai.project-id` properties.\nThe `spring.ai.openai.audio.transcription.base-url`, `spring.ai.openai.audio.transcription.api-key`, `spring.ai.openai.audio.transcription.organization-id` and `spring.ai.openai.audio.transcription.project-id` properties if set take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.transcription.options` can be overridden at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Configuration Properties", "heading_level": 4, "file_order": 3, "section_index": 4, "content_hash": "a3567b2fb7b339b2d28fd1b28cc68f3072b112b928961f4fa0d77fbcdf0086a5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:3fc3e209441b8ea29a81e6cf35bc458a33dcc6f15a7f52a11e67973559541934", "content": "For OpenAI-compatible APIs (such as LocalAI, Ollama with OpenAI compatibility, or custom proxies) that use different endpoint paths, you can configure the transcription path:\n\n[source,properties]\n----\nspring.ai.openai.audio.transcription.transcription-path=/custom/path/to/transcriptions\n----\n\nThis is particularly useful when:\n\n* Using API gateways or proxies that modify standard OpenAI paths\n* Working with OpenAI-compatible services that implement different URL structures\n* Testing against mock endpoints with custom paths\n* Deploying in environments with path-based routing requirements", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Custom API Paths", "heading_level": 3, "file_order": 3, "section_index": 5, "content_hash": "3fc3e209441b8ea29a81e6cf35bc458a33dcc6f15a7f52a11e67973559541934", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:dfe12a6f5cd29d7f2e266e4404a4ea5a6e3835b8c5f8666e5889ac7760a5e77c", "content": "The `OpenAiAudioTranscriptionOptions` class provides the options to use when making a transcription.\nOn start-up, the options specified by `spring.ai.openai.audio.transcription` are used but you can override these at runtime.\n\nFor example:\n\n[source,java]\n----\nOpenAiAudioApi.TranscriptResponseFormat responseFormat = OpenAiAudioApi.TranscriptResponseFormat.VTT;\n\nOpenAiAudioTranscriptionOptions transcriptionOptions = OpenAiAudioTranscriptionOptions.builder()\n .language(\"en\")\n .prompt(\"Ask not this, but ask that\")\n .temperature(0f)\n .responseFormat(this.responseFormat)\n .build();\nAudioTranscriptionPrompt transcriptionRequest = new AudioTranscriptionPrompt(audioFile, this.transcriptionOptions);\nAudioTranscriptionResponse response = openAiTranscriptionModel.call(this.transcriptionRequest);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Runtime Options [[transcription-options]]", "heading_level": 2, "file_order": 3, "section_index": 6, "content_hash": "dfe12a6f5cd29d7f2e266e4404a4ea5a6e3835b8c5f8666e5889ac7760a5e77c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:ee39f4efc7839dc31989d79b59fe212937cf1365ef068955eb64d3ba3875625e", "content": "Add the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `OpenAiAudioTranscriptionModel`\n\n[source,java]\n----\nvar openAiAudioApi = new OpenAiAudioApi(System.getenv(\"OPENAI_API_KEY\"));\n\nvar openAiAudioTranscriptionModel = new OpenAiAudioTranscriptionModel(this.openAiAudioApi);\n\nvar transcriptionOptions = OpenAiAudioTranscriptionOptions.builder()\n .responseFormat(TranscriptResponseFormat.TEXT)\n .temperature(0f)\n .build();\n\nvar audioFile = new FileSystemResource(\"/path/to/your/resource/speech/jfk.flac\");\n\nAudioTranscriptionPrompt transcriptionRequest = new AudioTranscriptionPrompt(this.audioFile, this.transcriptionOptions);\nAudioTranscriptionResponse response = openAiTranscriptionModel.call(this.transcriptionRequest);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Manual Configuration", "heading_level": 2, "file_order": 3, "section_index": 7, "content_hash": "ee39f4efc7839dc31989d79b59fe212937cf1365ef068955eb64d3ba3875625e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:23f19fc095d6110e60c2c84d1197ae7e1981ccf90290c8789e389582f5258f8e", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/audio/transcription/OpenAiTranscriptionModelIT.java[OpenAiTranscriptionModelIT.java] test provides some general examples how to use the library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc", "title": "openai-transcriptions", "heading": "Example Code", "heading_level": 2, "file_order": 3, "section_index": 8, "content_hash": "23f19fc095d6110e60c2c84d1197ae7e1981ccf90290c8789e389582f5258f8e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions/openai-transcriptions.adoc"}}
{"id": "sha256:ac4a175f80d52bd24e6762062d1fb0a7edfa9265098304c3330b0dace601c45a", "content": "[[Speech]]\n\nSpring AI provides a unified API for Text-To-Speech (TTS) through the `TextToSpeechModel` and `StreamingTextToSpeechModel` interfaces. This allows you to write portable code that works across different TTS providers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "speech", "heading_level": 1, "file_order": 4, "section_index": 0, "content_hash": "ac4a175f80d52bd24e6762062d1fb0a7edfa9265098304c3330b0dace601c45a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:5bb75b3c13e3c5f1d39275eeae629f46810fc5e5086d7aa8915e6c90fd6adf25", "content": "- xref:api/audio/speech/openai-speech.adoc[OpenAI's Speech API]\n- xref:api/audio/speech/elevenlabs-speech.adoc[Eleven Labs Text-To-Speech API]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Supported Providers", "heading_level": 2, "file_order": 4, "section_index": 1, "content_hash": "5bb75b3c13e3c5f1d39275eeae629f46810fc5e5086d7aa8915e6c90fd6adf25", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:16f6eb8a7ca49f79a98584a06514ada747a0242abaecb81a7c4b2514135c2a90", "content": "All TTS providers implement the following shared interfaces:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Common Interface", "heading_level": 2, "file_order": 4, "section_index": 2, "content_hash": "16f6eb8a7ca49f79a98584a06514ada747a0242abaecb81a7c4b2514135c2a90", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:295909254751c39f6ed2bd59407fa467dd8e0417966f9c6642e7420264a3cab9", "content": "The `TextToSpeechModel` interface provides methods for converting text to speech:\n\n[source,java]\n----\npublic interface TextToSpeechModel extends Model<TextToSpeechPrompt, TextToSpeechResponse>, StreamingTextToSpeechModel {\n\n /**\n * Converts text to speech with default options.\n */\n default byte[] call(String text) {\n // Default implementation\n }\n\n /**\n * Converts text to speech with custom options.\n */\n TextToSpeechResponse call(TextToSpeechPrompt prompt);\n\n /**\n * Returns the default options for this model.\n */\n default TextToSpeechOptions getDefaultOptions() {\n // Default implementation\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "TextToSpeechModel", "heading_level": 3, "file_order": 4, "section_index": 3, "content_hash": "295909254751c39f6ed2bd59407fa467dd8e0417966f9c6642e7420264a3cab9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:a94dbe3b7b3917be755ede9c687db17a5451cd2f5fd6a0a43113a49265ff64ee", "content": "The `StreamingTextToSpeechModel` interface provides methods for streaming audio in real-time:\n\n[source,java]\n----\n@FunctionalInterface\npublic interface StreamingTextToSpeechModel extends StreamingModel<TextToSpeechPrompt, TextToSpeechResponse> {\n\n /**\n * Streams text-to-speech responses with metadata.\n */\n Flux<TextToSpeechResponse> stream(TextToSpeechPrompt prompt);\n\n /**\n * Streams audio bytes for the given text.\n */\n default Flux<byte[]> stream(String text) {\n // Default implementation\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "StreamingTextToSpeechModel", "heading_level": 3, "file_order": 4, "section_index": 4, "content_hash": "a94dbe3b7b3917be755ede9c687db17a5451cd2f5fd6a0a43113a49265ff64ee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:36d6fd545218d3750244def30a4176acf9b059408d8a5cf18e25eb470af91d1c", "content": "The `TextToSpeechPrompt` class encapsulates the input text and options:\n\n[source,java]\n----\nTextToSpeechPrompt prompt = new TextToSpeechPrompt(\n \"Hello, this is a text-to-speech example.\",\n options\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "TextToSpeechPrompt", "heading_level": 3, "file_order": 4, "section_index": 5, "content_hash": "36d6fd545218d3750244def30a4176acf9b059408d8a5cf18e25eb470af91d1c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:85db62b0073fb01665ce72bd75cd9f9b7e341e2eb66d49b85de3ad69661b9e30", "content": "The `TextToSpeechResponse` class contains the generated audio and metadata:\n\n[source,java]\n----\nTextToSpeechResponse response = model.call(prompt);\nbyte[] audioBytes = response.getResult().getOutput();\nTextToSpeechResponseMetadata metadata = response.getMetadata();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "TextToSpeechResponse", "heading_level": 3, "file_order": 4, "section_index": 6, "content_hash": "85db62b0073fb01665ce72bd75cd9f9b7e341e2eb66d49b85de3ad69661b9e30", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:30e138d2020321116e7f9ddde65c7d08d61b8d86d5b63b638af437f8d18de09e", "content": "One of the key benefits of the shared TTS interfaces is the ability to write code that works with any TTS provider without modification. The actual provider (OpenAI, ElevenLabs, etc.) is determined by your Spring Boot configuration, allowing you to switch providers without changing application code.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Writing Provider-Agnostic Code", "heading_level": 2, "file_order": 4, "section_index": 7, "content_hash": "30e138d2020321116e7f9ddde65c7d08d61b8d86d5b63b638af437f8d18de09e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:b82ea7895a595351dfdddf609b8e7fabc4c3fd59ea5c221713d877622d11a791", "content": "The shared interfaces allow you to write code that works with any TTS provider:\n\n[source,java]\n----\n@Service\npublic class NarrationService {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public NarrationService(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n public byte[] narrate(String text) {\n // Works with any TTS provider\n return textToSpeechModel.call(text);\n }\n\n public byte[] narrateWithOptions(String text, TextToSpeechOptions options) {\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text, options);\n TextToSpeechResponse response = textToSpeechModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----\n\nThis service works seamlessly with OpenAI, ElevenLabs, or any other TTS provider, with the actual implementation determined by your Spring Boot configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Basic Service Example", "heading_level": 3, "file_order": 4, "section_index": 8, "content_hash": "b82ea7895a595351dfdddf609b8e7fabc4c3fd59ea5c221713d877622d11a791", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:ce8390ccdad72d9fbf72d9e1950400c6ff8701407df6e2ab16ff7ce04ff17397", "content": "You can build applications that support multiple TTS providers simultaneously:\n\n[source,java]\n----\n@Service\npublic class MultiProviderNarrationService {\n\n private final Map<String, TextToSpeechModel> providers;\n\n public MultiProviderNarrationService(List<TextToSpeechModel> models) {\n // Spring will inject all available TextToSpeechModel beans\n this.providers = models.stream()\n .collect(Collectors.toMap(\n model -> model.getClass().getSimpleName(),\n model -> model\n ));\n }\n\n public byte[] narrateWithProvider(String text, String providerName) {\n TextToSpeechModel model = providers.get(providerName);\n if (model == null) {\n throw new IllegalArgumentException(\"Unknown provider: \" + providerName);\n }\n return model.call(text);\n }\n\n public Set<String> getAvailableProviders() {\n return providers.keySet();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Advanced Example: Multi-Provider Support", "heading_level": 3, "file_order": 4, "section_index": 9, "content_hash": "ce8390ccdad72d9fbf72d9e1950400c6ff8701407df6e2ab16ff7ce04ff17397", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:3189ded70442c30fab75742344f4ab2901ecfafe43946cfc03a30a9122779465", "content": "The shared interfaces also support streaming for real-time audio generation:\n\n[source,java]\n----\n@Service\npublic class StreamingNarrationService {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public StreamingNarrationService(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n public Flux<byte[]> streamNarration(String text) {\n // TextToSpeechModel extends StreamingTextToSpeechModel\n return textToSpeechModel.stream(text);\n }\n\n public Flux<TextToSpeechResponse> streamWithMetadata(String text, TextToSpeechOptions options) {\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text, options);\n return textToSpeechModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Streaming Audio Example", "heading_level": 3, "file_order": 4, "section_index": 10, "content_hash": "3189ded70442c30fab75742344f4ab2901ecfafe43946cfc03a30a9122779465", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:8546a3283c750da717a72cc93a37879806534d3927b625ecbd05d8dfef489aa2", "content": "Building a REST API with provider-agnostic TTS:\n\n[source,java]\n----\n@RestController\n@RequestMapping(\"/api/tts\")\npublic class TextToSpeechController {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public TextToSpeechController(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n @PostMapping(value = \"/synthesize\", produces = \"audio/mpeg\")\n public ResponseEntity<byte[]> synthesize(@RequestBody SynthesisRequest request) {\n byte[] audio = textToSpeechModel.call(request.text());\n return ResponseEntity.ok()\n .contentType(MediaType.parseMediaType(\"audio/mpeg\"))\n .header(\"Content-Disposition\", \"attachment; filename=\\\"speech.mp3\\\"\")\n .body(audio);\n }\n\n @GetMapping(value = \"/stream\", produces = MediaType.APPLICATION_OCTET_STREAM_VALUE)\n public Flux<byte[]> streamSynthesis(@RequestParam String text) {\n return textToSpeechModel.stream(text);\n }\n\n record SynthesisRequest(String text) {}\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "REST Controller Example", "heading_level": 3, "file_order": 4, "section_index": 11, "content_hash": "8546a3283c750da717a72cc93a37879806534d3927b625ecbd05d8dfef489aa2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:b2acf437520b414db2dd563b290547f80b6373db7d998bd3f93affdaefe1e6de", "content": "Switch between providers using Spring profiles or properties:\n\n[source,yaml]\n----\n# application-openai.yml\nspring:\n ai:\n model:\n audio:\n speech: openai\n openai:\n api-key: ${OPENAI_API_KEY}\n audio:\n speech:\n options:\n model: gpt-4o-mini-tts\n voice: alloy\n\n# application-elevenlabs.yml\nspring:\n ai:\n model:\n audio:\n speech: elevenlabs\n elevenlabs:\n api-key: ${ELEVENLABS_API_KEY}\n tts:\n options:\n model-id: eleven_turbo_v2_5\n voice-id: your_voice_id\n----\n\nThen activate the desired provider:\n[source,bash]\n----\n# Use OpenAI\njava -jar app.jar --spring.profiles.active=openai\n\n# Use ElevenLabs\njava -jar app.jar --spring.profiles.active=elevenlabs\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Configuration-Based Provider Selection", "heading_level": 3, "file_order": 4, "section_index": 12, "content_hash": "b2acf437520b414db2dd563b290547f80b6373db7d998bd3f93affdaefe1e6de", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:a29b133c0ded50a23709b76f75f5bf71f115be3e38c56292bdfe97c8c5790be3", "content": "For maximum portability, use only the common `TextToSpeechOptions` interface methods:\n\n[source,java]\n----\n@Service\npublic class PortableNarrationService {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public PortableNarrationService(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n public byte[] createPortableNarration(String text) {\n // Use provider's default options for maximum portability\n TextToSpeechOptions defaultOptions = textToSpeechModel.getDefaultOptions();\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text, defaultOptions);\n TextToSpeechResponse response = textToSpeechModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Using Portable Options", "heading_level": 3, "file_order": 4, "section_index": 13, "content_hash": "a29b133c0ded50a23709b76f75f5bf71f115be3e38c56292bdfe97c8c5790be3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:b8a7d77c0b16e36ce0c1053a72d104a6ceaf59b998f233fe2eec1f01e269eba1", "content": "When you need provider-specific features, you can still use them while maintaining a portable codebase:\n\n[source,java]\n----\n@Service\npublic class FlexibleNarrationService {\n\n private final TextToSpeechModel textToSpeechModel;\n\n public FlexibleNarrationService(TextToSpeechModel textToSpeechModel) {\n this.textToSpeechModel = textToSpeechModel;\n }\n\n public byte[] narrate(String text, TextToSpeechOptions baseOptions) {\n TextToSpeechOptions options = baseOptions;\n\n // Apply provider-specific optimizations if available\n if (textToSpeechModel instanceof OpenAiAudioSpeechModel) {\n options = OpenAiAudioSpeechOptions.builder()\n .from(baseOptions)\n .model(\"gpt-4o-tts\") // OpenAI-specific: use high-quality model\n .speed(1.0)\n .build();\n } else if (textToSpeechModel instanceof ElevenLabsTextToSpeechModel) {\n // ElevenLabs-specific options could go here\n }\n\n TextToSpeechPrompt prompt = new TextToSpeechPrompt(text, options);\n TextToSpeechResponse response = textToSpeechModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Working with Provider-Specific Features", "heading_level": 3, "file_order": 4, "section_index": 14, "content_hash": "b8a7d77c0b16e36ce0c1053a72d104a6ceaf59b998f233fe2eec1f01e269eba1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:0d30f01947728f4a65d22c3b3b065bbc4d1437a65a3a127b98f07604c84036dc", "content": "1. **Depend on Interfaces**: Always inject `TextToSpeechModel` rather than concrete implementations\n2. **Use Common Options**: Stick to `TextToSpeechOptions` interface methods for maximum portability\n3. **Handle Metadata Gracefully**: Different providers return different metadata; handle it generically\n4. **Test with Multiple Providers**: Ensure your code works with at least two TTS providers\n5. **Document Provider Assumptions**: If you rely on specific provider behavior, document it clearly", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Best Practices for Portable Code", "heading_level": 3, "file_order": 4, "section_index": 15, "content_hash": "0d30f01947728f4a65d22c3b3b065bbc4d1437a65a3a127b98f07604c84036dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:666abd1f6a331fc4c5925b373328cd66c62d87027120782087b9a620b42ef298", "content": "While the shared interfaces provide portability, each provider also offers specific features through provider-specific options classes (e.g., `OpenAiAudioSpeechOptions`, `ElevenLabsSpeechOptions`). These classes implement the `TextToSpeechOptions` interface while adding provider-specific capabilities.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/speech.adoc", "title": "speech", "heading": "Provider-Specific Features", "heading_level": 2, "file_order": 4, "section_index": 16, "content_hash": "666abd1f6a331fc4c5925b373328cd66c62d87027120782087b9a620b42ef298", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/speech.adoc"}}
{"id": "sha256:7dcbebcd825f4bf2b0dc95cd7a51bfdb2bcfafb21407b814a28eadd5af30bbee", "content": "[[Transcription]]\n\nSpring AI provides a unified API for Speech-to-Text transcription through the `TranscriptionModel` interface. This allows you to write portable code that works across different transcription providers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "transcriptions", "heading_level": 1, "file_order": 5, "section_index": 0, "content_hash": "7dcbebcd825f4bf2b0dc95cd7a51bfdb2bcfafb21407b814a28eadd5af30bbee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:463fd5bd4f62c2eddbf236a11608b30ce07515d278604b4f8825b14d37c7f236", "content": "- xref:api/audio/transcriptions/openai-transcriptions.adoc[OpenAI's Whisper API]\n- xref:api/audio/transcriptions/azure-openai-transcriptions.adoc[Azure OpenAI Whisper API]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "Supported Providers", "heading_level": 2, "file_order": 5, "section_index": 1, "content_hash": "463fd5bd4f62c2eddbf236a11608b30ce07515d278604b4f8825b14d37c7f236", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:068b256e4aca4a6139093219c987d3f38445ae87ebdcb26d071588e701fc25e9", "content": "All transcription providers implement the following shared interface:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "Common Interface", "heading_level": 2, "file_order": 5, "section_index": 2, "content_hash": "068b256e4aca4a6139093219c987d3f38445ae87ebdcb26d071588e701fc25e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:2100b2531ebca0b8b7688ff49d6c527753fe6ba5623dde6a708af8104e015478", "content": "The `TranscriptionModel` interface provides methods for converting audio to text:\n\n[source,java]\n----\npublic interface TranscriptionModel extends Model<AudioTranscriptionPrompt, AudioTranscriptionResponse> {\n\n /**\n * Transcribes the audio from the given prompt.\n */\n AudioTranscriptionResponse call(AudioTranscriptionPrompt transcriptionPrompt);\n\n /**\n * A convenience method for transcribing an audio resource.\n */\n default String transcribe(Resource resource) {\n AudioTranscriptionPrompt prompt = new AudioTranscriptionPrompt(resource);\n return this.call(prompt).getResult().getOutput();\n }\n\n /**\n * A convenience method for transcribing an audio resource with options.\n */\n default String transcribe(Resource resource, AudioTranscriptionOptions options) {\n AudioTranscriptionPrompt prompt = new AudioTranscriptionPrompt(resource, options);\n return this.call(prompt).getResult().getOutput();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "TranscriptionModel", "heading_level": 3, "file_order": 5, "section_index": 3, "content_hash": "2100b2531ebca0b8b7688ff49d6c527753fe6ba5623dde6a708af8104e015478", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:3a14efb8af547f833a9a3e83729beaef16e691e5cc7b54b267c5e888372f19aa", "content": "The `AudioTranscriptionPrompt` class encapsulates the input audio and options:\n\n[source,java]\n----\nResource audioFile = new FileSystemResource(\"/path/to/audio.mp3\");\nAudioTranscriptionPrompt prompt = new AudioTranscriptionPrompt(\n audioFile,\n options\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "AudioTranscriptionPrompt", "heading_level": 3, "file_order": 5, "section_index": 4, "content_hash": "3a14efb8af547f833a9a3e83729beaef16e691e5cc7b54b267c5e888372f19aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:184cebcc7fac7eedfe504658e2fd52b2ac309967f0e270925781d9226c44df70", "content": "The `AudioTranscriptionResponse` class contains the transcribed text and metadata:\n\n[source,java]\n----\nAudioTranscriptionResponse response = model.call(prompt);\nString transcribedText = response.getResult().getOutput();\nAudioTranscriptionResponseMetadata metadata = response.getMetadata();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "AudioTranscriptionResponse", "heading_level": 3, "file_order": 5, "section_index": 5, "content_hash": "184cebcc7fac7eedfe504658e2fd52b2ac309967f0e270925781d9226c44df70", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:44f723405624635decb5fc5a01e97ee56a94cd03b7f3387a0b0cd88779b74c00", "content": "One of the key benefits of the shared transcription interface is the ability to write code that works with any transcription provider without modification. The actual provider (OpenAI, Azure OpenAI, etc.) is determined by your Spring Boot configuration, allowing you to switch providers without changing application code.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "Writing Provider-Agnostic Code", "heading_level": 2, "file_order": 5, "section_index": 6, "content_hash": "44f723405624635decb5fc5a01e97ee56a94cd03b7f3387a0b0cd88779b74c00", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:9cc14f80f4038862bbcf22a9933cd1bacb8f6ebeec16a593cb2d58ed0323abe8", "content": "The shared interface allows you to write code that works with any transcription provider:\n\n[source,java]\n----\n@Service\npublic class TranscriptionService {\n\n private final TranscriptionModel transcriptionModel;\n\n public TranscriptionService(TranscriptionModel transcriptionModel) {\n this.transcriptionModel = transcriptionModel;\n }\n\n public String transcribeAudio(Resource audioFile) {\n return transcriptionModel.transcribe(audioFile);\n }\n\n public String transcribeWithOptions(Resource audioFile, AudioTranscriptionOptions options) {\n AudioTranscriptionPrompt prompt = new AudioTranscriptionPrompt(audioFile, options);\n AudioTranscriptionResponse response = transcriptionModel.call(prompt);\n return response.getResult().getOutput();\n }\n}\n----\n\nThis service works seamlessly with OpenAI, Azure OpenAI, or any other transcription provider, with the actual implementation determined by your Spring Boot configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "Basic Service Example", "heading_level": 3, "file_order": 5, "section_index": 7, "content_hash": "9cc14f80f4038862bbcf22a9933cd1bacb8f6ebeec16a593cb2d58ed0323abe8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:fd18a5570ba3dee9719a527fc55eba1569992fbbac33d2ff7dde4cc4da56bd62", "content": "While the shared interface provides portability, each provider also offers specific features through provider-specific options classes (e.g., `OpenAiAudioTranscriptionOptions`, `AzureOpenAiAudioTranscriptionOptions`). These classes implement the `AudioTranscriptionOptions` interface while adding provider-specific capabilities.\n\nFor detailed information about provider-specific features, see the individual provider documentation pages.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/audio/transcriptions.adoc", "title": "transcriptions", "heading": "Provider-Specific Features", "heading_level": 2, "file_order": 5, "section_index": 8, "content_hash": "fd18a5570ba3dee9719a527fc55eba1569992fbbac33d2ff7dde4cc4da56bd62", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/audio/transcriptions.adoc"}}
{"id": "sha256:28ed8cd1b75c0e81d1907edbd29ebe83f15e38220bfd39de223f419af0a0dfe6", "content": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/[OCI GenAI Service] offers generative AI chat with on-demand models, or dedicated AI clusters.\n\nThe https://docs.oracle.com/en-us/iaas/Content/generative-ai/chat-models.htm[OCI Chat Models Page] and https://docs.oracle.com/en-us/iaas/Content/generative-ai/use-playground-embed.htm[OCI Generative AI Playground] provide detailed information about using and hosting chat models on OCI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "OCI GenAI Cohere Chat", "heading_level": 1, "file_order": 6, "section_index": 0, "content_hash": "28ed8cd1b75c0e81d1907edbd29ebe83f15e38220bfd39de223f419af0a0dfe6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:2b4ef40f286691b8fde353de2e4008d957680d9e6e9c39ffb8a7afe97dc2c583", "content": "You will need an active https://signup.oraclecloud.com/[Oracle Cloud Infrastructure (OCI)] account to use the OCI GenAI Cohere Chat client. The client offers four different ways to connect, including simple authentication with a user and private key, workload identity, instance principal, or OCI configuration file authentication.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 6, "section_index": 1, "content_hash": "2b4ef40f286691b8fde353de2e4008d957680d9e6e9c39ffb8a7afe97dc2c583", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:353b84518c029de2de100b5fdd3ad1b3e3129e1bf7e9e6ed0d8ffb4eb8af5abd", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 6, "section_index": 2, "content_hash": "353b84518c029de2de100b5fdd3ad1b3e3129e1bf7e9e6ed0d8ffb4eb8af5abd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:4c4966c15aaadc6e4f87866bd58fde02dfd1da1dfac0e2dfc46b204c92a49a09", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\nSpring AI provides Spring Boot auto-configuration for the OCI GenAI Cohere Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-oci-genai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-oci-genai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 6, "section_index": 3, "content_hash": "4c4966c15aaadc6e4f87866bd58fde02dfd1da1dfac0e2dfc46b204c92a49a09", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:c22a1f2c4a1a9cb10b497d4c41ba0da67a7fa92d0a2dc0969cce15196fda1db8", "content": "The prefix `spring.ai.oci.genai` is the property prefix to configure the connection to OCI GenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.oci.genai.authenticationType | The type of authentication to use when authenticating to OCI. May be `file`, `instance-principal`, `workload-identity`, or `simple`. | file\n| spring.ai.oci.genai.region | OCI service region. | us-chicago-1\n| spring.ai.oci.genai.tenantId | OCI tenant OCID, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.userId | OCI user OCID, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.fingerprint | Private key fingerprint, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.privateKey | Private key content, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.passPhrase | Optional private key passphrase, used when authenticating with `simple` auth and a passphrase protected private key. | -\n| spring.ai.oci.genai.file | Path to OCI config file. Used when authenticating with `file` auth. | <user's home directory>/.oci/config\n| spring.ai.oci.genai.profile | OCI profile name. Used when authenticating with `file` auth. | DEFAULT\n| spring.ai.oci.genai.endpoint | Optional OCI GenAI endpoint. | -\n\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 6, "section_index": 4, "content_hash": "c22a1f2c4a1a9cb10b497d4c41ba0da67a7fa92d0a2dc0969cce15196fda1db8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:c4adfa1545cac61609fe65bbc8ea14161c7e4d833c35b52aebb9d52733b24510", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\nTo enable, spring.ai.model.chat=oci-genai (It is enabled by default)\nTo disable, spring.ai.model.chat=none (or any value which doesn't match oci-genai)\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.oci.genai.cohere.chat` is the property prefix that configures the `ChatModel` implementation for OCI GenAI Cohere Chat.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.model.chat | Enable OCI GenAI Cohere chat model. | oci-genai\n| spring.ai.oci.genai.cohere.chat.enabled (no longer valid) | Enable OCI GenAI Cohere chat model. | true\n| spring.ai.oci.genai.cohere.chat.options.model | Model OCID or endpoint | -\n| spring.ai.oci.genai.cohere.chat.options.compartment | Model compartment OCID. | -\n| spring.ai.oci.genai.cohere.chat.options.servingMode | The model serving mode to be used. May be `on-demand`, or `dedicated`. | on-demand\n| spring.ai.oci.genai.cohere.chat.options.preambleOverride | Override the chat model's prompt preamble | -\n| spring.ai.oci.genai.cohere.chat.options.temperature | Inference temperature | -\n| spring.ai.oci.genai.cohere.chat.options.topP | Top P parameter | -\n| spring.ai.oci.genai.cohere.chat.options.topK | Top K parameter | -\n| spring.ai.oci.genai.cohere.chat.options.frequencyPenalty | Higher values will reduce repeated tokens and outputs will be more random. | -\n| spring.ai.oci.genai.cohere.chat.options.presencePenalty | Higher values encourage generating outputs with tokens that haven't been used. | -\n| spring.ai.oci.genai.cohere.chat.options.stop | List of textual sequences that will end completions generation. | -\n| spring.ai.oci.genai.cohere.chat.options.documents | List of documents used in chat context. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.oci.genai.cohere.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 6, "section_index": 5, "content_hash": "c4adfa1545cac61609fe65bbc8ea14161c7e4d833c35b52aebb9d52733b24510", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:68f9d42217b4a32833353b869507f6b1d6e08bba6714fe5ed607943708f13c6a", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-oci-genai/src/main/java/org/springframework/ai/oci/cohere/OCICohereChatOptions.java[OCICohereChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OCICohereChatModel(api, options)` constructor or the `spring.ai.oci.genai.cohere.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OCICohereChatOptions.builder()\n .model(\"my-model-ocid\")\n .compartment(\"my-compartment-ocid\")\n .temperature(0.5)\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 6, "section_index": 6, "content_hash": "68f9d42217b4a32833353b869507f6b1d6e08bba6714fe5ed607943708f13c6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:60a07310b13386e8f36491bb9e3c4252b8ea383af1f92d257f3fdb3aa1210617", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-oci-genai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OCI GenAI Cohere chat model:\n\n[source,application.properties]\n----\nspring.ai.oci.genai.authenticationType=file\nspring.ai.oci.genai.file=/path/to/oci/config/file\nspring.ai.oci.genai.cohere.chat.options.compartment=my-compartment-ocid\nspring.ai.oci.genai.cohere.chat.options.servingMode=on-demand\nspring.ai.oci.genai.cohere.chat.options.model=my-chat-model-ocid\n----\n\nTIP: replace the `file`, `compartment`, and `model` with your values from your OCI account.\n\nThis will create a `OCICohereChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OCICohereChatModel chatModel;\n\n @Autowired\n public ChatController(OCICohereChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var prompt = new Prompt(new UserMessage(message));\n return chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 6, "section_index": 7, "content_hash": "60a07310b13386e8f36491bb9e3c4252b8ea383af1f92d257f3fdb3aa1210617", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:42be14b10474c7b1e17273c34ccd306d098cfd276ab12f7d95cf9530b1e6ee76", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-oci-genai/src/main/java/org/springframework/ai/oci/cohere/OCICohereChatModel.java[OCICohereChatModel] implements the `ChatModel` and uses the OCI Java SDK to connect to the OCI GenAI service.\n\nAdd the `spring-ai-oci-genai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-oci-genai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-oci-genai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `OCICohereChatModel` and use it for text generations:\n\n[source,java]\n----\nvar CONFIG_FILE = Paths.get(System.getProperty(\"user.home\"), \".oci\", \"config\").toString();\nvar COMPARTMENT_ID = System.getenv(\"OCI_COMPARTMENT_ID\");\nvar MODEL_ID = System.getenv(\"OCI_CHAT_MODEL_ID\");\n\nConfigFileAuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(\n CONFIG_FILE,\n \"DEFAULT\"\n);\nvar genAi = GenerativeAiInferenceClient.builder()\n .region(Region.valueOf(\"us-chicago-1\"))\n .build(authProvider);\n\nvar chatModel = new OCICohereChatModel(genAi, OCICohereChatOptions.builder()\n .model(MODEL_ID)\n .compartment(COMPARTMENT_ID)\n .servingMode(\"on-demand\")\n .build());\n\nChatResponse response = chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `OCICohereChatOptions` provides the configuration information for the chat requests.\nThe `OCICohereChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc", "title": "OCI GenAI Cohere Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 6, "section_index": 8, "content_hash": "42be14b10474c7b1e17273c34ccd306d098cfd276ab12f7d95cf9530b1e6ee76", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/oci-genai/cohere-chat.adoc"}}
{"id": "sha256:bf0f8a3ca378252de8cd96dd50103076b994e83fb7db597ac68a015aecfbb18b", "content": "link:https://www.anthropic.com/[Anthropic Claude] is a family of foundational AI models that can be used in a variety of applications.\nFor developers and businesses, you can leverage the API access and build directly on top of link:https://www.anthropic.com/api[Anthropic's AI infrastructure].\n\nSpring AI supports the Anthropic link:https://docs.anthropic.com/claude/reference/messages_post[Messaging API] for sync and streaming text generations.\n\nTIP: Anthropic's Claude models are also available through Amazon Bedrock Converse.\nSpring AI provides dedicated xref:api/chat/bedrock-converse.adoc[Amazon Bedrock Converse Anthropic] client implementations as well.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Anthropic Chat", "heading_level": 1, "file_order": 7, "section_index": 0, "content_hash": "bf0f8a3ca378252de8cd96dd50103076b994e83fb7db597ac68a015aecfbb18b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:18b9f3c91d23b9dcd6986fa0575a6f7af3d743cda6291f0587969a3b9dcccbf1", "content": "You will need to create an API key on the Anthropic portal.\n\nCreate an account at https://console.anthropic.com/dashboard[Anthropic API dashboard] and generate the API key on the https://console.anthropic.com/settings/keys[Get API Keys] page.\n\nThe Spring AI project defines a configuration property named `spring.ai.anthropic.api-key` that you should set to the value of the `API Key` obtained from anthropic.com.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.anthropic.api-key=<your-anthropic-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n anthropic:\n api-key: ${ANTHROPIC_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport ANTHROPIC_API_KEY=<your-anthropic-api-key>\n----\n\nYou can also get this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"ANTHROPIC_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 7, "section_index": 1, "content_hash": "18b9f3c91d23b9dcd6986fa0575a6f7af3d743cda6291f0587969a3b9dcccbf1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:681f4e96b994269bab8a26a1dd652d6c30a80b1863c2a280b58586af3a6733f1", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 7, "section_index": 2, "content_hash": "681f4e96b994269bab8a26a1dd652d6c30a80b1863c2a280b58586af3a6733f1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:6639f42074684934afc1869188d8c8c6b275dee36eabe51d5f1d1c1e2647f71c", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Anthropic Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` file:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-anthropic</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-anthropic'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 7, "section_index": 3, "content_hash": "6639f42074684934afc1869188d8c8c6b275dee36eabe51d5f1d1c1e2647f71c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:e61055e79d13f67f825e6e8d14d74245e2c9c83238aa7e49a15f43b4d5d2c12f", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the Anthropic chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should NOT trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====\n\nNOTE: currently the retry policies are not applicable for the streaming API.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 7, "section_index": 4, "content_hash": "e61055e79d13f67f825e6e8d14d74245e2c9c83238aa7e49a15f43b4d5d2c12f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:3a647ee80091a01a9301707f9fc1b33fdf86281d47e3dc8c9c492316f3068bb0", "content": "The prefix `spring.ai.anthropic` is used as the property prefix that lets you connect to Anthropic.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.anthropic.base-url | The URL to connect to | https://api.anthropic.com\n| spring.ai.anthropic.completions-path | The path to append to the base URL. | `/v1/chat/completions`\n| spring.ai.anthropic.version | Anthropic API version | 2023-06-01\n| spring.ai.anthropic.api-key | The API Key | -\n| spring.ai.anthropic.beta-version | Enables new/experimental features. If set to `max-tokens-3-5-sonnet-2024-07-15`\nthe output tokens limit is increased from `4096` to `8192` tokens (for claude-3-5-sonnet only). | `tools-2024-04-04`\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 7, "section_index": 5, "content_hash": "3a647ee80091a01a9301707f9fc1b33fdf86281d47e3dc8c9c492316f3068bb0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:3b03cd523f46b5b0e63229bb4203af6bd555238f4a2431a9ac4f463f0a393611", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=anthropic (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match anthropic)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.anthropic.chat` is the property prefix that lets you configure the chat model implementation for Anthropic.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.anthropic.chat.enabled (Removed and no longer valid) | Enable Anthropic chat model. | true\n| spring.ai.model.chat | Enable Anthropic chat model. | anthropic\n| spring.ai.anthropic.chat.options.model | This is the Anthropic Chat model to use. Supports: `claude-sonnet-4-5`, `claude-opus-4-5`, `claude-haiku-4-5`, `claude-opus-4-1`, `claude-opus-4-0`, `claude-sonnet-4-0`, `claude-3-7-sonnet-latest`, `claude-3-5-sonnet-latest`, `claude-3-5-haiku-latest`, `claude-3-opus-latest`, `claude-3-haiku-20240307` | `claude-sonnet-4-5`\n| spring.ai.anthropic.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.anthropic.chat.options.max-tokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | 500\n| spring.ai.anthropic.chat.options.stop-sequence | Custom text sequences that will cause the model to stop generating. Our models will normally stop when they have naturally completed their turn, which will result in a response stop_reason of \"end_turn\". If you want the model to stop generating when it encounters custom strings of text, you can use the stop_sequences parameter. If the model encounters one of the custom sequences, the response stop_reason value will be \"stop_sequence\" and the response stop_sequence value will contain the matched stop sequence. | -\n| spring.ai.anthropic.chat.options.top-p | Use nucleus sampling. In nucleus sampling, we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified by top_p. You should either alter temperature or top_p, but not both. Recommended for advanced use cases only. You usually only need to use temperature. | -\n| spring.ai.anthropic.chat.options.top-k | Only sample from the top K options for each subsequent token. Used to remove \"long tail\" low probability responses. Learn more technical details here. Recommended for advanced use cases only. You usually only need to use temperature. | -\n| spring.ai.anthropic.chat.options.tool-names | List of tools, identified by their names, to enable for tool calling in a single prompt requests. Tools with those names must exist in the toolCallbacks registry. | -\n| spring.ai.anthropic.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.anthropic.chat.options.toolChoice | Controls which (if any) tool is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a tool. Specifying a particular tool via `{\"type: \"tool\", \"name\": \"my_tool\"}` forces the model to call that tool. `none` is the default when no functions are present. `auto` is the default if functions are present. | -\n| spring.ai.anthropic.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n| spring.ai.anthropic.chat.options.http-headers | Optional HTTP headers to be added to the chat completion request. | -\n|====\n\nTIP: For the latest list of model aliases and their descriptions, see the link:https://docs.anthropic.com/en/docs/about-claude/models/overview#model-aliases[official Anthropic model aliases documentation].\n\nTIP: All properties prefixed with `spring.ai.anthropic.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 7, "section_index": 6, "content_hash": "3b03cd523f46b5b0e63229bb4203af6bd555238f4a2431a9ac4f463f0a393611", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:b8998bd8e04f881da58ab0588f8e703ea5d3b8260e54948d8a2a718081630275", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/main/java/org/springframework/ai/anthropic/AnthropicChatOptions.java[AnthropicChatOptions.java] provides model configurations, such as the model to use, the temperature, the max token count, etc.\n\nOn start-up, the default options can be configured with the `AnthropicChatModel(api, options)` constructor or the `spring.ai.anthropic.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/main/java/org/springframework/ai/anthropic/AnthropicChatOptions.java[AnthropicChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 7, "section_index": 7, "content_hash": "b8998bd8e04f881da58ab0588f8e703ea5d3b8260e54948d8a2a718081630275", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:ec55af071d94d05f7c84afc09cad92cf0152ff3389031695626a560331f5783f", "content": "Anthropic's https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching[prompt caching feature] allows you to cache frequently used prompts to reduce costs and improve response times for repeated interactions.\nWhen you cache a prompt, subsequent identical requests can reuse the cached content, significantly reducing the number of input tokens processed.\n\n[NOTE]\n====\n*Supported Models*\n\nPrompt caching is currently supported on Claude Sonnet 4.5, Claude Opus 4.5, Claude Haiku 4.5, Claude Opus 4, Claude Sonnet 4, Claude Sonnet 3.7, Claude Sonnet 3.5, Claude Haiku 3.5, Claude Haiku 3, and Claude Opus 3.\n\n*Token Requirements*\n\nDifferent models have different minimum token thresholds for cache effectiveness:\n- Claude Sonnet 4: 1024+ tokens\n- Claude Haiku models: 2048+ tokens\n- Other models: 1024+ tokens\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Prompt Caching", "heading_level": 2, "file_order": 7, "section_index": 8, "content_hash": "ec55af071d94d05f7c84afc09cad92cf0152ff3389031695626a560331f5783f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:cb20eee8cf9e9f3e4eb4e7d188429912e0ad7f9199fa10fa45e8c9bda169f497", "content": "Spring AI provides strategic cache placement through the `AnthropicCacheStrategy` enum.\nEach strategy automatically places cache breakpoints at optimal locations while staying within Anthropic's 4-breakpoint limit.\n\n[cols=\"2,3,5\", stripes=even]\n|====\n| Strategy | Breakpoints Used | Use Case\n\n| `NONE`\n| 0\n| Disables prompt caching completely.\nUse when requests are one-off or content is too small to benefit from caching.\n\n| `SYSTEM_ONLY`\n| 1\n| Caches system message content.\nTools are cached implicitly via Anthropic's automatic ~20-block lookback mechanism.\nUse when system prompts are large and stable with fewer than 20 tools.\n\n| `TOOLS_ONLY`\n| 1\n| Caches tool definitions only. System messages remain uncached and are processed fresh on each request.\nUse when tool definitions are large and stable (5000+ tokens) but system prompts change frequently or vary per tenant/context.\n\n| `SYSTEM_AND_TOOLS`\n| 2\n| Caches both tool definitions (breakpoint 1) and system message (breakpoint 2) explicitly.\nUse when you have 20+ tools (beyond automatic lookback) or want deterministic caching of both components.\nSystem changes don't invalidate tool cache.\n\n| `CONVERSATION_HISTORY`\n| 1-4\n| Caches entire conversation history up to the current user question.\nUse for multi-turn conversations with chat memory where conversation history grows over time.\n|====\n\nIMPORTANT: Due to Anthropic's cascade invalidation, changing tool definitions will invalidate ALL downstream cache breakpoints (system, messages).\nTool stability is critical when using `SYSTEM_AND_TOOLS` or `CONVERSATION_HISTORY` strategies.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Cache Strategies", "heading_level": 3, "file_order": 7, "section_index": 9, "content_hash": "cb20eee8cf9e9f3e4eb4e7d188429912e0ad7f9199fa10fa45e8c9bda169f497", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:7137a4a3a556b0343ab61dab3847f7200d11a3175aed731749170f6a5db9a6e4", "content": "Enable prompt caching by setting `cacheOptions` on `AnthropicChatOptions` and choosing a `strategy`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Enabling Prompt Caching", "heading_level": 3, "file_order": 7, "section_index": 10, "content_hash": "7137a4a3a556b0343ab61dab3847f7200d11a3175aed731749170f6a5db9a6e4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:f5c370efee6ac2b863637661c06f2bd65e2686924167f00bbb6991ba988ad2e2", "content": "Best for: Stable system prompts with <20 tools (tools cached implicitly via automatic lookback).\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a helpful AI assistant with extensive knowledge...\"),\n new UserMessage(\"What is machine learning?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "System-Only Caching", "heading_level": 4, "file_order": 7, "section_index": 11, "content_hash": "f5c370efee6ac2b863637661c06f2bd65e2686924167f00bbb6991ba988ad2e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:41a57f6164952dcf60180afc6c3d1bb1f799c6fb43a1c28aac45863b539bb87c", "content": "Best for: Large stable tool sets with dynamic system prompts (multi-tenant apps, A/B testing).\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a \" + persona + \" assistant...\"), // Dynamic per-tenant\n new UserMessage(\"What's the weather like in San Francisco?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.TOOLS_ONLY)\n .build())\n .toolCallbacks(weatherToolCallback) // Large tool set cached\n .maxTokens(500)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tools-Only Caching", "heading_level": 4, "file_order": 7, "section_index": 12, "content_hash": "41a57f6164952dcf60180afc6c3d1bb1f799c6fb43a1c28aac45863b539bb87c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:9fc28a8dcde3a061d52452c32f9d2664b737d64dfcd19b724242c8e017dec73d", "content": "Best for: 20+ tools (beyond automatic lookback) or when both components should be cached independently.\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a weather analysis assistant...\"),\n new UserMessage(\"What's the weather like in San Francisco?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_AND_TOOLS)\n .build())\n .toolCallbacks(weatherToolCallback) // 20+ tools\n .maxTokens(500)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "System and Tools Caching", "heading_level": 4, "file_order": 7, "section_index": 13, "content_hash": "9fc28a8dcde3a061d52452c32f9d2664b737d64dfcd19b724242c8e017dec73d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:aff46918b24b4a1b0f826713942242b4c51453833ae29514bda5ec5f2c0b90e0", "content": "[source,java]\n----\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultSystem(\"You are a personalized career counselor...\")\n .defaultAdvisors(MessageChatMemoryAdvisor.builder(chatMemory)\n .conversationId(conversationId)\n .build())\n .build();\n\nString response = chatClient.prompt()\n .user(\"What career advice would you give me?\")\n .options(AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.CONVERSATION_HISTORY)\n .build())\n .maxTokens(500)\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Conversation History Caching", "heading_level": 4, "file_order": 7, "section_index": 14, "content_hash": "aff46918b24b4a1b0f826713942242b4c51453833ae29514bda5ec5f2c0b90e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:e689d1c535a49fef31decc57c89125bcd9b256cccfca1d9001a6d3e82188a73b", "content": "[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .system(\"You are an expert document analyst...\")\n .user(\"Analyze this large document: \" + document)\n .options(AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using ChatClient Fluent API", "heading_level": 4, "file_order": 7, "section_index": 15, "content_hash": "e689d1c535a49fef31decc57c89125bcd9b256cccfca1d9001a6d3e82188a73b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:21bd70bead0308d23fa4ee0eba0ec75ae5b7b50e105035dd950702ddfa91da79", "content": "By default, cached content uses a 5-minute TTL.\nYou can set a 1-hour TTL for specific message types.\nWhen 1-hour TTL is used, Spring AI automatically sets the required Anthropic beta header.\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(new SystemMessage(largeSystemPrompt)),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .messageTypeTtl(MessageType.SYSTEM, AnthropicCacheTtl.ONE_HOUR)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n----\n\nNOTE: Extended TTL uses Anthropic beta feature `extended-cache-ttl-2025-04-11`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Per-Message TTL (5m or 1h)", "heading_level": 4, "file_order": 7, "section_index": 16, "content_hash": "21bd70bead0308d23fa4ee0eba0ec75ae5b7b50e105035dd950702ddfa91da79", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:56533388b949d6b8c6333f15361b8ebc1402027a8b36ee0bcb7a7e2898d17087", "content": "Control when cache breakpoints are used by setting minimum content lengths and an optional token-based length function:\n\n[source,java]\n----\nAnthropicCacheOptions cache = AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.CONVERSATION_HISTORY)\n .messageTypeMinContentLength(MessageType.SYSTEM, 1024)\n .messageTypeMinContentLength(MessageType.USER, 1024)\n .messageTypeMinContentLength(MessageType.ASSISTANT, 1024)\n .contentLengthFunction(text -> MyTokenCounter.count(text))\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(/* messages */),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(cache)\n .build()\n )\n);\n----\n\nNOTE: Tool Definitions are always considered for caching if `SYSTEM_AND_TOOLS` strategy is used, regardless of content length.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Cache Eligibility Filters", "heading_level": 4, "file_order": 7, "section_index": 17, "content_hash": "56533388b949d6b8c6333f15361b8ebc1402027a8b36ee0bcb7a7e2898d17087", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:5bcdbaa895b8e19b423aaf9814c0eabe87913f0ce7e2333da5355e9f0e72a3f8", "content": "Here's a complete example demonstrating prompt caching with cost tracking:\n\n[source,java]\n----\nString largeSystemPrompt = \"You are an expert software architect specializing in distributed systems...\";\n\nChatResponse firstResponse = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(largeSystemPrompt),\n new UserMessage(\"What is microservices architecture?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n\nAnthropicApi.Usage firstUsage = (AnthropicApi.Usage) firstResponse.getMetadata()\n .getUsage().getNativeUsage();\n\nSystem.out.println(\"Cache creation tokens: \" + firstUsage.cacheCreationInputTokens());\nSystem.out.println(\"Cache read tokens: \" + firstUsage.cacheReadInputTokens());\n\nChatResponse secondResponse = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(largeSystemPrompt),\n new UserMessage(\"What are the benefits of event sourcing?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n\nAnthropicApi.Usage secondUsage = (AnthropicApi.Usage) secondResponse.getMetadata()\n .getUsage().getNativeUsage();\n\nSystem.out.println(\"Cache creation tokens: \" + secondUsage.cacheCreationInputTokens()); // Should be 0\nSystem.out.println(\"Cache read tokens: \" + secondUsage.cacheReadInputTokens()); // Should be > 0\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Usage Example", "heading_level": 3, "file_order": 7, "section_index": 18, "content_hash": "5bcdbaa895b8e19b423aaf9814c0eabe87913f0ce7e2333da5355e9f0e72a3f8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:af4746ae18c7b0301b043b41b77556a8ead637ed534cfee687e73eaf335c760d", "content": "The `Usage` record provides detailed information about cache-related token consumption.\nTo access Anthropic-specific cache metrics, use the `getNativeUsage()` method:\n\n[source,java]\n----\nAnthropicApi.Usage usage = (AnthropicApi.Usage) response.getMetadata()\n .getUsage().getNativeUsage();\n----\n\nCache-specific metrics include:\n\n* `cacheCreationInputTokens()`: Returns the number of tokens used when creating a cache entry\n* `cacheReadInputTokens()`: Returns the number of tokens read from an existing cache entry\n\nWhen you first send a cached prompt:\n- `cacheCreationInputTokens()` will be greater than 0\n- `cacheReadInputTokens()` will be 0\n\nWhen you send the same cached prompt again:\n- `cacheCreationInputTokens()` will be 0\n- `cacheReadInputTokens()` will be greater than 0", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Token Usage Tracking", "heading_level": 3, "file_order": 7, "section_index": 19, "content_hash": "af4746ae18c7b0301b043b41b77556a8ead637ed534cfee687e73eaf335c760d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:21c9ffb6ae81bd57224ea03931325d32ce41b85eed08cf6f027ac72df74fdbf5", "content": "Analyze large legal contracts or compliance documents efficiently by caching document content across multiple questions:\n\n[source,java]\n----\nString legalContract = loadDocument(\"merger-agreement.pdf\"); // ~3000 tokens\n\nString legalSystemPrompt = \"You are an expert legal analyst specializing in corporate law. \" +\n \"Analyze the following contract and provide precise answers about terms, obligations, and risks: \" +\n legalContract;\n\nChatResponse riskAnalysis = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(legalSystemPrompt),\n new UserMessage(\"What are the key termination clauses and associated penalties?\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(1000)\n .build()\n )\n);\n\nChatResponse obligationAnalysis = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(legalSystemPrompt), // Same content - cache hit\n new UserMessage(\"List all financial obligations and payment schedules.\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(1000)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Legal Document Analysis", "heading_level": 4, "file_order": 7, "section_index": 20, "content_hash": "21c9ffb6ae81bd57224ea03931325d32ce41b85eed08cf6f027ac72df74fdbf5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:4e82fd311fe957f59c62f278179954f3169b6997b94ec1a5ee19aa1abea2148e", "content": "Process multiple code files with consistent review criteria while caching the review guidelines:\n\n[source,java]\n----\nString reviewGuidelines = \"\"\"\n You are a senior software engineer conducting code reviews. Apply these criteria:\n - Security vulnerabilities and best practices\n - Performance optimizations and memory usage\n - Code maintainability and readability\n - Testing coverage and edge cases\n - Design patterns and architecture compliance\n \"\"\";\n\nList<String> codeFiles = Arrays.asList(\n \"UserService.java\", \"PaymentController.java\", \"SecurityConfig.java\"\n);\n\nList<String> reviews = new ArrayList<>();\n\nfor (String filename : codeFiles) {\n String sourceCode = loadSourceFile(filename);\n\n ChatResponse review = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(reviewGuidelines), // Cached across all reviews\n new UserMessage(\"Review this \" + filename + \" code:\\n\\n\" + sourceCode)\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(800)\n .build()\n )\n );\n\n reviews.add(review.getResult().getOutput().getText());\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Batch Code Review", "heading_level": 4, "file_order": 7, "section_index": 21, "content_hash": "4e82fd311fe957f59c62f278179954f3169b6997b94ec1a5ee19aa1abea2148e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:eb00df3eee940652bda686f2a1b8f35c281c249ae81242376293d441abf037e6", "content": "Build a multi-tenant application where tools are shared but system prompts are customized per tenant:\n\n[source,java]\n----\nList<FunctionCallback> sharedTools = Arrays.asList(\n weatherToolCallback, // ~500 tokens\n calendarToolCallback, // ~800 tokens\n emailToolCallback, // ~700 tokens\n analyticsToolCallback, // ~600 tokens\n reportingToolCallback, // ~900 tokens\n // ... 20+ more tools, totaling 5000+ tokens\n);\n\n@Service\npublic class MultiTenantAIService {\n\n public String handleTenantRequest(String tenantId, String userQuery) {\n // Get tenant-specific configuration\n TenantConfig config = tenantRepository.findById(tenantId);\n\n // Dynamic system prompt per tenant\n String tenantSystemPrompt = String.format(\"\"\"\n You are %s's AI assistant. Company values: %s.\n Brand voice: %s. Compliance requirements: %s.\n \"\"\", config.companyName(), config.values(),\n config.brandVoice(), config.compliance());\n\n ChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(tenantSystemPrompt), // Different per tenant, NOT cached\n new UserMessage(userQuery)\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.TOOLS_ONLY) // Cache tools only\n .build())\n .toolCallbacks(sharedTools) // Cached once, shared across all tenants\n .maxTokens(800)\n .build()\n )\n );\n\n return response.getResult().getOutput().getText();\n }\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Multi-Tenant SaaS with Shared Tools", "heading_level": 4, "file_order": 7, "section_index": 22, "content_hash": "eb00df3eee940652bda686f2a1b8f35c281c249ae81242376293d441abf037e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:bebd9c97bc7b73a5c1fdf5bfb02cc2daa0ce12cff27c449f09989e636ea81bfb", "content": "Create a customer support system that caches your product knowledge base for consistent, accurate responses:\n\n[source,java]\n----\nString knowledgeBase = \"\"\"\n PRODUCT DOCUMENTATION:\n - API endpoints and authentication methods\n - Common troubleshooting procedures\n - Billing and subscription details\n - Integration guides and examples\n - Known issues and workarounds\n \"\"\" + loadProductDocs(); // ~2500 tokens\n\n@Service\npublic class CustomerSupportService {\n\n public String handleCustomerQuery(String customerQuery, String customerId) {\n ChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a helpful customer support agent. \" +\n \"Use this knowledge base to provide accurate solutions: \" + knowledgeBase),\n new UserMessage(\"Customer \" + customerId + \" asks: \" + customerQuery)\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(600)\n .build()\n )\n );\n\n return response.getResult().getOutput().getText();\n }\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Customer Support with Knowledge Base", "heading_level": 4, "file_order": 7, "section_index": 23, "content_hash": "bebd9c97bc7b73a5c1fdf5bfb02cc2daa0ce12cff27c449f09989e636ea81bfb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:83e8076e28b9f95bd064da04ccd90c14c4d022b8f9461ea1186a040416abc110", "content": "1. **Choose the Right Strategy**:\n - Use `SYSTEM_ONLY` for stable system prompts with <20 tools (tools cached implicitly via automatic lookback)\n - Use `TOOLS_ONLY` for large stable tool sets (5000+ tokens) with dynamic system prompts (multi-tenant, A/B testing)\n - Use `SYSTEM_AND_TOOLS` when you have 20+ tools (beyond automatic lookback) or want both cached independently\n - Use `CONVERSATION_HISTORY` with ChatClient memory for multi-turn conversations\n - Use `NONE` to explicitly disable caching\n\n2. **Understand Cascade Invalidation**: Anthropic's cache hierarchy (`tools → system → messages`) means changes flow downward:\n - Changing **tools** invalidates: tools + system + messages (all caches) ❌❌❌\n - Changing **system** invalidates: system + messages (tools cache remains valid) ✅❌❌\n - Changing **messages** invalidates: messages only (tools and system caches remain valid) ✅✅❌\n\n **Tool stability is critical** when using `SYSTEM_AND_TOOLS` or `CONVERSATION_HISTORY` strategies.\n\n3. **SYSTEM_AND_TOOLS Independence**: With `SYSTEM_AND_TOOLS`, changing the system message does NOT invalidate the tool cache, allowing efficient reuse of cached tools even when system prompts vary.\n\n4. **Meet Token Requirements**: Focus on caching content that meets the minimum token requirements (1024+ tokens for Sonnet 4, 2048+ for Haiku models).\n\n5. **Reuse Identical Content**: Caching works best with exact matches of prompt content. Even small changes will require a new cache entry.\n\n6. **Monitor Token Usage**: Use the cache usage statistics to track cache effectiveness:\n ```java\n AnthropicApi.Usage usage = (AnthropicApi.Usage) response.getMetadata().getUsage().getNativeUsage();\n if (usage != null) {\n System.out.println(\"Cache creation: \" + usage.cacheCreationInputTokens());\n System.out.println(\"Cache read: \" + usage.cacheReadInputTokens());\n }\n ```\n\n7. **Strategic Cache Placement**: The implementation automatically places cache breakpoints at optimal locations based on your chosen strategy, ensuring compliance with Anthropic's 4-breakpoint limit.\n\n8. **Cache Lifetime**: Default TTL is 5 minutes; set 1-hour TTL per message type via `messageTypeTtl(...)`. Each cache access resets the timer.\n\n9. **Tool Caching Limitations**: Be aware that tool-based interactions may not provide cache usage metadata in the response.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Best Practices", "heading_level": 3, "file_order": 7, "section_index": 24, "content_hash": "83e8076e28b9f95bd064da04ccd90c14c4d022b8f9461ea1186a040416abc110", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:6671b15d229e2bccf8be0f8aeb761ad4f9d4c9bac62e04dfa5740445f8682a75", "content": "The prompt caching implementation in Spring AI follows these key design principles:\n\n1. **Strategic Cache Placement**: Cache breakpoints are automatically placed at optimal locations based on the chosen strategy, ensuring compliance with Anthropic's 4-breakpoint limit.\n - `CONVERSATION_HISTORY` places cache breakpoints on: tools (if present), system message, and the last user message\n - This enables Anthropic's prefix matching to incrementally cache the growing conversation history\n - Each turn builds on the previous cached prefix, maximizing cache reuse\n\n2. **Provider Portability**: Cache configuration is done through `AnthropicChatOptions` rather than individual messages, preserving compatibility when switching between different AI providers.\n\n3. **Thread Safety**: The cache breakpoint tracking is implemented with thread-safe mechanisms to handle concurrent requests correctly.\n\n4. **Automatic Content Ordering**: The implementation ensures proper on-the-wire ordering of JSON content blocks and cache controls according to Anthropic's API requirements.\n\n5. **Aggregate Eligibility Checking**: For `CONVERSATION_HISTORY`, the implementation considers all message types (user, assistant, tool) within the last ~20 content blocks when determining if the combined content meets the minimum token threshold for caching.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Implementation Details", "heading_level": 3, "file_order": 7, "section_index": 25, "content_hash": "6671b15d229e2bccf8be0f8aeb761ad4f9d4c9bac62e04dfa5740445f8682a75", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2ce0c264a8dd965affdbe9e3de121ae0abb0da53902d9a93101eef99770260ed", "content": "The current cache strategies are designed to handle **90% of common use cases** effectively. For applications requiring more granular control, future enhancements may include:\n\n- **Message-level cache control** for fine-grained breakpoint placement\n- **Multi-block content caching** within individual messages\n- **Advanced cache boundary selection** for complex tool scenarios\n- **Mixed TTL strategies** for optimized cache hierarchies\n\nThese enhancements will maintain full backward compatibility while unlocking Anthropic's complete prompt caching capabilities for specialized use cases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Future Enhancements", "heading_level": 3, "file_order": 7, "section_index": 26, "content_hash": "2ce0c264a8dd965affdbe9e3de121ae0abb0da53902d9a93101eef99770260ed", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:981b15cd6c78c2660756fa0dd84409b4741e28c32f5661ec32b3c2fc8a85a8f2", "content": "Anthropic Claude models support a \"thinking\" feature that allows the model to show its reasoning process before providing a final answer. This feature enables more transparent and detailed problem-solving, particularly for complex questions that require step-by-step reasoning.\n\n[NOTE]\n====\n*Supported Models*\n\nThe thinking feature is supported by the following Claude models:\n\n* Claude 4 models (`claude-opus-4-20250514`, `claude-sonnet-4-20250514`)\n* Claude 3.7 Sonnet (`claude-3-7-sonnet-20250219`)\n\n*Model capabilities:*\n\n* *Claude 3.7 Sonnet*: Returns full thinking output. Behavior is consistent but does not support summarized or interleaved thinking.\n* *Claude 4 models*: Support summarized thinking, interleaved thinking, and enhanced tool integration.\n\nAPI request structure is the same across all supported models, but output behavior varies.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Thinking", "heading_level": 2, "file_order": 7, "section_index": 27, "content_hash": "981b15cd6c78c2660756fa0dd84409b4741e28c32f5661ec32b3c2fc8a85a8f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:30d4ad89d0df920a5874f03363bc32eef6ba33eea797a3f2fba51522548292df", "content": "To enable thinking on any supported Claude model, include the following configuration in your request:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Thinking Configuration", "heading_level": 3, "file_order": 7, "section_index": 28, "content_hash": "30d4ad89d0df920a5874f03363bc32eef6ba33eea797a3f2fba51522548292df", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:d9b35ad9865cf38455d31276f0c9777d2a0931751ed1ad9509441a1e948899c4", "content": "1. **Add the `thinking` object**:\n- `\"type\": \"enabled\"`\n- `budget_tokens`: Token limit for reasoning (recommend starting at 1024)\n\n2. **Token budget rules**:\n- `budget_tokens` must typically be less than `max_tokens`\n- Claude may use fewer tokens than allocated\n- Larger budgets increase depth of reasoning but may impact latency\n- When using tool use with interleaved thinking (Claude 4 only), this constraint is relaxed, but not yet supported in Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Required Configuration", "heading_level": 4, "file_order": 7, "section_index": 29, "content_hash": "d9b35ad9865cf38455d31276f0c9777d2a0931751ed1ad9509441a1e948899c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:0ad5486b082c26a077847ecbd3fa94e14bee23bb6bad739f0a57aa2cfa7838f8", "content": "* **Claude 3.7** returns full thinking content in the response\n* **Claude 4** returns a *summarized* version of the model's internal reasoning to reduce latency and protect sensitive content\n* **Thinking tokens are billable** as part of output tokens (even if not all are visible in response)\n* **Interleaved Thinking** is only available on Claude 4 models and requires the beta header `interleaved-thinking-2025-05-14`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Key Considerations", "heading_level": 4, "file_order": 7, "section_index": 30, "content_hash": "0ad5486b082c26a077847ecbd3fa94e14bee23bb6bad739f0a57aa2cfa7838f8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:dc664ddc1aa2406f413a3e88ddec4143cc2634f22bd7a76e5b5a674f45564b39", "content": "Claude 4 models support interleaved thinking with tool use, allowing the model to reason between tool calls.\n\n[NOTE]\n====\nThe current Spring AI implementation supports basic thinking and tool use separately, but does not yet support interleaved thinking with tool use (where thinking continues across multiple tool calls).\n====\n\nFor details on interleaved thinking with tool use, see the https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#extended-thinking-with-tool-use[Anthropic documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tool Integration and Interleaved Thinking", "heading_level": 4, "file_order": 7, "section_index": 31, "content_hash": "dc664ddc1aa2406f413a3e88ddec4143cc2634f22bd7a76e5b5a674f45564b39", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:d47a75b0d037aa9825d19e29086b57c470943a4fbdfa7534dd1d70000f823500", "content": "Here's how to enable thinking in a non-streaming request using the ChatClient API:\n\n[source,java]\n----\nChatClient chatClient = ChatClient.create(chatModel);\n\nChatResponse response = chatClient.prompt()\n .options(AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(1.0) // Temperature should be set to 1 when thinking is enabled\n .maxTokens(8192)\n .thinking(AnthropicApi.ThinkingType.ENABLED, 2048) // Must be ≥1024 && < max_tokens\n .build())\n .user(\"Are there an infinite number of prime numbers such that n mod 4 == 3?\")\n .call()\n .chatResponse();\n\nChatResponse response4 = chatClient.prompt()\n .options(AnthropicChatOptions.builder()\n .model(\"claude-opus-4-0\")\n .maxTokens(8192)\n // No explicit thinking configuration needed\n .build())\n .user(\"Are there an infinite number of prime numbers such that n mod 4 == 3?\")\n .call()\n .chatResponse();\n\nfor (Generation generation : response.getResults()) {\n AssistantMessage message = generation.getOutput();\n if (message.getText() != null) {\n // Regular text response\n System.out.println(\"Text response: \" + message.getText());\n }\n else if (message.getMetadata().containsKey(\"signature\")) {\n // Thinking content\n System.out.println(\"Thinking: \" + message.getMetadata().get(\"thinking\"));\n System.out.println(\"Signature: \" + message.getMetadata().get(\"signature\"));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Non-streaming Example", "heading_level": 3, "file_order": 7, "section_index": 32, "content_hash": "d47a75b0d037aa9825d19e29086b57c470943a4fbdfa7534dd1d70000f823500", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:710b056e367968dd51f032057951eb051e31e0d9acf1b2764d56e395dacd824e", "content": "You can also use thinking with streaming responses:\n\n[source,java]\n----\nChatClient chatClient = ChatClient.create(chatModel);\n\nFlux<ChatResponse> responseFlux = chatClient.prompt()\n .options(AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(1.0)\n .maxTokens(8192)\n .thinking(AnthropicApi.ThinkingType.ENABLED, 2048)\n .build())\n .user(\"Are there an infinite number of prime numbers such that n mod 4 == 3?\")\n .stream();\n\nFlux<ChatResponse> responseFlux4 = chatClient.prompt()\n .options(AnthropicChatOptions.builder()\n .model(\"claude-opus-4-0\")\n .maxTokens(8192)\n // No explicit thinking configuration needed\n .build())\n .user(\"Are there an infinite number of prime numbers such that n mod 4 == 3?\")\n .stream();\n\nString textContent = responseFlux.collectList()\n .block()\n .stream()\n .map(ChatResponse::getResults)\n .flatMap(List::stream)\n .map(Generation::getOutput)\n .map(AssistantMessage::getText)\n .filter(text -> text != null && !text.isBlank())\n .collect(Collectors.joining());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Streaming Example", "heading_level": 3, "file_order": 7, "section_index": 33, "content_hash": "710b056e367968dd51f032057951eb051e31e0d9acf1b2764d56e395dacd824e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:d3f35013d1d499f76d8b53f649c01b6e5d66268a72c759b83caa451297ce5647", "content": "Claude 4 models integrate thinking and tool use capabilities:\n\n* *Claude 3.7 Sonnet*: Supports both thinking and tool use, but they operate separately and require more explicit configuration\n* *Claude 4 models*: Natively interleave thinking and tool use, providing deeper reasoning during tool interactions", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tool Use Integration", "heading_level": 3, "file_order": 7, "section_index": 34, "content_hash": "d3f35013d1d499f76d8b53f649c01b6e5d66268a72c759b83caa451297ce5647", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:315701a5decfa3fb64effc6166e206d33696bf9bc1285c4232cf6aee962b78c9", "content": "The thinking feature provides several benefits:\n\n1. **Transparency**: See the model's reasoning process and how it arrived at its conclusion\n2. **Debugging**: Identify where the model might be making logical errors\n3. **Education**: Use the step-by-step reasoning as a teaching tool\n4. **Complex Problem Solving**: Better results on math, logic, and reasoning tasks\n\nNote that enabling thinking requires a higher token budget, as the thinking process itself consumes tokens from your allocation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Benefits of Using Thinking", "heading_level": 3, "file_order": 7, "section_index": 35, "content_hash": "315701a5decfa3fb64effc6166e206d33696bf9bc1285c4232cf6aee962b78c9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:db8ca62f1572e639cbbadc35925cd2d1b7096978513489e5e0d01909fc963f3d", "content": "You can register custom Java Tools with the `AnthropicChatModel` and have the Anthropic Claude model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tool/Function Calling", "heading_level": 2, "file_order": 7, "section_index": 36, "content_hash": "db8ca62f1572e639cbbadc35925cd2d1b7096978513489e5e0d01909fc963f3d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:1302c437ba25fa60c854ab339ec0c943e3e0b8694a92b207936b69bb8e1be1d1", "content": "The `tool_choice` parameter allows you to control how the model uses the provided tools. This feature gives you fine-grained control over tool execution behavior.\n\nFor complete API details, see the https://docs.anthropic.com/en/api/messages#body-tool-choice[Anthropic tool_choice documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tool Choice", "heading_level": 3, "file_order": 7, "section_index": 37, "content_hash": "1302c437ba25fa60c854ab339ec0c943e3e0b8694a92b207936b69bb8e1be1d1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:7a006c2e8d5dad0bc543518cddb6fbb8daa4e1d6295a64222f680a79d382d6bc", "content": "Spring AI provides four tool choice strategies through the `AnthropicApi.ToolChoice` interface:\n\n* **`ToolChoiceAuto`** (default): The model automatically decides whether to use tools or respond with text\n* **`ToolChoiceAny`**: The model must use at least one of the available tools\n* **`ToolChoiceTool`**: The model must use a specific tool by name\n* **`ToolChoiceNone`**: The model cannot use any tools", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Tool Choice Options", "heading_level": 4, "file_order": 7, "section_index": 38, "content_hash": "7a006c2e8d5dad0bc543518cddb6fbb8daa4e1d6295a64222f680a79d382d6bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:c941fcb3448cb53f6a664f4d1268219d0e3102f938c0a5ff74da1545d4fb050d", "content": "All tool choice options (except `ToolChoiceNone`) support a `disableParallelToolUse` parameter. When set to `true`, the model will output at most one tool use.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Disabling Parallel Tool Use", "heading_level": 4, "file_order": 7, "section_index": 39, "content_hash": "c941fcb3448cb53f6a664f4d1268219d0e3102f938c0a5ff74da1545d4fb050d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:133c3bb13042e7c96e378dc7bd133ba1b87bf61abf2e3d09e9976d79fd2ead13", "content": "Let the model decide whether to use tools:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather in San Francisco?\",\n AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceAuto())\n .toolCallbacks(weatherToolCallback)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Auto Mode (Default Behavior)", "heading_level": 5, "file_order": 7, "section_index": 40, "content_hash": "133c3bb13042e7c96e378dc7bd133ba1b87bf61abf2e3d09e9976d79fd2ead13", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:b898bebe12f18f6537c9d602d0c00c7bb22ecd4e68743c0f22035ef657e70e5e", "content": "Require the model to use at least one tool:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather?\",\n AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceAny())\n .toolCallbacks(weatherToolCallback, calculatorToolCallback)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Force Tool Use (Any)", "heading_level": 5, "file_order": 7, "section_index": 41, "content_hash": "b898bebe12f18f6537c9d602d0c00c7bb22ecd4e68743c0f22035ef657e70e5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:f1748a3780ec7dbd82485d80eb6da0432892f6e1a56e7c433d9e3591f9340339", "content": "Require the model to use a specific tool by name:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather in San Francisco?\",\n AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceTool(\"get_weather\"))\n .toolCallbacks(weatherToolCallback, calculatorToolCallback)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Force Specific Tool", "heading_level": 5, "file_order": 7, "section_index": 42, "content_hash": "f1748a3780ec7dbd82485d80eb6da0432892f6e1a56e7c433d9e3591f9340339", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:e59a753cef0dae667e420cbf6055caabe8c1e969467e541150d2c8f7db7acadb", "content": "Prevent the model from using any tools:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather in San Francisco?\",\n AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceNone())\n .toolCallbacks(weatherToolCallback)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Disable Tool Use", "heading_level": 5, "file_order": 7, "section_index": 43, "content_hash": "e59a753cef0dae667e420cbf6055caabe8c1e969467e541150d2c8f7db7acadb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:cb18b0b711adb2986b2dae298e03dab0eb2074d9249b84d0f2cb4c4e7f62d710", "content": "Force the model to use only one tool at a time:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather in San Francisco and what's 2+2?\",\n AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceAuto(true)) // disableParallelToolUse = true\n .toolCallbacks(weatherToolCallback, calculatorToolCallback)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Disable Parallel Tool Use", "heading_level": 5, "file_order": 7, "section_index": 44, "content_hash": "cb18b0b711adb2986b2dae298e03dab0eb2074d9249b84d0f2cb4c4e7f62d710", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:e03aca4e9b99de94ad2d4146255b17bc98d7643c5815e77e2425ae1d7aa1dda7", "content": "You can also use tool choice with the fluent ChatClient API:\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"What's the weather in San Francisco?\")\n .options(AnthropicChatOptions.builder()\n .toolChoice(new AnthropicApi.ToolChoiceTool(\"get_weather\"))\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using ChatClient API", "heading_level": 4, "file_order": 7, "section_index": 45, "content_hash": "e03aca4e9b99de94ad2d4146255b17bc98d7643c5815e77e2425ae1d7aa1dda7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:4cf65522452166032ae61c8a26174771d7d8efbf722ca9d6dd242ba1ed3027b2", "content": "* **Validation**: Use `ToolChoiceTool` to ensure a specific tool is called for critical operations\n* **Efficiency**: Use `ToolChoiceAny` when you know a tool must be used to avoid unnecessary text generation\n* **Control**: Use `ToolChoiceNone` to temporarily disable tool access while keeping tool definitions registered\n* **Sequential Processing**: Use `disableParallelToolUse` to force sequential tool execution for dependent operations", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Use Cases", "heading_level": 4, "file_order": 7, "section_index": 46, "content_hash": "4cf65522452166032ae61c8a26174771d7d8efbf722ca9d6dd242ba1ed3027b2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:27496ea7d755276def5868840f963ebbbcef828ea5fb6071010c75e1b905b0e9", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, pdf, images, data formats.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 7, "section_index": 47, "content_hash": "27496ea7d755276def5868840f963ebbbcef828ea5fb6071010c75e1b905b0e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:855f6a4cd5a0fc527c9431ee2be0d5e5ed08132d4e441e253f83f1d771ac1ceb", "content": "Currently, Anthropic Claude 3 supports the `base64` source type for `images`, and the `image/jpeg`, `image/png`, `image/gif`, and `image/webp` media types.\nCheck the link:https://docs.anthropic.com/claude/docs/vision[Vision guide] for more information.\nAnthropic Claude 3.5 Sonnet also supports the `pdf` source type for `application/pdf` files.\n\nSpring AI's `Message` interface supports multimodal AI models by introducing the Media type.\nThis type contains data and information about media attachments in messages, using Spring's `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a simple code example extracted from https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/test/java/org/springframework/ai/anthropic/AnthropicChatModelIT.java[AnthropicChatModelIT.java], demonstrating the combination of user text with an image.\n\n[source,java]\n----\nvar imageData = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n List.of(new Media(MimeTypeUtils.IMAGE_PNG, this.imageData)));\n\nChatResponse response = chatModel.call(new Prompt(List.of(this.userMessage)));\n\nlogger.info(response.getResult().getOutput().getText());\n----\n\nIt takes as an input the `multimodal.test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generates a response something like:\n\n----\nThe image shows a close-up view of a wire fruit basket containing several pieces of fruit.\n...\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Images", "heading_level": 3, "file_order": 7, "section_index": 48, "content_hash": "855f6a4cd5a0fc527c9431ee2be0d5e5ed08132d4e441e253f83f1d771ac1ceb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:a377661c0f53ef8913bc5efca465915e2dc38dea386f259c25b4d4ae7c4a068f", "content": "Starting with Sonnet 3.5 https://docs.anthropic.com/en/docs/build-with-claude/pdf-support[PDF support (beta)] is provided.\nUse the `application/pdf` media type to attach a PDF file to the message:\n\n[source,java]\n----\nvar pdfData = new ClassPathResource(\"/spring-ai-reference-overview.pdf\");\n\nvar userMessage = new UserMessage(\n \"You are a very professional document summarization specialist. Please summarize the given document.\",\n List.of(new Media(new MimeType(\"application\", \"pdf\"), pdfData)));\n\nvar response = this.chatModel.call(new Prompt(List.of(userMessage)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "PDF", "heading_level": 3, "file_order": 7, "section_index": 49, "content_hash": "a377661c0f53ef8913bc5efca465915e2dc38dea386f259c25b4d4ae7c4a068f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:c3e7de3da348b03c0da5c1dca428794fa52c31cf514d066f5f759be25ff52f25", "content": "Anthropic's https://docs.anthropic.com/en/docs/build-with-claude/citations[Citations API] allows Claude to reference specific parts of provided documents when generating responses.\nWhen citation documents are included in a prompt, Claude can cite the source material, and citation metadata (character ranges, page numbers, or content blocks) is returned in the response metadata.\n\nCitations help improve:\n\n* **Accuracy verification**: Users can verify Claude's responses against source material\n* **Transparency**: See exactly which parts of documents informed the response\n* **Compliance**: Meet requirements for source attribution in regulated industries\n* **Trust**: Build confidence by showing where information came from\n\n[NOTE]\n====\n*Supported Models*\n\nCitations are supported on Claude 3.7 Sonnet and Claude 4 models (Opus and Sonnet).\n\n*Document Types*\n\nThree types of citation documents are supported:\n\n* **Plain Text**: Text content with character-level citations\n* **PDF**: PDF documents with page-level citations\n* **Custom Content**: User-defined content blocks with block-level citations\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Citations", "heading_level": 2, "file_order": 7, "section_index": 50, "content_hash": "c3e7de3da348b03c0da5c1dca428794fa52c31cf514d066f5f759be25ff52f25", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:173e67e372cc5be0930bcd5eaa7e57c53ea613676448478613d6fffc278f26f8", "content": "Use the `CitationDocument` builder to create documents that can be cited:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Creating Citation Documents", "heading_level": 3, "file_order": 7, "section_index": 51, "content_hash": "173e67e372cc5be0930bcd5eaa7e57c53ea613676448478613d6fffc278f26f8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:b60664c8c4a363673d77d7115b2d852b28ddfe48edb06ba42271a19dd73afab9", "content": "[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .plainText(\"The Eiffel Tower was completed in 1889 in Paris, France. \" +\n \"It stands 330 meters tall and was designed by Gustave Eiffel.\")\n .title(\"Eiffel Tower Facts\")\n .citationsEnabled(true)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Plain Text Documents", "heading_level": 4, "file_order": 7, "section_index": 52, "content_hash": "b60664c8c4a363673d77d7115b2d852b28ddfe48edb06ba42271a19dd73afab9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:ec290279423b190b19ed0c0c398280f9026b372c1c4f0465c5bc60c6cfff04a6", "content": "[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .pdfFile(\"path/to/document.pdf\")\n .title(\"Technical Specification\")\n .citationsEnabled(true)\n .build();\n\nbyte[] pdfBytes = loadPdfBytes();\nCitationDocument document = CitationDocument.builder()\n .pdf(pdfBytes)\n .title(\"Product Manual\")\n .citationsEnabled(true)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "PDF Documents", "heading_level": 4, "file_order": 7, "section_index": 53, "content_hash": "ec290279423b190b19ed0c0c398280f9026b372c1c4f0465c5bc60c6cfff04a6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:f0298941329b02675ad7f4b8ce3e5fe42ab5e56288587aa074af5df2a154e5a9", "content": "For fine-grained citation control, use custom content blocks:\n\n[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .customContent(\n \"The Great Wall of China is approximately 21,196 kilometers long.\",\n \"It was built over many centuries, starting in the 7th century BC.\",\n \"The wall was constructed to protect Chinese states from invasions.\"\n )\n .title(\"Great Wall Facts\")\n .citationsEnabled(true)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Custom Content Blocks", "heading_level": 4, "file_order": 7, "section_index": 54, "content_hash": "f0298941329b02675ad7f4b8ce3e5fe42ab5e56288587aa074af5df2a154e5a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:3b3ebbb88ba81cca5ae62f4afd55d76d31764e44bf3e4167956c1e17a35c0017", "content": "Include citation documents in your chat options:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"When was the Eiffel Tower built and how tall is it?\",\n AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .maxTokens(1024)\n .citationDocuments(document)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using Citations in Requests", "heading_level": 3, "file_order": 7, "section_index": 55, "content_hash": "3b3ebbb88ba81cca5ae62f4afd55d76d31764e44bf3e4167956c1e17a35c0017", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:a4b8be2a66eac37139e13a64a9a5abfb573009535f4af57fa3f587692af32b26", "content": "You can provide multiple documents for Claude to reference:\n\n[source,java]\n----\nCitationDocument parisDoc = CitationDocument.builder()\n .plainText(\"Paris is the capital city of France with a population of 2.1 million.\")\n .title(\"Paris Information\")\n .citationsEnabled(true)\n .build();\n\nCitationDocument eiffelDoc = CitationDocument.builder()\n .plainText(\"The Eiffel Tower was designed by Gustave Eiffel for the 1889 World's Fair.\")\n .title(\"Eiffel Tower History\")\n .citationsEnabled(true)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"What is the capital of France and who designed the Eiffel Tower?\",\n AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .citationDocuments(parisDoc, eiffelDoc)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Multiple Documents", "heading_level": 4, "file_order": 7, "section_index": 56, "content_hash": "a4b8be2a66eac37139e13a64a9a5abfb573009535f4af57fa3f587692af32b26", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:02939badbaec3e1957ed210aa1aed7c039918a644d9ae737def75997da437063", "content": "Citations are returned in the response metadata:\n\n[source,java]\n----\nChatResponse response = chatModel.call(prompt);\n\n@SuppressWarnings(\"unchecked\")\nList<Citation> citations = (List<Citation>) response.getMetadata().get(\"citations\");\n\nInteger citationCount = (Integer) response.getMetadata().get(\"citationCount\");\nSystem.out.println(\"Total citations: \" + citationCount);\n\nfor (Citation citation : citations) {\n System.out.println(\"Document: \" + citation.getDocumentTitle());\n System.out.println(\"Location: \" + citation.getLocationDescription());\n System.out.println(\"Cited text: \" + citation.getCitedText());\n System.out.println(\"Document index: \" + citation.getDocumentIndex());\n System.out.println();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Accessing Citations", "heading_level": 3, "file_order": 7, "section_index": 57, "content_hash": "02939badbaec3e1957ed210aa1aed7c039918a644d9ae737def75997da437063", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:ed612397099b41e40b6f3a749b81b3886ce787f536a65949df23030ff9c98c88", "content": "Citations contain different location information depending on the document type:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Citation Types", "heading_level": 3, "file_order": 7, "section_index": 58, "content_hash": "ed612397099b41e40b6f3a749b81b3886ce787f536a65949df23030ff9c98c88", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:6c13f02cb912a8426feeb20a690f93af75e24169f3e7e90bcc71ed42c22f65c7", "content": "For plain text documents, citations include character indices:\n\n[source,java]\n----\nCitation citation = citations.get(0);\nif (citation.getType() == Citation.LocationType.CHAR_LOCATION) {\n int start = citation.getStartCharIndex();\n int end = citation.getEndCharIndex();\n String text = citation.getCitedText();\n System.out.println(\"Characters \" + start + \"-\" + end + \": \" + text);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Character Location (Plain Text)", "heading_level": 4, "file_order": 7, "section_index": 59, "content_hash": "6c13f02cb912a8426feeb20a690f93af75e24169f3e7e90bcc71ed42c22f65c7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:263e0828f8f880c7b8f71562fa78ea7bf0da08b376d9dab4376c705df2b21192", "content": "For PDF documents, citations include page numbers:\n\n[source,java]\n----\nCitation citation = citations.get(0);\nif (citation.getType() == Citation.LocationType.PAGE_LOCATION) {\n int startPage = citation.getStartPageNumber();\n int endPage = citation.getEndPageNumber();\n System.out.println(\"Pages \" + startPage + \"-\" + endPage);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Page Location (PDF)", "heading_level": 4, "file_order": 7, "section_index": 60, "content_hash": "263e0828f8f880c7b8f71562fa78ea7bf0da08b376d9dab4376c705df2b21192", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:cdf6c044225a42b62d80090bc066c013ba78e4cd0bf3f1e5fadcf21cd6ae22f6", "content": "For custom content, citations reference specific content blocks:\n\n[source,java]\n----\nCitation citation = citations.get(0);\nif (citation.getType() == Citation.LocationType.CONTENT_BLOCK_LOCATION) {\n int startBlock = citation.getStartBlockIndex();\n int endBlock = citation.getEndBlockIndex();\n System.out.println(\"Content blocks \" + startBlock + \"-\" + endBlock);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Content Block Location (Custom Content)", "heading_level": 4, "file_order": 7, "section_index": 61, "content_hash": "cdf6c044225a42b62d80090bc066c013ba78e4cd0bf3f1e5fadcf21cd6ae22f6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:9df38788348100fc026f8d5471a347b62d00aa8b69128681a5502770b438b209", "content": "Here's a complete example demonstrating citation usage:\n\n[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .plainText(\"Spring AI is an application framework for AI engineering. \" +\n \"It provides a Spring-friendly API for developing AI applications. \" +\n \"The framework includes abstractions for chat models, embedding models, \" +\n \"and vector databases.\")\n .title(\"Spring AI Overview\")\n .citationsEnabled(true)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"What is Spring AI?\",\n AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .maxTokens(1024)\n .citationDocuments(document)\n .build()\n )\n);\n\nSystem.out.println(\"Response: \" + response.getResult().getOutput().getText());\nSystem.out.println(\"\\nCitations:\");\n\nList<Citation> citations = (List<Citation>) response.getMetadata().get(\"citations\");\n\nif (citations != null && !citations.isEmpty()) {\n for (int i = 0; i < citations.size(); i++) {\n Citation citation = citations.get(i);\n System.out.println(\"\\n[\" + (i + 1) + \"] \" + citation.getDocumentTitle());\n System.out.println(\" Location: \" + citation.getLocationDescription());\n System.out.println(\" Text: \" + citation.getCitedText());\n }\n} else {\n System.out.println(\"No citations were provided in the response.\");\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Complete Example", "heading_level": 3, "file_order": 7, "section_index": 62, "content_hash": "9df38788348100fc026f8d5471a347b62d00aa8b69128681a5502770b438b209", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:7b9ee56d8b20e4b8e30c693717f65b053bfa6626db54c002c89662f805e06218", "content": "1. **Use descriptive titles**: Provide meaningful titles for citation documents to help users identify sources in the citations.\n2. **Check for null citations**: Not all responses will include citations, so always validate the citations metadata exists before accessing it.\n3. **Consider document size**: Larger documents provide more context but consume more input tokens and may affect response time.\n4. **Leverage multiple documents**: When answering questions that span multiple sources, provide all relevant documents in a single request rather than making multiple calls.\n5. **Use appropriate document types**: Choose plain text for simple content, PDF for existing documents, and custom content blocks when you need fine-grained control over citation granularity.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Best Practices", "heading_level": 3, "file_order": 7, "section_index": 63, "content_hash": "7b9ee56d8b20e4b8e30c693717f65b053bfa6626db54c002c89662f805e06218", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2d475454a26c6458fd4d71528c8deed817c7105ae314d00ef1ac93a8b660281b", "content": "Analyze contracts and legal documents while maintaining source attribution:\n\n[source,java]\n----\nCitationDocument contract = CitationDocument.builder()\n .pdfFile(\"merger-agreement.pdf\")\n .title(\"Merger Agreement 2024\")\n .citationsEnabled(true)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"What are the key termination clauses in this contract?\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .maxTokens(2000)\n .citationDocuments(contract)\n .build()\n )\n);\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Legal Document Analysis", "heading_level": 4, "file_order": 7, "section_index": 64, "content_hash": "2d475454a26c6458fd4d71528c8deed817c7105ae314d00ef1ac93a8b660281b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:43868d755183919692fad57e89431ce992883ad9ff3a9f7b83c01cc8878bb568", "content": "Provide accurate customer support answers with verifiable sources:\n\n[source,java]\n----\nCitationDocument kbArticle1 = CitationDocument.builder()\n .plainText(loadKnowledgeBaseArticle(\"authentication\"))\n .title(\"Authentication Guide\")\n .citationsEnabled(true)\n .build();\n\nCitationDocument kbArticle2 = CitationDocument.builder()\n .plainText(loadKnowledgeBaseArticle(\"billing\"))\n .title(\"Billing FAQ\")\n .citationsEnabled(true)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"How do I reset my password and update my billing information?\",\n AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .citationDocuments(kbArticle1, kbArticle2)\n .build()\n )\n);\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Customer Support Knowledge Base", "heading_level": 4, "file_order": 7, "section_index": 65, "content_hash": "43868d755183919692fad57e89431ce992883ad9ff3a9f7b83c01cc8878bb568", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:5ff8f789f2b2089910f2dc9ee3a2c148ea370ef7afff6e61ef19cc4b0eb30af1", "content": "Generate reports that require source citations for compliance:\n\n[source,java]\n----\nCitationDocument clinicalStudy = CitationDocument.builder()\n .pdfFile(\"clinical-trial-results.pdf\")\n .title(\"Clinical Trial Phase III Results\")\n .citationsEnabled(true)\n .build();\n\nCitationDocument regulatoryGuidance = CitationDocument.builder()\n .plainText(loadRegulatoryDocument())\n .title(\"FDA Guidance Document\")\n .citationsEnabled(true)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Summarize the efficacy findings and regulatory implications.\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4\")\n .maxTokens(3000)\n .citationDocuments(clinicalStudy, regulatoryGuidance)\n .build()\n )\n);\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Research and Compliance", "heading_level": 4, "file_order": 7, "section_index": 66, "content_hash": "5ff8f789f2b2089910f2dc9ee3a2c148ea370ef7afff6e61ef19cc4b0eb30af1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:643634d5fe3c19aea24e7c73e946244f285b9662533cd4f24b29949b51a5c7c6", "content": "Optionally provide context about the document that won't be cited but can guide Claude's understanding:\n\n[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .plainText(\"...\")\n .title(\"Legal Contract\")\n .context(\"This is a merger agreement dated January 2024 between Company A and Company B\")\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Context Field", "heading_level": 4, "file_order": 7, "section_index": 67, "content_hash": "643634d5fe3c19aea24e7c73e946244f285b9662533cd4f24b29949b51a5c7c6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:aaeec1bde88947c56f12fe2c10e92111a1c09c989de8637d5811daaefc3c3f4a", "content": "By default, citations are disabled for all documents (opt-in behavior).\nTo enable citations, explicitly set `citationsEnabled(true)`:\n\n[source,java]\n----\nCitationDocument document = CitationDocument.builder()\n .plainText(\"The Eiffel Tower was completed in 1889...\")\n .title(\"Historical Facts\")\n .citationsEnabled(true) // Explicitly enable citations for this document\n .build();\n----\n\nYou can also provide documents without citations for background context:\n\n[source,java]\n----\nCitationDocument backgroundDoc = CitationDocument.builder()\n .plainText(\"Background information about the industry...\")\n .title(\"Context Document\")\n // citationsEnabled defaults to false - Claude will use this but not cite it\n .build();\n----\n\n[NOTE]\n====\nAnthropic requires consistent citation settings across all documents in a request.\nYou cannot mix citation-enabled and citation-disabled documents in the same request.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Controlling Citations", "heading_level": 4, "file_order": 7, "section_index": 68, "content_hash": "aaeec1bde88947c56f12fe2c10e92111a1c09c989de8637d5811daaefc3c3f4a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2163c2145343cd29b0687f620fb31d85c72d22ed7ecabed1b005c378c2a52f43", "content": "Anthropic's https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview[Skills API] extends Claude's capabilities with specialized, pre-packaged abilities for document generation.\nSkills enable Claude to create actual downloadable files - Excel spreadsheets, PowerPoint presentations, Word documents, and PDFs - rather than just describing what these documents might contain.\n\nSkills solve a fundamental limitation of traditional LLMs:\n\n* **Traditional Claude**: \"Here's how your sales report would look...\" (text description only)\n* **With Skills**: Creates an actual `sales_report.xlsx` file you can download and open in Excel\n\n[NOTE]\n====\n*Supported Models*\n\nSkills are supported on Claude Sonnet 4, Claude Sonnet 4.5, Claude Opus 4, and later models.\n\n*Requirements*\n\n* Skills require the code execution capability (automatically enabled by Spring AI)\n* Maximum of 8 skills per request\n* Generated files are available for download via the Files API for 24 hours\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Skills", "heading_level": 2, "file_order": 7, "section_index": 69, "content_hash": "2163c2145343cd29b0687f620fb31d85c72d22ed7ecabed1b005c378c2a52f43", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:fc0ff7e504a5e833f736c0c76e7381a1d4dd44a999f14ead675cf725664dde06", "content": "Spring AI provides type-safe access to Anthropic's pre-built skills through the `AnthropicSkill` enum:\n\n[cols=\"2,3,4\", stripes=even]\n|====\n| Skill | Description | Generated File Type\n\n| `XLSX`\n| Excel spreadsheet generation and manipulation\n| `.xlsx` (Microsoft Excel)\n\n| `PPTX`\n| PowerPoint presentation creation\n| `.pptx` (Microsoft PowerPoint)\n\n| `DOCX`\n| Word document generation\n| `.docx` (Microsoft Word)\n\n| `PDF`\n| PDF document creation\n| `.pdf` (Portable Document Format)\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Pre-built Anthropic Skills", "heading_level": 3, "file_order": 7, "section_index": 70, "content_hash": "fc0ff7e504a5e833f736c0c76e7381a1d4dd44a999f14ead675cf725664dde06", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:3bcac9c2528e865885d85d7daa2b039e5e01538f73b348ecbbec8982f285bf9f", "content": "Enable skills by adding them to your `AnthropicChatOptions`:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Create an Excel spreadsheet with Q1 2025 sales data. \" +\n \"Include columns for Month, Revenue, and Expenses with 3 rows of sample data.\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .build()\n )\n);\n\nString responseText = response.getResult().getOutput().getText();\nSystem.out.println(responseText);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Basic Usage", "heading_level": 3, "file_order": 7, "section_index": 71, "content_hash": "3bcac9c2528e865885d85d7daa2b039e5e01538f73b348ecbbec8982f285bf9f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:fa873f6bc64627c4f32def5f62e6671fa173bb58b5fd7728576f73ac1818a28e", "content": "You can enable multiple skills in a single request (up to 8):\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Create a sales report with both an Excel file containing the raw data \" +\n \"and a PowerPoint presentation summarizing the key findings.\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(8192)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .skill(AnthropicApi.AnthropicSkill.PPTX)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Multiple Skills", "heading_level": 3, "file_order": 7, "section_index": 72, "content_hash": "fa873f6bc64627c4f32def5f62e6671fa173bb58b5fd7728576f73ac1818a28e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:7f09357a87c37924e27952a0b7c988ce8e5ee6682d55c405cf5ef06e4377bd07", "content": "For more control, use `SkillContainer` directly:\n\n[source,java]\n----\nAnthropicApi.SkillContainer container = AnthropicApi.SkillContainer.builder()\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .skill(AnthropicApi.AnthropicSkill.PPTX, \"20251013\") // Specific version\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the quarterly report\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skillContainer(container)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using SkillContainer for Advanced Configuration", "heading_level": 3, "file_order": 7, "section_index": 73, "content_hash": "7f09357a87c37924e27952a0b7c988ce8e5ee6682d55c405cf5ef06e4377bd07", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2976b9a724f5f051b02c3d4d34e126c785f590de7278048e78cf9f0384fce855", "content": "Skills work seamlessly with the ChatClient fluent API:\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"Create a PowerPoint presentation about Spring AI with 3 slides: \" +\n \"Title, Key Features, and Getting Started\")\n .options(AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.PPTX)\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using ChatClient Fluent API", "heading_level": 3, "file_order": 7, "section_index": 74, "content_hash": "2976b9a724f5f051b02c3d4d34e126c785f590de7278048e78cf9f0384fce855", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:36555c9b712db27e443775e3bbd4a6ae0b265be065caf29eaf621c3b368ae56f", "content": "Skills work with streaming responses:\n\n[source,java]\n----\nFlux<ChatResponse> responseFlux = chatModel.stream(\n new Prompt(\n \"Create a Word document explaining machine learning concepts\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.DOCX)\n .build()\n )\n);\n\nresponseFlux.subscribe(response -> {\n String content = response.getResult().getOutput().getText();\n System.out.print(content);\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Streaming with Skills", "heading_level": 3, "file_order": 7, "section_index": 75, "content_hash": "36555c9b712db27e443775e3bbd4a6ae0b265be065caf29eaf621c3b368ae56f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:945d5c60c32807265115dab121fa4b837ef20efe7e4724d25e829fb63ad31061", "content": "When Claude generates files using Skills, the response contains file IDs that can be used to download the actual files via the Files API.\nSpring AI provides the `AnthropicSkillsResponseHelper` utility class for extracting file IDs and downloading files.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Downloading Generated Files", "heading_level": 3, "file_order": 7, "section_index": 76, "content_hash": "945d5c60c32807265115dab121fa4b837ef20efe7e4724d25e829fb63ad31061", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:3c7a1d6de7eb46ab929eaecfce464412ae485bfad07222ceeedb2d7a1a63b8ac", "content": "[source,java]\n----\nimport org.springframework.ai.anthropic.AnthropicSkillsResponseHelper;\n\nChatResponse response = chatModel.call(prompt);\n\nList<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n\nfor (String fileId : fileIds) {\n System.out.println(\"Generated file ID: \" + fileId);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Extracting File IDs", "heading_level": 4, "file_order": 7, "section_index": 77, "content_hash": "3c7a1d6de7eb46ab929eaecfce464412ae485bfad07222ceeedb2d7a1a63b8ac", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:600a097955009fd16e2884694fd19da2a102684b56008f6b18442811e39bd551", "content": "Before downloading, you can retrieve file metadata:\n\n[source,java]\n----\n@Autowired\nprivate AnthropicApi anthropicApi;\n\nString fileId = fileIds.get(0);\nAnthropicApi.FileMetadata metadata = anthropicApi.getFileMetadata(fileId);\n\nSystem.out.println(\"Filename: \" + metadata.filename()); // e.g., \"sales_report.xlsx\"\nSystem.out.println(\"Size: \" + metadata.size() + \" bytes\"); // e.g., 5082\nSystem.out.println(\"MIME Type: \" + metadata.mimeType()); // e.g., \"application/vnd...\"\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Getting File Metadata", "heading_level": 4, "file_order": 7, "section_index": 78, "content_hash": "600a097955009fd16e2884694fd19da2a102684b56008f6b18442811e39bd551", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:43a3bad9c35dd2d7e51b73332f87ea82341be855e1c2b75c1a77bcc079e5821e", "content": "[source,java]\n----\nbyte[] fileContent = anthropicApi.downloadFile(fileId);\n\nPath outputPath = Path.of(\"downloads\", metadata.filename());\nFiles.write(outputPath, fileContent);\n\nSystem.out.println(\"Saved file to: \" + outputPath);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Downloading File Content", "heading_level": 4, "file_order": 7, "section_index": 79, "content_hash": "43a3bad9c35dd2d7e51b73332f87ea82341be855e1c2b75c1a77bcc079e5821e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:da836ebf7a656ef64d9dc755e483f22c59f40add4e51ab75ee3983c9786989d7", "content": "The `AnthropicSkillsResponseHelper` provides a convenience method to download all generated files at once:\n\n[source,java]\n----\nPath targetDir = Path.of(\"generated-files\");\nFiles.createDirectories(targetDir);\n\nList<Path> savedFiles = AnthropicSkillsResponseHelper.downloadAllFiles(response, anthropicApi, targetDir);\n\nfor (Path file : savedFiles) {\n System.out.println(\"Downloaded: \" + file.getFileName() +\n \" (\" + Files.size(file) + \" bytes)\");\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Convenience Method: Download All Files", "heading_level": 4, "file_order": 7, "section_index": 80, "content_hash": "da836ebf7a656ef64d9dc755e483f22c59f40add4e51ab75ee3983c9786989d7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:e3e2504d1c362685bdca01d9cf1f067d21428368dcad770393e218deb5ff69b0", "content": "Here's a complete example showing Skills usage with file download:\n\n[source,java]\n----\n@Service\npublic class DocumentGenerationService {\n\n private final AnthropicChatModel chatModel;\n private final AnthropicApi anthropicApi;\n\n public DocumentGenerationService(AnthropicChatModel chatModel, AnthropicApi anthropicApi) {\n this.chatModel = chatModel;\n this.anthropicApi = anthropicApi;\n }\n\n public Path generateSalesReport(String quarter, Path outputDir) throws IOException {\n // Generate Excel report using Skills\n ChatResponse response = chatModel.call(\n new Prompt(\n \"Create an Excel spreadsheet with \" + quarter + \" sales data. \" +\n \"Include Month, Revenue, Expenses, and Profit columns.\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .build()\n )\n );\n\n // Extract file IDs from the response\n List<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n\n if (fileIds.isEmpty()) {\n throw new RuntimeException(\"No file was generated\");\n }\n\n // Download the generated file\n String fileId = fileIds.get(0);\n AnthropicApi.FileMetadata metadata = anthropicApi.getFileMetadata(fileId);\n byte[] content = anthropicApi.downloadFile(fileId);\n\n // Save to output directory\n Path outputPath = outputDir.resolve(metadata.filename());\n Files.write(outputPath, content);\n\n return outputPath;\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Complete File Download Example", "heading_level": 4, "file_order": 7, "section_index": 81, "content_hash": "e3e2504d1c362685bdca01d9cf1f067d21428368dcad770393e218deb5ff69b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:efef125b8bd4f6e40c17863677d43dfaec0b435818684bcc4d7e8d9ffeb826ea", "content": "The `AnthropicApi` provides direct access to the Files API:\n\n[cols=\"2,4\", stripes=even]\n|====\n| Method | Description\n\n| `getFileMetadata(fileId)`\n| Get metadata including filename, size, MIME type, and expiration time\n\n| `downloadFile(fileId)`\n| Download file content as byte array\n\n| `listFiles(limit, page)`\n| List files with pagination support\n\n| `deleteFile(fileId)`\n| Delete a file immediately (files auto-expire after 24 hours)\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Files API Operations", "heading_level": 3, "file_order": 7, "section_index": 82, "content_hash": "efef125b8bd4f6e40c17863677d43dfaec0b435818684bcc4d7e8d9ffeb826ea", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:8a17a03f7a0e31c10cedcbf821e1f2bef338cec173c059293c3f74d8b4978b70", "content": "[source,java]\n----\nAnthropicApi.FilesListResponse files = anthropicApi.listFiles(20, null);\n\nfor (AnthropicApi.FileMetadata file : files.data()) {\n System.out.println(file.id() + \": \" + file.filename());\n}\n\nif (files.hasMore()) {\n AnthropicApi.FilesListResponse nextPage = anthropicApi.listFiles(20, files.nextPage());\n // Process next page...\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Listing Files", "heading_level": 4, "file_order": 7, "section_index": 83, "content_hash": "8a17a03f7a0e31c10cedcbf821e1f2bef338cec173c059293c3f74d8b4978b70", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:ce0af4d6e426ea648f47612810b0a90eff73f14c8517112de89e4e7bd2b24436", "content": "For multi-turn conversations with Skills, you may need to extract the container ID:\n\n[source,java]\n----\nString containerId = AnthropicSkillsResponseHelper.extractContainerId(response);\n\nif (containerId != null) {\n System.out.println(\"Container ID for reuse: \" + containerId);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Extracting Container ID", "heading_level": 4, "file_order": 7, "section_index": 84, "content_hash": "ce0af4d6e426ea648f47612810b0a90eff73f14c8517112de89e4e7bd2b24436", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:4ca73f86bd4bf7263eb344c070b4842775e2ef8293a01919cb8835f602b0fc86", "content": "1. **Use appropriate models**: Skills work best with Claude Sonnet 4 and later models. Ensure you're using a supported model.\n\n2. **Set sufficient max tokens**: Document generation can require significant tokens. Use `maxTokens(4096)` or higher for complex documents.\n\n3. **Be specific in prompts**: Provide clear, detailed instructions about document structure, content, and formatting.\n\n4. **Handle file downloads promptly**: Generated files expire after 24 hours. Download files soon after generation.\n\n5. **Check for file IDs**: Always verify that file IDs were returned before attempting downloads. Some prompts may result in text responses without file generation.\n\n6. **Use defensive error handling**: Wrap file operations in try-catch blocks to handle network issues or expired files gracefully.\n\n[source,java]\n----\nList<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n\nif (fileIds.isEmpty()) {\n // Claude may have responded with text instead of generating a file\n String text = response.getResult().getOutput().getText();\n log.warn(\"No files generated. Response: {}\", text);\n return;\n}\n\ntry {\n byte[] content = anthropicApi.downloadFile(fileIds.get(0));\n // Process file...\n} catch (Exception e) {\n log.error(\"Failed to download file: {}\", e.getMessage());\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Best Practices", "heading_level": 3, "file_order": 7, "section_index": 85, "content_hash": "4ca73f86bd4bf7263eb344c070b4842775e2ef8293a01919cb8835f602b0fc86", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:0ad2138ac06141351b028afacea21b1f65a00168270d6e308e779b4676dcaafe", "content": "Generate formatted business reports from data:\n\n[source,java]\n----\n@Service\npublic class ReportService {\n\n private final AnthropicChatModel chatModel;\n private final AnthropicApi anthropicApi;\n\n public byte[] generateMonthlyReport(SalesData data) throws IOException {\n String prompt = String.format(\n \"Create a PowerPoint presentation summarizing monthly sales performance. \" +\n \"Total Revenue: $%,.2f, Total Expenses: $%,.2f, Net Profit: $%,.2f. \" +\n \"Include charts and key insights. Create 5 slides: \" +\n \"1) Title, 2) Revenue Overview, 3) Expense Breakdown, \" +\n \"4) Profit Analysis, 5) Recommendations.\",\n data.revenue(), data.expenses(), data.profit()\n );\n\n ChatResponse response = chatModel.call(\n new Prompt(prompt,\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(8192)\n .skill(AnthropicApi.AnthropicSkill.PPTX)\n .build()\n )\n );\n\n List<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n return anthropicApi.downloadFile(fileIds.get(0));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Automated Report Generation", "heading_level": 4, "file_order": 7, "section_index": 86, "content_hash": "0ad2138ac06141351b028afacea21b1f65a00168270d6e308e779b4676dcaafe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:bfa53bf6361a4bf39e87b865d6516d8f58e29481a600a6a3ccd4c63eab686324", "content": "Export structured data to Excel format:\n\n[source,java]\n----\n@RestController\npublic class ExportController {\n\n private final AnthropicChatModel chatModel;\n private final AnthropicApi anthropicApi;\n private final CustomerRepository customerRepository;\n\n @GetMapping(\"/export/customers\")\n public ResponseEntity<byte[]> exportCustomers() throws IOException {\n List<Customer> customers = customerRepository.findAll();\n\n String dataDescription = customers.stream()\n .map(c -> String.format(\"%s, %s, %s\", c.name(), c.email(), c.tier()))\n .collect(Collectors.joining(\"\\n\"));\n\n ChatResponse response = chatModel.call(\n new Prompt(\n \"Create an Excel spreadsheet with customer data. \" +\n \"Columns: Name, Email, Tier. Format the header row with bold text. \" +\n \"Data:\\n\" + dataDescription,\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .build()\n )\n );\n\n List<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n byte[] content = anthropicApi.downloadFile(fileIds.get(0));\n AnthropicApi.FileMetadata metadata = anthropicApi.getFileMetadata(fileIds.get(0));\n\n return ResponseEntity.ok()\n .header(HttpHeaders.CONTENT_DISPOSITION,\n \"attachment; filename=\\\"\" + metadata.filename() + \"\\\"\")\n .contentType(MediaType.parseMediaType(metadata.mimeType()))\n .body(content);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Data Export Service", "heading_level": 4, "file_order": 7, "section_index": 87, "content_hash": "bfa53bf6361a4bf39e87b865d6516d8f58e29481a600a6a3ccd4c63eab686324", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:152402c676e43e304bc8f90950108a9dfa11035964210e06014d2c547291828b", "content": "Generate multiple document formats from a single request:\n\n[source,java]\n----\npublic Map<String, byte[]> generateProjectDocumentation(ProjectInfo project) throws IOException {\n ChatResponse response = chatModel.call(\n new Prompt(\n \"Create project documentation for: \" + project.name() + \"\\n\" +\n \"Description: \" + project.description() + \"\\n\\n\" +\n \"Generate:\\n\" +\n \"1. An Excel file with the project timeline and milestones\\n\" +\n \"2. A PowerPoint overview presentation (3-5 slides)\\n\" +\n \"3. A Word document with detailed specifications\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(16384)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .skill(AnthropicApi.AnthropicSkill.PPTX)\n .skill(AnthropicApi.AnthropicSkill.DOCX)\n .build()\n )\n );\n\n Map<String, byte[]> documents = new HashMap<>();\n List<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n\n for (String fileId : fileIds) {\n AnthropicApi.FileMetadata metadata = anthropicApi.getFileMetadata(fileId);\n byte[] content = anthropicApi.downloadFile(fileId);\n documents.put(metadata.filename(), content);\n }\n\n return documents;\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Multi-Format Document Generation", "heading_level": 4, "file_order": 7, "section_index": 88, "content_hash": "152402c676e43e304bc8f90950108a9dfa11035964210e06014d2c547291828b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2779753187c5bd24eac45c0c83901d52aa20153920aa233ec8ffe5366448171c", "content": "Skills can be combined with other Anthropic features like Prompt Caching:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are an expert data analyst and document creator...\"),\n new UserMessage(\"Create a financial summary spreadsheet\")\n ),\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .cacheOptions(AnthropicCacheOptions.builder()\n .strategy(AnthropicCacheStrategy.SYSTEM_ONLY)\n .build())\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Combining Skills with Other Features", "heading_level": 3, "file_order": 7, "section_index": 89, "content_hash": "2779753187c5bd24eac45c0c83901d52aa20153920aa233ec8ffe5366448171c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:d09f2fb3c43f83b847a93e9c0f541cdd1018f8ec0244f3d212b41ae706145722", "content": "In addition to pre-built skills, Anthropic supports custom skills that you can create for specialized document templates, formatting rules, or domain-specific behaviors.\nCustom skills are `SKILL.md` files with instructions that you upload to your Anthropic workspace.\nOnce uploaded, you can use them in Spring AI alongside pre-built skills.\n\nCustom skills are ideal for:\n\n* **Corporate branding**: Apply consistent headers, footers, logos, and color schemes\n* **Compliance requirements**: Add required disclaimers, confidentiality notices, or audit trails\n* **Document templates**: Enforce specific structures for reports, proposals, or specifications\n* **Domain expertise**: Include industry-specific terminology, calculations, or formatting rules\n\nFor details on creating custom skills, refer to the https://platform.claude.com/docs/en/api/skills-guide[Anthropic Skills API documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Custom Skills", "heading_level": 3, "file_order": 7, "section_index": 90, "content_hash": "d09f2fb3c43f83b847a93e9c0f541cdd1018f8ec0244f3d212b41ae706145722", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:2d9c5d2ffd7adc456ff06d385534659117b380c1a57065652e6e44995723bbcc", "content": "Upload your skill using the Anthropic API.\nNote the specific format requirements for the `files[]` parameter:\n\n[source,bash]\n----\ncurl -X POST \"https://api.anthropic.com/v1/skills\" \\\n -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n -H \"anthropic-version: 2023-06-01\" \\\n -H \"anthropic-beta: skills-2025-10-02\" \\\n -F \"display_title=My Custom Skill\" \\\n -F \"files[]=@SKILL.md;filename=my-skill-name/SKILL.md\"\n----\n\n[IMPORTANT]\n====\n* Use `files[]=` (with square brackets), not `files=`\n* The `filename` parameter must include a directory matching the `name` field in your SKILL.md YAML frontmatter\n* After uploading, verify your skill appears in the Anthropic Console under **Settings > Capabilities**\n====\n\nThe response contains your skill ID:\n\n[source,json]\n----\n{\n \"id\": \"skill_01AbCdEfGhIjKlMnOpQrStUv\",\n \"display_title\": \"My Custom Skill\",\n \"source\": \"custom\",\n \"latest_version\": \"1765845644409101\"\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Uploading a Custom Skill", "heading_level": 4, "file_order": 7, "section_index": 91, "content_hash": "2d9c5d2ffd7adc456ff06d385534659117b380c1a57065652e6e44995723bbcc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:b25f9150f641ab733030593a5cd116dfc7645bbc61e4fcdff68bcc2951a50370", "content": "Reference your custom skill by its ID using the `.skill()` method:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Create a quarterly sales report\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(\"skill_01AbCdEfGhIjKlMnOpQrStUv\")\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using Custom Skills in Spring AI", "heading_level": 4, "file_order": 7, "section_index": 92, "content_hash": "b25f9150f641ab733030593a5cd116dfc7645bbc61e4fcdff68bcc2951a50370", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:b8b0eff8e3b4da6b84a7364066646fbeafb25aaa5979ced96ae4187f863b3c0f", "content": "You can use both pre-built and custom skills in the same request.\nThis allows you to leverage Anthropic's document generation capabilities while applying your organization's specific requirements:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Create a sales report spreadsheet\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(4096)\n .skill(AnthropicApi.AnthropicSkill.XLSX) // Pre-built\n .skill(\"skill_01AbCdEfGhIjKlMnOpQrStUv\") // Your custom skill\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Combining Pre-built and Custom Skills", "heading_level": 4, "file_order": 7, "section_index": 93, "content_hash": "b8b0eff8e3b4da6b84a7364066646fbeafb25aaa5979ced96ae4187f863b3c0f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:16ab28eea99127a5ce2e21f77bb18742fe998c4d3d668c355f661e1b17c872ac", "content": "For more control over skill versions, use `SkillContainer` directly:\n\n[source,java]\n----\nAnthropicApi.SkillContainer container = AnthropicApi.SkillContainer.builder()\n .skill(AnthropicApi.AnthropicSkill.XLSX)\n .skill(\"skill_01AbCdEfGhIjKlMnOpQrStUv\") // Uses latest version\n .skill(\"skill_02XyZaBcDeFgHiJkLmNoPq\", \"1765845644409101\") // Specific version\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the report\",\n AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(8192)\n .skillContainer(container)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Using SkillContainer with Custom Skills", "heading_level": 4, "file_order": 7, "section_index": 94, "content_hash": "16ab28eea99127a5ce2e21f77bb18742fe998c4d3d668c355f661e1b17c872ac", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:9f34c3eed2f47b5eb182c76bf90749e95770cf5dc76e965da4ec0e2bb87efec8", "content": "To update an existing skill, upload a new version to the `/versions` endpoint:\n\n[source,bash]\n----\ncurl -X POST \"https://api.anthropic.com/v1/skills/YOUR_SKILL_ID/versions\" \\\n -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n -H \"anthropic-version: 2023-06-01\" \\\n -H \"anthropic-beta: skills-2025-10-02\" \\\n -F \"files[]=@SKILL.md;filename=my-skill-name/SKILL.md\"\n----\n\nWhen using `latest` as the version (the default), the new version is picked up automatically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Updating a Custom Skill", "heading_level": 4, "file_order": 7, "section_index": 95, "content_hash": "9f34c3eed2f47b5eb182c76bf90749e95770cf5dc76e965da4ec0e2bb87efec8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:a8a9dc5790d83aa45995776fbd341f9d70bf3f3420e0473896f236ed3d9e0bfe", "content": "Here's a complete example showing a service that optionally applies a custom branding skill:\n\n[source,java]\n----\n@Service\npublic class BrandedDocumentService {\n\n private static final String BRANDING_SKILL_ID = \"skill_01AbCdEfGhIjKlMnOpQrStUv\";\n\n private final AnthropicChatModel chatModel;\n private final AnthropicApi anthropicApi;\n\n public BrandedDocumentService(AnthropicChatModel chatModel, AnthropicApi anthropicApi) {\n this.chatModel = chatModel;\n this.anthropicApi = anthropicApi;\n }\n\n public byte[] generateReport(String prompt, boolean includeBranding) throws IOException {\n // Build options with document skill\n AnthropicChatOptions.Builder optionsBuilder = AnthropicChatOptions.builder()\n .model(\"claude-sonnet-4-5\")\n .maxTokens(8192)\n .skill(AnthropicApi.AnthropicSkill.XLSX);\n\n // Add custom branding skill if requested\n if (includeBranding) {\n optionsBuilder.skill(BRANDING_SKILL_ID);\n }\n\n ChatResponse response = chatModel.call(\n new Prompt(prompt, optionsBuilder.build())\n );\n\n // Extract and download the generated file\n List<String> fileIds = AnthropicSkillsResponseHelper.extractFileIds(response);\n\n if (fileIds.isEmpty()) {\n throw new RuntimeException(\"No file was generated\");\n }\n\n return anthropicApi.downloadFile(fileIds.get(0));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Complete Custom Skills Example", "heading_level": 4, "file_order": 7, "section_index": 96, "content_hash": "a8a9dc5790d83aa45995776fbd341f9d70bf3f3420e0473896f236ed3d9e0bfe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:a323009c371480a257842e51cd197cee99d519cc94ae47ffcf60504f2182fc09", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-anthropic` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the Anthropic chat model:\n\n[source,application.properties]\n----\nspring.ai.anthropic.api-key=YOUR_API_KEY\nspring.ai.anthropic.chat.options.model=claude-3-5-sonnet-latest\nspring.ai.anthropic.chat.options.temperature=0.7\nspring.ai.anthropic.chat.options.max-tokens=450\n----\n\nTIP: Replace the `api-key` with your Anthropic credentials.\n\nThis will create a `AnthropicChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final AnthropicChatModel chatModel;\n\n @Autowired\n public ChatController(AnthropicChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 7, "section_index": 97, "content_hash": "a323009c371480a257842e51cd197cee99d519cc94ae47ffcf60504f2182fc09", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:4004087cef9fa660f5c1cd31982f3d526c2e7b5c6f55411f891816d968231373", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/main/java/org/springframework/ai/anthropic/AnthropicChatModel.java[AnthropicChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the Anthropic service.\n\nAdd the `spring-ai-anthropic` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-anthropic</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-anthropic'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `AnthropicChatModel` and use it for text generations:\n\n[source,java]\n----\nvar anthropicApi = new AnthropicApi(System.getenv(\"ANTHROPIC_API_KEY\"));\nvar anthropicChatOptions = AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-20250219\")\n .temperature(0.4)\n .maxTokens(200)\n .build()\nvar chatModel = AnthropicChatModel.builder().anthropicApi(anthropicApi)\n .defaultOptions(anthropicChatOptions).build();\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `AnthropicChatOptions` provides the configuration information for the chat requests.\nThe `AnthropicChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 7, "section_index": 98, "content_hash": "4004087cef9fa660f5c1cd31982f3d526c2e7b5c6f55411f891816d968231373", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:d9d20583d0133de37db35b9e5f7406ad84108587f4abd0343b7313ee033b28d5", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/main/java/org/springframework/ai/anthropic/api/AnthropicApi.java[AnthropicApi] provides is lightweight Java client for link:https://docs.anthropic.com/claude/reference/messages_post[Anthropic Message API].\n\nFollowing class diagram illustrates the `AnthropicApi` chat interfaces and building blocks:\n\nimage::anthropic-claude3-class-diagram.jpg[AnthropicApi Chat API Diagram, width=1000, align=\"center\"]\n\nimage::anthropic-claude3-events-model.jpg[AnthropicApi Event Model, width=1000, align=\"center\"]\n\nHere is a simple snippet how to use the api programmatically:\n\n[source,java]\n----\nAnthropicApi anthropicApi =\n new AnthropicApi(System.getenv(\"ANTHROPIC_API_KEY\"));\n\nAnthropicMessage chatCompletionMessage = new AnthropicMessage(\n List.of(new ContentBlock(\"Tell me a Joke?\")), Role.USER);\n\nResponseEntity<ChatCompletionResponse> response = this.anthropicApi\n .chatCompletionEntity(new ChatCompletionRequest(AnthropicApi.ChatModel.CLAUDE_3_OPUS.getValue(),\n List.of(this.chatCompletionMessage), null, 100, 0.8, false));\n\nFlux<StreamResponse> response = this.anthropicApi\n .chatCompletionStream(new ChatCompletionRequest(AnthropicApi.ChatModel.CLAUDE_3_OPUS.getValue(),\n List.of(this.chatCompletionMessage), null, 100, 0.8, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/main/java/org/springframework/ai/anthropic/api/AnthropicApi.java[AnthropicApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Low-level AnthropicApi Client [[low-level-api]]", "heading_level": 2, "file_order": 7, "section_index": 99, "content_hash": "d9d20583d0133de37db35b9e5f7406ad84108587f4abd0343b7313ee033b28d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:315f6e141fabe22d4eea99ffaee78f3fa8acfee1cfd4495b37dd35891889e2ce", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic/src/test/java/org/springframework/ai/anthropic/chat/api/AnthropicApiIT.java[AnthropicApiIT.java] test provides some general examples how to use the lightweight library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc", "title": "Anthropic Chat", "heading": "Low-level API Examples", "heading_level": 3, "file_order": 7, "section_index": 100, "content_hash": "315f6e141fabe22d4eea99ffaee78f3fa8acfee1cfd4495b37dd35891889e2ce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/anthropic-chat.adoc"}}
{"id": "sha256:ad0b41aadc173044a28b3477ad2f22f3387d4b3c8fc915f63837bc4363e04c4e", "content": "Azure's OpenAI offering, powered by ChatGPT, extends beyond traditional OpenAI capabilities, delivering AI-driven text generation with enhanced functionality. Azure offers additional AI safety and responsible AI features, as highlighted in their recent update https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/announcing-new-ai-safety-amp-responsible-ai-features-in-azure/ba-p/3983686[here].\n\nAzure offers Java developers the opportunity to leverage AI's full potential by integrating it with an array of Azure services, which includes AI-related resources such as Vector Stores on Azure.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Azure OpenAI Chat", "heading_level": 1, "file_order": 8, "section_index": 0, "content_hash": "ad0b41aadc173044a28b3477ad2f22f3387d4b3c8fc915f63837bc4363e04c4e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:040acd0d375085a7adbbdf1ef67dc595eaefcaca5deae38383ed051ef39e891c", "content": "The Azure OpenAI client offers three options to connect: using an Azure API key or using an OpenAI API Key, or using Microsoft Entra ID.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 8, "section_index": 1, "content_hash": "040acd0d375085a7adbbdf1ef67dc595eaefcaca5deae38383ed051ef39e891c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:e4b63b989a94fac815ad4d1e5ccdadabc21e6fbd7c5be3acdc59d29358bea0fb", "content": "To access models using an API key, obtain your Azure OpenAI `endpoint` and `api-key` from the Azure OpenAI Service section on the https://portal.azure.com[Azure Portal].\n\nSpring AI defines two configuration properties:\n\n1. `spring.ai.azure.openai.api-key`: Set this to the value of the `API Key` obtained from Azure.\n2. `spring.ai.azure.openai.endpoint`: Set this to the endpoint URL obtained when provisioning your model in Azure.\n\nYou can set these configuration properties in your `application.properties` or `application.yml` file:\n\n[source,properties]\n----\nspring.ai.azure.openai.api-key=<your-azure-api-key>\nspring.ai.azure.openai.endpoint=<your-azure-endpoint-url>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference custom environment variables:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n azure:\n openai:\n api-key: ${AZURE_OPENAI_API_KEY}\n endpoint: ${AZURE_OPENAI_ENDPOINT}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>\nexport AZURE_OPENAI_ENDPOINT=<your-azure-openai-endpoint-url>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Azure API Key & Endpoint", "heading_level": 3, "file_order": 8, "section_index": 2, "content_hash": "e4b63b989a94fac815ad4d1e5ccdadabc21e6fbd7c5be3acdc59d29358bea0fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:7f70af361dba16280ce2511f5b7f8652c6184d44b94f2ae7384a36da54970c06", "content": "To authenticate with the OpenAI service (not Azure), provide an OpenAI API key. This will automatically set the endpoint to https://api.openai.com/v1.\n\nWhen using this approach, set the `spring.ai.azure.openai.chat.options.deployment-name` property to the name of the https://platform.openai.com/docs/models[OpenAI model] you wish to use.\n\nIn your application configuration:\n\n[source,properties]\n----\nspring.ai.azure.openai.openai-api-key=<your-azure-openai-key>\nspring.ai.azure.openai.chat.options.deployment-name=<openai-model-name>\n----\n\nUsing environment variables with SpEL:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n azure:\n openai:\n openai-api-key: ${AZURE_OPENAI_API_KEY}\n chat:\n options:\n deployment-name: ${AZURE_OPENAI_MODEL_NAME}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AZURE_OPENAI_API_KEY=<your-openai-key>\nexport AZURE_OPENAI_MODEL_NAME=<openai-model-name>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "OpenAI Key", "heading_level": 3, "file_order": 8, "section_index": 3, "content_hash": "7f70af361dba16280ce2511f5b7f8652c6184d44b94f2ae7384a36da54970c06", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:768dd1519457495b7572dc9eac8725ceb11027cbc96f62f0d73deaf21de47606", "content": "For keyless authentication using Microsoft Entra ID (formerly Azure Active Directory), set _only_ the `spring.ai.azure.openai.endpoint` configuration property and _not_ the api-key property mentioned above.\n\nFinding only the endpoint property, your application will evaluate several different options for retrieving credentials and an `OpenAIClient` instance will be created using the token credentials.\n\nNOTE: It is no longer necessary to create a `TokenCredential` bean; it is configured for you automatically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Microsoft Entra ID", "heading_level": 3, "file_order": 8, "section_index": 4, "content_hash": "768dd1519457495b7572dc9eac8725ceb11027cbc96f62f0d73deaf21de47606", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:317173971f68c61d6bf474c5f457c57c689cb00d46a7ed0c97112f3c8d2fb146", "content": "To use Azure AI applications, you need to create an Azure AI Deployment through the link:https://oai.azure.com/portal[Azure AI Portal].\nIn Azure, each client must specify a `Deployment Name` to connect to the Azure OpenAI service.\nIt's important to note that the `Deployment Name` is different from the model you choose to deploy.\nFor example, a deployment named 'MyAiDeployment' could be configured to use either the GPT 3.5 Turbo model or the GPT 4.0 model.\n\nTo get started, follow these steps to create a deployment with the default settings:\n\n Deployment Name: `gpt-4o`\n Model Name: `gpt-4o`\n\nThis Azure configuration aligns with the default configurations of the Spring Boot Azure AI Starter and its Autoconfiguration feature.\nIf you use a different Deployment Name, make sure to update the configuration property accordingly:\n\n```\nspring.ai.azure.openai.chat.options.deployment-name=<my deployment name>\n```\n\nThe different deployment structures of Azure OpenAI and OpenAI leads to a property in the Azure OpenAI client library named `deploymentOrModelName`.\nThis is because in OpenAI there is no `Deployment Name`, only a `Model Name`.\n\nNOTE: The property `spring.ai.azure.openai.chat.options.model` has been renamed to `spring.ai.azure.openai.chat.options.deployment-name`.\n\nNOTE: If you decide to connect to `OpenAI` instead of `Azure OpenAI`, by setting the `spring.ai.azure.openai.openai-api-key=<Your OpenAI Key>` property,\nthen the `spring.ai.azure.openai.chat.options.deployment-name` is treated as an link:https://platform.openai.com/docs/models[OpenAI model] name.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Deployment Name", "heading_level": 3, "file_order": 8, "section_index": 5, "content_hash": "317173971f68c61d6bf474c5f457c57c689cb00d46a7ed0c97112f3c8d2fb146", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:8c844aaab98f5c3e0143d1e3b147acdf01c81a71701d503fb55b8be7b5fbf946", "content": "You can configure the client to use directly `OpenAI` instead of the `Azure OpenAI` deployed models.\nFor this you need to set the `spring.ai.azure.openai.openai-api-key=<Your OpenAI Key>` instead of `spring.ai.azure.openai.api-key=<Your Azure OpenAi Key>`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Access the OpenAI Model", "heading_level": 4, "file_order": 8, "section_index": 6, "content_hash": "8c844aaab98f5c3e0143d1e3b147acdf01c81a71701d503fb55b8be7b5fbf946", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:3cdcfbfea05e4491c083fca86991e2c626d3ba0a3c86069ed9efec627cc0dedb", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 8, "section_index": 7, "content_hash": "3cdcfbfea05e4491c083fca86991e2c626d3ba0a3c86069ed9efec627cc0dedb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:f2f7d2efe62894f828d38acf2ce5fac24c5cd81455d60c7e39633e4f9a3eb84c", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-azure-openai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-azure-openai'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nThe Azure OpenAI Chat Client is created using the link:https://github.com/Azure/azure-sdk-for-java/blob/main/sdk/openai/azure-ai-openai/src/main/java/com/azure/ai/openai/OpenAIClientBuilder.java[OpenAIClientBuilder] provided by the Azure SDK. Spring AI allows to customize the builder by providing link:https://github.com/spring-projects/spring-ai/blob/main/auto-configurations/models/spring-ai-autoconfigure-model-azure-openai/src/main/java/org/springframework/ai/model/azure/openai/autoconfigure/AzureOpenAIClientBuilderCustomizer.java[AzureOpenAIClientBuilderCustomizer] beans.\n\nA customizer might be used for example to change the default response timeout:\n\n[source,java]\n----\n@Configuration\npublic class AzureOpenAiConfig {\n\n\t@Bean\n\tpublic AzureOpenAIClientBuilderCustomizer responseTimeoutCustomizer() {\n return openAiClientBuilder -> {\n HttpClientOptions clientOptions = new HttpClientOptions()\n .setResponseTimeout(Duration.ofMinutes(5));\n openAiClientBuilder.httpClient(HttpClient.createDefault(clientOptions));\n };\n\t}\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 8, "section_index": 8, "content_hash": "f2f7d2efe62894f828d38acf2ce5fac24c5cd81455d60c7e39633e4f9a3eb84c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:644821b096774b399820c2064fc9b44af1939de6e8dbb804d846171038469998", "content": "The prefix `spring.ai.azure.openai` is the property prefix to configure the connection to Azure OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.azure.openai.api-key | The Key from Azure AI OpenAI `Keys and Endpoint` section under `Resource Management` | -\n| spring.ai.azure.openai.endpoint | The endpoint from the Azure AI OpenAI `Keys and Endpoint` section under `Resource Management` | -\n| spring.ai.azure.openai.openai-api-key | (non Azure) OpenAI API key. Used to authenticate with the OpenAI service, instead of Azure OpenAI.\nThis automatically sets the endpoint to https://api.openai.com/v1. Use either `api-key` or `openai-api-key` property.\nWith this configuration the `spring.ai.azure.openai.chat.options.deployment-name` is treated as an https://platform.openai.com/docs/models[OpenAi Model] name.| -\n| spring.ai.azure.openai.custom-headers | A map of custom headers to be included in the API requests. Each entry in the map represents a header, where the key is the header name and the value is the header value. | Empty map\n|====\n\n[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=azure-openai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match azure-openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.azure.openai.chat` is the property prefix that configures the `ChatModel` implementation for Azure OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.azure.openai.chat.enabled (Removed and no longer valid) | Enable Azure OpenAI chat model. | true\n| spring.ai.model.chat | Enable Azure OpenAI chat model. | azure-openai\n| spring.ai.azure.openai.chat.options.deployment-name | In use with Azure, this refers to the \"Deployment Name\" of your model, which you can find at https://oai.azure.com/portal.\nIt's important to note that within an Azure OpenAI deployment, the \"Deployment Name\" is distinct from the model itself.\nThe confusion around these terms stems from the intention to make the Azure OpenAI client library compatible with the original OpenAI endpoint.\nThe deployment structures offered by Azure OpenAI and Sam Altman's OpenAI differ significantly.\nDeployments model name to provide as part of this completions request. | gpt-4o\n| spring.ai.azure.openai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. *Use for non-reasoning models (e.g., gpt-4o, gpt-3.5-turbo). Cannot be used with maxCompletionTokens.* | -\n| spring.ai.azure.openai.chat.options.maxCompletionTokens | An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens. *Required for reasoning models (e.g., o1, o3, o4-mini series). Cannot be used with maxTokens.* | -\n| spring.ai.azure.openai.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | -\n| spring.ai.azure.openai.chat.options.topP | An alternative to sampling with temperature called nucleus sampling. This value causes the model to consider the results of tokens with the provided probability mass. | -\n| spring.ai.azure.openai.chat.options.logitBias | A map between GPT token IDs and bias scores that influences the probability of specific tokens appearing in a completions response. Token IDs are computed via external tokenizer tools, while bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias score varies by model. | -\n| spring.ai.azure.openai.chat.options.user | An identifier for the caller or end user of the operation. This may be used for tracking or rate-limiting purposes. | -\n| spring.ai.azure.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n| spring.ai.azure.openai.chat.options.n | The number of chat completions choices that should be generated for a chat completions response. | -\n| spring.ai.azure.openai.chat.options.stop | A collection of textual sequences that will end completions generation. | -\n| spring.ai.azure.openai.chat.options.presencePenalty | A value that influences the probability of generated tokens appearing based on their existing presence in generated text. Positive values will make tokens less likely to appear when they already exist and increase the model's likelihood to output new topics. | -\n| spring.ai.azure.openai.chat.options.responseFormat.type | Compatible with `GPT-4o`, `GPT-4o mini`, `GPT-4 Turbo` and all `GPT-3.5 Turbo` models newer than `gpt-3.5-turbo-1106`.\nThe `JSON_OBJECT` type enables JSON mode, which guarantees the message the model generates is valid JSON.\nThe `JSON_SCHEMA` type enables Structured Outputs which guarantees the model will match your supplied JSON schema. The `JSON_SCHEMA` type requires setting the `responseFormat.schema` property as well. | -\n| spring.ai.azure.openai.chat.options.responseFormat.schema | Response format JSON schema. Applicable only for `responseFormat.type=JSON_SCHEMA` | -\n| spring.ai.azure.openai.chat.options.frequencyPenalty | A value that influences the probability of generated tokens appearing based on their cumulative frequency in generated text. Positive values will make tokens less likely to appear as their frequency increases and decrease the likelihood of the model repeating the same statements verbatim. | -\n| spring.ai.azure.openai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.azure.openai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.azure.openai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nTIP: All properties prefixed with `spring.ai.azure.openai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Chat Properties", "heading_level": 3, "file_order": 8, "section_index": 9, "content_hash": "644821b096774b399820c2064fc9b44af1939de6e8dbb804d846171038469998", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:3d51302fce1f10f8960fc6647cf8b0a7a12e9977c3c1298a01ffa2e49a5dc0d2", "content": "Azure OpenAI has model-specific requirements for token limiting parameters:\n\n[cols=\"1,1,2\", options=\"header\"]\n|====\n| Model Family | Required Parameter | Notes\n\n| **Reasoning Models** +\n(o1, o3, o4-mini series)\n| `maxCompletionTokens`\n| These models only accept `maxCompletionTokens`. Using `maxTokens` will result in an API error.\n\n| **Non-Reasoning Models** +\n(gpt-4o, gpt-3.5-turbo, etc.)\n| `maxTokens`\n| Traditional models use `maxTokens` for output limiting. Using `maxCompletionTokens` may result in an API error.\n|====\n\nIMPORTANT: The parameters `maxTokens` and `maxCompletionTokens` are **mutually exclusive**. Setting both parameters simultaneously will result in an API error from Azure OpenAI. The Spring AI Azure OpenAI client will automatically clear the previously set parameter when you set the other one, with a warning message.\n\n.Example: Using maxCompletionTokens for reasoning models\n[source,java]\n----\nvar options = AzureOpenAiChatOptions.builder()\n .deploymentName(\"o1-preview\")\n .maxCompletionTokens(500) // Required for reasoning models\n .build();\n----\n\n.Example: Using maxTokens for non-reasoning models\n[source,java]\n----\nvar options = AzureOpenAiChatOptions.builder()\n .deploymentName(\"gpt-4o\")\n .maxTokens(500) // Required for non-reasoning models\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Token Limit Parameters: Model-Specific Usage", "heading_level": 3, "file_order": 8, "section_index": 10, "content_hash": "3d51302fce1f10f8960fc6647cf8b0a7a12e9977c3c1298a01ffa2e49a5dc0d2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:e9a2501bf6f3addcbd98d7a8c4fbdb2029973e3a0eb5b27478f593618a78294f", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-azure-openai/src/main/java/org/springframework/ai/azure/openai/AzureOpenAiChatOptions.java[AzureOpenAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `AzureOpenAiChatModel(api, options)` constructor or the `spring.ai.azure.openai.chat.options.*` properties.\n\nAt runtime you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n AzureOpenAiChatOptions.builder()\n .deploymentName(\"gpt-4o\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-azure-openai/src/main/java/org/springframework/ai/azure/openai/AzureOpenAiChatOptions.java[AzureOpenAiChatOptions.java] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 8, "section_index": 11, "content_hash": "e9a2501bf6f3addcbd98d7a8c4fbdb2029973e3a0eb5b27478f593618a78294f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:a73a100969133e9eae7bf262539ec99b17845c6382ee71ddab632d1be24fea3c", "content": "You can register custom Java functions with the AzureOpenAiChatModel and have the model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 8, "section_index": 12, "content_hash": "a73a100969133e9eae7bf262539ec99b17845c6382ee71ddab632d1be24fea3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:84fefabea35e9ccf3142c7457a23f4ce1736e2ba50cc373428d6058b260731cf", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.\nPresently, the Azure OpenAI `gpt-4o` model offers multimodal support.\n\nThe Azure OpenAI can incorporate a list of base64-encoded images or image urls with the message.\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a code example excerpted from link:https://github.com/spring-projects/spring-ai/blob/c9a3e66f90187ce7eae7eb78c462ec622685de6c/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/OpenAiChatModelIT.java#L293[OpenAiChatModelIT.java], illustrating the fusion of user text with an image using the `GPT_4_O` model.\n\n[source,java]\n----\nURL url = new URL(\"https://docs.spring.io/spring-ai/reference/_images/multimodal.test.png\");\nString response = ChatClient.create(chatModel).prompt()\n .options(AzureOpenAiChatOptions.builder().deploymentName(\"gpt-4o\").build())\n .user(u -> u.text(\"Explain what do you see on this picture?\").media(MimeTypeUtils.IMAGE_PNG, this.url))\n .call()\n .content();\n----\n\nTIP: you can pass multiple images as well.\n\nIt takes as an input the `multimodal.test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generates a response like this:\n\n----\nThis is an image of a fruit bowl with a simple design. The bowl is made of metal with curved wire edges that\ncreate an open structure, allowing the fruit to be visible from all angles. Inside the bowl, there are two\nyellow bananas resting on top of what appears to be a red apple. The bananas are slightly overripe, as\nindicated by the brown spots on their peels. The bowl has a metal ring at the top, likely to serve as a handle\nfor carrying. The bowl is placed on a flat surface with a neutral-colored background that provides a clear\nview of the fruit inside.\n----\n\nYou can also pass in a classpath resource instead of a URL as shown in the example below\n\n[source,java]\n----\nResource resource = new ClassPathResource(\"multimodality/multimodal.test.png\");\n\nString response = ChatClient.create(chatModel).prompt()\n .options(AzureOpenAiChatOptions.builder()\n .deploymentName(\"gpt-4o\").build())\n .user(u -> u.text(\"Explain what do you see on this picture?\")\n .media(MimeTypeUtils.IMAGE_PNG, this.resource))\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 8, "section_index": 13, "content_hash": "84fefabea35e9ccf3142c7457a23f4ce1736e2ba50cc373428d6058b260731cf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:9ce2ddc62f6aa3608f9cc1116cc615b9456b1fba3874a04267ac86a588468a8f", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-azure-openai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.azure.openai.api-key=YOUR_API_KEY\nspring.ai.azure.openai.endpoint=YOUR_ENDPOINT\nspring.ai.azure.openai.chat.options.deployment-name=gpt-4o\nspring.ai.azure.openai.chat.options.temperature=0.7\n----\n\nTIP: replace the `api-key` and `endpoint` with your Azure OpenAI credentials.\n\nThis will create a `AzureOpenAiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final AzureOpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(AzureOpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 8, "section_index": 14, "content_hash": "9ce2ddc62f6aa3608f9cc1116cc615b9456b1fba3874a04267ac86a588468a8f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:ef610a0f83d830c3f54ef661ed32652c426400657c3392d8b39fc0edb6b427e7", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-azure-openai/src/main/java/org/springframework/ai/azure/openai/AzureOpenAiChatModel.java[AzureOpenAiChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the link:https://learn.microsoft.com/en-us/java/api/overview/azure/ai-openai-readme?view=azure-java-preview[Azure OpenAI Java Client].\n\nTo enable it, add the `spring-ai-azure-openai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: The `spring-ai-azure-openai` dependency also provide the access to the `AzureOpenAiChatModel`. For more information about the `AzureOpenAiChatModel` refer to the link:../chat/azure-openai-chat.html[Azure OpenAI Chat] section.\n\nNext, create an `AzureOpenAiChatModel` instance and use it to generate text responses:\n\n[source,java]\n----\nvar openAIClientBuilder = new OpenAIClientBuilder()\n .credential(new AzureKeyCredential(System.getenv(\"AZURE_OPENAI_API_KEY\")))\n .endpoint(System.getenv(\"AZURE_OPENAI_ENDPOINT\"));\n\nvar openAIChatOptions = AzureOpenAiChatOptions.builder()\n .deploymentName(\"gpt-5\")\n .temperature(0.4)\n .maxCompletionTokens(200)\n .build();\n\nvar chatModel = AzureOpenAiChatModel.builder()\n .openAIClientBuilder(openAIClientBuilder)\n .defaultOptions(openAIChatOptions)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> streamingResponses = chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\n----\n\nNOTE: the `gpt-4o` is actually the `Deployment Name` as presented in the Azure AI Portal.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc", "title": "Azure OpenAI Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 8, "section_index": 15, "content_hash": "ef610a0f83d830c3f54ef661ed32652c426400657c3392d8b39fc0edb6b427e7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/azure-openai-chat.adoc"}}
{"id": "sha256:375bc332bf9648220ce6740e1c703eb1378f9cc003a38a81118482867b1b5acb", "content": "link:https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html[Amazon Bedrock Converse API] provides a unified interface for conversational AI models with enhanced capabilities including function/tool calling, multimodal inputs, and streaming responses.\n\nThe Bedrock Converse API has the following high-level features:\n\n* Tool/Function Calling: Support for function definitions and tool use during conversations\n* Multimodal Input: Ability to process both text and image inputs in conversations\n* Streaming Support: Real-time streaming of model responses\n* System Messages: Support for system-level instructions and context setting\n\nTIP: The Bedrock Converse API provides a unified interface across multiple model providers while handling AWS-specific authentication and infrastructure concerns.\nCurrently, the Converse API link:https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html[Supported Models] include:\n`Amazon Titan`, `Amazon Nova`, `AI21 Labs`, `Anthropic Claude`, `Cohere Command`, `Meta Llama`, `Mistral AI`.\n\n[NOTE]\n====\nFollowing the Bedrock recommendations, Spring AI is transitioning to using Amazon Bedrock's Converse API for all chat conversation implementations in Spring AI.\nWhile the existing xref:api/bedrock-chat.adoc[InvokeModel API] supports conversation applications, we strongly recommend adopting the Converse API for all Chat conversation models.\n\nThe Converse API does not support embedding operations, so these will remain in the current API and the embedding model functionality in the existing `InvokeModel API` will be maintained\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Bedrock Converse API", "heading_level": 1, "file_order": 9, "section_index": 0, "content_hash": "375bc332bf9648220ce6740e1c703eb1378f9cc003a38a81118482867b1b5acb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:8b3ad12801c09f733086ec44d09fc04869d4bc34fa02f6289eadd2f7c6f0c834", "content": "Refer to https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html[Getting started with Amazon Bedrock] for setting up API access\n\n* Obtain AWS credentials: If you don't have an AWS account and AWS CLI configured yet, this video guide can help you configure it: link:https://youtu.be/gswVHTrRX8I?si=buaY7aeI0l3-bBVb[AWS CLI & SDK Setup in Less Than 4 Minutes!]. You should be able to obtain your access and security keys.\n\n* Enable the Models to use: Go to link:https://us-east-1.console.aws.amazon.com/bedrock/home[Amazon Bedrock] and from the link:https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess[Model Access] menu on the left, configure access to the models you are going to use.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Prerequisites", "heading_level": 2, "file_order": 9, "section_index": 1, "content_hash": "8b3ad12801c09f733086ec44d09fc04869d4bc34fa02f6289eadd2f7c6f0c834", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:fb2fe6481910c9d1f21fb8dc022dbb15305fb3f93d0cdef84b087616a19d6633", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the `spring-ai-starter-model-bedrock-converse` dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-bedrock-converse</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-bedrock-converse'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Auto-configuration", "heading_level": 2, "file_order": 9, "section_index": 2, "content_hash": "fb2fe6481910c9d1f21fb8dc022dbb15305fb3f93d0cdef84b087616a19d6633", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:5013b14dc05c40bb31f38085ca90378f4249059aaeee5a74b2bdb487d21ddcc0", "content": "The prefix `spring.ai.bedrock.aws` is the property prefix to configure the connection to AWS Bedrock.\n\n[cols=\"3,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.bedrock.aws.region | AWS region to use | us-east-1\n| spring.ai.bedrock.aws.timeout | AWS max duration for entire API call | 5m\n| spring.ai.bedrock.aws.connectionTimeout | Max duration to wait while establishing connection | 5s\n| spring.ai.bedrock.aws.connectionAcquisitionTimeout | Max duration to wait for new connection from the pool | 30s\n| spring.ai.bedrock.aws.asyncReadTimeout | Max duration spent reading asynchronous responses | 30s\n| spring.ai.bedrock.aws.access-key | AWS access key | -\n| spring.ai.bedrock.aws.secret-key | AWS secret key | -\n| spring.ai.bedrock.aws.session-token | AWS session token for temporary credentials | -\n| spring.ai.bedrock.aws.profile.name | AWS profile name. | -\n| spring.ai.bedrock.aws.profile.credentials-path | AWS credentials file path. | -\n| spring.ai.bedrock.aws.profile.configuration-path | AWS config file path. | -\n|====\n\n[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=bedrock-converse (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match bedrock-converse)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.bedrock.converse.chat` is the property prefix that configures the chat model implementation for the Converse API.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.bedrock.converse.chat.enabled (Removed and no longer valid) | Enable Bedrock Converse chat model. | true\n| spring.ai.model.chat | Enable Bedrock Converse chat model. | bedrock-converse\n| spring.ai.bedrock.converse.chat.options.model | The model ID to use. You can use the https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html[Supported models and model features] | None. Select your https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/models[modelId] from the AWS Bedrock console.\n| spring.ai.bedrock.converse.chat.options.temperature | Controls the randomness of the output. Values can range over [0.0,1.0] | 0.8\n| spring.ai.bedrock.converse.chat.options.top-p | The maximum cumulative probability of tokens to consider when sampling. | AWS Bedrock default\n| spring.ai.bedrock.converse.chat.options.top-k | Number of token choices for generating the next token. | AWS Bedrock default\n| spring.ai.bedrock.converse.chat.options.max-tokens | Maximum number of tokens in the generated response. | 500\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Chat Properties", "heading_level": 3, "file_order": 9, "section_index": 3, "content_hash": "5013b14dc05c40bb31f38085ca90378f4249059aaeee5a74b2bdb487d21ddcc0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:1bbf7ca46092251e17d8ecdf6b160f07ec7ecfbd4a03a145c6a7e9424d67f06c", "content": "Use the portable `ChatOptions` or `BedrockChatOptions` portable builders to create model configurations, such as temperature, maxToken, topP, etc.\n\nOn start-up, the default options can be configured with the `BedrockConverseProxyChatModel(api, options)` constructor or the `spring.ai.bedrock.converse.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call:\n\n[source,java]\n----\nvar options = BedrockChatOptions.builder()\n .model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\")\n .temperature(0.6)\n .maxTokens(300)\n .toolCallbacks(List.of(FunctionToolCallback.builder(\"getCurrentWeather\", new WeatherService())\n .description(\"Get the weather in location. Return temperature in 36°F or 36°C format. Use multi-turn if needed.\")\n .inputType(WeatherService.Request.class)\n .build()))\n .build();\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What is current weather in Amsterdam?\")\n .options(options)\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 9, "section_index": 4, "content_hash": "1bbf7ca46092251e17d8ecdf6b160f07ec7ecfbd4a03a145c6a7e9424d67f06c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:a3ca3abe75edb1f6bf768703ea80244cc6fd964446894710412f6602be05765c", "content": "AWS Bedrock's https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-caching.html[prompt caching feature] allows you to cache frequently used prompts to reduce costs and improve response times for repeated interactions.\nWhen you cache a prompt, subsequent identical requests can reuse the cached content, significantly reducing the number of input tokens processed.\n\n[NOTE]\n====\n*Supported Models*\n\nPrompt caching is supported on Claude 3.x, Claude 4.x, and Amazon Nova models available through AWS Bedrock.\n\n*Token Requirements*\n\nDifferent models have different minimum token thresholds for cache effectiveness:\n- Claude Sonnet 4 and most models: 1024+ tokens\n- Model-specific requirements may vary - consult AWS Bedrock documentation\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Prompt Caching", "heading_level": 2, "file_order": 9, "section_index": 5, "content_hash": "a3ca3abe75edb1f6bf768703ea80244cc6fd964446894710412f6602be05765c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:1b69804687720eab9bfd1734156b653de6596a1ef0be5ccb54d0649440f14510", "content": "Spring AI provides strategic cache placement through the `BedrockCacheStrategy` enum:\n\n* `NONE`: Disables prompt caching completely (default)\n* `SYSTEM_ONLY`: Caches only the system message content\n* `TOOLS_ONLY`: Caches tool definitions only (Claude models only)\n* `SYSTEM_AND_TOOLS`: Caches both system message and tool definitions (Claude models only)\n* `CONVERSATION_HISTORY`: Caches entire conversation history in chat memory scenarios\n\nThis strategic approach ensures optimal cache breakpoint placement while staying within AWS Bedrock's 4-breakpoint limit.\n\n[NOTE]\n====\n*Amazon Nova Limitations*\n\nAmazon Nova models (Nova Micro, Lite, Pro, Premier) only support caching for `system` and `messages` content.\nThey do **not** support caching for `tools`.\n\nIf you attempt to use `TOOLS_ONLY` or `SYSTEM_AND_TOOLS` strategies with Nova models, AWS will return a `ValidationException`.\nUse `SYSTEM_ONLY` strategy for Amazon Nova models.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Cache Strategies", "heading_level": 3, "file_order": 9, "section_index": 6, "content_hash": "1b69804687720eab9bfd1734156b653de6596a1ef0be5ccb54d0649440f14510", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:a5b5ff186966256e5da37aff6702cf29539abedfd64e0b54dd89ea7d2b3772de", "content": "Enable prompt caching by setting `cacheOptions` on `BedrockChatOptions` and choosing a `strategy`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Enabling Prompt Caching", "heading_level": 3, "file_order": 9, "section_index": 7, "content_hash": "a5b5ff186966256e5da37aff6702cf29539abedfd64e0b54dd89ea7d2b3772de", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:cd83123a08956fd2ca8bfac502770a5fef77c0530e4164f789da5ba549bc72cf", "content": "The most common use case - cache system instructions across multiple requests:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a helpful AI assistant with extensive knowledge...\"),\n new UserMessage(\"What is machine learning?\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "System-Only Caching", "heading_level": 4, "file_order": 9, "section_index": 8, "content_hash": "cd83123a08956fd2ca8bfac502770a5fef77c0530e4164f789da5ba549bc72cf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:78e52182c6215d0ac68f43b7fe9cd3f527ccfc43f9c2a6b99b47ba6c06c695c6", "content": "Cache large tool definitions while keeping system prompts dynamic (Claude models only):\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What's the weather in San Francisco?\",\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.TOOLS_ONLY)\n .build())\n .toolCallbacks(weatherToolCallbacks) // Large tool definitions\n .maxTokens(500)\n .build()\n )\n);\n----\n\nNOTE: This strategy is only supported on Claude models.\nAmazon Nova models will return a `ValidationException`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Tools-Only Caching", "heading_level": 4, "file_order": 9, "section_index": 9, "content_hash": "78e52182c6215d0ac68f43b7fe9cd3f527ccfc43f9c2a6b99b47ba6c06c695c6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:c21907e56e6392a3f9af5c0a3cd0ede8560f886982e27c088157d4874119eec8", "content": "Cache both system instructions and tool definitions for maximum reuse (Claude models only):\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a weather analysis assistant...\"),\n new UserMessage(\"What's the weather like in Tokyo?\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_AND_TOOLS)\n .build())\n .toolCallbacks(weatherToolCallbacks)\n .maxTokens(500)\n .build()\n )\n);\n----\n\nNOTE: This strategy uses 2 cache breakpoints (one for tools, one for system).\nOnly supported on Claude models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "System and Tools Caching", "heading_level": 4, "file_order": 9, "section_index": 10, "content_hash": "c21907e56e6392a3f9af5c0a3cd0ede8560f886982e27c088157d4874119eec8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:6510e93504817b8a7dcf230c8c19862e88e2cc137be4d180b03af905babcd717", "content": "Cache growing conversation history for multi-turn chatbots and assistants:\n\n[source,java]\n----\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultSystem(\"You are a personalized career counselor...\")\n .defaultAdvisors(MessageChatMemoryAdvisor.builder(chatMemory)\n .conversationId(conversationId)\n .build())\n .build();\n\nString response = chatClient.prompt()\n .user(\"What career advice would you give me?\")\n .options(BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.CONVERSATION_HISTORY)\n .build())\n .maxTokens(500)\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Conversation History Caching", "heading_level": 4, "file_order": 9, "section_index": 11, "content_hash": "6510e93504817b8a7dcf230c8c19862e88e2cc137be4d180b03af905babcd717", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:20dbe53fab5ec67fdbd20fc2ced6ad48085f58e127f810daff75c79958277602", "content": "[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .system(\"You are an expert document analyst...\")\n .user(\"Analyze this large document: \" + document)\n .options(BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Using ChatClient Fluent API", "heading_level": 4, "file_order": 9, "section_index": 12, "content_hash": "20dbe53fab5ec67fdbd20fc2ced6ad48085f58e127f810daff75c79958277602", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:0cb492b1982e5f95d2faeebe7bb0d5a9289efdf48ce8d0882b43b4515961dcec", "content": "Here's a complete example demonstrating prompt caching with cost tracking:\n\n[source,java]\n----\nString largeSystemPrompt = \"You are an expert software architect specializing in distributed systems...\";\n\nChatResponse firstResponse = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(largeSystemPrompt),\n new UserMessage(\"What is microservices architecture?\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n\nInteger cacheWrite1 = (Integer) firstResponse.getMetadata()\n .getMetadata()\n .get(\"cacheWriteInputTokens\");\nInteger cacheRead1 = (Integer) firstResponse.getMetadata()\n .getMetadata()\n .get(\"cacheReadInputTokens\");\n\nSystem.out.println(\"Cache creation tokens: \" + cacheWrite1);\nSystem.out.println(\"Cache read tokens: \" + cacheRead1);\n\nChatResponse secondResponse = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(largeSystemPrompt), // Same prompt - cache hit\n new UserMessage(\"What are the benefits of event sourcing?\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(500)\n .build()\n )\n);\n\nInteger cacheWrite2 = (Integer) secondResponse.getMetadata()\n .getMetadata()\n .get(\"cacheWriteInputTokens\");\nInteger cacheRead2 = (Integer) secondResponse.getMetadata()\n .getMetadata()\n .get(\"cacheReadInputTokens\");\n\nSystem.out.println(\"Cache creation tokens: \" + cacheWrite2); // Should be 0\nSystem.out.println(\"Cache read tokens: \" + cacheRead2); // Should be > 0\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Usage Example", "heading_level": 3, "file_order": 9, "section_index": 13, "content_hash": "0cb492b1982e5f95d2faeebe7bb0d5a9289efdf48ce8d0882b43b4515961dcec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:df2c917055d4ad089b873ae05db9980ab4dc240ce79cd05a5ee2b8f895c7e24c", "content": "AWS Bedrock provides cache-specific metrics through the response.\nCache metrics are accessible via two methods:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Token Usage Tracking", "heading_level": 3, "file_order": 9, "section_index": 14, "content_hash": "df2c917055d4ad089b873ae05db9980ab4dc240ce79cd05a5ee2b8f895c7e24c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:ac735bfdab41f5b09cf0229f058b0d84e8dfd7a1a31787ebd97a5f5002018696", "content": "For observability handlers and metrics collection, access cache metrics through the native `TokenUsage` object:\n\n[source,java]\n----\nimport software.amazon.awssdk.services.bedrockruntime.model.TokenUsage;\n\nChatResponse response = chatModel.call(/* ... */);\n\nTokenUsage tokenUsage = (TokenUsage) response.getMetadata()\n .getUsage()\n .getNativeUsage();\n\nif (tokenUsage != null) {\n Integer cacheWrite = tokenUsage.cacheWriteInputTokens();\n Integer cacheRead = tokenUsage.cacheReadInputTokens();\n System.out.println(\"Cache write: \" + cacheWrite + \", Cache read: \" + cacheRead);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Native Usage Object (Recommended for Observability)", "heading_level": 4, "file_order": 9, "section_index": 15, "content_hash": "ac735bfdab41f5b09cf0229f058b0d84e8dfd7a1a31787ebd97a5f5002018696", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:aa5736a90e22be1143f661031a62a10a300a71f3c0499571965eb59e1e6ef033", "content": "Cache metrics are also available via the metadata Map for backward compatibility:\n\n[source,java]\n----\nChatResponse response = chatModel.call(/* ... */);\n\nInteger cacheWrite = (Integer) response.getMetadata()\n .getMetadata()\n .get(\"cacheWriteInputTokens\");\nInteger cacheRead = (Integer) response.getMetadata()\n .getMetadata()\n .get(\"cacheReadInputTokens\");\n----\n\nCache-specific metrics include:\n\n* `cacheWriteInputTokens`: Returns the number of tokens used when creating a cache entry\n* `cacheReadInputTokens`: Returns the number of tokens read from an existing cache entry\n\nWhen you first send a cached prompt:\n- `cacheWriteInputTokens` will be greater than 0\n- `cacheReadInputTokens` will be 0\n\nWhen you send the same cached prompt again (within 5-minute TTL):\n- `cacheWriteInputTokens` will be 0\n- `cacheReadInputTokens` will be greater than 0", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Metadata Map (Backward Compatible)", "heading_level": 4, "file_order": 9, "section_index": 16, "content_hash": "aa5736a90e22be1143f661031a62a10a300a71f3c0499571965eb59e1e6ef033", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:6e01da562833bd5bf6f3101fce6450a693cb1049dcdee6168fc16a51b62b1831", "content": "Analyze large legal contracts or compliance documents efficiently by caching document content across multiple questions:\n\n[source,java]\n----\nString legalContract = loadDocument(\"merger-agreement.pdf\"); // ~3000 tokens\n\nString legalSystemPrompt = \"You are an expert legal analyst specializing in corporate law. \" +\n \"Analyze the following contract and provide precise answers about terms, obligations, and risks: \" +\n legalContract;\n\nChatResponse riskAnalysis = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(legalSystemPrompt),\n new UserMessage(\"What are the key termination clauses and associated penalties?\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(1000)\n .build()\n )\n);\n\nChatResponse obligationAnalysis = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(legalSystemPrompt), // Same content - cache hit\n new UserMessage(\"List all financial obligations and payment schedules.\")\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(1000)\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Legal Document Analysis", "heading_level": 4, "file_order": 9, "section_index": 17, "content_hash": "6e01da562833bd5bf6f3101fce6450a693cb1049dcdee6168fc16a51b62b1831", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:604972aabe1fc01c4a9a3527cc5ce027d12d3fe1503c5805376f3e701f51a1d7", "content": "Process multiple code files with consistent review criteria while caching the review guidelines:\n\n[source,java]\n----\nString reviewGuidelines = \"\"\"\n You are a senior software engineer conducting code reviews. Apply these criteria:\n - Security vulnerabilities and best practices\n - Performance optimizations and memory usage\n - Code maintainability and readability\n - Testing coverage and edge cases\n - Design patterns and architecture compliance\n \"\"\";\n\nList<String> codeFiles = Arrays.asList(\n \"UserService.java\", \"PaymentController.java\", \"SecurityConfig.java\"\n);\n\nList<String> reviews = new ArrayList<>();\n\nfor (String filename : codeFiles) {\n String sourceCode = loadSourceFile(filename);\n\n ChatResponse review = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(reviewGuidelines), // Cached across all reviews\n new UserMessage(\"Review this \" + filename + \" code:\\n\\n\" + sourceCode)\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(800)\n .build()\n )\n );\n\n reviews.add(review.getResult().getOutput().getText());\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Batch Code Review", "heading_level": 4, "file_order": 9, "section_index": 18, "content_hash": "604972aabe1fc01c4a9a3527cc5ce027d12d3fe1503c5805376f3e701f51a1d7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:c8f089c65bcda3aaf7465dd160a43ae7c25635dab6d0a63ec4c89411ade4201e", "content": "Create a customer support system that caches your product knowledge base for consistent, accurate responses:\n\n[source,java]\n----\nString knowledgeBase = \"\"\"\n PRODUCT DOCUMENTATION:\n - API endpoints and authentication methods\n - Common troubleshooting procedures\n - Billing and subscription details\n - Integration guides and examples\n - Known issues and workarounds\n \"\"\" + loadProductDocs(); // ~2500 tokens\n\n@Service\npublic class CustomerSupportService {\n\n public String handleCustomerQuery(String customerQuery, String customerId) {\n ChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(\"You are a helpful customer support agent. \" +\n \"Use this knowledge base to provide accurate solutions: \" + knowledgeBase),\n new UserMessage(\"Customer \" + customerId + \" asks: \" + customerQuery)\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_ONLY)\n .build())\n .maxTokens(600)\n .build()\n )\n );\n\n return response.getResult().getOutput().getText();\n }\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Customer Support with Knowledge Base", "heading_level": 4, "file_order": 9, "section_index": 19, "content_hash": "c8f089c65bcda3aaf7465dd160a43ae7c25635dab6d0a63ec4c89411ade4201e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:38c6ddafc8c6d97e380f9fb13283f4296ef9374deef4ee35131d3b42a298ab19", "content": "Cache shared tool definitions across different tenants while customizing system prompts per tenant:\n\n[source,java]\n----\nList<FunctionToolCallback> sharedTools = createLargeToolRegistry(); // ~2000 tokens\n\n@Service\npublic class MultiTenantAIService {\n\n public String processRequest(String tenantId, String userQuery) {\n // Load tenant-specific system prompt (changes per tenant)\n String tenantPrompt = loadTenantSystemPrompt(tenantId);\n\n ChatResponse response = chatModel.call(\n new Prompt(\n List.of(\n new SystemMessage(tenantPrompt), // Tenant-specific, not cached\n new UserMessage(userQuery)\n ),\n BedrockChatOptions.builder()\n .model(\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.TOOLS_ONLY)\n .build())\n .toolCallbacks(sharedTools) // Shared tools - cached\n .maxTokens(500)\n .build()\n )\n );\n\n return response.getResult().getOutput().getText();\n }\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Multi-Tenant SaaS Application", "heading_level": 4, "file_order": 9, "section_index": 20, "content_hash": "38c6ddafc8c6d97e380f9fb13283f4296ef9374deef4ee35131d3b42a298ab19", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:529eaa4a4921d05b9612b0b74f91d58c8c49002a5ae5a2ac9825b789bd8631db", "content": "1. **Choose the Right Strategy**:\n - Use `SYSTEM_ONLY` for reusable system prompts and instructions (works with all models)\n - Use `TOOLS_ONLY` when you have large stable tools but dynamic system prompts (Claude only)\n - Use `SYSTEM_AND_TOOLS` when both system and tools are large and stable (Claude only)\n - Use `CONVERSATION_HISTORY` with ChatClient memory for multi-turn conversations\n - Use `NONE` to explicitly disable caching\n\n2. **Meet Token Requirements**: Focus on caching content that meets the minimum token requirements (1024+ tokens for most models).\n\n3. **Reuse Identical Content**: Caching works best with exact matches of prompt content.\nEven small changes will require a new cache entry.\n\n4. **Monitor Token Usage**: Track cache effectiveness using the metadata metrics:\n\n Integer cacheWrite = (Integer) response.getMetadata().getMetadata().get(\"cacheWriteInputTokens\");\n Integer cacheRead = (Integer) response.getMetadata().getMetadata().get(\"cacheReadInputTokens\");\n if (cacheRead != null && cacheRead > 0) {\n System.out.println(\"Cache hit: \" + cacheRead + \" tokens saved\");\n }\n\n5. **Strategic Cache Placement**: The implementation automatically places cache breakpoints at optimal locations based on your chosen strategy, ensuring compliance with AWS Bedrock's 4-breakpoint limit.\n\n6. **Cache Lifetime**: AWS Bedrock caches have a fixed 5-minute TTL (Time To Live).\nEach cache access resets the timer.\n\n7. **Model Compatibility**: Be aware of model-specific limitations:\n - **Claude models**: Support all caching strategies\n - **Amazon Nova models**: Only support `SYSTEM_ONLY` and `CONVERSATION_HISTORY` (tool caching not supported)\n\n8. **Tool Stability**: When using `TOOLS_ONLY`, `SYSTEM_AND_TOOLS`, or `CONVERSATION_HISTORY` strategies, ensure tools remain stable.\nChanging tool definitions will invalidate all downstream cache breakpoints due to cascade invalidation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Best Practices", "heading_level": 3, "file_order": 9, "section_index": 21, "content_hash": "529eaa4a4921d05b9612b0b74f91d58c8c49002a5ae5a2ac9825b789bd8631db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:ed36a364ca6e59eeb44d0b907955ac676e47541e3894fb4a02337074d98cda6f", "content": "AWS Bedrock follows a hierarchical cache model with cascade invalidation:\n\n**Cache Hierarchy**: `Tools → System → Messages`\n\nChanges at each level invalidate that level and all subsequent levels:\n\n[cols=\"1,1,1,1\", stripes=even]\n|====\n| What Changes | Tools Cache | System Cache | Messages Cache\n\n| Tools | ❌ Invalid | ❌ Invalid | ❌ Invalid\n| System | ✅ Valid | ❌ Invalid | ❌ Invalid\n| Messages | ✅ Valid | ✅ Valid | ❌ Invalid\n|====\n\n**Example with `SYSTEM_AND_TOOLS` strategy**:\n\n[source,java]\n----\nChatResponse r1 = chatModel.call(\n new Prompt(\n List.of(new SystemMessage(\"System prompt\"), new UserMessage(\"Question\")),\n BedrockChatOptions.builder()\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_AND_TOOLS)\n .build())\n .toolCallbacks(tools)\n .build()\n )\n);\n\nChatResponse r2 = chatModel.call(\n new Prompt(\n List.of(new SystemMessage(\"DIFFERENT system prompt\"), new UserMessage(\"Question\")),\n BedrockChatOptions.builder()\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_AND_TOOLS)\n .build())\n .toolCallbacks(tools) // SAME tools\n .build()\n )\n);\n\nChatResponse r3 = chatModel.call(\n new Prompt(\n List.of(new SystemMessage(\"DIFFERENT system prompt\"), new UserMessage(\"Question\")),\n BedrockChatOptions.builder()\n .cacheOptions(BedrockCacheOptions.builder()\n .strategy(BedrockCacheStrategy.SYSTEM_AND_TOOLS)\n .build())\n .toolCallbacks(newTools) // DIFFERENT tools\n .build()\n )\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Cache Invalidation and Cascade Behavior", "heading_level": 3, "file_order": 9, "section_index": 22, "content_hash": "ed36a364ca6e59eeb44d0b907955ac676e47541e3894fb4a02337074d98cda6f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:1e21c85bc30832799b9aa0d8862e1da5f7406cb11f27f26226b8ad1407d82639", "content": "The prompt caching implementation in Spring AI follows these key design principles:\n\n1. **Strategic Cache Placement**: Cache breakpoints are automatically placed at optimal locations based on the chosen strategy, ensuring compliance with AWS Bedrock's 4-breakpoint limit.\n\n2. **Provider Portability**: Cache configuration is done through `BedrockChatOptions` rather than individual messages, preserving compatibility when switching between different AI providers.\n\n3. **Thread Safety**: The cache breakpoint tracking is implemented with thread-safe mechanisms to handle concurrent requests correctly.\n\n4. **UNION Type Pattern**: AWS SDK uses UNION types where cache points are added as separate blocks rather than properties.\nThis is different from direct API approaches but ensures type safety and API compliance.\n\n5. **Incremental Caching**: The `CONVERSATION_HISTORY` strategy places cache breakpoints on the last user message, enabling incremental caching where each conversation turn builds on the previous cached prefix.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Implementation Details", "heading_level": 3, "file_order": 9, "section_index": 23, "content_hash": "1e21c85bc30832799b9aa0d8862e1da5f7406cb11f27f26226b8ad1407d82639", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:205f292a0a12a0bc2b93758b071f39aec723ff9b258e905dc38d8959f2c37e3a", "content": "AWS Bedrock pricing for prompt caching (approximate, varies by model):\n\n* **Cache writes**: ~25% more expensive than base input tokens\n* **Cache reads**: ~90% cheaper (only 10% of base input token price)\n* **Break-even point**: After just 1 cache read, you've saved money\n\n**Example cost calculation**:\n\n[source,java]\n----\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Cost Considerations", "heading_level": 3, "file_order": 9, "section_index": 24, "content_hash": "205f292a0a12a0bc2b93758b071f39aec723ff9b258e905dc38d8959f2c37e3a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:3d7b1d4b0a24f04f8514dcb87160c19c00d779b9276e142f42dd498864dd1958", "content": "The Bedrock Converse API supports tool calling capabilities, allowing models to use tools during conversations.\nHere's an example of how to define and use @Tool based tools:\n\n[source,java]\n----\n\npublic class WeatherService {\n\n @Tool(description = \"Get the weather in location\")\n public String weatherByLocation(@ToolParam(description= \"City or state name\") String location) {\n ...\n }\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .tools(new WeatherService())\n .call()\n .content();\n----\n\nYou can use the java.util.function beans as tools as well:\n\n[source,java]\n----\n@Bean\n@Description(\"Get the weather in location. Return temperature in 36°F or 36°C format.\")\npublic Function<Request, Response> weatherFunction() {\n return new MockWeatherService();\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .toolNames(\"weatherFunction\")\n .inputType(Request.class)\n .call()\n .content();\n----\n\nFind more in xref:api/tools.adoc[Tools] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Tool Calling", "heading_level": 2, "file_order": 9, "section_index": 25, "content_hash": "3d7b1d4b0a24f04f8514dcb87160c19c00d779b9276e142f42dd498864dd1958", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:a17547de1b601497e8cc01e4bdfa3991af6bcdea09e70df8d8be8a11e96ab08e", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, video, pdf, doc, html, md and more data formats.\n\nThe Bedrock Converse API supports multimodal inputs, including text and image inputs, and can generate a text response based on the combined input.\n\nYou need a model that supports multimodal inputs, such as the Anthropic Claude or Amazon Nova models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Multimodal", "heading_level": 2, "file_order": 9, "section_index": 26, "content_hash": "a17547de1b601497e8cc01e4bdfa3991af6bcdea09e70df8d8be8a11e96ab08e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:4d5f2aca6e45db91460bda7ed5127e9cf69d3e17fe362e247452eba99518b23f", "content": "For link:https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html[models] that support vision multimodality, such as Amazon Nova, Anthropic Claude, Llama 3.2, the Bedrock Converse API Amazon allows you to include multiple images in the payload. Those models can analyze the passed images and answer questions, classify an image, as well as summarize images based on provided instructions.\n\nCurrently, Bedrock Converse supports the `base64` encoded images of `image/jpeg`, `image/png`, `image/gif` and `image/webp` mime types.\n\nSpring AI's `Message` interface supports multimodal AI models by introducing the `Media` type.\nIt contains data and information about media attachments in messages, using Spring's `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a simple code example, demonstrating the combination of user text with an image.\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(u -> u.text(\"Explain what do you see on this picture?\")\n .media(Media.Format.IMAGE_PNG, new ClassPathResource(\"/test.png\")))\n .call()\n .content();\n\nlogger.info(response);\n----\n\nIt takes as an input the `test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generates a response something like:\n\n----\nThe image shows a close-up view of a wire fruit basket containing several pieces of fruit.\n...\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Images", "heading_level": 3, "file_order": 9, "section_index": 27, "content_hash": "4d5f2aca6e45db91460bda7ed5127e9cf69d3e17fe362e247452eba99518b23f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:c55000d56d9c839229d50b1e1646dd88f68be8daf008902d9d149a79e04af07e", "content": "The link:https://docs.aws.amazon.com/nova/latest/userguide/modalities-video.html[Amazon Nova models] allow you to include a single video in the payload, which can be provided either in base64 format or through an Amazon S3 URI.\n\nCurrently, Bedrock Nova supports the videos of `video/x-matroska`, `video/quicktime`, `video/mp4`, `video/webm`, `video/x-flv`, `video/mpeg`, `video/x-ms-wmv` and `video/3gpp` mime types.\n\nSpring AI's `Message` interface supports multimodal AI models by introducing the `Media` type.\nIt contains data and information about media attachments in messages, using Spring's `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a simple code example, demonstrating the combination of user text with a video.\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(u -> u.text(\"Explain what do you see in this video?\")\n .media(Media.Format.VIDEO_MP4, new ClassPathResource(\"/test.video.mp4\")))\n .call()\n .content();\n\nlogger.info(response);\n----\n\nIt takes as an input the `test.video.mp4` image:\n\nimage::test.video.jpeg[Multimodal Test Video, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see in this video?\", and generates a response something like:\n\n----\nThe video shows a group of baby chickens, also known as chicks, huddled together on a surface\n...\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Video", "heading_level": 3, "file_order": 9, "section_index": 28, "content_hash": "c55000d56d9c839229d50b1e1646dd88f68be8daf008902d9d149a79e04af07e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:b95de994df4c48e2204ae4fce059d3316fade671d4d45287b72e9a3fd079bb0e", "content": "For some models, Bedrock allows you to include documents in the payload through Converse API document support, which can be provided in bytes.\nThe document support has two different variants as explained below:\n\n- **Text document types** (txt, csv, html, md, and so on), where the emphasis is on text understanding. These use case include answering based on textual elements of the document.\n- **Media document types** (pdf, docx, xlsx), where the emphasis is on vision-based understanding to answer questions. These use cases include answering questions based on charts, graphs, and so on.\n\nCurrently the Anthropic link:https://docs.anthropic.com/en/docs/build-with-claude/pdf-support[PDF support (beta)] and Amazon Bedrock Nova models support document multimodality.\n\nBelow is a simple code example, demonstrating the combination of user text with a media document.\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(u -> u.text(\n \"You are a very professional document summarization specialist. Please summarize the given document.\")\n .media(Media.Format.DOC_PDF, new ClassPathResource(\"/spring-ai-reference-overview.pdf\")))\n .call()\n .content();\n\nlogger.info(response);\n----\n\nIt takes as an input the `spring-ai-reference-overview.pdf` document:\n\nimage::test.pdf.png[Multimodal Test PNG, 200, 200, align=\"left\"]\n\nalong with the text message \"You are a very professional document summarization specialist. Please summarize the given document.\", and generates a response something like:\n\n----\n**Introduction:**\n- Spring AI is designed to simplify the development of applications with artificial intelligence (AI) capabilities, aiming to avoid unnecessary complexity.\n...\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Documents", "heading_level": 3, "file_order": 9, "section_index": 29, "content_hash": "b95de994df4c48e2204ae4fce059d3316fade671d4d45287b72e9a3fd079bb0e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:786e0ecb13df8fc4286a453c95b0ffbdaa8d2d3623f86e2ee3832d5382574800", "content": "Create a new Spring Boot project and add the `spring-ai-starter-model-bedrock-converse` to your dependencies.\n\nAdd an `application.properties` file under `src/main/resources`:\n\n[source,properties]\n----\nspring.ai.bedrock.aws.region=eu-central-1\nspring.ai.bedrock.aws.timeout=10m\nspring.ai.bedrock.aws.access-key=${AWS_ACCESS_KEY_ID}\nspring.ai.bedrock.aws.secret-key=${AWS_SECRET_ACCESS_KEY}\n# session token is only required for temporary credentials\nspring.ai.bedrock.aws.session-token=${AWS_SESSION_TOKEN}\n\nspring.ai.bedrock.converse.chat.options.temperature=0.8\nspring.ai.bedrock.converse.chat.options.top-k=15\n----\n\nHere's an example controller using the chat model:\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final ChatClient chatClient;\n\n @Autowired\n public ChatController(ChatClient.Builder builder) {\n this.chatClient = builder.build();\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatClient.prompt(message).call().content());\n }\n\n @GetMapping(\"/ai/generateStream\")\n public Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return this.chatClient.prompt(message).stream().content();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc", "title": "Bedrock Converse API", "heading": "Sample Controller", "heading_level": 2, "file_order": 9, "section_index": 30, "content_hash": "786e0ecb13df8fc4286a453c95b0ffbdaa8d2d3623f86e2ee3832d5382574800", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/bedrock-converse.adoc"}}
{"id": "sha256:520e23003034fd28b841ba61c0f0708d6e8deb3695506d0353f082c98b644153", "content": "This table compares various Chat Models supported by Spring AI, detailing their capabilities:\n\n- xref:api/multimodality.adoc[Multimodality]: The types of input the model can process (e.g., text, image, audio, video).\n- xref:api/tools.adoc[Tools/Function Calling]: Whether the model supports function calling or tool use.\n- Streaming: If the model offers streaming responses.\n- Retry: Support for retry mechanisms.\n- xref:observability/index.adoc[Observability]: Features for monitoring and debugging.\n- xref:api/structured-output-converter.adoc#_built_in_json_mode[Built-in JSON]: Native support for JSON output.\n- Local deployment: Whether the model can be run locally.\n- OpenAI API Compatibility: If the model is compatible with OpenAI's API.\n\n[cols=\"10,5,1,1,1,1,1,1,1\", stripes=even]\n|====\n| Provider | Multimodality ^| Tools/Functions ^| Streaming ^| Retry ^| Observability ^| Built-in JSON ^| Local ^| OpenAI API Compatible\n\n| xref::api/chat/anthropic-chat.adoc[Anthropic Claude] | text, pdf, image ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/azure-openai-chat.adoc[Azure OpenAI] | text, image ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/deepseek-chat.adoc[DeepSeek (OpenAI-proxy)] | text ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16]\n| xref::api/chat/google-genai-chat.adoc[Google GenAI] | text, pdf, image, audio, video ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/vertexai-gemini-chat.adoc[Google VertexAI Gemini] | text, pdf, image, audio, video ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/groq-chat.adoc[Groq (OpenAI-proxy)] | text, image ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/huggingface.adoc[HuggingFace] | text ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/mistralai-chat.adoc[Mistral AI] | text, image, audio ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/minimax-chat.adoc[MiniMax] | text ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/moonshot-chat.adoc[Moonshot AI] | text ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a|\n| xref::api/chat/nvidia-chat.adoc[NVIDIA (OpenAI-proxy)] | text, image ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/oci-genai/cohere-chat.adoc[OCI GenAI/Cohere] | text ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/ollama-chat.adoc[Ollama] | text, image ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16]\n| xref::api/chat/openai-sdk-chat.adoc[OpenAI SDK (Official)] a| In: text, image, audio\nOut: text, audio ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/openai-chat.adoc[OpenAI] a| In: text, image, audio\nOut: text, audio ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/perplexity-chat.adoc[Perplexity (OpenAI-proxy)] | text ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16]\n| xref::api/chat/qianfan-chat.adoc[QianFan] | text ^a| image::no.svg[width=12] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/zhipuai-chat.adoc[ZhiPu AI] | text, image, docs ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n| xref::api/chat/bedrock-converse.adoc[Amazon Bedrock Converse] | text, image, video, docs (pdf, html, md, docx ...) ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::yes.svg[width=16] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12] ^a| image::no.svg[width=12]\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/comparison.adoc", "title": "Chat Models Comparison", "heading": "Chat Models Comparison", "heading_level": 1, "file_order": 10, "section_index": 0, "content_hash": "520e23003034fd28b841ba61c0f0708d6e8deb3695506d0353f082c98b644153", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/comparison.adoc"}}
{"id": "sha256:3d86b4175f3299bc299accc030fd852600ab1669107c9d55e9d4f5152f3e047f", "content": "Spring AI supports the various AI language models from DeepSeek. You can interact with DeepSeek language models and create a multilingual conversational assistant based on DeepSeek models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "DeepSeek Chat", "heading_level": 1, "file_order": 11, "section_index": 0, "content_hash": "3d86b4175f3299bc299accc030fd852600ab1669107c9d55e9d4f5152f3e047f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:25969b67fa29bfabcac42ef758d0fbcb07233a8e41cd69025ab67803a0d39314", "content": "You will need to create an API key with DeepSeek to access DeepSeek language models.\n\nCreate an account at https://platform.deepseek.com/sign_up[DeepSeek registration page] and generate a token on the https://platform.deepseek.com/api_keys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.deepseek.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.deepseek.api-key=<your-deepseek-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n deepseek:\n api-key: ${DEEPSEEK_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport DEEPSEEK_API_KEY=<your-deepseek-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"DEEPSEEK_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 11, "section_index": 1, "content_hash": "25969b67fa29bfabcac42ef758d0fbcb07233a8e41cd69025ab67803a0d39314", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:28d0f801808db6d77c4dcb76bde5e200693225a4255ead9fea690b96b79cdcc2", "content": "Spring AI artifacts are published in the Spring Milestone and Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout your entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 11, "section_index": 2, "content_hash": "28d0f801808db6d77c4dcb76bde5e200693225a4255ead9fea690b96b79cdcc2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:99b82d8a972c366216c5875394a4fded36b7be1dc06bc885ac6e148a7a43f22e", "content": "Spring AI provides Spring Boot auto-configuration for the DeepSeek Chat Model.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-deepseek</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-deepseek'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 11, "section_index": 3, "content_hash": "99b82d8a972c366216c5875394a4fded36b7be1dc06bc885ac6e148a7a43f22e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:1e3c76cd8f8f3c941988d3ac62a0835d5389ee8704ac844214972a210a5ea5e3", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the DeepSeek Chat model.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throws a NonTransientAiException, and does not attempt a retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 11, "section_index": 4, "content_hash": "1e3c76cd8f8f3c941988d3ac62a0835d5389ee8704ac844214972a210a5ea5e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:4167e8b9340adf9bf5c479265d85fdd0cda12605309b49e85a7724a2e19a3aba", "content": "The prefix `spring.ai.deepseek` is used as the property prefix that lets you connect to DeepSeek.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.deepseek.base-url | The URL to connect to | `+https://api.deepseek.com+`\n| spring.ai.deepseek.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 11, "section_index": 5, "content_hash": "4167e8b9340adf9bf5c479265d85fdd0cda12605309b49e85a7724a2e19a3aba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:e0b7a49c6e045abe63dc684d4057c078a428f300df29c301e720ca861df65feb", "content": "The prefix `spring.ai.deepseek.chat` is the property prefix that lets you configure the chat model implementation for DeepSeek.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.deepseek.chat.enabled | Enables the DeepSeek chat model. | true\n| spring.ai.deepseek.chat.base-url | Optionally overrides the spring.ai.deepseek.base-url to provide a chat-specific URL | `+https://api.deepseek.com/+`\n| spring.ai.deepseek.chat.api-key | Optionally overrides the spring.ai.deepseek.api-key to provide a chat-specific API key | -\n| spring.ai.deepseek.chat.completions-path | The path to the chat completions endpoint | `/chat/completions`\n| spring.ai.deepseek.chat.beta-prefix-path | The prefix path to the beta feature endpoint | `/beta`\n| spring.ai.deepseek.chat.options.model | ID of the model to use. You can use either deepseek-reasoner or deepseek-chat. | deepseek-chat\n| spring.ai.deepseek.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.deepseek.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.deepseek.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | 0.0f\n| spring.ai.deepseek.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.deepseek.chat.options.temperature | Which sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p, but not both. | 1.0F\n| spring.ai.deepseek.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature, but not both. | 1.0F\n| spring.ai.deepseek.chat.options.logprobs | Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of the message. | -\n| spring.ai.deepseek.chat.options.topLogprobs | An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used. | -\n| spring.ai.deepseek.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.deepseek.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.deepseek.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nNOTE: You can override the common `spring.ai.deepseek.base-url` and `spring.ai.deepseek.api-key` for the `ChatModel` implementations.\nThe `spring.ai.deepseek.chat.base-url` and `spring.ai.deepseek.chat.api-key` properties, if set, take precedence over the common properties.\nThis is useful if you want to use different DeepSeek accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.deepseek.chat.options` can be overridden at runtime by adding a request-specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 11, "section_index": 6, "content_hash": "e0b7a49c6e045abe63dc684d4057c078a428f300df29c301e720ca861df65feb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:309c5ceccde4d39fb6b11eff300ec9b06b0f04e17b1f112f09d268d6d7d72986", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/main/java/org/springframework/ai/deepseek/DeepSeekChatOptions.java[DeepSeekChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn startup, the default options can be configured with the `DeepSeekChatModel(api, options)` constructor or the `spring.ai.deepseek.chat.options.*` properties.\n\nAt runtime, you can override the default options by adding new, request-specific options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates. Please provide the JSON response without any code block markers such as ```json```.\",\n DeepSeekChatOptions.builder()\n .withModel(DeepSeekApi.ChatModel.DEEPSEEK_CHAT.getValue())\n .withTemperature(0.8f)\n .build()\n ));\n----\n\nTIP: In addition to the model-specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/main/java/org/springframework/ai/deepseek/DeepSeekChatOptions.java[DeepSeekChatOptions], you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 11, "section_index": 7, "content_hash": "309c5ceccde4d39fb6b11eff300ec9b06b0f04e17b1f112f09d268d6d7d72986", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:7ecefb532f1469044dc49a90f8274e1a44a520ad09e82eb7460cd187aaabc747", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-deepseek` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file under the `src/main/resources` directory to enable and configure the DeepSeek Chat model:\n\n[source,application.properties]\n----\nspring.ai.deepseek.api-key=YOUR_API_KEY\nspring.ai.deepseek.chat.options.model=deepseek-chat\nspring.ai.deepseek.chat.options.temperature=0.8\n----\n\nTIP: Replace the `api-key` with your DeepSeek credentials.\n\nThis will create a `DeepSeekChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generation.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final DeepSeekChatModel chatModel;\n\n @Autowired\n public ChatController(DeepSeekChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var prompt = new Prompt(new UserMessage(message));\n return chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Sample Controller (Auto-configuration)", "heading_level": 2, "file_order": 11, "section_index": 8, "content_hash": "7ecefb532f1469044dc49a90f8274e1a44a520ad09e82eb7460cd187aaabc747", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:816c12e5c7a7e123f9d2de7b83b6c0f287934388f8bc083d137c5bf15f0ac58f", "content": "The chat prefix completion follows the Chat Completion API, where users provide an assistant's prefix message for the model to complete the rest of the message.\n\nWhen using prefix completion, the user must ensure that the last message in the messages list is a DeepSeekAssistantMessage.\n\nBelow is a complete Java code example for chat prefix completion. In this example, we set the prefix message of the assistant to \"```python\\n\" to force the model to output Python code, and set the stop parameter to ['```'] to prevent additional explanations from the model.\n\n[source,java]\n----\n@RestController\npublic class CodeGenerateController {\n\n private final DeepSeekChatModel chatModel;\n\n @Autowired\n public ChatController(DeepSeekChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generatePythonCode\")\n public String generate(@RequestParam(value = \"message\", defaultValue = \"Please write quick sort code\") String message) {\n UserMessage userMessage = new UserMessage(message);\n Message assistantMessage = DeepSeekAssistantMessage.prefixAssistantMessage(\"```python\\\\n\");\n Prompt prompt = new Prompt(List.of(userMessage, assistantMessage), ChatOptions.builder().stopSequences(List.of(\"```\")).build());\n ChatResponse response = chatModel.call(prompt);\n return response.getResult().getOutput().getText();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Chat Prefix Completion", "heading_level": 2, "file_order": 11, "section_index": 9, "content_hash": "816c12e5c7a7e123f9d2de7b83b6c0f287934388f8bc083d137c5bf15f0ac58f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:93f6c1e30e83a9a31fb7539b124cdc1b62d7d8826e8d6c742aab6d6bf8c2ab00", "content": "The `deepseek-reasoner` is a reasoning model developed by DeepSeek. Before delivering the final answer, the model first generates a Chain of Thought (CoT) to enhance the accuracy of its responses. Our API provides users with access to the CoT content generated by `deepseek-reasoner`, enabling them to view, display, and distill it.\n\nYou can use the `DeepSeekAssistantMessage` to get the CoT content generated by `deepseek-reasoner`.\n[source,java]\n----\npublic void deepSeekReasonerExample() {\n DeepSeekChatOptions promptOptions = DeepSeekChatOptions.builder()\n .model(DeepSeekApi.ChatModel.DEEPSEEK_REASONER.getValue())\n .build();\n Prompt prompt = new Prompt(\"9.11 and 9.8, which is greater?\", promptOptions);\n ChatResponse response = chatModel.call(prompt);\n\n // Get the CoT content generated by deepseek-reasoner, only available when using deepseek-reasoner model\n DeepSeekAssistantMessage deepSeekAssistantMessage = (DeepSeekAssistantMessage) response.getResult().getOutput();\n String reasoningContent = deepSeekAssistantMessage.getReasoningContent();\n String text = deepSeekAssistantMessage.getText();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Reasoning Model (deepseek-reasoner)", "heading_level": 2, "file_order": 11, "section_index": 10, "content_hash": "93f6c1e30e83a9a31fb7539b124cdc1b62d7d8826e8d6c742aab6d6bf8c2ab00", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:537c101187cdd1baf21088c35a26212179f76014d7bce070f58586b21c923992", "content": "In each round of the conversation, the model outputs the CoT (reasoning_content) and the final answer (content). In the next round of the conversation, the CoT from previous rounds is not concatenated into the context, as illustrated in the following diagram:\n\nimage::deepseek_r1_multiround_example.png[Multimodal Test Image, align=\"center\"]\n\nPlease note that if the reasoning_content field is included in the sequence of input messages, the API will return a 400 error. Therefore, you should remove the reasoning_content field from the API response before making the API request, as demonstrated in the API example.\n[source,java]\n----\npublic String deepSeekReasonerMultiRoundExample() {\n List<Message> messages = new ArrayList<>();\n messages.add(new UserMessage(\"9.11 and 9.8, which is greater?\"));\n DeepSeekChatOptions promptOptions = DeepSeekChatOptions.builder()\n .model(DeepSeekApi.ChatModel.DEEPSEEK_REASONER.getValue())\n .build();\n\n Prompt prompt = new Prompt(messages, promptOptions);\n ChatResponse response = chatModel.call(prompt);\n\n DeepSeekAssistantMessage deepSeekAssistantMessage = (DeepSeekAssistantMessage) response.getResult().getOutput();\n String reasoningContent = deepSeekAssistantMessage.getReasoningContent();\n String text = deepSeekAssistantMessage.getText();\n\n messages.add(AssistantMessage.builder().content(Objects.requireNonNull(text)).build());\n messages.add(new UserMessage(\"How many Rs are there in the word 'strawberry'?\"));\n Prompt prompt2 = new Prompt(messages, promptOptions);\n ChatResponse response2 = chatModel.call(prompt2);\n\n DeepSeekAssistantMessage deepSeekAssistantMessage2 = (DeepSeekAssistantMessage) response2.getResult().getOutput();\n String reasoningContent2 = deepSeekAssistantMessage2.getReasoningContent();\n return deepSeekAssistantMessage2.getText();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Reasoning Model Multi-round Conversation", "heading_level": 2, "file_order": 11, "section_index": 11, "content_hash": "537c101187cdd1baf21088c35a26212179f76014d7bce070f58586b21c923992", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:12ac27a2a05032a80cd3051a62140718a83bdafcf6769becc82c7639a8efa8e0", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/main/java/org/springframework/ai/deepseek/DeepSeekChatModel.java[DeepSeekChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the DeepSeek service.\n\nAdd the `spring-ai-deepseek` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-deepseek</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-deepseek'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `DeepSeekChatModel` and use it for text generation:\n\n[source,java]\n----\nDeepSeekApi deepSeekApi = DeepSeekApi.builder()\n .apiKey(System.getenv(\"DEEPSEEK_API_KEY\"))\n .build();\nDeepSeekChatOptions options = DeepSeekChatOptions.builder()\n .model(DeepSeekApi.ChatModel.DEEPSEEK_CHAT.getValue())\n .temperature(0.4)\n .maxTokens(200)\n .build();\nDeepSeekChatModel chatModel = DeepSeekChatModel.builder()\n .deepSeekApi(deepSeekApi)\n .defaultOptions(options)\n .build();\nChatResponse response = chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> streamResponse = chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `DeepSeekChatOptions` provides the configuration information for the chat requests.\nThe `DeepSeekChatOptions.Builder` is a fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 11, "section_index": 12, "content_hash": "12ac27a2a05032a80cd3051a62140718a83bdafcf6769becc82c7639a8efa8e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:ee6247ff46fb8274ee8837cebaf1aff1c6db98591f1af9ccd5dbd0e43231164a", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/main/java/org/springframework/ai/deepseek/api/DeepSeekApi.java[DeepSeekApi] is a lightweight Java client for link:https://platform.deepseek.com/api-docs/[DeepSeek API].\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nDeepSeekApi deepSeekApi =\n new DeepSeekApi(System.getenv(\"DEEPSEEK_API_KEY\"));\n\nChatCompletionMessage chatCompletionMessage =\n new ChatCompletionMessage(\"Hello world\", Role.USER);\n\nResponseEntity<ChatCompletion> response = deepSeekApi.chatCompletionEntity(\n new ChatCompletionRequest(List.of(chatCompletionMessage), DeepSeekApi.ChatModel.DEEPSEEK_CHAT.getValue(), 0.7, false));\n\nFlux<ChatCompletionChunk> streamResponse = deepSeekApi.chatCompletionStream(\n new ChatCompletionRequest(List.of(chatCompletionMessage), DeepSeekApi.ChatModel.DEEPSEEK_CHAT.getValue(), 0.7, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/main/java/org/springframework/ai/deepseek/api/DeepSeekApi.java[DeepSeekApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "Low-level DeepSeekApi Client [[low-level-api]]", "heading_level": 3, "file_order": 11, "section_index": 13, "content_hash": "ee6247ff46fb8274ee8837cebaf1aff1c6db98591f1af9ccd5dbd0e43231164a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:461a70115c2640f14bf43751bee5153a9a43a7ab5ba3b8912b5095f8e754ffb8", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-deepseek/src/test/java/org/springframework/ai/deepseek/api/DeepSeekApiIT.java[DeepSeekApiIT.java] test provides some general examples of how to use the lightweight library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc", "title": "DeepSeek Chat", "heading": "DeepSeekApi Samples", "heading_level": 4, "file_order": 11, "section_index": 14, "content_hash": "461a70115c2640f14bf43751bee5153a9a43a7ab5ba3b8912b5095f8e754ffb8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/deepseek-chat.adoc"}}
{"id": "sha256:30f5185a966272617c372dcbc46342265eba79ab9088c9540ed1b65b415d8af6", "content": "https://docs.docker.com/desktop/features/model-runner/[Docker Model Runner] is an AI Inference Engine offering a wide range of models from link:https://hub.docker.com/u/ai[various providers].\n\nSpring AI integrates with the Docker Model Runner by reusing the existing xref::api/chat/openai-chat.adoc[OpenAI] backed `ChatClient`.\nTo do this, set the base URL to `http://localhost:12434/engines` and select one of the provided https://hub.docker.com/u/ai[LLM models].\n\nCheck the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/DockerModelRunnerWithOpenAiChatModelIT.java[DockerModelRunnerWithOpenAiChatModelIT.java] tests\nfor examples of how to use the Docker Model Runner with Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Docker Model Runner Chat", "heading_level": 1, "file_order": 12, "section_index": 0, "content_hash": "30f5185a966272617c372dcbc46342265eba79ab9088c9540ed1b65b415d8af6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:983234d5c241da6b6e7ade17308d2584b911a2af8dd90fac482a0dae23f8aa43", "content": "* Download Docker Desktop for Mac 4.40.0.\n\nChoose one of the following options to enable the Model Runner:\n\nOption 1:\n\n* Enable Model Runner `docker desktop enable model-runner --tcp 12434`.\n* Set the base-url to `http://localhost:12434/engines`\n\nOption 2:\n\n* Enable Model Runner `docker desktop enable model-runner`.\n* Use Testcontainers and set the base-url as follows:\n\n[source,java]\n----\n@Container\nprivate static final DockerModelRunnerContainer DMR = new DockerModelRunnerContainer(\"alpine/socat:1.7.4.3-r0\");\n\n@Bean\npublic OpenAiApi chatCompletionApi() {\n\tvar baseUrl = DMR.getOpenAIEndpoint();\n\treturn OpenAiApi.builder().baseUrl(baseUrl).apiKey(\"test\").build();\n}\n----\n\nYou can learn more about the Docker Model Runner by reading the https://www.docker.com/blog/run-llms-locally/[Run LLMs Locally with Docker] blog post.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Prerequisite", "heading_level": 2, "file_order": 12, "section_index": 1, "content_hash": "983234d5c241da6b6e7ade17308d2584b911a2af8dd90fac482a0dae23f8aa43", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:105f5e05c20840f162b7a5b06453b02d42bf85349b093b7235c1b95b2426d9f4", "content": "[NOTE]\n====\nThe artifact IDs for Spring AI starter modules have been renamed since version 1.0.0.M7. Dependency names should now follow updated naming patterns for models, vector stores, and MCP starters.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Chat Client.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor add the following to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 12, "section_index": 2, "content_hash": "105f5e05c20840f162b7a5b06453b02d42bf85349b093b7235c1b95b2426d9f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:4b6b5f7eb33e6b92cb91f87dd8b4a05c91f91d2c4b200147fc4ed68455fc8f93", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 12, "section_index": 3, "content_hash": "4b6b5f7eb33e6b92cb91f87dd8b4a05c91f91d2c4b200147fc4ed68455fc8f93", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:6c5bf94456fa2c478565182fd36d26492a90da1ffa0809443c8783e89f0f4af9", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to. Must be set to `https://hub.docker.com/u/ai` | -\n| spring.ai.openai.api-key | Any string | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 12, "section_index": 4, "content_hash": "6c5bf94456fa2c478565182fd36d26492a90da1ffa0809443c8783e89f0f4af9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:3332c9378ace89cc705c7c6aac9e69c7709c2121970a12735a265af7e324d223", "content": "[NOTE]\n====\nEnabling and disabling chat auto-configurations is now done via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, `spring.ai.model.chat=openai` (It is enabled by default)\n\nTo disable, `spring.ai.model.chat=none` (or any value which doesn't match openai)\n\nThis change allows for the configuration of multiple models in your application.\n====\n\nThe prefix `spring.ai.openai.chat` is the property prefix that lets you configure the chat model implementation for OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.chat.enabled (Removed and no longer valid) | Enable OpenAI chat model. | true\n| spring.ai.model.chat | Enable OpenAI chat model. | openai\n| spring.ai.openai.chat.base-url | Optional overrides the `spring.ai.openai.base-url` to provide a chat specific url. Must be set to `http://localhost:12434/engines` | -\n| spring.ai.openai.chat.api-key | Optional overrides the spring.ai.openai.api-key to provide chat specific api-key | -\n| spring.ai.openai.chat.options.model | The link:https://hub.docker.com/u/ai[LLM model] to use | -\n| spring.ai.openai.chat.options.temperature | The sampling temperature that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.openai.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.openai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.openai.chat.options.n | How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs. | 1\n| spring.ai.openai.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | -\n| spring.ai.openai.chat.options.responseFormat | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON.| -\n| spring.ai.openai.chat.options.seed | This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. | -\n| spring.ai.openai.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.openai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both. | -\n| spring.ai.openai.chat.options.tools | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. | -\n| spring.ai.openai.chat.options.toolChoice | Controls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"type: \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function. none is the default when no functions are present. auto is the default if functions are present. | -\n| spring.ai.openai.chat.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n| spring.ai.openai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.openai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.openai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nTIP: All properties prefixed with `spring.ai.openai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 12, "section_index": 5, "content_hash": "3332c9378ace89cc705c7c6aac9e69c7709c2121970a12735a265af7e324d223", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:4e8e8c23d092f71060461b94bd931e9540c210e29ef8851e3887a9e7169d15f2", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiChatModel(api, options)` constructor or the `spring.ai.openai.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiChatOptions.builder()\n .model(\"ai/gemma3:4B-F16\")\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 12, "section_index": 6, "content_hash": "4e8e8c23d092f71060461b94bd931e9540c210e29ef8851e3887a9e7169d15f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:c6f905ff759e966b8907898627124fd644c0dcd0eb3b8101a212c73d24be1988", "content": "Docker Model Runner supports Tool/Function calling when selecting a model that supports it.\n\nYou can register custom Java functions with your ChatModel and have the provided model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique for connecting the LLM capabilities with external tools and APIs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 12, "section_index": 7, "content_hash": "c6f905ff759e966b8907898627124fd644c0dcd0eb3b8101a212c73d24be1988", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:e74232948b1df3c3ff81ec0588b18798ab84dd5edfd8907110a6c5e7b6531585", "content": "Here's a simple example of how to use Docker Model Runner function calling with Spring AI:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=test\nspring.ai.openai.base-url=http://localhost:12434/engines\nspring.ai.openai.chat.options.model=ai/gemma3:4B-F16\n----\n\n[source,java]\n----\n@SpringBootApplication\npublic class DockerModelRunnerLlmApplication {\n\n public static void main(String[] args) {\n SpringApplication.run(DockerModelRunnerLlmApplication.class, args);\n }\n\n @Bean\n CommandLineRunner runner(ChatClient.Builder chatClientBuilder) {\n return args -> {\n var chatClient = chatClientBuilder.build();\n\n var response = chatClient.prompt()\n .user(\"What is the weather in Amsterdam and Paris?\")\n .functions(\"weatherFunction\") // reference by bean name.\n .call()\n .content();\n\n System.out.println(response);\n };\n }\n\n @Bean\n @Description(\"Get the weather in location\")\n public Function<WeatherRequest, WeatherResponse> weatherFunction() {\n return new MockWeatherService();\n }\n\n public static class MockWeatherService implements Function<WeatherRequest, WeatherResponse> {\n\n public record WeatherRequest(String location, String unit) {}\n public record WeatherResponse(double temp, String unit) {}\n\n @Override\n public WeatherResponse apply(WeatherRequest request) {\n double temperature = request.location().contains(\"Amsterdam\") ? 20 : 25;\n return new WeatherResponse(temperature, request.unit);\n }\n }\n}\n----\n\nIn this example, when the model needs weather information, it will automatically call the `weatherFunction` bean, which can then fetch real-time weather data.\nThe expected response is: \"The weather in Amsterdam is currently 20 degrees Celsius, and the weather in Paris is currently 25 degrees Celsius.\"\n\nRead more about OpenAI link:https://docs.spring.io/spring-ai/reference/api/chat/functions/openai-chat-functions.html[Function Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Tool Example", "heading_level": 3, "file_order": 12, "section_index": 8, "content_hash": "e74232948b1df3c3ff81ec0588b18798ab84dd5edfd8907110a6c5e7b6531585", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:83572ab811a477d9084975ca7654291fa01d413adeae49e5b1d72ef9a43c19fb", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-openai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=test\nspring.ai.openai.base-url=http://localhost:12434/engines\nspring.ai.openai.chat.options.model=ai/gemma3:4B-F16\n\n# Docker Model Runner doesn't support embeddings, so we need to disable them.\nspring.ai.openai.embedding.enabled=false\n----\n\nHere is an example of a simple `@Controller` class that uses the chat model for text generation.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/dmr-chat.adoc", "title": "Docker Model Runner Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 12, "section_index": 9, "content_hash": "83572ab811a477d9084975ca7654291fa01d413adeae49e5b1d72ef9a43c19fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/dmr-chat.adoc"}}
{"id": "sha256:d424e710bdb55ad062cedd844a25a412cc27484d45dce5c6ae65859acf8f41b4", "content": "The https://ai.google.dev/gemini-api/docs[Google GenAI API] allows developers to build generative AI applications using Google's Gemini models through either the Gemini Developer API or Vertex AI.\nThe Google GenAI API supports multimodal prompts as input and outputs text or code.\nA multimodal model is capable of processing information from multiple modalities, including images, videos, and text. For example, you can send the model a photo of a plate of cookies and ask it to give you a recipe for those cookies.\n\nGemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to link:https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash[Gemini 2.0 Flash], link:https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash-lite[Gemini 2.0 Flash-Lite], all link:https://ai.google.dev/gemini-api/docs/models[Gemini Pro] models, up to and including the most recent link:https://ai.google.dev/gemini-api/docs/models#gemini-3-pro[Gemini 3 Pro].\n\nThis implementation provides two authentication modes:\n\n- **Gemini Developer API**: Use an API key for quick prototyping and development\n- **Vertex AI**: Use Google Cloud credentials for production deployments with enterprise features\n\nlink:https://ai.google.dev/api[Gemini API Reference]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Google GenAI Chat", "heading_level": 1, "file_order": 13, "section_index": 0, "content_hash": "d424e710bdb55ad062cedd844a25a412cc27484d45dce5c6ae65859acf8f41b4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:713fe597fd4eefcc775b9fecacb81a246db7b61ecd3e5da56a605550c834f906", "content": "Choose one of the following authentication methods:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 13, "section_index": 1, "content_hash": "713fe597fd4eefcc775b9fecacb81a246db7b61ecd3e5da56a605550c834f906", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:b34f71d5081f84f3ebf258c99525bd7a5ccf24952e6d9753ee8c46cc7cb5df53", "content": "- Obtain an API key from the https://aistudio.google.com/app/apikey[Google AI Studio]\n- Set the API key as an environment variable or in your application properties", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Option 1: Gemini Developer API (API Key)", "heading_level": 3, "file_order": 13, "section_index": 2, "content_hash": "b34f71d5081f84f3ebf258c99525bd7a5ccf24952e6d9753ee8c46cc7cb5df53", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:9d5691b43eee311e7ad27a60e13f15d356b2d85dfbf45a23ae41933aa997b794", "content": "- Install the link:https://cloud.google.com/sdk/docs/install[gcloud] CLI, appropriate for your OS.\n- Authenticate by running the following command.\nReplace `PROJECT_ID` with your Google Cloud project ID and `ACCOUNT` with your Google Cloud username.\n\n[source]\n----\ngcloud config set project <PROJECT_ID> &&\ngcloud auth application-default login <ACCOUNT>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Option 2: Vertex AI (Google Cloud)", "heading_level": 3, "file_order": 13, "section_index": 3, "content_hash": "9d5691b43eee311e7ad27a60e13f15d356b2d85dfbf45a23ae41933aa997b794", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:3db356cfadf7d0f62837f6b137dafe73a9e30594a16f5c2fec744d258d40678e", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Google GenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-google-genai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-google-genai'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 13, "section_index": 4, "content_hash": "3db356cfadf7d0f62837f6b137dafe73a9e30594a16f5c2fec744d258d40678e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:8ecd8da5b564bf245e04cb74eac6c971a00557cfd9a6c9d673dc4bbeb3a61aea", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=google-genai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match google-genai)\n\nThis change is done to allow configuration of multiple models.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Chat Properties", "heading_level": 3, "file_order": 13, "section_index": 5, "content_hash": "8ecd8da5b564bf245e04cb74eac6c971a00557cfd9a6c9d673dc4bbeb3a61aea", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:2c6e50f4065bcf7c8cc8757e44ee790ccad06f12e92861b653e2dcb009e597e3", "content": "The prefix `spring.ai.google.genai` is used as the property prefix that lets you connect to Google GenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.model.chat | Enable Chat Model client | google-genai\n| spring.ai.google.genai.api-key | API key for Gemini Developer API. When provided, the client uses the Gemini Developer API instead of Vertex AI. | -\n| spring.ai.google.genai.project-id | Google Cloud Platform project ID (required for Vertex AI mode) | -\n| spring.ai.google.genai.location | Google Cloud region (required for Vertex AI mode) | -\n| spring.ai.google.genai.credentials-uri | URI to Google Cloud credentials. When provided it is used to create a `GoogleCredentials` instance for authentication. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 13, "section_index": 6, "content_hash": "2c6e50f4065bcf7c8cc8757e44ee790ccad06f12e92861b653e2dcb009e597e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:1dfc7d10d3a9b1e5093e75514fec144871417d1da94bff62d7a199537d3ab1b5", "content": "The prefix `spring.ai.google.genai.chat` is the property prefix that lets you configure the chat model implementation for Google GenAI Chat.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.google.genai.chat.options.model | Supported https://ai.google.dev/gemini-api/docs/models[Google GenAI Chat models] to use include `gemini-2.0-flash`, `gemini-2.0-flash-lite`, `gemini-pro`, and `gemini-1.5-flash`. | gemini-2.0-flash\n| spring.ai.google.genai.chat.options.response-mime-type | Output response mimetype of the generated candidate text. | `text/plain`: (default) Text output or `application/json`: JSON response.\n| spring.ai.google.genai.chat.options.google-search-retrieval | Use Google search Grounding feature | `true` or `false`, default `false`.\n| spring.ai.google.genai.chat.options.temperature | Controls the randomness of the output. Values can range over [0.0,1.0], inclusive. A value closer to 1.0 will produce responses that are more varied, while a value closer to 0.0 will typically result in less surprising responses from the generative. | -\n| spring.ai.google.genai.chat.options.top-k | The maximum number of tokens to consider when sampling. The generative uses combined Top-k and nucleus sampling. Top-k sampling considers the set of topK most probable tokens. | -\n| spring.ai.google.genai.chat.options.top-p | The maximum cumulative probability of tokens to consider when sampling. The generative uses combined Top-k and nucleus sampling. Nucleus sampling considers the smallest set of tokens whose probability sum is at least topP. | -\n| spring.ai.google.genai.chat.options.candidate-count | The number of generated response messages to return. This value must be between [1, 8], inclusive. Defaults to 1. | 1\n| spring.ai.google.genai.chat.options.max-output-tokens | The maximum number of tokens to generate. | -\n| spring.ai.google.genai.chat.options.frequency-penalty | Frequency penalties for reducing repetition. | -\n| spring.ai.google.genai.chat.options.presence-penalty | Presence penalties for reducing repetition. | -\n| spring.ai.google.genai.chat.options.thinking-budget | Thinking budget for the thinking process. See <<thinking-config>>. | -\n| spring.ai.google.genai.chat.options.thinking-level | The level of thinking tokens the model should generate. Valid values: `LOW`, `HIGH`, `THINKING_LEVEL_UNSPECIFIED`. See <<thinking-config>>. | -\n| spring.ai.google.genai.chat.options.include-thoughts | Enable thought signatures for function calling. **Required** for Gemini 3 Pro to avoid validation errors during the internal tool execution loop. See <<thought-signatures>>. | false\n| spring.ai.google.genai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.google.genai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.google.genai.chat.options.internal-tool-execution-enabled | If true, the tool execution should be performed, otherwise the response from the model is returned back to the user. Default is null, but if it's null, `ToolCallingChatOptions.DEFAULT_TOOL_EXECUTION_ENABLED` which is true will take into account | -\n| spring.ai.google.genai.chat.options.safety-settings | List of safety settings to control safety filters, as defined by https://ai.google.dev/gemini-api/docs/safety-settings[Google GenAI Safety Settings]. Each safety setting can have a method, threshold, and category. | -\n| spring.ai.google.genai.chat.options.cached-content-name | The name of cached content to use for this request. When set along with `use-cached-content=true`, the cached content will be used as context. See <<cached-content>>. | -\n| spring.ai.google.genai.chat.options.use-cached-content | Whether to use cached content if available. When true and `cached-content-name` is set, the system will use the cached content. | false\n| spring.ai.google.genai.chat.options.auto-cache-threshold | Automatically cache prompts that exceed this token threshold. When set, prompts larger than this value will be automatically cached for reuse. Set to null to disable auto-caching. | -\n| spring.ai.google.genai.chat.options.auto-cache-ttl | Time-to-live (Duration) for auto-cached content in ISO-8601 format (e.g., `PT1H` for 1 hour). Used when auto-caching is enabled. | PT1H\n| spring.ai.google.genai.chat.enable-cached-content | Enable the `GoogleGenAiCachedContentService` bean for managing cached content. | true\n\n|====\n\nTIP: All properties prefixed with `spring.ai.google.genai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Chat Model Properties", "heading_level": 4, "file_order": 13, "section_index": 7, "content_hash": "1dfc7d10d3a9b1e5093e75514fec144871417d1da94bff62d7a199537d3ab1b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:6f684cff923b3c48b8004e0b149c87cee202ca9c4d73e1a867ff9c51dd71a5a8", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-google-genai/src/main/java/org/springframework/ai/google/genai/GoogleGenAiChatOptions.java[GoogleGenAiChatOptions.java] provides model configurations, such as the temperature, the topK, etc.\n\nOn start-up, the default options can be configured with the `GoogleGenAiChatModel(client, options)` constructor or the `spring.ai.google.genai.chat.options.*` properties.\n\nAt runtime, you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example, to override the default temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n GoogleGenAiChatOptions.builder()\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific `GoogleGenAiChatOptions` you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Runtime options [[chat-options]]", "heading_level": 2, "file_order": 13, "section_index": 8, "content_hash": "6f684cff923b3c48b8004e0b149c87cee202ca9c4d73e1a867ff9c51dd71a5a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:f51e5427c7431a89c7cb516647dca0ce7e8c22aca76b788524745cddec4b63ba", "content": "The Google GenAI model supports tool calling (function calling) capabilities, allowing models to use tools during conversations.\nHere's an example of how to define and use `@Tool`-based tools:\n\n[source,java]\n----\n\npublic class WeatherService {\n\n @Tool(description = \"Get the weather in location\")\n public String weatherByLocation(@ToolParam(description= \"City or state name\") String location) {\n ...\n }\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .tools(new WeatherService())\n .call()\n .content();\n----\n\nYou can use the java.util.function beans as tools as well:\n\n[source,java]\n----\n@Bean\n@Description(\"Get the weather in location. Return temperature in 36°F or 36°C format.\")\npublic Function<Request, Response> weatherFunction() {\n return new MockWeatherService();\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .toolNames(\"weatherFunction\")\n .inputType(Request.class)\n .call()\n .content();\n----\n\nFind more in xref:api/tools.adoc[Tools] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Tool Calling", "heading_level": 2, "file_order": 13, "section_index": 9, "content_hash": "f51e5427c7431a89c7cb516647dca0ce7e8c22aca76b788524745cddec4b63ba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:33b865aa0aee19dee55653e6c4b1ebb173482ba4c6da3ac7ae95a6fc7d5ace90", "content": "Gemini models support a \"thinking\" capability that allows the model to perform deeper reasoning before generating responses. This is controlled through the `ThinkingConfig` which includes three related options: `thinkingBudget`, `thinkingLevel`, and `includeThoughts`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Thinking Configuration [[thinking-config]]", "heading_level": 2, "file_order": 13, "section_index": 10, "content_hash": "33b865aa0aee19dee55653e6c4b1ebb173482ba4c6da3ac7ae95a6fc7d5ace90", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:905a12d780a62c6f8d681d6b5ee1c70e645117c4f5a68370dfcb55907c45dde2", "content": "The `thinkingLevel` option controls the depth of reasoning tokens the model generates. This is available for models that support thinking (e.g., Gemini 3 Pro Preview).\n\n[cols=\"1,3\", stripes=even]\n|====\n| Value | Description\n\n| `LOW` | Minimal thinking. Use for simple queries where speed is preferred over deep analysis.\n| `HIGH` | Extensive thinking. Use for complex problems requiring deep analysis and step-by-step reasoning.\n| `THINKING_LEVEL_UNSPECIFIED` | The model uses its default behavior.\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Thinking Level", "heading_level": 3, "file_order": 13, "section_index": 11, "content_hash": "905a12d780a62c6f8d681d6b5ee1c70e645117c4f5a68370dfcb55907c45dde2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:906712b8865f721312179f1faf2860a0405cdafd50158856bf561166851f4a80", "content": "[source,application.properties]\n----\nspring.ai.google.genai.chat.options.model=gemini-3-pro-preview\nspring.ai.google.genai.chat.options.thinking-level=HIGH\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Configuration via Properties", "heading_level": 4, "file_order": 13, "section_index": 12, "content_hash": "906712b8865f721312179f1faf2860a0405cdafd50158856bf561166851f4a80", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:6462f7798bf451c9a2fee53c4400c7075584a98abdb3e54b4701ac9ae96ef48f", "content": "[source,java]\n----\nimport org.springframework.ai.google.genai.common.GoogleGenAiThinkingLevel;\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Explain the theory of relativity in simple terms.\",\n GoogleGenAiChatOptions.builder()\n .model(\"gemini-3-pro-preview\")\n .thinkingLevel(GoogleGenAiThinkingLevel.HIGH)\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Programmatic Configuration", "heading_level": 4, "file_order": 13, "section_index": 13, "content_hash": "6462f7798bf451c9a2fee53c4400c7075584a98abdb3e54b4701ac9ae96ef48f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:ee09bb39f7de3c2252f5f3cb7493ce760531028c3f7f2c81d6b0b2c8ddfd197d", "content": "The `thinkingBudget` option sets a token budget for the thinking process:\n\n- **Positive value**: Maximum number of tokens for thinking (e.g., `8192`)\n- **Zero (`0`)**: Disables thinking entirely\n- **Not set**: Model decides automatically based on query complexity\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Solve this complex math problem step by step.\",\n GoogleGenAiChatOptions.builder()\n .model(\"gemini-2.5-pro\")\n .thinkingBudget(8192)\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Thinking Budget", "heading_level": 3, "file_order": 13, "section_index": 14, "content_hash": "ee09bb39f7de3c2252f5f3cb7493ce760531028c3f7f2c81d6b0b2c8ddfd197d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:9f64a8927fb5cfc68f8dfb17f65f256aaaaa6a0580916680fc04f21bca93f42c", "content": "[IMPORTANT]\n====\n**`thinkingLevel` and `thinkingBudget` are mutually exclusive.** You cannot use both in the same request - doing so will result in an API error.\n\n* Use `thinkingLevel` (`LOW`, `HIGH`) for **Gemini 3 Pro** models\n* Use `thinkingBudget` (token count) for **Gemini 2.5** series models\n====\n\nYou can combine `includeThoughts` with either `thinkingLevel` or `thinkingBudget` (but not both):\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Analyze this complex scenario.\",\n GoogleGenAiChatOptions.builder()\n .model(\"gemini-3-pro-preview\")\n .thinkingLevel(GoogleGenAiThinkingLevel.HIGH)\n .includeThoughts(true)\n .build()\n ));\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Analyze this complex scenario.\",\n GoogleGenAiChatOptions.builder()\n .model(\"gemini-2.5-pro\")\n .thinkingBudget(8192)\n .includeThoughts(true)\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Option Compatibility", "heading_level": 3, "file_order": 13, "section_index": 15, "content_hash": "9f64a8927fb5cfc68f8dfb17f65f256aaaaa6a0580916680fc04f21bca93f42c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:b3f5ca4cb8a2d2b2ed6f8deec19ff8f1e161b22d02d446b5441c60e55eb17e98", "content": "The thinking configuration options are model-specific:\n\n[cols=\"2,1,1,2\", stripes=even]\n|====\n| Model | thinkingLevel | thinkingBudget | Notes\n\n| Gemini 3 Pro (Preview)\n| ✅ Supported\n| ⚠️ Backwards compatible only\n| Use `thinkingLevel`. Cannot disable thinking. Requires **global** endpoint.\n\n| Gemini 2.5 Pro\n| ❌ Not supported\n| ✅ Supported\n| Use `thinkingBudget`. Set to 0 to disable, -1 for dynamic.\n\n| Gemini 2.5 Flash\n| ❌ Not supported\n| ✅ Supported\n| Use `thinkingBudget`. Set to 0 to disable, -1 for dynamic.\n\n| Gemini 2.5 Flash-Lite\n| ❌ Not supported\n| ✅ Supported\n| Thinking disabled by default. Set `thinkingBudget` to enable.\n\n| Gemini 2.0 Flash\n| ❌ Not supported\n| ❌ Not supported\n| Thinking not available.\n|====\n\n[IMPORTANT]\n====\n* Using `thinkingLevel` with unsupported models (e.g., Gemini 2.5 or earlier) will result in an API error.\n* Gemini 3 Pro Preview is only available on **global** endpoints. Set `spring.ai.google.genai.location=global` or `GOOGLE_CLOUD_LOCATION=global`.\n* Check the https://ai.google.dev/gemini-api/docs/thinking[Google GenAI Thinking documentation] for the latest model capabilities.\n====\n\nNOTE: Enabling thinking features increases token usage and API costs. Use appropriately based on the complexity of your queries.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Model Support", "heading_level": 3, "file_order": 13, "section_index": 16, "content_hash": "b3f5ca4cb8a2d2b2ed6f8deec19ff8f1e161b22d02d446b5441c60e55eb17e98", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:007a020234af7bed254d4d801a6f0db5ad01c20fe8708a5bc4d76f9f415a6a52", "content": "Gemini 3 Pro introduces thought signatures, which are opaque byte arrays that preserve the model's reasoning context during function calling. When `includeThoughts` is enabled, the model returns thought signatures that must be passed back within the **same turn** during the internal tool execution loop.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Thought Signatures [[thought-signatures]]", "heading_level": 2, "file_order": 13, "section_index": 17, "content_hash": "007a020234af7bed254d4d801a6f0db5ad01c20fe8708a5bc4d76f9f415a6a52", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:e7382b0d53bc7a2d0a7645a8eb7e80af90e8a81079d8a0d54f99d764cb9f0ef3", "content": "**IMPORTANT**: Thought signature validation only applies to the **current turn** - specifically during the internal tool execution loop when the model makes function calls (both parallel and sequential). The API does **not** validate thought signatures for previous turns in conversation history.\n\nPer https://ai.google.dev/gemini-api/docs/thought-signatures[Google's documentation]:\n\n* Validation is enforced for function calls within the current turn only\n* Previous turn signatures do not need to be preserved\n* Missing signatures in the current turn's function calls result in HTTP 400 errors for Gemini 3 Pro\n* For parallel function calls, only the first `functionCall` part carries the signature\n\nFor Gemini 2.5 Pro and earlier models, thought signatures are optional and the API is lenient.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "When Thought Signatures Matter", "heading_level": 3, "file_order": 13, "section_index": 18, "content_hash": "e7382b0d53bc7a2d0a7645a8eb7e80af90e8a81079d8a0d54f99d764cb9f0ef3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:654068f8b09b1890eee5bcbd186a7e121f50ca26d9d37aa9650c69ef16d8fa5c", "content": "Enable thought signatures using configuration properties:\n\n[source,application.properties]\n----\nspring.ai.google.genai.chat.options.model=gemini-3-pro-preview\nspring.ai.google.genai.chat.options.include-thoughts=true\n----\n\nOr programmatically at runtime:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Your question here\",\n GoogleGenAiChatOptions.builder()\n .model(\"gemini-3-pro-preview\")\n .includeThoughts(true)\n .toolCallbacks(callbacks)\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Configuration", "heading_level": 3, "file_order": 13, "section_index": 19, "content_hash": "654068f8b09b1890eee5bcbd186a7e121f50ca26d9d37aa9650c69ef16d8fa5c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:a998b4b5cf33af267a18e3d669c66a0b7715f8c5b854045e5add9a45a70ddf45", "content": "Spring AI automatically handles thought signatures during the internal tool execution loop. When `internalToolExecutionEnabled` is true (the default), Spring AI:\n\n1. **Extracts** thought signatures from model responses\n2. **Attaches** them to the correct `functionCall` parts when sending back function responses\n3. **Propagates** them correctly during function calls within a single turn (both parallel and sequential)\n\nYou don't need to manually manage thought signatures - Spring AI ensures they are properly attached to `functionCall` parts as required by the API specification.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Automatic Handling", "heading_level": 3, "file_order": 13, "section_index": 20, "content_hash": "a998b4b5cf33af267a18e3d669c66a0b7715f8c5b854045e5add9a45a70ddf45", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:808c0b2828892c3ef47df0284779254e1833dc12eddeba948243b36819452c61", "content": "[source,java]\n----\n@Bean\n@Description(\"Get the weather in a location\")\npublic Function<WeatherRequest, WeatherResponse> weatherFunction() {\n return new WeatherService();\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .options(GoogleGenAiChatOptions.builder()\n .model(\"gemini-3-pro-preview\")\n .includeThoughts(true)\n .build())\n .toolNames(\"weatherFunction\")\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Example with Function Calling", "heading_level": 3, "file_order": 13, "section_index": 21, "content_hash": "808c0b2828892c3ef47df0284779254e1833dc12eddeba948243b36819452c61", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:3ceb32608fa3bd4002b35e5a8ff1148c6f85c20ccb95e3ac24fcbbefacf19465", "content": "If you set `internalToolExecutionEnabled=false` to manually control the tool execution loop, you must handle thought signatures yourself when using Gemini 3 Pro with `includeThoughts=true`.\n\n**Requirements for manual tool execution with thought signatures:**\n\n1. Extract thought signatures from the response metadata:\n+\n[source,java]\n----\nAssistantMessage assistantMessage = response.getResult().getOutput();\nMap<String, Object> metadata = assistantMessage.getMetadata();\nList<byte[]> thoughtSignatures = (List<byte[]>) metadata.get(\"thoughtSignatures\");\n----\n\n2. When sending back function responses, include the original `AssistantMessage` with its metadata intact in your message history. Spring AI will automatically attach the thought signatures to the correct `functionCall` parts.\n\n3. For Gemini 3 Pro, failing to preserve thought signatures during the current turn will result in HTTP 400 errors from the API.\n\nIMPORTANT: Only the current turn's function calls require thought signatures. When starting a new conversation turn (after completing a function calling round), you do not need to preserve the previous turn's signatures.\n\nNOTE: Enabling `includeThoughts` increases token usage as thought processes are included in responses. This impacts API costs but provides better reasoning transparency.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Manual Tool Execution Mode", "heading_level": 3, "file_order": 13, "section_index": 22, "content_hash": "3ceb32608fa3bd4002b35e5a8ff1148c6f85c20ccb95e3ac24fcbbefacf19465", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:6ca711194299086bdddb4e485d7e6ae45e9a6cc5132c1dbbb26835bfd54a34dc", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various (input) sources, including `text`, `pdf`, `images`, `audio`, and other data formats.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 13, "section_index": 23, "content_hash": "6ca711194299086bdddb4e485d7e6ae45e9a6cc5132c1dbbb26835bfd54a34dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:b7b189afe43c47213c3a3e47596510af4e2dea06f3220d68b29d23704b8c0f78", "content": "Google's Gemini AI models support this capability by comprehending and integrating text, code, audio, images, and video.\nFor more details, refer to the blog post https://blog.google/technology/ai/google-gemini-ai/#introducing-gemini[Introducing Gemini].\n\nSpring AI's `Message` interface supports multimodal AI models by introducing the Media type.\nThis type contains data and information about media attachments in messages, using Spring's `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a simple code example extracted from https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-google-genai/src/test/java/org/springframework/ai/google/genai/GoogleGenAiChatModelIT.java[GoogleGenAiChatModelIT.java], demonstrating the combination of user text with an image.\n\n[source,java]\n----\nbyte[] data = new ClassPathResource(\"/vertex-test.png\").getContentAsByteArray();\n\nvar userMessage = UserMessage.builder()\n .text(\"Explain what do you see o this picture?\")\n .media(List.of(new Media(MimeTypeUtils.IMAGE_PNG, data)))\n .build();\n\nChatResponse response = chatModel.call(new Prompt(List.of(this.userMessage)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Image, Audio, Video", "heading_level": 3, "file_order": 13, "section_index": 24, "content_hash": "b7b189afe43c47213c3a3e47596510af4e2dea06f3220d68b29d23704b8c0f78", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:01c7f67016a7683d61492f67d755dc516772e63bc3f54972e74e3aea377a1c85", "content": "Google GenAI provides support for PDF input types.\nUse the `application/pdf` media type to attach a PDF file to the message:\n\n[source,java]\n----\nvar pdfData = new ClassPathResource(\"/spring-ai-reference-overview.pdf\");\n\nvar userMessage = UserMessage.builder()\n .text(\"You are a very professional document summarization specialist. Please summarize the given document.\")\n .media(List.of(new Media(new MimeType(\"application\", \"pdf\"), pdfData)))\n .build();\n\nvar response = this.chatModel.call(new Prompt(List.of(userMessage)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "PDF", "heading_level": 3, "file_order": 13, "section_index": 25, "content_hash": "01c7f67016a7683d61492f67d755dc516772e63bc3f54972e74e3aea377a1c85", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:23da35f6f7856db5d30b08ea3c769030a76831a9ab31c15e5e62e3c3a60c3759", "content": "Google GenAI's https://ai.google.dev/gemini-api/docs/caching[Context Caching] allows you to cache large amounts of content (such as long documents, code repositories, or media) and reuse it across multiple requests. This significantly reduces API costs and improves response latency for repeated queries on the same content.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Cached Content [[cached-content]]", "heading_level": 2, "file_order": 13, "section_index": 26, "content_hash": "23da35f6f7856db5d30b08ea3c769030a76831a9ab31c15e5e62e3c3a60c3759", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:c4fb1d1b174e690b5c438d06cd0f40467229be976d9d663d65d2ace3747a229e", "content": "- **Cost Reduction**: Cached tokens are billed at a much lower rate than regular input tokens (typically 75-90% cheaper)\n- **Improved Performance**: Reusing cached content reduces processing time for large contexts\n- **Consistency**: Same cached context ensures consistent responses across multiple requests", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Benefits", "heading_level": 3, "file_order": 13, "section_index": 27, "content_hash": "c4fb1d1b174e690b5c438d06cd0f40467229be976d9d663d65d2ace3747a229e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:f3b3eb67a4e086e74c65d527127e29e833e6f8a493dbe245fb3ab1905d79b9be", "content": "- Minimum cache size: 32,768 tokens (approximately 25,000 words)\n- Maximum cache duration: 1 hour by default (configurable via TTL)\n- Cached content must include either system instructions or conversation history", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Cache Requirements", "heading_level": 3, "file_order": 13, "section_index": 28, "content_hash": "f3b3eb67a4e086e74c65d527127e29e833e6f8a493dbe245fb3ab1905d79b9be", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:35c3d4a7c8065c51f1ae6c15cb6dec752bef9b2ee66edd37643ba9d7d950c15f", "content": "Spring AI provides `GoogleGenAiCachedContentService` for programmatic cache management. The service is automatically configured when using the Spring Boot auto-configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using Cached Content Service", "heading_level": 3, "file_order": 13, "section_index": 29, "content_hash": "35c3d4a7c8065c51f1ae6c15cb6dec752bef9b2ee66edd37643ba9d7d950c15f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:dbab8eec3796a2e88a5f6cc3e8ea515e58e18b7416b097ab503d2385ee82c6e5", "content": "[source,java]\n----\n@Autowired\nprivate GoogleGenAiCachedContentService cachedContentService;\n\nString largeDocument = \"... your large context here (>32k tokens) ...\";\n\nCachedContentRequest request = CachedContentRequest.builder()\n .model(\"gemini-2.0-flash\")\n .contents(List.of(\n Content.builder()\n .role(\"user\")\n .parts(List.of(Part.fromText(largeDocument)))\n .build()\n ))\n .displayName(\"My Large Document Cache\")\n .ttl(Duration.ofHours(1))\n .build();\n\nGoogleGenAiCachedContent cachedContent = cachedContentService.create(request);\nString cacheName = cachedContent.getName(); // Save this for reuse\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Creating Cached Content", "heading_level": 4, "file_order": 13, "section_index": 30, "content_hash": "dbab8eec3796a2e88a5f6cc3e8ea515e58e18b7416b097ab503d2385ee82c6e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:64cd1f3b5d0c024b30567f9914dc5d5ffacfce1a63b81eda24f955cb9c7ac2c5", "content": "Once you've created cached content, reference it in your chat requests:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Summarize the key points from the document\",\n GoogleGenAiChatOptions.builder()\n .useCachedContent(true)\n .cachedContentName(cacheName) // Use the cached content name\n .build()\n ));\n----\n\nOr via configuration properties:\n\n[source,application.properties]\n----\nspring.ai.google.genai.chat.options.use-cached-content=true\nspring.ai.google.genai.chat.options.cached-content-name=cachedContent/your-cache-name\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using Cached Content in Chat Requests", "heading_level": 4, "file_order": 13, "section_index": 31, "content_hash": "64cd1f3b5d0c024b30567f9914dc5d5ffacfce1a63b81eda24f955cb9c7ac2c5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:8498e226d5725712bb05d0a5e170c79b8a1467071e59454e19ed3656865fe7ac", "content": "The `GoogleGenAiCachedContentService` provides comprehensive cache management:\n\n[source,java]\n----\nGoogleGenAiCachedContent content = cachedContentService.get(cacheName);\n\nCachedContentUpdateRequest updateRequest = CachedContentUpdateRequest.builder()\n .ttl(Duration.ofHours(2))\n .build();\nGoogleGenAiCachedContent updated = cachedContentService.update(cacheName, updateRequest);\n\nList<GoogleGenAiCachedContent> allCaches = cachedContentService.listAll();\n\nboolean deleted = cachedContentService.delete(cacheName);\n\nGoogleGenAiCachedContent extended = cachedContentService.extendTtl(cacheName, Duration.ofMinutes(30));\n\nint removedCount = cachedContentService.cleanupExpired();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Managing Cached Content", "heading_level": 4, "file_order": 13, "section_index": 32, "content_hash": "8498e226d5725712bb05d0a5e170c79b8a1467071e59454e19ed3656865fe7ac", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:aeb370179476a25f78760bf697614cf8475bd1173d49af90f98305276f70f1f7", "content": "All operations have asynchronous variants:\n\n[source,java]\n----\nCompletableFuture<GoogleGenAiCachedContent> futureCache =\n cachedContentService.createAsync(request);\n\nCompletableFuture<GoogleGenAiCachedContent> futureGet =\n cachedContentService.getAsync(cacheName);\n\nCompletableFuture<Boolean> futureDelete =\n cachedContentService.deleteAsync(cacheName);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Asynchronous Operations", "heading_level": 4, "file_order": 13, "section_index": 33, "content_hash": "aeb370179476a25f78760bf697614cf8475bd1173d49af90f98305276f70f1f7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:cd50e7a707116c7cd1ca440391d29fb4529666cf96b8b8ebf09247bb264f7eea", "content": "Spring AI can automatically cache large prompts when they exceed a specified token threshold:\n\n[source,application.properties]\n----\n# Automatically cache prompts larger than 100,000 tokens\nspring.ai.google.genai.chat.options.auto-cache-threshold=100000\n# Set auto-cache TTL to 1 hour\nspring.ai.google.genai.chat.options.auto-cache-ttl=PT1H\n----\n\nOr programmatically:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n largePrompt,\n GoogleGenAiChatOptions.builder()\n .autoCacheThreshold(100000)\n .autoCacheTtl(Duration.ofHours(1))\n .build()\n ));\n----\n\nNOTE: Auto-caching is useful for one-time large contexts. For repeated use of the same context, manually creating and referencing cached content is more efficient.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Auto-Caching", "heading_level": 3, "file_order": 13, "section_index": 34, "content_hash": "cd50e7a707116c7cd1ca440391d29fb4529666cf96b8b8ebf09247bb264f7eea", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:536f01c3a4a81b2ca5013a74247b50391d3f727cf62634d35525b150e08f8e01", "content": "Cached content includes usage metadata accessible via the service:\n\n[source,java]\n----\nGoogleGenAiCachedContent content = cachedContentService.get(cacheName);\n\nboolean expired = content.isExpired();\n\nDuration remaining = content.getRemainingTtl();\n\nCachedContentUsageMetadata metadata = content.getUsageMetadata();\nif (metadata != null) {\n System.out.println(\"Total tokens: \" + metadata.totalTokenCount().orElse(0));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Monitoring Cache Usage", "heading_level": 3, "file_order": 13, "section_index": 35, "content_hash": "536f01c3a4a81b2ca5013a74247b50391d3f727cf62634d35525b150e08f8e01", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:c17d684f4351a4ea30c3800dfc99595fc447d7c2e839f88d54bd8f45cb8fbe64", "content": "1. **Cache Lifetime**: Set appropriate TTL based on your use case. Shorter TTLs for frequently changing content, longer for static content.\n2. **Cache Naming**: Use descriptive display names to identify cached content easily.\n3. **Cleanup**: Periodically clean up expired caches to maintain organization.\n4. **Token Threshold**: Only cache content that exceeds the minimum threshold (32,768 tokens).\n5. **Cost Optimization**: Reuse cached content across multiple requests to maximize cost savings.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Best Practices", "heading_level": 3, "file_order": 13, "section_index": 36, "content_hash": "c17d684f4351a4ea30c3800dfc99595fc447d7c2e839f88d54bd8f45cb8fbe64", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:57a3d4404508379a5fac4cbfa7f7e4f7840e6040137b65ee47697517012364fc", "content": "Complete configuration example:\n\n[source,application.properties]\n----\n# Enable cached content service (enabled by default)\nspring.ai.google.genai.chat.enable-cached-content=true\n\n# Use a specific cached content\nspring.ai.google.genai.chat.options.use-cached-content=true\nspring.ai.google.genai.chat.options.cached-content-name=cachedContent/my-cache-123\n\n# Auto-caching configuration\nspring.ai.google.genai.chat.options.auto-cache-threshold=50000\nspring.ai.google.genai.chat.options.auto-cache-ttl=PT30M\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Configuration Example", "heading_level": 3, "file_order": 13, "section_index": 37, "content_hash": "57a3d4404508379a5fac4cbfa7f7e4f7840e6040137b65ee47697517012364fc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:4fd7f63a7d143dc557ad8aa18eb48526c1c08f2c2954be3bd73aedc50db35602", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-google-genai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the Google GenAI chat model:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 13, "section_index": 38, "content_hash": "4fd7f63a7d143dc557ad8aa18eb48526c1c08f2c2954be3bd73aedc50db35602", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:456a3a3613b02fbf0aa81b267dd41aaa1f8cfa8d88b023c972549183b7820df2", "content": "[source,application.properties]\n----\nspring.ai.google.genai.api-key=YOUR_API_KEY\nspring.ai.google.genai.chat.options.model=gemini-2.0-flash\nspring.ai.google.genai.chat.options.temperature=0.5\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using Gemini Developer API (API Key)", "heading_level": 3, "file_order": 13, "section_index": 39, "content_hash": "456a3a3613b02fbf0aa81b267dd41aaa1f8cfa8d88b023c972549183b7820df2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:63a6cef61dbbdaa2473405d046f6f792456892e5e5493eb72ee7cdeafb925413", "content": "[source,application.properties]\n----\nspring.ai.google.genai.project-id=PROJECT_ID\nspring.ai.google.genai.location=LOCATION\nspring.ai.google.genai.chat.options.model=gemini-2.0-flash\nspring.ai.google.genai.chat.options.temperature=0.5\n----\n\nTIP: Replace the `project-id` with your Google Cloud Project ID and `location` is Google Cloud Region\nlike `us-central1`, `europe-west1`, etc...\n\n[NOTE]\n====\nEach model has its own set of supported regions, you can find the list of supported regions in the model page.\n====\n\nThis will create a `GoogleGenAiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final GoogleGenAiChatModel chatModel;\n\n @Autowired\n public ChatController(GoogleGenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using Vertex AI", "heading_level": 3, "file_order": 13, "section_index": 40, "content_hash": "63a6cef61dbbdaa2473405d046f6f792456892e5e5493eb72ee7cdeafb925413", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:ed78c09fd4de8a92dc4774715d6779d3c4e6010cff3a7403de81b6beb16a3448", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-google-genai/src/main/java/org/springframework/ai/google/genai/GoogleGenAiChatModel.java[GoogleGenAiChatModel] implements the `ChatModel` and uses the `com.google.genai.Client` to connect to the Google GenAI service.\n\nAdd the `spring-ai-google-genai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-google-genai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-google-genai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `GoogleGenAiChatModel` and use it for text generations:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 13, "section_index": 41, "content_hash": "ed78c09fd4de8a92dc4774715d6779d3c4e6010cff3a7403de81b6beb16a3448", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:4a5e65dd6f300b9b60e7913e6d3d81ad19d43e3647894c4c3b81202bed18d603", "content": "[source,java]\n----\nClient genAiClient = Client.builder()\n .apiKey(System.getenv(\"GOOGLE_API_KEY\"))\n .build();\n\nvar chatModel = new GoogleGenAiChatModel(genAiClient,\n GoogleGenAiChatOptions.builder()\n .model(ChatModel.GEMINI_2_0_FLASH)\n .temperature(0.4)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using API Key", "heading_level": 3, "file_order": 13, "section_index": 42, "content_hash": "4a5e65dd6f300b9b60e7913e6d3d81ad19d43e3647894c4c3b81202bed18d603", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:22f44db4e7678cdb55b814e749377654acf774add3c03a08e18b2ee3fd3053bb", "content": "[source,java]\n----\nClient genAiClient = Client.builder()\n .project(System.getenv(\"GOOGLE_CLOUD_PROJECT\"))\n .location(System.getenv(\"GOOGLE_CLOUD_LOCATION\"))\n .vertexAI(true)\n .build();\n\nvar chatModel = new GoogleGenAiChatModel(genAiClient,\n GoogleGenAiChatOptions.builder()\n .model(ChatModel.GEMINI_2_0_FLASH)\n .temperature(0.4)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `GoogleGenAiChatOptions` provides the configuration information for the chat requests.\nThe `GoogleGenAiChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Using Vertex AI", "heading_level": 3, "file_order": 13, "section_index": 43, "content_hash": "22f44db4e7678cdb55b814e749377654acf774add3c03a08e18b2ee3fd3053bb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:1012026514684b337a4d2fcf06dcafaa72f15bc746746c249f2c9c9357e84aa9", "content": "If you're currently using the Vertex AI Gemini implementation (`spring-ai-vertex-ai-gemini`), you can migrate to Google GenAI with minimal changes:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Migration from Vertex AI Gemini", "heading_level": 2, "file_order": 13, "section_index": 44, "content_hash": "1012026514684b337a4d2fcf06dcafaa72f15bc746746c249f2c9c9357e84aa9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:892ccbd3f9868aa6dbe56b04dc53bfe8ed8bafc06b343477cf8fd35509310bc6", "content": "1. **SDK**: Google GenAI uses the new `com.google.genai.Client` instead of `com.google.cloud.vertexai.VertexAI`\n2. **Authentication**: Supports both API key and Google Cloud credentials\n3. **Package Names**: Classes are in `org.springframework.ai.google.genai` instead of `org.springframework.ai.vertexai.gemini`\n4. **Property Prefix**: Uses `spring.ai.google.genai` instead of `spring.ai.vertex.ai.gemini`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Key Differences", "heading_level": 3, "file_order": 13, "section_index": 45, "content_hash": "892ccbd3f9868aa6dbe56b04dc53bfe8ed8bafc06b343477cf8fd35509310bc6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:18b87ed456f1375b0bff8d94a4d6aa4548b02e76ebeeadbd7afe0619ed650aa0", "content": "**Use Google GenAI when:**\n- You want quick prototyping with API keys\n- You need the latest Gemini features from the Developer API\n- You want flexibility to switch between API key and Vertex AI modes\n\n**Use Vertex AI Gemini when:**\n- You have existing Vertex AI infrastructure\n- You need specific Vertex AI enterprise features\n- Your organization requires Google Cloud-only deployment", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "When to Use Google GenAI vs Vertex AI Gemini", "heading_level": 3, "file_order": 13, "section_index": 46, "content_hash": "18b87ed456f1375b0bff8d94a4d6aa4548b02e76ebeeadbd7afe0619ed650aa0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:5f8c64915ab74e0bd98e13ec438ac06074edcc4d761bf9fa115afe1e0d2c9141", "content": "The Google GenAI implementation is built on the new Google GenAI Java SDK, which provides a modern, streamlined API for accessing Gemini models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc", "title": "Google GenAI Chat", "heading": "Low-level Java Client [[low-level-api]]", "heading_level": 2, "file_order": 13, "section_index": 47, "content_hash": "5f8c64915ab74e0bd98e13ec438ac06074edcc4d761bf9fa115afe1e0d2c9141", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-genai-chat.adoc"}}
{"id": "sha256:8867f4d8b6cd9186beb1d302d66fe910799af89c48226ad3f7f84fca94b63c13", "content": "link:https://cloud.google.com/vertex-ai/docs/reference[VertexAI API] provides high-quality custom machine learning models with minimal machine learning expertise and effort.\n\nSpring AI provides integration with VertexAI API through the following client(s):\n\n* xref:api/chat/vertexai-gemini-chat.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/google-vertexai.adoc", "title": "Google VertexAI API", "heading": "Google VertexAI API", "heading_level": 1, "file_order": 14, "section_index": 0, "content_hash": "8867f4d8b6cd9186beb1d302d66fe910799af89c48226ad3f7f84fca94b63c13", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/google-vertexai.adoc"}}
{"id": "sha256:edd774560a97ee498bcf0c238bfd96cd1ec21d0b65ec91f11bdb06ed40138525", "content": "https://groq.com/[Groq] is an extremely fast, LPU™ based, AI Inference Engine that support various https://console.groq.com/docs/models[AI Models],\nsupports `Tool/Function Calling` and exposes a `OpenAI API` compatible endpoint.\n\nSpring AI integrates with the https://groq.com/[Groq] by reusing the existing xref::api/chat/openai-chat.adoc[OpenAI] client.\nFor this you need to obtain a https://console.groq.com/keys[Groq Api Key], set the base-url to https://api.groq.com/openai and select one of the\nprovided https://console.groq.com/docs/models[Groq models].\n\nimage::spring-ai-groq-integration.jpg[w=800,align=\"center\"]\n\nNOTE: The Groq API is not fully compatible with the OpenAI API.\nBe aware for the following https://console.groq.com/docs/openai[compatibility constrains].\nAdditionally, currently Groq doesn't support multimodal messages.\n\nCheck the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/GroqWithOpenAiChatModelIT.java[GroqWithOpenAiChatModelIT.java] tests\nfor examples of using Groq with Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Groq Chat", "heading_level": 1, "file_order": 15, "section_index": 0, "content_hash": "edd774560a97ee498bcf0c238bfd96cd1ec21d0b65ec91f11bdb06ed40138525", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:af35d49d588090794374ec29238fabdef2b7a08745b1d0b5df8b0b7fc6e75eb4", "content": "* **Create an API Key**:\nVisit https://console.groq.com/keys[here] to create an API Key.\nThe Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from groq.com.\n\n* **Set the Groq URL**:\nYou have to set the `spring.ai.openai.base-url` property to `+https://api.groq.com/openai+`.\n\n* **Select a Groq Model**:\nUse the `spring.ai.openai.chat.model=<model name>` property to select from the available https://console.groq.com/docs/models[Groq Models].\n\nYou can set these configuration properties in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<your-groq-api-key>\nspring.ai.openai.base-url=https://api.groq.com/openai\nspring.ai.openai.chat.model=llama3-70b-8192\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference custom environment variables:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${GROQ_API_KEY}\n base-url: ${GROQ_BASE_URL}\n chat:\n model: ${GROQ_MODEL}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport GROQ_API_KEY=<your-groq-api-key>\nexport GROQ_BASE_URL=https://api.groq.com/openai\nexport GROQ_MODEL=llama3-70b-8192\n----\n\nYou can also set these configurations programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"GROQ_API_KEY\");\nString baseUrl = System.getenv(\"GROQ_BASE_URL\");\nString model = System.getenv(\"GROQ_MODEL\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 15, "section_index": 1, "content_hash": "af35d49d588090794374ec29238fabdef2b7a08745b1d0b5df8b0b7fc6e75eb4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:9b27ffd2721d682bdfc02f0ec4a9bb9eec1e5dee8363c53a3bf7be5a6ea9dd9f", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 15, "section_index": 2, "content_hash": "9b27ffd2721d682bdfc02f0ec4a9bb9eec1e5dee8363c53a3bf7be5a6ea9dd9f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:117515b2fb00fd03d20759585ce4509c1ed2eeb00e1665baa91e0f7e68e8deb9", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 15, "section_index": 3, "content_hash": "117515b2fb00fd03d20759585ce4509c1ed2eeb00e1665baa91e0f7e68e8deb9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:74cc7ab7bd7b5229e18cea5fa4570cffec03f5cca0f19a941b8e0d8fd79b38c8", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 15, "section_index": 4, "content_hash": "74cc7ab7bd7b5229e18cea5fa4570cffec03f5cca0f19a941b8e0d8fd79b38c8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:80554dff0f36e88d1733e51cfc36850f5f65c5e621f2045dc7d0d67ba9d508cf", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to. Must be set to `+https://api.groq.com/openai+` | -\n| spring.ai.openai.api-key | The Groq API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 15, "section_index": 5, "content_hash": "80554dff0f36e88d1733e51cfc36850f5f65c5e621f2045dc7d0d67ba9d508cf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:0fade2a1c631b2cc49f3d30c77ba598ddb5475b29558578e4b94ac19dad5af2b", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=openai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.chat` is the property prefix that lets you configure the chat model implementation for OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.chat.enabled (Removed and no longer valid) | Enable OpenAI chat model. | true\n| spring.ai.openai.chat | Enable OpenAI chat model. | openai\n| spring.ai.openai.chat.base-url | Optional overrides the spring.ai.openai.base-url to provide chat specific url. Must be set to `+https://api.groq.com/openai+` | -\n| spring.ai.openai.chat.api-key | Optional overrides the spring.ai.openai.api-key to provide chat specific api-key | -\n| spring.ai.openai.chat.options.model | The https://console.groq.com/docs/models[available model] names are `llama3-8b-8192`, `llama3-70b-8192`, `mixtral-8x7b-32768`, `gemma2-9b-it`. | -\n| spring.ai.openai.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.openai.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.openai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.openai.chat.options.n | How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs. | 1\n| spring.ai.openai.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | -\n| spring.ai.openai.chat.options.responseFormat | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON.| -\n| spring.ai.openai.chat.options.seed | This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. | -\n| spring.ai.openai.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.openai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both. | -\n| spring.ai.openai.chat.options.tools | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. | -\n| spring.ai.openai.chat.options.toolChoice | Controls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"type: \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function. none is the default when no functions are present. auto is the default if functions are present. | -\n| spring.ai.openai.chat.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n| spring.ai.openai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.openai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.openai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nTIP: All properties prefixed with `spring.ai.openai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 15, "section_index": 6, "content_hash": "0fade2a1c631b2cc49f3d30c77ba598ddb5475b29558578e4b94ac19dad5af2b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:69214cdfbdc5b84afd9146ddf560742a34d71c83886e29af3f1901b5cafcd7a6", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiChatModel(api, options)` constructor or the `spring.ai.openai.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiChatOptions.builder()\n .model(\"mixtral-8x7b-32768\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 15, "section_index": 7, "content_hash": "69214cdfbdc5b84afd9146ddf560742a34d71c83886e29af3f1901b5cafcd7a6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:662ef37943f52bf3d3aaba4bb9a496a690fb4dd31cfaec9a3e979a35d02c0a50", "content": "Groq API endpoints support https://console.groq.com/docs/tool-use[tool/function calling] when selecting one of the Tool/Function supporting models.\n\nTIP: Check the Tool https://console.groq.com/docs/tool-use[Supported Models].\n\nimage::spring-ai-groq-functions-2.jpg[w=800,align=\"center\"]\n\nYou can register custom Java functions with your ChatModel and have the provided Groq model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 15, "section_index": 8, "content_hash": "662ef37943f52bf3d3aaba4bb9a496a690fb4dd31cfaec9a3e979a35d02c0a50", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:13bab78f466b5674db6ea223456fe567615caf75ef3617f420e907d0c5a58e76", "content": "Here's a simple example of how to use Groq function calling with Spring AI:\n\n[source,java]\n----\n@SpringBootApplication\npublic class GroqApplication {\n\n public static void main(String[] args) {\n SpringApplication.run(GroqApplication.class, args);\n }\n\n @Bean\n CommandLineRunner runner(ChatClient.Builder chatClientBuilder) {\n return args -> {\n var chatClient = chatClientBuilder.build();\n\n var response = chatClient.prompt()\n .user(\"What is the weather in Amsterdam and Paris?\")\n .functions(\"weatherFunction\") // reference by bean name.\n .call()\n .content();\n\n System.out.println(response);\n };\n }\n\n @Bean\n @Description(\"Get the weather in location\")\n public Function<WeatherRequest, WeatherResponse> weatherFunction() {\n return new MockWeatherService();\n }\n\n public static class MockWeatherService implements Function<WeatherRequest, WeatherResponse> {\n\n public record WeatherRequest(String location, String unit) {}\n public record WeatherResponse(double temp, String unit) {}\n\n @Override\n public WeatherResponse apply(WeatherRequest request) {\n double temperature = request.location().contains(\"Amsterdam\") ? 20 : 25;\n return new WeatherResponse(temperature, request.unit);\n }\n }\n}\n----\n\nIn this example, when the model needs weather information, it will automatically call the `weatherFunction` bean, which can then fetch real-time weather data.\nThe expected response looks like this: \"The weather in Amsterdam is currently 20 degrees Celsius, and the weather in Paris is currently 25 degrees Celsius.\"\n\nRead more about OpenAI link:https://docs.spring.io/spring-ai/reference/api/chat/functions/openai-chat-functions.html[Function Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Tool Example", "heading_level": 3, "file_order": 15, "section_index": 9, "content_hash": "13bab78f466b5674db6ea223456fe567615caf75ef3617f420e907d0c5a58e76", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:fd5bc989d70dca53221a7879714bc9c34cc748bdef9eb804b8193cf5fd725172", "content": "NOTE: Currently the Groq API doesn't support media content.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 15, "section_index": 10, "content_hash": "fd5bc989d70dca53221a7879714bc9c34cc748bdef9eb804b8193cf5fd725172", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:bbf8e5710806a8c89b22a1b3272711d28b0aff91800168008246635097ed4126", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-openai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=<GROQ_API_KEY>\nspring.ai.openai.base-url=https://api.groq.com/openai\nspring.ai.openai.chat.options.model=llama3-70b-8192\nspring.ai.openai.chat.options.temperature=0.7\n----\n\nTIP: replace the `api-key` with your OpenAI credentials.\n\nThis will create a `OpenAiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 15, "section_index": 11, "content_hash": "bbf8e5710806a8c89b22a1b3272711d28b0aff91800168008246635097ed4126", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:9af5d0da14354fda02b543b00d952523c59563afe923cb50d52ac531da597740", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatModel.java[OpenAiChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the OpenAI service.\n\nAdd the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `OpenAiChatModel` and use it for text generations:\n\n[source,java]\n----\nvar openAiApi = new OpenAiApi(\"https://api.groq.com/openai\", System.getenv(\"GROQ_API_KEY\"));\nvar openAiChatOptions = OpenAiChatOptions.builder()\n .model(\"llama3-70b-8192\")\n .temperature(0.4)\n .maxTokens(200)\n .build();\nvar chatModel = new OpenAiChatModel(this.openAiApi, this.openAiChatOptions);\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `OpenAiChatOptions` provides the configuration information for the chat requests.\nThe `OpenAiChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/groq-chat.adoc", "title": "Groq Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 15, "section_index": 12, "content_hash": "9af5d0da14354fda02b543b00d952523c59563afe923cb50d52ac531da597740", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/groq-chat.adoc"}}
{"id": "sha256:b549b324d98d47ebc05b78c1846535bbb24b0c73f18e1fb41d67f685ef342032", "content": "Hugging Face Text Generation Inference (TGI) is a specialized deployment solution for serving Large Language Models (LLMs) in the cloud, making them accessible via an API. TGI provides optimized performance for text generation tasks through features like continuous batching, token streaming, and efficient memory management.\n\nIMPORTANT: Text Generation Inference requires models to be compatible with its architecture-specific optimizations. While many popular LLMs are supported, not all models on Hugging Face Hub can be deployed using TGI. If you need to deploy other types of models, consider using standard Hugging Face Inference Endpoints instead.\n\nTIP: For a complete and up-to-date list of supported models and architectures, see the link:https://huggingface.co/docs/text-generation-inference/en/supported_models[Text Generation Inference supported models documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Hugging Face Chat", "heading_level": 1, "file_order": 16, "section_index": 0, "content_hash": "b549b324d98d47ebc05b78c1846535bbb24b0c73f18e1fb41d67f685ef342032", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:9796d4f0d5e5b94347abacbc1320459cbc6eb059ce022193801b2e02c3fcae8d", "content": "You will need to create an Inference Endpoint on Hugging Face and create an API token to access the endpoint.\nFurther details can be found link:https://huggingface.co/docs/inference-endpoints/index[here].\n\nThe Spring AI project defines two configuration properties:\n\n1. `spring.ai.huggingface.chat.api-key`: Set this to the value of the API token obtained from Hugging Face.\n2. `spring.ai.huggingface.chat.url`: Set this to the inference endpoint URL obtained when provisioning your model in Hugging Face.\n\nYou can find your inference endpoint URL on the Inference Endpoint's UI link:https://ui.endpoints.huggingface.co/[here].\n\nYou can set these configuration properties in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.huggingface.chat.api-key=<your-huggingface-api-key>\nspring.ai.huggingface.chat.url=<your-inference-endpoint-url>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference custom environment variables:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n huggingface:\n chat:\n api-key: ${HUGGINGFACE_API_KEY}\n url: ${HUGGINGFACE_ENDPOINT_URL}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport HUGGINGFACE_API_KEY=<your-huggingface-api-key>\nexport HUGGINGFACE_ENDPOINT_URL=<your-inference-endpoint-url>\n----\n\nYou can also set these configurations programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"HUGGINGFACE_API_KEY\");\nString endpointUrl = System.getenv(\"HUGGINGFACE_ENDPOINT_URL\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 16, "section_index": 1, "content_hash": "9796d4f0d5e5b94347abacbc1320459cbc6eb059ce022193801b2e02c3fcae8d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:45e660f9177d823062275c99ef04ec49289ed5ff1df6872cf2b0f28ae1395289", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 16, "section_index": 2, "content_hash": "45e660f9177d823062275c99ef04ec49289ed5ff1df6872cf2b0f28ae1395289", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:016e8564e51c1519b05328126eaed14ca97e27d26523002338744059e747f223", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Hugging Face Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-huggingface</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-huggingface'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 16, "section_index": 3, "content_hash": "016e8564e51c1519b05328126eaed14ca97e27d26523002338744059e747f223", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:23d8c6bd5020805c614fe5684992e3061030b96605726eafa7efaff22c2cfd00", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=huggingface (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match huggingface)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.huggingface` is the property prefix that lets you configure the chat model implementation for Hugging Face.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.huggingface.chat.api-key | API Key to authenticate with the Inference Endpoint. | -\n| spring.ai.huggingface.chat.url | URL of the Inference Endpoint to connect to | -\n| spring.ai.huggingface.chat.enabled (Removed and no longer valid) | Enable Hugging Face chat model. | true\n| spring.ai.model.chat | Enable Hugging Face chat model. | huggingface\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Chat Properties", "heading_level": 3, "file_order": 16, "section_index": 4, "content_hash": "23d8c6bd5020805c614fe5684992e3061030b96605726eafa7efaff22c2cfd00", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:438e275b51905704e4033ab928bb688aa1018786dff6028341e51edbd7661df0", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-huggingface` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file, under the `src/main/resources` directory, to enable and configure the Hugging Face chat model:\n\n[source,application.properties]\n----\nspring.ai.huggingface.chat.api-key=YOUR_API_KEY\nspring.ai.huggingface.chat.url=YOUR_INFERENCE_ENDPOINT_URL\n----\n\nTIP: replace the `api-key` and `url` with your Hugging Face values.\n\nThis will create a `HuggingfaceChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final HuggingfaceChatModel chatModel;\n\n @Autowired\n public ChatController(HuggingfaceChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Sample Controller (Auto-configuration)", "heading_level": 2, "file_order": 16, "section_index": 5, "content_hash": "438e275b51905704e4033ab928bb688aa1018786dff6028341e51edbd7661df0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:ce22a843c2a3a4cfd3070adfc2471326667bb6d0a26631319f8d3a728868d9f4", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-huggingface/src/main/java/org/springframework/ai/huggingface/HuggingfaceChatModel.java[HuggingfaceChatModel] implements the `ChatModel` interface and uses the <<low-level-api>> to connect to the Hugging Face inference endpoints.\n\nAdd the `spring-ai-huggingface` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-huggingface</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-huggingface'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `HuggingfaceChatModel` and use it for text generations:\n\n[source,java]\n----\nHuggingfaceChatModel chatModel = new HuggingfaceChatModel(apiKey, url);\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nSystem.out.println(response.getResult().getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/huggingface.adoc", "title": "Hugging Face Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 16, "section_index": 6, "content_hash": "ce22a843c2a3a4cfd3070adfc2471326667bb6d0a26631319f8d3a728868d9f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/huggingface.adoc"}}
{"id": "sha256:123aac37896b019081dad2b62fbe4614c062a5056b9f3375c905d9cd5d9e8905", "content": "Spring AI supports the various AI language models from MiniMax. You can interact with MiniMax language models and create a multilingual conversational assistant based on MiniMax models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "MiniMax Chat", "heading_level": 1, "file_order": 17, "section_index": 0, "content_hash": "123aac37896b019081dad2b62fbe4614c062a5056b9f3375c905d9cd5d9e8905", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:5bfe818149ec0fc3ea39c373d66f3fd8bd775cb31c71be5415f26fae3058fdf8", "content": "You will need to create an API with MiniMax to access MiniMax language models.\n\nCreate an account at https://www.minimaxi.com/login[MiniMax registration page] and generate the token on the https://www.minimaxi.com/user-center/basic-information/interface-key[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.minimax.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.minimax.api-key=<your-minimax-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n minimax:\n api-key: ${MINIMAX_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport MINIMAX_API_KEY=<your-minimax-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"MINIMAX_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 17, "section_index": 1, "content_hash": "5bfe818149ec0fc3ea39c373d66f3fd8bd775cb31c71be5415f26fae3058fdf8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:ff1c644d46b4caa11bd2b9950c96fa41f888b37ff20ceae3a8d5de9c32d9a484", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 17, "section_index": 2, "content_hash": "ff1c644d46b4caa11bd2b9950c96fa41f888b37ff20ceae3a8d5de9c32d9a484", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:c6a9cc9c9f094ddfe8db90a411c0b28771fa07d7ac1731e2103a55e99769f213", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the MiniMax Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-minimax</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-minimax'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 17, "section_index": 3, "content_hash": "c6a9cc9c9f094ddfe8db90a411c0b28771fa07d7ac1731e2103a55e99769f213", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:02fbae28e6520f78bd56c9175d576e5bc5686214988e5c8cceac0f54d8106d97", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the MiniMax chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 17, "section_index": 4, "content_hash": "02fbae28e6520f78bd56c9175d576e5bc5686214988e5c8cceac0f54d8106d97", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:657fc091719c06689581a645b4b313c9003b2ac106a5e4a3d3d7ce18f31ccbce", "content": "The prefix `spring.ai.minimax` is used as the property prefix that lets you connect to MiniMax.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.minimax.base-url | The URL to connect to | https://api.minimax.chat\n| spring.ai.minimax.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 17, "section_index": 5, "content_hash": "657fc091719c06689581a645b4b313c9003b2ac106a5e4a3d3d7ce18f31ccbce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:5ab6ebb874d37eb712ce39e7aa90437d009caf81e0d38590d01845e9da23fed2", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=minimax (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match minimax)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.minimax.chat` is the property prefix that lets you configure the chat model implementation for MiniMax.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.minimax.chat.enabled (Removed and no longer valid) | Enable MiniMax chat model. | true\n| spring.ai.model.chat | Enable MiniMax chat model. | minimax\n| spring.ai.minimax.chat.base-url | Optional overrides the spring.ai.minimax.base-url to provide chat specific url | https://api.minimax.chat\n| spring.ai.minimax.chat.api-key | Optional overrides the spring.ai.minimax.api-key to provide chat specific api-key | -\n| spring.ai.minimax.chat.options.model | This is the MiniMax Chat model to use | `abab6.5g-chat` (the `abab5.5-chat`, `abab5.5s-chat`, `abab6.5-chat`, `abab6.5g-chat`, `abab6.5t-chat` and `abab6.5s-chat` point to the latest model versions)\n| spring.ai.minimax.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.minimax.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | -\n| spring.ai.minimax.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both. | 1.0\n| spring.ai.minimax.chat.options.n | How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Default value is 1 and cannot be greater than 5. Specifically, when the temperature is very small and close to 0, we can only return 1 result. If n is already set and>1 at this time, service will return an illegal input parameter (invalid_request_error) | 1\n| spring.ai.minimax.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | 0.0f\n| spring.ai.minimax.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.minimax.chat.options.stop | The model will stop generating characters specified by stop, and currently only supports a single stop word in the format of [\"stop_word1\"] | -\n| spring.ai.minimax.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.minimax.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.minimax.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nNOTE: You can override the common `spring.ai.minimax.base-url` and `spring.ai.minimax.api-key` for the `ChatModel` implementations.\nThe `spring.ai.minimax.chat.base-url` and `spring.ai.minimax.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different MiniMax accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.minimax.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 17, "section_index": 6, "content_hash": "5ab6ebb874d37eb712ce39e7aa90437d009caf81e0d38590d01845e9da23fed2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:9a6f4956687214738ccb137a845951a8baaa8687a9cedbd964a0963885bf40eb", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/MiniMaxChatOptions.java[MiniMaxChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `MiniMaxChatModel(api, options)` constructor or the `spring.ai.minimax.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n MiniMaxChatOptions.builder()\n .model(MiniMaxApi.ChatModel.ABAB_6_5_S_Chat.getValue())\n .temperature(0.5)\n .build()\n ));\n----\n\nTIP: In addition to the model specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/MiniMaxChatOptions.java[MiniMaxChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 17, "section_index": 7, "content_hash": "9a6f4956687214738ccb137a845951a8baaa8687a9cedbd964a0963885bf40eb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:10552defe4d28cff0cb4b95dac699baf2814224d49fef3f9e8a8ca846083534b", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-minimax` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the MiniMax chat model:\n\n[source,application.properties]\n----\nspring.ai.minimax.api-key=YOUR_API_KEY\nspring.ai.minimax.chat.options.model=abab6.5g-chat\nspring.ai.minimax.chat.options.temperature=0.7\n----\n\nTIP: replace the `api-key` with your MiniMax credentials.\n\nThis will create a `MiniMaxChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final MiniMaxChatModel chatModel;\n\n @Autowired\n public ChatController(MiniMaxChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 17, "section_index": 8, "content_hash": "10552defe4d28cff0cb4b95dac699baf2814224d49fef3f9e8a8ca846083534b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:493f44c5f94c7ab532d11061f53f33de84e66cb5d9b448d8c6adc80fdca12645", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/MiniMaxChatModel.java[MiniMaxChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the MiniMax service.\n\nAdd the `spring-ai-minimax` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-minimax</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-minimax'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `MiniMaxChatModel` and use it for text generations:\n\n[source,java]\n----\nvar miniMaxApi = new MiniMaxApi(System.getenv(\"MINIMAX_API_KEY\"));\n\nvar chatModel = new MiniMaxChatModel(this.miniMaxApi, MiniMaxChatOptions.builder()\n .model(MiniMaxApi.ChatModel.ABAB_6_5_S_Chat.getValue())\n .temperature(0.4)\n .maxTokens(200)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> streamResponse = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `MiniMaxChatOptions` provides the configuration information for the chat requests.\nThe `MiniMaxChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 17, "section_index": 9, "content_hash": "493f44c5f94c7ab532d11061f53f33de84e66cb5d9b448d8c6adc80fdca12645", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:08a11a588d1e8ca6ab8f6798115c4e11de31bac8bc1f649b6583e3e561e5d589", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/api/MiniMaxApi.java[MiniMaxApi] provides is lightweight Java client for link:https://www.minimaxi.com/document/guides/chat-model/V2[MiniMax API].\n\nHere is a simple snippet how to use the api programmatically:\n\n[source,java]\n----\nMiniMaxApi miniMaxApi =\n new MiniMaxApi(System.getenv(\"MINIMAX_API_KEY\"));\n\nChatCompletionMessage chatCompletionMessage =\n new ChatCompletionMessage(\"Hello world\", Role.USER);\n\nResponseEntity<ChatCompletion> response = this.miniMaxApi.chatCompletionEntity(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), MiniMaxApi.ChatModel.ABAB_6_5_S_Chat.getValue(), 0.7, false));\n\nFlux<ChatCompletionChunk> streamResponse = this.miniMaxApi.chatCompletionStream(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), MiniMaxApi.ChatModel.ABAB_6_5_S_Chat.getValue(), 0.7, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/api/MiniMaxApi.java[MiniMaxApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "Low-level MiniMaxApi Client [[low-level-api]]", "heading_level": 3, "file_order": 17, "section_index": 10, "content_hash": "08a11a588d1e8ca6ab8f6798115c4e11de31bac8bc1f649b6583e3e561e5d589", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:844a99a96b6656c6dc4232155430660c8e73e935ef9f57c1955395ca979093a4", "content": "The MiniMax model supported the web search feature. The web search feature allows you to search the web for information and return the results in the chat response.\n\nAbout web search follow the https://platform.minimaxi.com/document/ChatCompletion%20v2[MiniMax ChatCompletion] for further information.\n\nHere is a simple snippet how to use the web search:\n\n[source,java]\n----\nUserMessage userMessage = new UserMessage(\n \"How many gold medals has the United States won in total at the 2024 Olympics?\");\n\nList<Message> messages = new ArrayList<>(List.of(this.userMessage));\n\nList<MiniMaxApi.FunctionTool> functionTool = List.of(MiniMaxApi.FunctionTool.webSearchFunctionTool());\n\nMiniMaxChatOptions options = MiniMaxChatOptions.builder()\n .model(MiniMaxApi.ChatModel.ABAB_6_5_S_Chat.value)\n .tools(this.functionTool)\n .build();\n\nChatResponse response = chatModel.call(new Prompt(this.messages, this.options));\n\nFlux<ChatResponse> streamResponse = chatModel.stream(new Prompt(this.messages, this.options));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "WebSearch chat [[web-search]]", "heading_level": 3, "file_order": 17, "section_index": 11, "content_hash": "844a99a96b6656c6dc4232155430660c8e73e935ef9f57c1955395ca979093a4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:77b2ee5fefd311569800f5feef2e8cc7a460c061a354ae33feafac02a1d45c71", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/test/java/org/springframework/ai/minimax/api/MiniMaxApiIT.java[MiniMaxApiIT.java] test provides some general examples how to use the lightweight library.\n\n* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/test/java/org/springframework/ai/minimax/api/MiniMaxApiToolFunctionCallIT.java[MiniMaxApiToolFunctionCallIT.java] test shows how to use the low-level API to call tool functions.>", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/minimax-chat.adoc", "title": "MiniMax Chat", "heading": "MiniMaxApi Samples", "heading_level": 4, "file_order": 17, "section_index": 12, "content_hash": "77b2ee5fefd311569800f5feef2e8cc7a460c061a354ae33feafac02a1d45c71", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/minimax-chat.adoc"}}
{"id": "sha256:42cef37563ae2dad4fd04e834c269a294ebbaa7fc39853723952acd787dbe729", "content": "Spring AI supports the various AI language models from Mistral AI. You can interact with Mistral AI language models and create a multilingual conversational assistant based on Mistral models.\n\nTIP: Mistral AI offers an OpenAI API-compatible endpoint as well.\nCheck the xref:_openai_api_compatibility[OpenAI API compatibility] section to learn how to use the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] integration to talk to a Mistral endpoint.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Mistral AI Chat", "heading_level": 1, "file_order": 18, "section_index": 0, "content_hash": "42cef37563ae2dad4fd04e834c269a294ebbaa7fc39853723952acd787dbe729", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:11ccdf42b7cd2ecc9c13b46c4a3aeebce111fe437b7616283d9cdb0f5c0a3296", "content": "You will need to create an API with Mistral AI to access Mistral AI language models.\n\nCreate an account at https://auth.mistral.ai/ui/registration[Mistral AI registration page] and generate the token on the https://console.mistral.ai/api-keys/[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.mistralai.api-key` that you should set to the value of the `API Key` obtained from console.mistral.ai.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.mistralai.api-key=<your-mistralai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n mistralai:\n api-key: ${MISTRALAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport MISTRALAI_API_KEY=<your-mistralai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"MISTRALAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 18, "section_index": 1, "content_hash": "11ccdf42b7cd2ecc9c13b46c4a3aeebce111fe437b7616283d9cdb0f5c0a3296", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:d042e5a3369ea2666c54e1327297375ae12a851c019e1ae2750b3bf69e5157d8", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 18, "section_index": 2, "content_hash": "d042e5a3369ea2666c54e1327297375ae12a851c019e1ae2750b3bf69e5157d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:47c6a6d18dea01c5954b0b75c99f8c03fda664d901f66373d88d6a63abcadfb7", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Mistral AI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 18, "section_index": 3, "content_hash": "47c6a6d18dea01c5954b0b75c99f8c03fda664d901f66373d88d6a63abcadfb7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:233cfe521e34c7cb7b218b30b59953bd9a859a99542af49a21aebb373e5a2d85", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the Mistral AI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 18, "section_index": 4, "content_hash": "233cfe521e34c7cb7b218b30b59953bd9a859a99542af49a21aebb373e5a2d85", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:77cac76d09068feca49fe7ee1c6c5a42a60a6da25bf0ef2e855c660ee883a9e8", "content": "The prefix `spring.ai.mistralai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.mistralai.base-url | The URL to connect to | https://api.mistral.ai\n| spring.ai.mistralai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 18, "section_index": 5, "content_hash": "77cac76d09068feca49fe7ee1c6c5a42a60a6da25bf0ef2e855c660ee883a9e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:26abae526a1919115e28cbacfef0618ab72abf83bf5435f2706e3b70c0d8707a", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=mistral (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match mistral)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.mistralai.chat` is the property prefix that lets you configure the chat model implementation for Mistral AI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.mistralai.chat.enabled (Removed and no longer valid) | Enable Mistral AI chat model. | true\n| spring.ai.model.chat | Enable Mistral AI chat model. | mistral\n| spring.ai.mistralai.chat.base-url | Optional override for the `spring.ai.mistralai.base-url` property to provide chat-specific URL. | -\n| spring.ai.mistralai.chat.api-key | Optional override for the `spring.ai.mistralai.api-key` to provide chat-specific API Key. | -\n| spring.ai.mistralai.chat.options.model | This is the Mistral AI Chat model to use | `open-mistral-7b`, `open-mixtral-8x7b`, `open-mixtral-8x22b`, `mistral-small-latest`, `mistral-large-latest`\n| spring.ai.mistralai.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify `temperature` and `top_p` for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.mistralai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.mistralai.chat.options.safePrompt | Indicates whether to inject a security prompt before all conversations. | false\n| spring.ai.mistralai.chat.options.randomSeed | This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. | -\n| spring.ai.mistralai.chat.options.stop | Stop generation if this token is detected. Or if one of these tokens is detected when providing an array. | -\n| spring.ai.mistralai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both. | -\n| spring.ai.mistralai.chat.options.responseFormat | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON. Setting to `{ \"type\": \"json_schema\" }` with a supplied schema enables native structured outputs, which guarantees the model will match your supplied JSON schema. See the <<structured-output>> section for more details.| -\n| spring.ai.mistralai.chat.options.tools | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. | -\n| spring.ai.mistralai.chat.options.toolChoice | Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{\"type: \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that function. `none` is the default when no functions are present. `auto` is the default if functions are present. | -\n| spring.ai.mistralai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.mistralai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.mistralai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nNOTE: You can override the common `spring.ai.mistralai.base-url` and `spring.ai.mistralai.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.mistralai.chat.base-url` and `spring.ai.mistralai.chat.api-key` properties, if set, take precedence over the common properties.\nThis is useful if you want to use different Mistral AI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.mistralai.chat.options` can be overridden at runtime by adding request-specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 18, "section_index": 6, "content_hash": "26abae526a1919115e28cbacfef0618ab72abf83bf5435f2706e3b70c0d8707a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:364dff961fa553fb2527dfe615cf555bca96fa2ef0bc78ab0548061543f39263", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/MistralAiChatOptions.java[MistralAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `MistralAiChatModel(api, options)` constructor or the `spring.ai.mistralai.chat.options.*` properties.\n\nAt run-time, you can override the default options by adding new, request-specific options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n MistralAiChatOptions.builder()\n .model(MistralAiApi.ChatModel.MISTRAL_LARGE.getValue())\n .temperature(0.5)\n .build()\n ));\n----\n\nTIP: In addition to the model specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/MistralAiChatOptions.java[MistralAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 18, "section_index": 7, "content_hash": "364dff961fa553fb2527dfe615cf555bca96fa2ef0bc78ab0548061543f39263", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:1b5f29b750a23cf99bad54c3c6df1b7a1cffcc793859cd1fcf4968fc9b8e0144", "content": "You can register custom Java functions with the `MistralAiChatModel` and have the Mistral AI model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 18, "section_index": 8, "content_hash": "1b5f29b750a23cf99bad54c3c6df1b7a1cffcc793859cd1fcf4968fc9b8e0144", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:1217de65f6beea603fe999c40c31c32c09b7551ab063eb9b29cf3f1ec7199743", "content": "Mistral AI supports native structured outputs through JSON Schema, ensuring the model generates responses that strictly conform to your specified structure.\nThis feature is available for Mistral Small and later models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Structured Output [[structured-output]]", "heading_level": 2, "file_order": 18, "section_index": 9, "content_hash": "1217de65f6beea603fe999c40c31c32c09b7551ab063eb9b29cf3f1ec7199743", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:33d734d78384c30ef38bc936f978ce874af19cc6e9a3c36d5bd22c65cfd5c1b0", "content": "The simplest way to use structured output is with the `ChatClient` high-level API and the `ENABLE_NATIVE_STRUCTURED_OUTPUT` advisor:\n\n[source,java]\n----\nrecord ActorsFilms(String actor, List<String> movies) {}\n\nActorsFilms actorsFilms = ChatClient.create(chatModel).prompt()\n .advisors(AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT)\n .user(\"Generate the filmography of 5 movies for Tom Hanks.\")\n .call()\n .entity(ActorsFilms.class);\n----\n\nThis approach automatically:\n- Generates a JSON schema from your Java class\n- Configures the model to use native structured output\n- Parses the response into your specified type", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Using ChatClient with Native Structured Output", "heading_level": 3, "file_order": 18, "section_index": 10, "content_hash": "33d734d78384c30ef38bc936f978ce874af19cc6e9a3c36d5bd22c65cfd5c1b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:ba8c82d59a97da66bbe65e454833d0402268e17f23f967e3bc30427764bf9af8", "content": "For more control, you can use the `ResponseFormat` class with `MistralAiChatOptions`:\n\n[source,java]\n----\nrecord MovieRecommendation(String title, String director, int year, String plotSummary) {}\n\nvar options = MistralAiChatOptions.builder()\n .model(MistralAiApi.ChatModel.MISTRAL_SMALL.getValue())\n .responseFormat(ResponseFormat.jsonSchema(MovieRecommendation.class))\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\"Recommend a classic science fiction movie.\", options));\n----\n\nThe `ResponseFormat` class provides several factory methods:\n\n* `ResponseFormat.text()` - Returns plain text output (default)\n* `ResponseFormat.jsonObject()` - Returns valid JSON (no schema enforcement)\n* `ResponseFormat.jsonSchema(Class<?>)` - Generates schema from a Java class\n* `ResponseFormat.jsonSchema(String)` - Uses a JSON schema string\n* `ResponseFormat.jsonSchema(Map)` - Uses a JSON schema map", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Using ResponseFormat Directly", "heading_level": 3, "file_order": 18, "section_index": 11, "content_hash": "ba8c82d59a97da66bbe65e454833d0402268e17f23f967e3bc30427764bf9af8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:701dc36c75013f05e64fe484357aab33cf40d82e1364bf088069d836a208a705", "content": "Mistral AI supports two JSON-related modes:\n\n* **JSON Mode** (`json_object`): Guarantees valid JSON output, but doesn't enforce a specific structure\n* **Structured Output** (`json_schema`): Guarantees output matching your JSON schema\n\n[source,java]\n----\nvar jsonMode = MistralAiChatOptions.builder()\n .responseFormat(ResponseFormat.jsonObject())\n .build();\n\nvar structuredOutput = MistralAiChatOptions.builder()\n .responseFormat(ResponseFormat.jsonSchema(MyClass.class))\n .build();\n----\n\nFor more information about structured outputs, see the xref:api/structured-output-converter.adoc[Structured Output Converter] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "JSON Mode vs Structured Output", "heading_level": 3, "file_order": 18, "section_index": 12, "content_hash": "701dc36c75013f05e64fe484357aab33cf40d82e1364bf088069d836a208a705", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:f6fc3854d99f27238e5a98913c199e67733a26896f984f33b83e36bbe4d2ed13", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.\nMistral AI supports text and vision modalities.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 18, "section_index": 13, "content_hash": "f6fc3854d99f27238e5a98913c199e67733a26896f984f33b83e36bbe4d2ed13", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:b28c3b0867bd068c7959802ef477969b6a5bb509f15e1da00679f09e01309cce", "content": "Mistral AI models that offer vision multimodal support include `pixtral-large-latest`.\nRefer to the link:https://docs.mistral.ai/capabilities/vision/[Vision] guide for more information.\n\nThe Mistral AI link:https://docs.mistral.ai/api/#tag/chat/operation/chat_completion_v1_chat_completions_post[User Message API] can incorporate a list of base64-encoded images or image urls with the message.\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-client-chat/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `org.springframework.core.io.Resource` for the raw media data.\n\nBelow is a code example excerpted from `MistralAiChatModelIT.java`, illustrating the fusion of user text with an image.\n\n[source,java]\n----\nvar imageResource = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n new Media(MimeTypeUtils.IMAGE_PNG, this.imageResource));\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage,\n ChatOptions.builder().model(MistralAiApi.ChatModel.PIXTRAL_LARGE.getValue()).build()));\n----\n\nor the image URL equivalent:\n\n[source,java]\n----\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n new Media(MimeTypeUtils.IMAGE_PNG,\n URI.create(\"https://docs.spring.io/spring-ai/reference/_images/multimodal.test.png\")));\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage,\n ChatOptions.builder().model(MistralAiApi.ChatModel.PIXTRAL_LARGE.getValue()).build()));\n----\n\nTIP: You can pass multiple images as well.\n\nThe example shows a model taking as an input the `multimodal.test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generating a response like this:\n\n----\nThis is an image of a fruit bowl with a simple design. The bowl is made of metal with curved wire edges that\ncreate an open structure, allowing the fruit to be visible from all angles. Inside the bowl, there are two\nyellow bananas resting on top of what appears to be a red apple. The bananas are slightly overripe, as\nindicated by the brown spots on their peels. The bowl has a metal ring at the top, likely to serve as a handle\nfor carrying. The bowl is placed on a flat surface with a neutral-colored background that provides a clear\nview of the fruit inside.\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Vision", "heading_level": 3, "file_order": 18, "section_index": 14, "content_hash": "b28c3b0867bd068c7959802ef477969b6a5bb509f15e1da00679f09e01309cce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:ab6f1610d1e95222c34a48d05c65afe0d76660b01920703ed59f631e04f71e33", "content": "Mistral is OpenAI API-compatible and you can use the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] client to talk to Mistrial.\nFor this, you need to configure the OpenAI base URL to the Mistral AI platform: `spring.ai.openai.chat.base-url=https://api.mistral.ai`, and select a Mistral model: `spring.ai.openai.chat.options.model=mistral-small-latest` and set the Mistral AI API key: `spring.ai.openai.chat.api-key=<YOUR MISTRAL API KEY`.\n\nCheck the link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/MistralWithOpenAiChatModelIT.java[MistralWithOpenAiChatModelIT.java] tests for examples of using Mistral over Spring AI OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "OpenAI API Compatibility", "heading_level": 2, "file_order": 18, "section_index": 15, "content_hash": "ab6f1610d1e95222c34a48d05c65afe0d76660b01920703ed59f631e04f71e33", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:b3e80ceacb5c58dcb6135297a3f77d5df9ea9c74eff30d24b021ccad21993657", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-mistral-ai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file under the `src/main/resources` directory to enable and configure the Mistral AI chat model:\n\n[source,application.properties]\n----\nspring.ai.mistralai.api-key=YOUR_API_KEY\nspring.ai.mistralai.chat.options.model=mistral-small\nspring.ai.mistralai.chat.options.temperature=0.7\n----\n\nTIP: Replace the `api-key` with your Mistral AI credentials.\n\nThis will create a `MistralAiChatModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final MistralAiChatModel chatModel;\n\n @Autowired\n public ChatController(MistralAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map<String,String> generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Sample Controller (Auto-configuration)", "heading_level": 2, "file_order": 18, "section_index": 16, "content_hash": "b3e80ceacb5c58dcb6135297a3f77d5df9ea9c74eff30d24b021ccad21993657", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:0f6b1a25c6b2a25741f36767f2e5d9e28d1984125b759127290d66e1815362b0", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/MistralAiChatModel.java[MistralAiChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the Mistral AI service.\n\nAdd the `spring-ai-mistral-ai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `MistralAiChatModel` and use it for text generations:\n\n[source,java]\n----\nvar mistralAiApi = new MistralAiApi(System.getenv(\"MISTRAL_AI_API_KEY\"));\n\nvar chatModel = new MistralAiChatModel(this.mistralAiApi, MistralAiChatOptions.builder()\n .model(MistralAiApi.ChatModel.MISTRAL_LARGE.getValue())\n .temperature(0.4)\n .maxTokens(200)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `MistralAiChatOptions` provides the configuration information for the chat requests.\nThe `MistralAiChatOptions.Builder` is a fluent options-builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 18, "section_index": 17, "content_hash": "0f6b1a25c6b2a25741f36767f2e5d9e28d1984125b759127290d66e1815362b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:ce8308d13a74d4ba624975e305aa67bc42bc2f47e97b6f5b3e685cdded4500cb", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/api/MistralAiApi.java[MistralAiApi] provides is lightweight Java client for link:https://docs.mistral.ai/api/[Mistral AI API].\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nMistralAiApi mistralAiApi = new MistralAiApi(System.getenv(\"MISTRAL_AI_API_KEY\"));\n\nChatCompletionMessage chatCompletionMessage =\n new ChatCompletionMessage(\"Hello world\", Role.USER);\n\nResponseEntity<ChatCompletion> response = this.mistralAiApi.chatCompletionEntity(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), MistralAiApi.ChatModel.MISTRAL_LARGE.getValue(), 0.8, false));\n\nFlux<ChatCompletionChunk> streamResponse = this.mistralAiApi.chatCompletionStream(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), MistralAiApi.ChatModel.MISTRAL_LARGE.getValue(), 0.8, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/api/MistralAiApi.java[MistralAiApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Low-level MistralAiApi Client [[low-level-api]]", "heading_level": 3, "file_order": 18, "section_index": 18, "content_hash": "ce8308d13a74d4ba624975e305aa67bc42bc2f47e97b6f5b3e685cdded4500cb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:633dc812dc943da433af341a9a066b4748134cd6f28225c83022b16186d1ed3a", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/test/java/org/springframework/ai/mistralai/api/MistralAiApiIT.java[MistralAiApiIT.java] tests provide some general examples of how to use the lightweight library.\n\n* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/test/java/org/springframework/ai/mistralai/api/tool/PaymentStatusFunctionCallingIT.java[PaymentStatusFunctionCallingIT.java] tests show how to use the low-level API to call tool functions.\nBased on the link:https://docs.mistral.ai/guides/function-calling/[Mistral AI Function Calling] tutorial.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "MistralAiApi Samples", "heading_level": 4, "file_order": 18, "section_index": 19, "content_hash": "633dc812dc943da433af341a9a066b4748134cd6f28225c83022b16186d1ed3a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:fa9e7321c6c8ff767139cbaeb40b64e66c13250b5198d3b3f8dc006f96586792", "content": "Spring AI supports Optical Character Recognition (OCR) with Mistral AI. This allows you to extract text and image data from documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Mistral AI OCR", "heading_level": 2, "file_order": 18, "section_index": 20, "content_hash": "fa9e7321c6c8ff767139cbaeb40b64e66c13250b5198d3b3f8dc006f96586792", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:a5cfaef98aab08a6a6ad13ea4394cff086486768a69d4b86486cb4da56d8bdae", "content": "You will need to create an API with Mistral AI to access Mistral AI language models.\nCreate an account at https://auth.mistral.ai/ui/registration[Mistral AI registration page] and generate the token on the https://console.mistral.ai/api-keys/[API Keys page].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 18, "section_index": 21, "content_hash": "a5cfaef98aab08a6a6ad13ea4394cff086486768a69d4b86486cb4da56d8bdae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:8b5c53056fbcda1432a4ff7940f3a12d2611faf5205317c1e85767f81648aadd", "content": "To use the Mistral AI OCR API, you will need to add the `spring-ai-mistral-ai` dependency to your project.\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-mistral-ai'\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Add Dependencies", "heading_level": 3, "file_order": 18, "section_index": 22, "content_hash": "8b5c53056fbcda1432a4ff7940f3a12d2611faf5205317c1e85767f81648aadd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:48d3667cb2b03c35685faff089214e84b4d031a2885366e8a1a0425650e579fe", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/api/MistralOcrApi.java[MistralOcrApi] provides a lightweight Java client for link:https://docs.mistral.ai/api/#tag/OCR[Mistral AI OCR API].\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nMistralOcrApi mistralAiApi = new MistralOcrApi(System.getenv(\"MISTRAL_AI_API_KEY\"));\n\nString documentUrl = \"https://arxiv.org/pdf/2201.04234\";\nMistralOcrApi.OCRRequest request = new MistralOcrApi.OCRRequest(\n MistralOcrApi.OCRModel.MISTRAL_OCR_LATEST.getValue(), \"test_id\",\n new MistralOcrApi.OCRRequest.DocumentURLChunk(documentUrl), List.of(0, 1, 2), true, 5, 50);\n\nResponseEntity<MistralOcrApi.OCRResponse> response = mistralAiApi.ocr(request);\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/api/MistralOcrApi.java[MistralOcrApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "Low-level MistralOcrApi Client", "heading_level": 3, "file_order": 18, "section_index": 23, "content_hash": "48d3667cb2b03c35685faff089214e84b4d031a2885366e8a1a0425650e579fe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:1f2067a5a1ec80b1d3821c1be98915e8772ccb610619b251f5a51d24fb0c6ffe", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/test/java/org/springframework/ai/mistralai/api/MistralOcrApiIT.java[MistralOcrApiIT.java] tests provide some general examples of how to use the lightweight library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc", "title": "Mistral AI Chat", "heading": "MistralOcrApi Sample", "heading_level": 4, "file_order": 18, "section_index": 24, "content_hash": "1f2067a5a1ec80b1d3821c1be98915e8772ccb610619b251f5a51d24fb0c6ffe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/mistralai-chat.adoc"}}
{"id": "sha256:2d242fbe070aebece6f3993ce17d09b5467be73575e40584fe1aa7962baed055", "content": "This functionality has been moved to the Spring AI Community repository.\n\nPlease visit https://github.com/spring-ai-community/moonshot for the latest version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/moonshot-chat.adoc", "title": "Moonshot AI Chat", "heading": "Moonshot AI Chat", "heading_level": 1, "file_order": 19, "section_index": 0, "content_hash": "2d242fbe070aebece6f3993ce17d09b5467be73575e40584fe1aa7962baed055", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/moonshot-chat.adoc"}}
{"id": "sha256:60f3751754acfe8a92cc493385993ef2470c212926785b3945ff76635edf885b", "content": "https://docs.api.nvidia.com/nim/reference/llm-apis[NVIDIA LLM API] is a proxy AI Inference Engine offering a wide range of models from link:https://docs.api.nvidia.com/nim/reference/llm-apis#models[various providers].\n\nSpring AI integrates with the NVIDIA LLM API by reusing the existing xref::api/chat/openai-chat.adoc[OpenAI] client.\nFor this you need to set the base-url to `+https://integrate.api.nvidia.com+`, select one of the provided https://docs.api.nvidia.com/nim/reference/llm-apis#model[LLM models] and get an `api-key` for it.\n\nimage::spring-ai-nvidia-llm-api-1.jpg[w=800,align=\"center\"]\n\nNOTE: NVIDIA LLM API requires the `max-tokens` parameter to be explicitly set or server error will be thrown.\n\nCheck the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/NvidiaWithOpenAiChatModelIT.java[NvidiaWithOpenAiChatModelIT.java] tests\nfor examples of using NVIDIA LLM API with Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "NVIDIA Chat", "heading_level": 1, "file_order": 20, "section_index": 0, "content_hash": "60f3751754acfe8a92cc493385993ef2470c212926785b3945ff76635edf885b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:121a49912c617813423691aeb95b7c930a5cb2e4d926c32022872fb6b4907bb0", "content": "* Create link:https://build.nvidia.com/explore/discover[NVIDIA] account with sufficient credits.\n* Select a LLM Model to use. For example the `meta/llama-3.1-70b-instruct` in the screenshot below.\n* From the selected model's page, you can get the `api-key` for accessing this model.\n\nimage::spring-ai-nvidia-registration.jpg[w=800,align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Prerequisite", "heading_level": 2, "file_order": 20, "section_index": 1, "content_hash": "121a49912c617813423691aeb95b7c930a5cb2e4d926c32022872fb6b4907bb0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:e264e55bffaf99ddc4ecf91e8f9a3334d5a6e3b431043575580251ef10d520a0", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 20, "section_index": 2, "content_hash": "e264e55bffaf99ddc4ecf91e8f9a3334d5a6e3b431043575580251ef10d520a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:c5255c4443f9f097853d849d34926c439486dbfdd2fb4094905ea75950a9f364", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 20, "section_index": 3, "content_hash": "c5255c4443f9f097853d849d34926c439486dbfdd2fb4094905ea75950a9f364", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:58863946e805b15875322fd1e6d67dc0eaf096e8524a50b20d382649cd72c977", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to. Must be set to `+https://integrate.api.nvidia.com+` | -\n| spring.ai.openai.api-key | The NVIDIA API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 20, "section_index": 4, "content_hash": "58863946e805b15875322fd1e6d67dc0eaf096e8524a50b20d382649cd72c977", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:6ee00d3613d4069a8a453a613010529974df5ca02c6c7b4daeb0481e8b51d9f4", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=openai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.chat` is the property prefix that lets you configure the chat model implementation for OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.chat.enabled (Removed and no longer valid) | Enable OpenAI chat model. | true\n| spring.ai.model.chat | Enable OpenAI chat model. | openai\n| spring.ai.openai.chat.base-url | Optional overrides the spring.ai.openai.base-url to provide chat specific url. Must be set to `+https://integrate.api.nvidia.com+` | -\n| spring.ai.openai.chat.api-key | Optional overrides the spring.ai.openai.api-key to provide chat specific api-key | -\n| spring.ai.openai.chat.options.model | The link:https://docs.api.nvidia.com/nim/reference/llm-apis#models[NVIDIA LLM model] to use | -\n| spring.ai.openai.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify temperature and top_p for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.openai.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.openai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | NOTE: NVIDIA LLM API requires the `max-tokens` parameter to be explicitly set or server error will be thrown.\n| spring.ai.openai.chat.options.n | How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs. | 1\n| spring.ai.openai.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | -\n| spring.ai.openai.chat.options.responseFormat | An object specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON.| -\n| spring.ai.openai.chat.options.seed | This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. | -\n| spring.ai.openai.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.openai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both. | -\n| spring.ai.openai.chat.options.tools | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. | -\n| spring.ai.openai.chat.options.toolChoice | Controls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"type: \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function. none is the default when no functions are present. auto is the default if functions are present. | -\n| spring.ai.openai.chat.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n| spring.ai.openai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.openai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.openai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nTIP: All properties prefixed with `spring.ai.openai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 20, "section_index": 5, "content_hash": "6ee00d3613d4069a8a453a613010529974df5ca02c6c7b4daeb0481e8b51d9f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:559a21b4cc46e74f0b7262a64b8afa579cc69c2f2fa6c8693aa4e22c6c95a73f", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiChatModel(api, options)` constructor or the `spring.ai.openai.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiChatOptions.builder()\n .model(\"mixtral-8x7b-32768\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 20, "section_index": 6, "content_hash": "559a21b4cc46e74f0b7262a64b8afa579cc69c2f2fa6c8693aa4e22c6c95a73f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:130733288dec291d2eaf54d90fe5406c41ae9fc84fbf602502f29c83b500ba3c", "content": "NVIDIA LLM API supports Tool/Function calling when selecting a model that supports it.\n\nimage::spring-ai-nvidia-function-calling.jpg[w=800,align=\"center\"]\n\nYou can register custom Java functions with your ChatModel and have the provided model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 20, "section_index": 7, "content_hash": "130733288dec291d2eaf54d90fe5406c41ae9fc84fbf602502f29c83b500ba3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:3bf6608b648b6f1daeb9bd6905aa250267b32b0c963eabce7375a69c99ace428", "content": "Here's a simple example of how to use NVIDIA LLM API function calling with Spring AI:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=${NVIDIA_API_KEY}\nspring.ai.openai.base-url=https://integrate.api.nvidia.com\nspring.ai.openai.chat.options.model=meta/llama-3.1-70b-instruct\nspring.ai.openai.chat.options.max-tokens=2048\n----\n\n[source,java]\n----\n@SpringBootApplication\npublic class NvidiaLlmApplication {\n\n public static void main(String[] args) {\n SpringApplication.run(NvidiaLlmApplication.class, args);\n }\n\n @Bean\n CommandLineRunner runner(ChatClient.Builder chatClientBuilder) {\n return args -> {\n var chatClient = chatClientBuilder.build();\n\n var response = chatClient.prompt()\n .user(\"What is the weather in Amsterdam and Paris?\")\n .functions(\"weatherFunction\") // reference by bean name.\n .call()\n .content();\n\n System.out.println(response);\n };\n }\n\n @Bean\n @Description(\"Get the weather in location\")\n public Function<WeatherRequest, WeatherResponse> weatherFunction() {\n return new MockWeatherService();\n }\n\n public static class MockWeatherService implements Function<WeatherRequest, WeatherResponse> {\n\n public record WeatherRequest(String location, String unit) {}\n public record WeatherResponse(double temp, String unit) {}\n\n @Override\n public WeatherResponse apply(WeatherRequest request) {\n double temperature = request.location().contains(\"Amsterdam\") ? 20 : 25;\n return new WeatherResponse(temperature, request.unit);\n }\n }\n}\n----\n\nIn this example, when the model needs weather information, it will automatically call the `weatherFunction` bean, which can then fetch real-time weather data.\nThe expected response looks like this: \"The weather in Amsterdam is currently 20 degrees Celsius, and the weather in Paris is currently 25 degrees Celsius.\"\n\nRead more about OpenAI link:https://docs.spring.io/spring-ai/reference/api/chat/functions/openai-chat-functions.html[Function Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Tool Example", "heading_level": 3, "file_order": 20, "section_index": 8, "content_hash": "3bf6608b648b6f1daeb9bd6905aa250267b32b0c963eabce7375a69c99ace428", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:d94e1f8586b13485c51f17615fbdbc18695ded553819141c2da3aa3ac2b156d2", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-openai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=${NVIDIA_API_KEY}\nspring.ai.openai.base-url=https://integrate.api.nvidia.com\nspring.ai.openai.chat.options.model=meta/llama-3.1-70b-instruct\n\n# The NVIDIA LLM API doesn't support embeddings, so we need to disable it.\nspring.ai.openai.embedding.enabled=false\n\n# The NVIDIA LLM API requires this parameter to be set explicitly or server internal error will be thrown.\nspring.ai.openai.chat.options.max-tokens=2048\n----\n\nTIP: replace the `api-key` with your NVIDIA credentials.\n\nNOTE: NVIDIA LLM API requires the `max-token` parameter to be explicitly set or server error will be thrown.\n\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc", "title": "NVIDIA Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 20, "section_index": 9, "content_hash": "d94e1f8586b13485c51f17615fbdbc18695ded553819141c2da3aa3ac2b156d2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/nvidia-chat.adoc"}}
{"id": "sha256:a7c08dd589f5f5add50a4cea6afa1af300c5fa38479e5901755bf2dc4735d272", "content": "With https://ollama.ai/[Ollama] you can run various Large Language Models (LLMs) locally and generate text from them.\nSpring AI supports the Ollama chat completion capabilities with the `OllamaChatModel` API.\n\nTIP: Ollama offers an OpenAI API compatible endpoint as well.\nThe xref:_openai_api_compatibility[OpenAI API compatibility] section explains how to use the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] to connect to an Ollama server.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Ollama Chat", "heading_level": 1, "file_order": 21, "section_index": 0, "content_hash": "a7c08dd589f5f5add50a4cea6afa1af300c5fa38479e5901755bf2dc4735d272", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:9156cd8a425d891101f4499adb0fd7dfc2be3252be1832eb6aef6d966c932af6", "content": "You first need access to an Ollama instance. There are a few options, including the following:\n\n* link:https://ollama.com/download[Download and install Ollama] on your local machine.\n* Configure and xref:api/testcontainers.adoc[run Ollama via Testcontainers].\n* Bind to an Ollama instance via xref:api/cloud-bindings.adoc[Kubernetes Service Bindings].\n\nYou can pull the models you want to use in your application from the link:https://ollama.com/library[Ollama model library]:\n\n[source,shellscript]\n----\nollama pull <model-name>\n----\n\nYou can also pull any of the thousands, free, link:https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face Models]:\n\n[source,shellscript]\n----\nollama pull hf.co/<username>/<model-repository>\n----\n\nAlternatively, you can enable the option to download automatically any needed model: xref:auto-pulling-models[Auto-pulling Models].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 21, "section_index": 1, "content_hash": "9156cd8a425d891101f4499adb0fd7dfc2be3252be1832eb6aef6d966c932af6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:fe8d76984b7b1972d40867e9e77033f38d79c80ed478b85400d6aa39ec0cd29a", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Ollama chat integration.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-ollama</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-ollama'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 21, "section_index": 2, "content_hash": "fe8d76984b7b1972d40867e9e77033f38d79c80ed478b85400d6aa39ec0cd29a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:f2783fcad045dd0794f3621580350424a75e6cee9a2a53c2ddeb1e0da3ffe085", "content": "The prefix `spring.ai.ollama` is the property prefix to configure the connection to Ollama.\n\n[cols=\"3,6,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.ollama.base-url | Base URL where Ollama API server is running. | `+http://localhost:11434+`\n|====\n\nHere are the properties for initializing the Ollama integration and xref:auto-pulling-models[auto-pulling models].\n\n[cols=\"3,6,1\"]\n|====\n| Property | Description | Default\n| spring.ai.ollama.init.pull-model-strategy | Whether to pull models at startup-time and how. | `never`\n| spring.ai.ollama.init.timeout | How long to wait for a model to be pulled. | `5m`\n| spring.ai.ollama.init.max-retries | Maximum number of retries for the model pull operation. | `0`\n| spring.ai.ollama.init.chat.include | Include this type of models in the initialization task. | `true`\n| spring.ai.ollama.init.chat.additional-models | Additional models to initialize besides the ones configured via default properties. | `[]`\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Base Properties", "heading_level": 3, "file_order": 21, "section_index": 3, "content_hash": "f2783fcad045dd0794f3621580350424a75e6cee9a2a53c2ddeb1e0da3ffe085", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:66766c14ee47b03651595e2d05103eea174378dab05abd8f46bfe8d5c8fab246", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=ollama (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match ollama)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.ollama.chat.options` is the property prefix that configures the Ollama chat model.\nIt includes the Ollama request (advanced) parameters such as the `model`, `keep-alive`, and `format` as well as the Ollama model `options` properties.\n\nHere are the advanced request parameter for the Ollama chat model:\n\n[cols=\"3,6,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.ollama.chat.enabled (Removed and no longer valid) | Enable Ollama chat model. | true\n| spring.ai.model.chat | Enable Ollama chat model. | ollama\n| spring.ai.ollama.chat.options.model | The name of the https://github.com/ollama/ollama?tab=readme-ov-file#model-library[supported model] to use. | mistral\n| spring.ai.ollama.chat.options.format | The format to return a response in. Accepts either `\"json\"` (any JSON structure) or a JSON Schema object (enforced structure). See <<Structured Outputs>> for details. | -\n| spring.ai.ollama.chat.options.keep_alive | Controls how long the model will stay loaded into memory following the request | 5m\n|====\n\nThe remaining `options` properties are based on the link:https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values[Ollama Valid Parameters and Values] and link:https://github.com/ollama/ollama/blob/main/api/types.go[Ollama Types]. The default values are based on the link:https://github.com/ollama/ollama/blob/b538dc3858014f94b099730a592751a5454cab0a/api/types.go#L364[Ollama Types Defaults].\n\n[cols=\"3,6,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.ollama.chat.options.numa | Whether to use NUMA. | false\n| spring.ai.ollama.chat.options.num-ctx | Sets the size of the context window used to generate the next token. | 2048\n| spring.ai.ollama.chat.options.num-batch | Prompt processing maximum batch size. | 512\n| spring.ai.ollama.chat.options.num-gpu | The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. 1 here indicates that NumGPU should be set dynamically | -1\n| spring.ai.ollama.chat.options.main-gpu | When using multiple GPUs this option controls which GPU is used for small tensors for which the overhead of splitting the computation across all GPUs is not worthwhile. The GPU in question will use slightly more VRAM to store a scratch buffer for temporary results. | 0\n| spring.ai.ollama.chat.options.low-vram | - | false\n| spring.ai.ollama.chat.options.f16-kv | - | true\n| spring.ai.ollama.chat.options.logits-all | Return logits for all the tokens, not just the last one. To enable completions to return logprobs, this must be true. | -\n| spring.ai.ollama.chat.options.vocab-only | Load only the vocabulary, not the weights. | -\n| spring.ai.ollama.chat.options.use-mmap | By default, models are mapped into memory, which allows the system to load only the necessary parts of the model as needed. However, if the model is larger than your total amount of RAM or if your system is low on available memory, using mmap might increase the risk of pageouts, negatively impacting performance. Disabling mmap results in slower load times but may reduce pageouts if you're not using mlock. Note that if the model is larger than the total amount of RAM, turning off mmap would prevent the model from loading at all. | null\n| spring.ai.ollama.chat.options.use-mlock | Lock the model in memory, preventing it from being swapped out when memory-mapped. This can improve performance but trades away some of the advantages of memory-mapping by requiring more RAM to run and potentially slowing down load times as the model loads into RAM. | false\n| spring.ai.ollama.chat.options.num-thread | Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). 0 = let the runtime decide | 0\n| spring.ai.ollama.chat.options.num-keep | - | 4\n| spring.ai.ollama.chat.options.seed | Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt. | -1\n| spring.ai.ollama.chat.options.num-predict | Maximum number of tokens to predict when generating text. (-1 = infinite generation, -2 = fill context) | -1\n| spring.ai.ollama.chat.options.top-k | Reduces the probability of generating nonsense. A higher value (e.g., 100) will give more diverse answers, while a lower value (e.g., 10) will be more conservative. | 40\n| spring.ai.ollama.chat.options.top-p | Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. | 0.9\n| spring.ai.ollama.chat.options.min-p | Alternative to the top_p, and aims to ensure a balance of quality and variety. The parameter p represents the minimum probability for a token to be considered, relative to the probability of the most likely token. For example, with p=0.05 and the most likely token having a probability of 0.9, logits with a value less than 0.045 are filtered out. | 0.0\n| spring.ai.ollama.chat.options.tfs-z | Tail-free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. | 1.0\n| spring.ai.ollama.chat.options.typical-p | - | 1.0\n| spring.ai.ollama.chat.options.repeat-last-n | Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx) | 64\n| spring.ai.ollama.chat.options.temperature | The temperature of the model. Increasing the temperature will make the model answer more creatively. | 0.8\n| spring.ai.ollama.chat.options.repeat-penalty | Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. | 1.1\n| spring.ai.ollama.chat.options.presence-penalty | - | 0.0\n| spring.ai.ollama.chat.options.frequency-penalty | - | 0.0\n| spring.ai.ollama.chat.options.mirostat | Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0) | 0\n| spring.ai.ollama.chat.options.mirostat-tau | Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. | 5.0\n| spring.ai.ollama.chat.options.mirostat-eta | Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. | 0.1\n| spring.ai.ollama.chat.options.penalize-newline | - | true\n| spring.ai.ollama.chat.options.stop | Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Multiple stop patterns may be set by specifying multiple separate stop parameters in a modelfile. | -\n| spring.ai.ollama.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.ollama.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.ollama.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nTIP: All properties prefixed with `spring.ai.ollama.chat.options` can be overridden at runtime by adding request-specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Chat Properties", "heading_level": 3, "file_order": 21, "section_index": 4, "content_hash": "66766c14ee47b03651595e2d05103eea174378dab05abd8f46bfe8d5c8fab246", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:7e38601bf746e77d26fc74b5f05ae73908f37073cc2efefd4c2b7dbb771f4ec9", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/main/java/org/springframework/ai/ollama/api/OllamaChatOptions.java[OllamaChatOptions.java] class provides model configurations, such as the model to use, the temperature, thinking mode, etc.\n\nIMPORTANT: The `OllamaOptions` class has been deprecated. Use `OllamaChatOptions` for chat models and `OllamaEmbeddingOptions` for embedding models instead. The new classes provide type-safe, model-specific configuration options.\n\nOn start-up, the default options can be configured with the `OllamaChatModel(api, options)` constructor or the `spring.ai.ollama.chat.options.*` properties.\n\nAt run-time, you can override the default options by adding new, request-specific options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OllamaChatOptions.builder()\n .model(OllamaModel.LLAMA3_1)\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/main/java/org/springframework/ai/ollama/api/OllamaChatOptions.java[OllamaChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].\n\n[[auto-pulling-models]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 21, "section_index": 5, "content_hash": "7e38601bf746e77d26fc74b5f05ae73908f37073cc2efefd4c2b7dbb771f4ec9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:1878ec36ecf81b7e6256f623bb86e1f9b54301a8cdc7d8af805e3085070786d4", "content": "Spring AI Ollama can automatically pull models when they are not available in your Ollama instance.\nThis feature is particularly useful for development and testing as well as for deploying your applications to new environments.\n\nTIP: You can also pull, by name, any of the thousands, free, link:https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face Models].\n\nThere are three strategies for pulling models:\n\n* `always` (defined in `PullModelStrategy.ALWAYS`): Always pull the model, even if it's already available. Useful to ensure you're using the latest version of the model.\n* `when_missing` (defined in `PullModelStrategy.WHEN_MISSING`): Only pull the model if it's not already available. This may result in using an older version of the model.\n* `never` (defined in `PullModelStrategy.NEVER`): Never pull the model automatically.\n\nCAUTION: Due to potential delays while downloading models, automatic pulling is not recommended for production environments. Instead, consider assessing and pre-downloading the necessary models in advance.\n\nAll models defined via configuration properties and default options can be automatically pulled at startup time.\nYou can configure the pull strategy, timeout, and maximum number of retries using configuration properties:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n timeout: 60s\n max-retries: 1\n----\n\nCAUTION: The application will not complete its initialization until all specified models are available in Ollama. Depending on the model size and internet connection speed, this may significantly slow down your application's startup time.\n\nYou can initialize additional models at startup, which is useful for models used dynamically at runtime:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n chat:\n additional-models:\n - llama3.2\n - qwen2.5\n----\n\nIf you want to apply the pulling strategy only to specific types of models, you can exclude chat models from the initialization task:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n chat:\n include: false\n----\n\nThis configuration will apply the pulling strategy to all models except chat models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Auto-pulling Models", "heading_level": 2, "file_order": 21, "section_index": 6, "content_hash": "1878ec36ecf81b7e6256f623bb86e1f9b54301a8cdc7d8af805e3085070786d4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:d573b18dbd52dfc57cb159692646a537991001aa7c6426609f4a649750771e3c", "content": "You can register custom Java functions with the `OllamaChatModel` and have the Ollama model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].\n\nTIP: You need Ollama 0.2.8 or newer to use the functional calling capabilities and Ollama 0.4.6 or newer to use them in streaming mode.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 21, "section_index": 7, "content_hash": "d573b18dbd52dfc57cb159692646a537991001aa7c6426609f4a649750771e3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:1362d79049e1089dae11893192256d7557f7bf864c71d95501646cd2f9ed5bc9", "content": "Ollama supports thinking mode for reasoning models that can emit their internal reasoning process before providing a final answer. This feature is available for models like Qwen3, DeepSeek-v3.1, DeepSeek R1, and GPT-OSS.\n\nTIP: Thinking mode helps you understand the model's reasoning process and can improve response quality for complex problems.\n\nIMPORTANT: *Default Behavior (Ollama 0.12+)*: Thinking-capable models (such as `qwen3:*-thinking`, `deepseek-r1`, `deepseek-v3.1`) *auto-enable thinking by default* when the think option is not explicitly set. Standard models (such as `qwen2.5:*`, `llama3.2`) do not enable thinking by default. To explicitly control this behavior, use `.enableThinking()` or `.disableThinking()`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Thinking Mode (Reasoning)", "heading_level": 2, "file_order": 21, "section_index": 8, "content_hash": "1362d79049e1089dae11893192256d7557f7bf864c71d95501646cd2f9ed5bc9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:6bc6722da28813d0e81bbab2ddae8a2484b275dd6e745910587652624712d502", "content": "Most models (Qwen3, DeepSeek-v3.1, DeepSeek R1) support simple boolean enable/disable:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"How many letter 'r' are in the word 'strawberry'?\",\n OllamaChatOptions.builder()\n .model(\"qwen3\")\n .enableThinking()\n .build()\n ));\n\nString thinking = response.getResult().getMetadata().get(\"thinking\");\nString answer = response.getResult().getOutput().getText();\n----\n\nYou can also disable thinking explicitly:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"What is 2+2?\",\n OllamaChatOptions.builder()\n .model(\"deepseek-r1\")\n .disableThinking()\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Enabling Thinking Mode", "heading_level": 3, "file_order": 21, "section_index": 9, "content_hash": "6bc6722da28813d0e81bbab2ddae8a2484b275dd6e745910587652624712d502", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:8a2615a516c4b8fecf2dd93d70dac1588499880d1d75f9f02e7e520322e6e8fc", "content": "The GPT-OSS model requires explicit thinking levels instead of boolean values:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate a short headline\",\n OllamaChatOptions.builder()\n .model(\"gpt-oss\")\n .thinkLow()\n .build()\n ));\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Analyze this dataset\",\n OllamaChatOptions.builder()\n .model(\"gpt-oss\")\n .thinkMedium()\n .build()\n ));\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"Solve this complex problem\",\n OllamaChatOptions.builder()\n .model(\"gpt-oss\")\n .thinkHigh()\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Thinking Levels (GPT-OSS Only)", "heading_level": 3, "file_order": 21, "section_index": 10, "content_hash": "8a2615a516c4b8fecf2dd93d70dac1588499880d1d75f9f02e7e520322e6e8fc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:23aec78566abcefc97e731d6c823d16d0049c6465e564fd8f849d46145bb3bd9", "content": "The thinking content is available in the response metadata:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Calculate 17 × 23\",\n OllamaChatOptions.builder()\n .model(\"deepseek-r1\")\n .enableThinking()\n .build()\n ));\n\nString thinking = response.getResult().getMetadata().get(\"thinking\");\nSystem.out.println(\"Reasoning: \" + thinking);\n\nString answer = response.getResult().getOutput().getText();\nSystem.out.println(\"Answer: \" + answer);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Accessing Thinking Content", "heading_level": 3, "file_order": 21, "section_index": 11, "content_hash": "23aec78566abcefc97e731d6c823d16d0049c6465e564fd8f849d46145bb3bd9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:b818276abc8375cc027258e957709beb93e0078d0103bc2db7df5b10908454c3", "content": "Thinking mode works with streaming responses as well:\n\n[source,java]\n----\nFlux<ChatResponse> stream = chatModel.stream(\n new Prompt(\n \"Explain quantum entanglement\",\n OllamaChatOptions.builder()\n .model(\"qwen3\")\n .enableThinking()\n .build()\n ));\n\nstream.subscribe(response -> {\n String thinking = response.getResult().getMetadata().get(\"thinking\");\n String content = response.getResult().getOutput().getText();\n\n if (thinking != null && !thinking.isEmpty()) {\n System.out.println(\"[Thinking] \" + thinking);\n }\n if (content != null && !content.isEmpty()) {\n System.out.println(\"[Response] \" + content);\n }\n});\n----\n\nNOTE: When thinking is disabled or not set, the `thinking` metadata field will be null or empty.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Streaming with Thinking", "heading_level": 3, "file_order": 21, "section_index": 12, "content_hash": "b818276abc8375cc027258e957709beb93e0078d0103bc2db7df5b10908454c3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:099ccf0a1332c2990f7c18182b7cc548533ccfa975335879f4216ba401b56433", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.\n\nSome of the models available in Ollama with multimodality support are https://ollama.com/library/llava[LLaVA] and https://ollama.com/library/bakllava[BakLLaVA] (see the link:https://ollama.com/search?c=vision[full list]).\nFor further details, refer to the link:https://llava-vl.github.io/[LLaVA: Large Language and Vision Assistant].\n\nThe Ollama link:https://github.com/ollama/ollama/blob/main/docs/api.md#parameters-1[Message API] provides an \"images\" parameter to incorporate a list of base64-encoded images with the message.\n\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `org.springframework.core.io.Resource` for the raw media data.\n\nBelow is a straightforward code example excerpted from link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/test/java/org/springframework/ai/ollama/OllamaChatModelMultimodalIT.java[OllamaChatModelMultimodalIT.java], illustrating the fusion of user text with an image.\n\n[source,java]\n----\nvar imageResource = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n new Media(MimeTypeUtils.IMAGE_PNG, this.imageResource));\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage,\n OllamaChatOptions.builder().model(OllamaModel.LLAVA)).build());\n----\n\nThe example shows a model taking as an input the `multimodal.test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generating a response like this:\n\n----\nThe image shows a small metal basket filled with ripe bananas and red apples. The basket is placed on a surface,\nwhich appears to be a table or countertop, as there's a hint of what seems like a kitchen cabinet or drawer in\nthe background. There's also a gold-colored ring visible behind the basket, which could indicate that this\nphoto was taken in an area with metallic decorations or fixtures. The overall setting suggests a home environment\nwhere fruits are being displayed, possibly for convenience or aesthetic purposes.\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 21, "section_index": 13, "content_hash": "099ccf0a1332c2990f7c18182b7cc548533ccfa975335879f4216ba401b56433", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:4fe97ef170e684134c89fef036109e63cba7fef344b0199e90e02069d2ef8cf9", "content": "Ollama provides custom https://ollama.com/blog/structured-outputs[Structured Outputs] APIs that ensure your model generates responses conforming strictly to your provided `JSON Schema`.\nIn addition to the existing Spring AI model-agnostic xref::api/structured-output-converter.adoc[Structured Output Converter], these APIs offer enhanced control and precision.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Structured Outputs", "heading_level": 2, "file_order": 21, "section_index": 14, "content_hash": "4fe97ef170e684134c89fef036109e63cba7fef344b0199e90e02069d2ef8cf9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:fcdd53e5148e516df9ffe061ac0e86e9e1fd08893374207b4edbcb823efae230", "content": "Ollama supports two different modes for structured output through the `format` parameter:\n\n1. **Simple \"json\" Format**: Instructs Ollama to return any valid JSON structure (unpredictable schema)\n2. **JSON Schema Format**: Instructs Ollama to return JSON conforming to a specific schema (predictable structure)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Two Modes for Structured Output", "heading_level": 3, "file_order": 21, "section_index": 15, "content_hash": "fcdd53e5148e516df9ffe061ac0e86e9e1fd08893374207b4edbcb823efae230", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:7a01edc2955adc6dc75454fdc0121041d5c2d900d001cb7ab6c2fc57f1f23df8", "content": "Use this when you want JSON output but don't need a specific structure:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"List 3 countries in Europe\",\n OllamaChatOptions.builder()\n .model(\"llama3.2\")\n .format(\"json\") // Any valid JSON\n .build()\n ));\n----\n\nThe model can return any JSON structure it chooses:\n\n[source,json]\n----\n[\"France\", \"Germany\", \"Italy\"]\n{\"countries\": [\"France\", \"Germany\", \"Italy\"]}\n{\"data\": {\"european_countries\": [\"France\", \"Germany\", \"Italy\"]}}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Simple \"json\" Format", "heading_level": 4, "file_order": 21, "section_index": 16, "content_hash": "7a01edc2955adc6dc75454fdc0121041d5c2d900d001cb7ab6c2fc57f1f23df8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:d6b9b2acd952c67d58f12daf2f29e5cedee4c3b93eba1782d14a88a96293b139", "content": "Use this when you need a guaranteed, predictable structure:\n\n[source,java]\n----\nString jsonSchema = \"\"\"\n{\n \"type\": \"object\",\n \"properties\": {\n \"countries\": {\n \"type\": \"array\",\n \"items\": { \"type\": \"string\" }\n }\n },\n \"required\": [\"countries\"]\n}\n\"\"\";\n\nChatResponse response = chatModel.call(\n new Prompt(\n \"List 3 countries in Europe\",\n OllamaChatOptions.builder()\n .model(\"llama3.2\")\n .outputSchema(jsonSchema) // Enforced schema\n .build()\n ));\n----\n\nThe model **must** return this exact structure:\n\n[source,json]\n----\n{\"countries\": [\"France\", \"Germany\", \"Italy\"]}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "JSON Schema Format (Recommended for Production)", "heading_level": 4, "file_order": 21, "section_index": 17, "content_hash": "d6b9b2acd952c67d58f12daf2f29e5cedee4c3b93eba1782d14a88a96293b139", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:fc0e8a77ab45683b419425b1c0c127cb6f3b40ca88fc09d99fd9619a41700dbf", "content": "Spring AI allows you to configure your response format programmatically using the `OllamaChatOptions` builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Configuration", "heading_level": 3, "file_order": 21, "section_index": 18, "content_hash": "fc0e8a77ab45683b419425b1c0c127cb6f3b40ca88fc09d99fd9619a41700dbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:d5ea239a6c8a773edf0ceb2b4a0262c4c8347885c4074f01a69bc5c35e4be43b", "content": "You can set the response format programmatically with the `OllamaChatOptions` builder:\n\n[source,java]\n----\nString jsonSchema = \"\"\"\n {\n \"type\": \"object\",\n \"properties\": {\n \"steps\": {\n \"type\": \"array\",\n \"items\": {\n \"type\": \"object\",\n \"properties\": {\n \"explanation\": { \"type\": \"string\" },\n \"output\": { \"type\": \"string\" }\n },\n \"required\": [\"explanation\", \"output\"],\n \"additionalProperties\": false\n }\n },\n \"final_answer\": { \"type\": \"string\" }\n },\n \"required\": [\"steps\", \"final_answer\"],\n \"additionalProperties\": false\n }\n \"\"\";\n\nPrompt prompt = new Prompt(\"how can I solve 8x + 7 = -23\",\n OllamaChatOptions.builder()\n .model(OllamaModel.LLAMA3_2.getName())\n .outputSchema(jsonSchema) // Pass JSON Schema as string\n .build());\n\nChatResponse response = this.ollamaChatModel.call(this.prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Using the Chat Options Builder with JSON Schema", "heading_level": 4, "file_order": 21, "section_index": 19, "content_hash": "d5ea239a6c8a773edf0ceb2b4a0262c4c8347885c4074f01a69bc5c35e4be43b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:32443882a33aaa8d8f76cd726799598c374b0591d763fe83141111180104c531", "content": "You can leverage existing xref::api/structured-output-converter.adoc#_bean_output_converter[BeanOutputConverter] utilities to automatically generate the JSON Schema from your domain objects and later convert the structured response into domain-specific instances:\n\n[source,java]\n----\nrecord MathReasoning(\n @JsonProperty(required = true, value = \"steps\") Steps steps,\n @JsonProperty(required = true, value = \"final_answer\") String finalAnswer) {\n\n record Steps(\n @JsonProperty(required = true, value = \"items\") Items[] items) {\n\n record Items(\n @JsonProperty(required = true, value = \"explanation\") String explanation,\n @JsonProperty(required = true, value = \"output\") String output) {\n }\n }\n}\n\nvar outputConverter = new BeanOutputConverter<>(MathReasoning.class);\n\nPrompt prompt = new Prompt(\"how can I solve 8x + 7 = -23\",\n OllamaChatOptions.builder()\n .model(OllamaModel.LLAMA3_2.getName())\n .outputSchema(outputConverter.getJsonSchema()) // Get JSON Schema as string\n .build());\n\nChatResponse response = this.ollamaChatModel.call(this.prompt);\nString content = this.response.getResult().getOutput().getText();\n\nMathReasoning mathReasoning = this.outputConverter.convert(this.content);\n----\n\nNOTE: Ensure you use the `@JsonProperty(required = true,...)` annotation for generating a schema that accurately marks fields as `required`.\nAlthough this is optional for JSON Schema, it's recommended for the structured response to function correctly.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Integrating with BeanOutputConverter Utilities", "heading_level": 4, "file_order": 21, "section_index": 20, "content_hash": "32443882a33aaa8d8f76cd726799598c374b0591d763fe83141111180104c531", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:34ae1f5a59412ebae9c240bb95338c06231188da5726b64fbf7af95cf818e8f2", "content": "Spring AI provides two methods for configuring structured output:\n\n[cols=\"2,3,3\", options=\"header\"]\n|====\n| Method | Use Case | Example\n\n| `.format(\"json\")`\n| Simple JSON mode - any structure\n| `.format(\"json\")`\n\n| `.outputSchema(jsonSchemaString)`\n| JSON Schema mode - enforced structure\n| `.outputSchema(\"{\\\"type\\\":\\\"object\\\",...}\")`\n\n| `.format(mapObject)`\n| JSON Schema mode - alternative API\n| `.format(new ObjectMapper().readValue(schema, Map.class))`\n|====\n\nTIP: For most use cases, use `.outputSchema(jsonSchemaString)` for JSON Schema validation or `.format(\"json\")` for simple JSON output.\nThe `.format(Map)` approach is also supported but requires manual JSON parsing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "API Methods: `.format()` vs `.outputSchema()`", "heading_level": 3, "file_order": 21, "section_index": 21, "content_hash": "34ae1f5a59412ebae9c240bb95338c06231188da5726b64fbf7af95cf818e8f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:ef02c39ab3ba9e0b29cbc66e606f118c2e244fcb530006472613cf66768a2704", "content": "Ollama is OpenAI API-compatible and you can use the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] client to talk to Ollama and use tools.\nFor this, you need to configure the OpenAI base URL to your Ollama instance: `spring.ai.openai.chat.base-url=http://localhost:11434` and select one of the provided Ollama models: `spring.ai.openai.chat.options.model=mistral`.\n\nTIP: When using the OpenAI client with Ollama, you can pass Ollama-specific parameters (like `top_k`, `repeat_penalty`, `num_predict`) using the xref:api/chat/openai-chat.adoc#openai-compatible-servers[`extraBody` option].\nThis allows you to leverage Ollama's full capabilities while using the OpenAI client.\n\nimage::spring-ai-ollama-over-openai.jpg[Ollama OpenAI API compatibility, 800, 600, align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "OpenAI API Compatibility", "heading_level": 2, "file_order": 21, "section_index": 22, "content_hash": "ef02c39ab3ba9e0b29cbc66e606f118c2e244fcb530006472613cf66768a2704", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:61843203851a3aa37abe44ccad856e4d5576bcab9a18daea0317beeba028c0c4", "content": "Ollama's OpenAI-compatible endpoint supports the `reasoning_content` field for thinking-capable models (such as `qwen3:*-thinking`, `deepseek-r1`, `deepseek-v3.1`).\nWhen using the Spring AI OpenAI client with Ollama, the model's reasoning process is automatically captured and made available through the response metadata.\n\nNOTE: This is an alternative to using Ollama's native thinking mode API (documented in <<Thinking Mode (Reasoning)>> above).\nBoth approaches work with Ollama's thinking models, but the OpenAI-compatible endpoint uses the `reasoning_content` field name instead of `thinking`.\n\nHere's an example of accessing reasoning content from Ollama through the OpenAI client:\n\n[source,java]\n----\n@Configuration\nclass OllamaConfig {\n @Bean\n OpenAiChatModel ollamaChatModel() {\n var openAiApi = new OpenAiApi(\"http://localhost:11434\", \"ollama\");\n return new OpenAiChatModel(openAiApi,\n OpenAiChatOptions.builder()\n .model(\"deepseek-r1\") // or qwen3, deepseek-v3.1, etc.\n .build());\n }\n}\n\nChatResponse response = chatModel.call(\n new Prompt(\"How many letter 'r' are in the word 'strawberry'?\"));\n\nString reasoning = response.getResult().getMetadata().get(\"reasoningContent\");\nif (reasoning != null && !reasoning.isEmpty()) {\n System.out.println(\"Model's reasoning process:\");\n System.out.println(reasoning);\n}\n\nString answer = response.getResult().getOutput().getText();\nSystem.out.println(\"Answer: \" + answer);\n----\n\nTIP: Thinking-capable models in Ollama (0.12+) automatically enable thinking mode when accessed through the OpenAI-compatible endpoint.\nThe reasoning content is captured automatically without requiring additional configuration.\n\nCheck the link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/OllamaWithOpenAiChatModelIT.java[OllamaWithOpenAiChatModelIT.java] tests for examples of using Ollama over Spring AI OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Reasoning Content via OpenAI Compatibility", "heading_level": 3, "file_order": 21, "section_index": 23, "content_hash": "61843203851a3aa37abe44ccad856e4d5576bcab9a18daea0317beeba028c0c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:1fb81637b5dd310e0214ea669979bd34d41b7fd508937754a711181198550f36", "content": "Ollama can access, out of the box, all https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face ] Chat Models.\nYou can pull any of these models by name: `ollama pull hf.co/<username>/<model-repository>` or configure the auto-pulling strategy: xref:auto-pulling-models[Auto-pulling Models]:\n\n[source]\n----\nspring.ai.ollama.chat.options.model=hf.co/bartowski/gemma-2-2b-it-GGUF\nspring.ai.ollama.init.pull-model-strategy=always\n----\n\n- `spring.ai.ollama.chat.options.model`: Specifies the https://huggingface.co/models?library=gguf&sort=trending[Hugging Face GGUF model] to use.\n- `spring.ai.ollama.init.pull-model-strategy=always`: (optional) Enables automatic model pulling at startup time.\nFor production, you should pre-download the models to avoid delays: `ollama pull hf.co/bartowski/gemma-2-2b-it-GGUF`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "HuggingFace Models", "heading_level": 2, "file_order": 21, "section_index": 24, "content_hash": "1fb81637b5dd310e0214ea669979bd34d41b7fd508937754a711181198550f36", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:2c10d1fcce051465a9754c94c07ddf5316e129a93cc65474fc68eb4f07ef84d2", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-ollama` to your pom (or gradle) dependencies.\n\nAdd a `application.yaml` file, under the `src/main/resources` directory, to enable and configure the Ollama chat model:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n base-url: http://localhost:11434\n chat:\n options:\n model: mistral\n temperature: 0.7\n----\n\nTIP: Replace the `base-url` with your Ollama server URL.\n\nThis will create an `OllamaChatModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OllamaChatModel chatModel;\n\n @Autowired\n public ChatController(OllamaChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map<String,String> generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 21, "section_index": 25, "content_hash": "2c10d1fcce051465a9754c94c07ddf5316e129a93cc65474fc68eb4f07ef84d2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:14a858b0843994e777a96dd29f7e8f79a6f062f12954b841c6fee6d19dcf11c1", "content": "If you don't want to use the Spring Boot auto-configuration, you can manually configure the `OllamaChatModel` in your application.\nThe https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/main/java/org/springframework/ai/ollama/OllamaChatModel.java[OllamaChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the Ollama service.\n\nTo use it, add the `spring-ai-ollama` dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-ollama</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-ollama'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: The `spring-ai-ollama` dependency provides access also to the `OllamaEmbeddingModel`.\nFor more information about the `OllamaEmbeddingModel` refer to the link:../embeddings/ollama-embeddings.html[Ollama Embedding Model] section.\n\nNext, create an `OllamaChatModel` instance and use it to send requests for text generation:\n\n[source,java]\n----\nvar ollamaApi = OllamaApi.builder().build();\n\nvar chatModel = OllamaChatModel.builder()\n .ollamaApi(ollamaApi)\n .defaultOptions(\n OllamaChatOptions.builder()\n .model(OllamaModel.MISTRAL)\n .temperature(0.9)\n .build())\n .build();\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `OllamaChatOptions` provides the configuration information for all chat requests.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 21, "section_index": 26, "content_hash": "14a858b0843994e777a96dd29f7e8f79a6f062f12954b841c6fee6d19dcf11c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:1381f690b8dd5b594be4276a2f2cf1d3c8b1823bf87fd744e259f26dd045e180", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/main/java/org/springframework/ai/ollama/api/OllamaApi.java[OllamaApi] provides a lightweight Java client for the Ollama Chat Completion API link:https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion[Ollama Chat Completion API].\n\nThe following class diagram illustrates the `OllamaApi` chat interfaces and building blocks:\n\nimage::ollama-chat-completion-api.jpg[OllamaApi Chat Completion API Diagram, 800, 600]\n\nNOTE: The `OllamaApi` is a low-level API and is not recommended for direct use. Use the `OllamaChatModel` instead.\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nOllamaApi ollamaApi = new OllamaApi(\"YOUR_HOST:YOUR_PORT\");\n\nvar request = ChatRequest.builder(\"orca-mini\")\n .stream(false) // not streaming\n .messages(List.of(\n Message.builder(Role.SYSTEM)\n .content(\"You are a geography teacher. You are talking to a student.\")\n .build(),\n Message.builder(Role.USER)\n .content(\"What is the capital of Bulgaria and what is the size? \"\n + \"What is the national anthem?\")\n .build()))\n .options(OllamaChatOptions.builder().temperature(0.9).build())\n .build();\n\nChatResponse response = this.ollamaApi.chat(this.request);\n\nvar request2 = ChatRequest.builder(\"orca-mini\")\n .ttream(true) // streaming\n .messages(List.of(Message.builder(Role.USER)\n .content(\"What is the capital of Bulgaria and what is the size? \" + \"What is the national anthem?\")\n .build()))\n .options(OllamaChatOptions.builder().temperature(0.9).build().toMap())\n .build();\n\nFlux<ChatResponse> streamingResponse = this.ollamaApi.streamingChat(this.request2);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/ollama-chat.adoc", "title": "Ollama Chat", "heading": "Low-level OllamaApi Client [[low-level-api]]", "heading_level": 2, "file_order": 21, "section_index": 27, "content_hash": "1381f690b8dd5b594be4276a2f2cf1d3c8b1823bf87fd744e259f26dd045e180", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/ollama-chat.adoc"}}
{"id": "sha256:66f34a6be27f2e19280acf8562b1b5de6a68dc46709885d6cafc21c5faeee2fd", "content": "Spring AI supports the various AI language models from OpenAI, the company behind ChatGPT, which has been instrumental in sparking interest in AI-driven text generation thanks to its creation of industry-leading text generation models and embeddings.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "OpenAI Chat", "heading_level": 1, "file_order": 22, "section_index": 0, "content_hash": "66f34a6be27f2e19280acf8562b1b5de6a68dc46709885d6cafc21c5faeee2fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:a904dcdacb05eff9c27f30ff770b8b55f9b26123b427b108ca35a7696de772e6", "content": "You will need to create an API with OpenAI to access ChatGPT models.\n\nCreate an account at https://platform.openai.com/signup[OpenAI signup page] and generate the token on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from openai.com.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<your-openai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${OPENAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport OPENAI_API_KEY=<your-openai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"OPENAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 22, "section_index": 1, "content_hash": "a904dcdacb05eff9c27f30ff770b8b55f9b26123b427b108ca35a7696de772e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:5ab37123049ad8742c793f19b7e7a76d5867038a25c1b2e2317e886f4faa5e89", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 22, "section_index": 2, "content_hash": "5ab37123049ad8742c793f19b7e7a76d5867038a25c1b2e2317e886f4faa5e89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:2137fbefcfdce9f10b94640e468641df0bf2b92df093a8c6343f20aed5424322", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 22, "section_index": 3, "content_hash": "2137fbefcfdce9f10b94640e468641df0bf2b92df093a8c6343f20aed5424322", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:ba3b663dbf560a39bdcb7abbd8b3cd3e7650eccd4248a998f4f6491f8812315f", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 22, "section_index": 4, "content_hash": "ba3b663dbf560a39bdcb7abbd8b3cd3e7650eccd4248a998f4f6491f8812315f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:9258a5e17d87faeaa051c8167052b325227bf4ad621ed0827654a867f7f54520", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally, you can specify which organization to use for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project to use for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), you can optionally specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 22, "section_index": 5, "content_hash": "9258a5e17d87faeaa051c8167052b325227bf4ad621ed0827654a867f7f54520", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:7dc57fd8fbf9fc5d05e1c8fedec4dbe5fb444655979ac0e06d28d80db79bb2f0", "content": "Spring AI automatically sends a `User-Agent: spring-ai` header with all requests to OpenAI.\nThis helps OpenAI identify requests originating from Spring AI for analytics and support purposes.\nThis header is sent automatically and requires no configuration from Spring AI users.\n\nIf you are an API provider building an OpenAI-compatible service, you can track Spring AI usage by reading the `User-Agent` HTTP header from incoming requests on your server.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "User-Agent Header", "heading_level": 4, "file_order": 22, "section_index": 6, "content_hash": "7dc57fd8fbf9fc5d05e1c8fedec4dbe5fb444655979ac0e06d28d80db79bb2f0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:778fc2a54e909a2863eeeaf61356e1222b6c3ddf3d5bd9e9867de97019751966", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=openai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.chat` is the property prefix that lets you configure the chat model implementation for OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.chat.enabled (Removed and no longer valid) | Enable OpenAI chat model. | true\n| spring.ai.model.chat | Enable OpenAI chat model. | openai\n| spring.ai.openai.chat.base-url | Optional override for the `spring.ai.openai.base-url` property to provide a chat-specific URL. | -\n| spring.ai.openai.chat.completions-path | The path to append to the base URL. | `/v1/chat/completions`\n| spring.ai.openai.chat.api-key | Optional override for the `spring.ai.openai.api-key` to provide a chat-specific API Key. | -\n| spring.ai.openai.chat.organization-id | Optionally, you can specify which organization to use for an API request. | -\n| spring.ai.openai.chat.project-id | Optionally, you can specify which project to use for an API request. | -\n| spring.ai.openai.chat.options.model | Name of the OpenAI chat model to use. You can select between models such as: `gpt-5-mini`, `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-3.5-turbo`, and more. See the https://platform.openai.com/docs/models[models] page for more information. | `gpt-5-mini`\n| spring.ai.openai.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify `temperature` and `top_p` for the same completions request as the interaction of these two settings is difficult to predict. | 0.8\n| spring.ai.openai.chat.options.frequencyPenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0f\n| spring.ai.openai.chat.options.logitBias | Modify the likelihood of specified tokens appearing in the completion. | -\n| spring.ai.openai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. *Use for non-reasoning models* (e.g., gpt-4o, gpt-3.5-turbo). *Cannot be used with reasoning models* (e.g., o1, o3, o4-mini series). *Mutually exclusive with maxCompletionTokens* - setting both will result in an API error. | -\n| spring.ai.openai.chat.options.maxCompletionTokens | An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens. *Required for reasoning models* (e.g., o1, o3, o4-mini series). *Cannot be used with non-reasoning models* (e.g., gpt-4o, gpt-3.5-turbo). *Mutually exclusive with maxTokens* - setting both will result in an API error. | -\n| spring.ai.openai.chat.options.n | How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as 1 to minimize costs. | 1\n| spring.ai.openai.chat.options.store | Whether to store the output of this chat completion request for use in our model | false\n| spring.ai.openai.chat.options.metadata | Developer-defined tags and values used for filtering completions in the chat completion dashboard | empty map\n| spring.ai.openai.chat.options.output-modalities | Output types that you would like the model to generate for this request. Most models are capable of generating text, which is the default.\nThe `gpt-4o-audio-preview` model can also be used to generate audio. To request that this model generate both text and audio responses,\nyou can use: `text`, `audio`. Not supported for streaming. | -\n| spring.ai.openai.chat.options.output-audio | Audio parameters for the audio generation. Required when audio output is requested with `output-modalities`: `audio`.\nRequires the `gpt-4o-audio-preview` model and is is not supported for streaming completions. | -\n| spring.ai.openai.chat.options.presencePenalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. | -\n| spring.ai.openai.chat.options.responseFormat.type | Compatible with `GPT-4o`, `GPT-4o mini`, `GPT-4 Turbo` and all `GPT-3.5 Turbo` models newer than `gpt-3.5-turbo-1106`. The `JSON_OBJECT` type enables JSON mode, which guarantees the message the model generates is valid JSON.\nThe `JSON_SCHEMA` type enables link:https://platform.openai.com/docs/guides/structured-outputs[Structured Outputs] which guarantees the model will match your supplied JSON schema. The JSON_SCHEMA type requires setting the `responseFormat.schema` property as well. | -\n| spring.ai.openai.chat.options.responseFormat.name | Response format schema name. Applicable only for `responseFormat.type=JSON_SCHEMA` | custom_schema\n| spring.ai.openai.chat.options.responseFormat.schema | Response format JSON schema. Applicable only for `responseFormat.type=JSON_SCHEMA` | -\n| spring.ai.openai.chat.options.responseFormat.strict | Response format JSON schema adherence strictness. Applicable only for `responseFormat.type=JSON_SCHEMA` | -\n| spring.ai.openai.chat.options.seed | This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. | -\n| spring.ai.openai.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.openai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both. | -\n| spring.ai.openai.chat.options.tools | A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. | -\n| spring.ai.openai.chat.options.toolChoice | Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{\"type: \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that function. `none` is the default when no functions are present. `auto` is the default if functions are present. | -\n| spring.ai.openai.chat.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n| spring.ai.openai.chat.options.parallel-tool-calls | Whether to enable link:https://platform.openai.com/docs/guides/function-calling/parallel-function-calling[parallel function calling] during tool use. | true\n| spring.ai.openai.chat.options.prompt-cache-key | A cache key used by OpenAI to optimize cache hit rates for similar requests. Improves latency and reduces costs. Replaces the deprecated `user` field for caching purposes. link:https://platform.openai.com/docs/guides/prompt-caching[Learn more]. | -\n| spring.ai.openai.chat.options.safety-identifier | A stable identifier to help OpenAI detect users violating usage policies. Should be a hashed value (e.g., hashed username or email). Replaces the deprecated `user` field for safety tracking. link:https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers[Learn more]. | -\n| spring.ai.openai.chat.options.http-headers | Optional HTTP headers to be added to the chat completion request. To override the `api-key` you need to use an `Authorization` header key, and you have to prefix the key value with the `Bearer` prefix. | -\n| spring.ai.openai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.openai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.openai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n| spring.ai.openai.chat.options.service-tier | Specifies the link:https://platform.openai.com/docs/api-reference/responses/create#responses_create-service_tier[processing type] used for serving the request. | -\n| spring.ai.openai.chat.options.extra-body | Additional parameters to include in the request. Accepts any key-value pairs that are flattened to the top level of the JSON request. Intended for use with OpenAI-compatible servers (vLLM, Ollama, etc.) that support parameters beyond the standard OpenAI API. The official OpenAI API ignores unknown parameters. See <<openai-compatible-servers>> for details. | -\n|====\n\n[NOTE]\n====\nWhen using GPT-5 models such as `gpt-5`, `gpt-5-mini`, and `gpt-5-nano`, the `temperature` parameter is not supported.\nThese models are optimized for reasoning and do not use temperature.\nSpecifying a temperature value will result in an error.\nIn contrast, conversational models like `gpt-5-chat` do support the `temperature` parameter.\n====\n\nNOTE: You can override the common `spring.ai.openai.base-url` and `spring.ai.openai.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.openai.chat.base-url` and `spring.ai.openai.chat.api-key` properties, if set, take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.chat.options` can be overridden at runtime by adding request-specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 22, "section_index": 7, "content_hash": "778fc2a54e909a2863eeeaf61356e1222b6c3ddf3d5bd9e9867de97019751966", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:9a933a994bf62b9dd7b544cc1748889f41651c33ee5010c9271bf3fb4dda85aa", "content": "OpenAI provides two mutually exclusive parameters for controlling token generation limits:\n\n[cols=\"2,3,3\", stripes=even]\n|====\n| Parameter | Use Case | Compatible Models\n\n| `maxTokens` | Non-reasoning models | gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo\n| `maxCompletionTokens` | Reasoning models | o1, o1-mini, o1-preview, o3, o4-mini series\n|====\n\nIMPORTANT: These parameters are **mutually exclusive**. Setting both will result in an API error from OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Token Limit Parameters: Model-Specific Usage", "heading_level": 3, "file_order": 22, "section_index": 8, "content_hash": "9a933a994bf62b9dd7b544cc1748889f41651c33ee5010c9271bf3fb4dda85aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:be7f080ebd488d10f1e88361508fbdae49ddbbcf1e8a656e33ea582d1e778529", "content": "**For non-reasoning models (gpt-4o, gpt-3.5-turbo):**\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Explain quantum computing in simple terms.\",\n OpenAiChatOptions.builder()\n .model(\"gpt-4o\")\n .maxTokens(150) // Use maxTokens for non-reasoning models\n .build()\n ));\n----\n\n**For reasoning models (o1, o3 series):**\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Solve this complex math problem step by step: ...\",\n OpenAiChatOptions.builder()\n .model(\"o1-preview\")\n .maxCompletionTokens(1000) // Use maxCompletionTokens for reasoning models\n .build()\n ));\n----\n\n**Builder Pattern Validation:**\nThe OpenAI ChatOptions builder automatically enforces mutual exclusivity with a \"last-set-wins\" approach:\n\n[source,java]\n----\nOpenAiChatOptions options = OpenAiChatOptions.builder()\n .maxTokens(100) // Set first\n .maxCompletionTokens(200) // This clears maxTokens and logs a warning\n .build();\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Usage Examples", "heading_level": 4, "file_order": 22, "section_index": 9, "content_hash": "be7f080ebd488d10f1e88361508fbdae49ddbbcf1e8a656e33ea582d1e778529", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:642d20b1fff487f3586fabb4171837245d1d22d3abacbb3e7b974b7fba293969", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions.java] class provides model configurations such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiChatModel(api, options)` constructor or the `spring.ai.openai.chat.options.*` properties.\n\nAt run-time, you can override the default options by adding new, request-specific options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiChatOptions.builder()\n .model(\"gpt-4o\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 22, "section_index": 10, "content_hash": "642d20b1fff487f3586fabb4171837245d1d22d3abacbb3e7b974b7fba293969", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:fd8597c24df3625df03a2c62d728e1cc2c833106e8f34e87b9e1b22a46a261f0", "content": "You can register custom Java functions with the `OpenAiChatModel` and have the OpenAI model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 22, "section_index": 11, "content_hash": "fd8597c24df3625df03a2c62d728e1cc2c833106e8f34e87b9e1b22a46a261f0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:5a6b11bf9577b4ffe18e99b18f9f7773b90872feaa09e112921921c630f33040", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.\nOpenAI supports text, vision, and audio input modalities.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 22, "section_index": 12, "content_hash": "5a6b11bf9577b4ffe18e99b18f9f7773b90872feaa09e112921921c630f33040", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:11cd7ec818bcfec90a11023c0bcad0ebe48e10cca8304f6628c9c86266212525", "content": "OpenAI models that offer vision multimodal support include `gpt-4`, `gpt-4o`, and `gpt-4o-mini`.\nRefer to the link:https://platform.openai.com/docs/guides/vision[Vision] guide for more information.\n\nThe OpenAI link:https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages[User Message API] can incorporate a list of base64-encoded images or image urls with the message.\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `org.springframework.core.io.Resource` for the raw media data.\n\nBelow is a code example excerpted from link:https://github.com/spring-projects/spring-ai/blob/c9a3e66f90187ce7eae7eb78c462ec622685de6c/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/OpenAiChatModelIT.java#L293[OpenAiChatModelIT.java], illustrating the fusion of user text with an image using the `gpt-4o` model.\n\n[source,java]\n----\nvar imageResource = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n new Media(MimeTypeUtils.IMAGE_PNG, this.imageResource));\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage,\n OpenAiChatOptions.builder().model(OpenAiApi.ChatModel.GPT_4_O.getValue()).build()));\n----\n\nTIP: GPT_4_VISION_PREVIEW will continue to be available only to existing users of this model starting June 17, 2024. If you are not an existing user, please use the GPT_4_O or GPT_4_TURBO models. More details https://platform.openai.com/docs/deprecations/2024-06-06-gpt-4-32k-and-vision-preview-models[here]\n\nor the image URL equivalent using the `gpt-4o` model:\n\n[source,java]\n----\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n new Media(MimeTypeUtils.IMAGE_PNG,\n URI.create(\"https://docs.spring.io/spring-ai/reference/_images/multimodal.test.png\")));\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage,\n OpenAiChatOptions.builder().model(OpenAiApi.ChatModel.GPT_4_O.getValue()).build()));\n----\n\nTIP: You can pass multiple images as well.\n\nThe example shows a model taking as an input the `multimodal.test.png` image:\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nalong with the text message \"Explain what do you see on this picture?\", and generating a response like this:\n\n----\nThis is an image of a fruit bowl with a simple design. The bowl is made of metal with curved wire edges that\ncreate an open structure, allowing the fruit to be visible from all angles. Inside the bowl, there are two\nyellow bananas resting on top of what appears to be a red apple. The bananas are slightly overripe, as\nindicated by the brown spots on their peels. The bowl has a metal ring at the top, likely to serve as a handle\nfor carrying. The bowl is placed on a flat surface with a neutral-colored background that provides a clear\nview of the fruit inside.\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Vision", "heading_level": 3, "file_order": 22, "section_index": 13, "content_hash": "11cd7ec818bcfec90a11023c0bcad0ebe48e10cca8304f6628c9c86266212525", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:a3645bae9fe69ea35d9434a1def75f2f07668ce752c0682c087921e1640e1809", "content": "OpenAI models that offer input audio multimodal support include `gpt-4o-audio-preview`.\nRefer to the link:https://platform.openai.com/docs/guides/audio[Audio] guide for more information.\n\nThe OpenAI link:https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages[User Message API] can incorporate a list of base64-encoded audio files with the message.\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `org.springframework.core.io.Resource` for the raw media data.\nCurrently, OpenAI support only the following media types: `audio/mp3` and `audio/wav`.\n\nBelow is a code example excerpted from link:https://github.com/spring-projects/spring-ai/blob/c9a3e66f90187ce7eae7eb78c462ec622685de6c/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/OpenAiChatModelIT.java#L442[OpenAiChatModelIT.java], illustrating the fusion of user text with an audio file using the `gpt-4o-audio-preview` model.\n\n[source,java]\n----\nvar audioResource = new ClassPathResource(\"speech1.mp3\");\n\nvar userMessage = new UserMessage(\"What is this recording about?\",\n List.of(new Media(MimeTypeUtils.parseMimeType(\"audio/mp3\"), audioResource)));\n\nChatResponse response = chatModel.call(new Prompt(List.of(userMessage),\n OpenAiChatOptions.builder().model(OpenAiApi.ChatModel.GPT_4_O_AUDIO_PREVIEW).build()));\n----\n\nTIP: You can pass multiple audio files as well.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Audio", "heading_level": 3, "file_order": 22, "section_index": 14, "content_hash": "a3645bae9fe69ea35d9434a1def75f2f07668ce752c0682c087921e1640e1809", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:d845b99a0a20a9f75b5fcc3fadbc1de1b2a9a602a1ec7dca0abba9d5cfbb8e43", "content": "OpenAI models that offer input audio multimodal support include `gpt-4o-audio-preview`.\nRefer to the link:https://platform.openai.com/docs/guides/audio[Audio] guide for more information.\n\nThe OpenAI link:https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages[Assistant Message API] can contain a list of base64-encoded audio files with the message.\nSpring AI’s link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\nThis type encompasses data and details regarding media attachments in messages, utilizing Spring’s `org.springframework.util.MimeType` and a `org.springframework.core.io.Resource` for the raw media data.\nCurrently, OpenAI support only the following audio types: `audio/mp3` and `audio/wav`.\n\nBelow is a code example, illustrating the response of user text along with an audio byte array, using the `gpt-4o-audio-preview` model:\n\n[source,java]\n----\nvar userMessage = new UserMessage(\"Tell me joke about Spring Framework\");\n\nChatResponse response = chatModel.call(new Prompt(List.of(userMessage),\n OpenAiChatOptions.builder()\n .model(OpenAiApi.ChatModel.GPT_4_O_AUDIO_PREVIEW)\n .outputModalities(List.of(\"text\", \"audio\"))\n .outputAudio(new AudioParameters(Voice.ALLOY, AudioResponseFormat.WAV))\n .build()));\n\nString text = response.getResult().getOutput().getText(); // audio transcript\n\nbyte[] waveAudio = response.getResult().getOutput().getMedia().get(0).getDataAsByteArray(); // audio data\n----\n\nYou have to specify an `audio` modality in the `OpenAiChatOptions` to generate audio output.\nThe `AudioParameters` class provides the voice and audio format for the audio output.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Output Audio", "heading_level": 3, "file_order": 22, "section_index": 15, "content_hash": "d845b99a0a20a9f75b5fcc3fadbc1de1b2a9a602a1ec7dca0abba9d5cfbb8e43", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:a83c9c0a50c6fbf40e29effd15d74e67a75544f7d8ad9814f5cd1c3ba2fd48af", "content": "OpenAI provides custom https://platform.openai.com/docs/guides/structured-outputs[Structured Outputs] APIs that ensure your model generates responses conforming strictly to your provided `JSON Schema`.\nIn addition to the existing Spring AI model-agnostic xref::api/structured-output-converter.adoc[Structured Output Converter], these APIs offer enhanced control and precision.\n\nNOTE: Currently, OpenAI supports a link:https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[subset of the JSON Schema language] format.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Structured Outputs", "heading_level": 2, "file_order": 22, "section_index": 16, "content_hash": "a83c9c0a50c6fbf40e29effd15d74e67a75544f7d8ad9814f5cd1c3ba2fd48af", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:2c3039fc1aacc2d8285cbd6842122d64ac6d26c575f48e1252c24e5a1ee38e95", "content": "Spring AI allows you to configure your response format either programmatically using the `OpenAiChatOptions` builder or through application properties.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Configuration", "heading_level": 3, "file_order": 22, "section_index": 17, "content_hash": "2c3039fc1aacc2d8285cbd6842122d64ac6d26c575f48e1252c24e5a1ee38e95", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:8218b020cf6b28b5f2c1c2efdf9674eb6dae833196e819239ca0984e035a2c95", "content": "You can set the response format programmatically with the `OpenAiChatOptions` builder as shown below:\n\n[source,java]\n----\nString jsonSchema = \"\"\"\n {\n \"type\": \"object\",\n \"properties\": {\n \"steps\": {\n \"type\": \"array\",\n \"items\": {\n \"type\": \"object\",\n \"properties\": {\n \"explanation\": { \"type\": \"string\" },\n \"output\": { \"type\": \"string\" }\n },\n \"required\": [\"explanation\", \"output\"],\n \"additionalProperties\": false\n }\n },\n \"final_answer\": { \"type\": \"string\" }\n },\n \"required\": [\"steps\", \"final_answer\"],\n \"additionalProperties\": false\n }\n \"\"\";\n\nPrompt prompt = new Prompt(\"how can I solve 8x + 7 = -23\",\n OpenAiChatOptions.builder()\n .model(ChatModel.GPT_4_O_MINI)\n .responseFormat(new ResponseFormat(ResponseFormat.Type.JSON_SCHEMA, this.jsonSchema))\n .build());\n\nChatResponse response = this.openAiChatModel.call(this.prompt);\n----\n\nNOTE: Adhere to the OpenAI link:https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[subset of the JSON Schema language] format.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Using the Chat Options Builder", "heading_level": 4, "file_order": 22, "section_index": 18, "content_hash": "8218b020cf6b28b5f2c1c2efdf9674eb6dae833196e819239ca0984e035a2c95", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:7c1612a77652645fa18952738c302f895265fd809a2903e498b502e5ca94f0d8", "content": "You can leverage existing xref::api/structured-output-converter.adoc#_bean_output_converter[BeanOutputConverter] utilities to automatically generate the JSON Schema from your domain objects and later convert the structured response into domain-specific instances:\n\n--\n[tabs]\n======\nJava::\n+\n[source,java]\n----\nrecord MathReasoning(\n @JsonProperty(required = true, value = \"steps\") Steps steps,\n @JsonProperty(required = true, value = \"final_answer\") String finalAnswer) {\n\n record Steps(\n @JsonProperty(required = true, value = \"items\") Items[] items) {\n\n record Items(\n @JsonProperty(required = true, value = \"explanation\") String explanation,\n @JsonProperty(required = true, value = \"output\") String output) {\n }\n }\n}\n\nvar outputConverter = new BeanOutputConverter<>(MathReasoning.class);\n\nvar jsonSchema = this.outputConverter.getJsonSchema();\n\nPrompt prompt = new Prompt(\"how can I solve 8x + 7 = -23\",\n OpenAiChatOptions.builder()\n .model(ChatModel.GPT_4_O_MINI)\n .responseFormat(new ResponseFormat(ResponseFormat.Type.JSON_SCHEMA, this.jsonSchema))\n .build());\n\nChatResponse response = this.openAiChatModel.call(this.prompt);\nString content = this.response.getResult().getOutput().getText();\n\nMathReasoning mathReasoning = this.outputConverter.convert(this.content);\n----\nKotlin::\n+\n[source,kotlin]\n----\ndata class MathReasoning(\n\tval steps: Steps,\n\t@get:JsonProperty(value = \"final_answer\") val finalAnswer: String) {\n\n\tdata class Steps(val items: Array<Items>) {\n\n data class Items(\n val explanation: String,\n val output: String)\n\t}\n}\n\nval outputConverter = BeanOutputConverter(MathReasoning::class.java)\n\nval jsonSchema = outputConverter.jsonSchema;\n\nval prompt = Prompt(\"how can I solve 8x + 7 = -23\",\n\tOpenAiChatOptions.builder()\n .model(ChatModel.GPT_4_O_MINI)\n .responseFormat(ResponseFormat(ResponseFormat.Type.JSON_SCHEMA, jsonSchema))\n .build())\n\nval response = openAiChatModel.call(prompt)\nval content = response.getResult().getOutput().getText()\n\nval mathReasoning = outputConverter.convert(content)\n----\n======\n--\n\nNOTE: Although this is optional for JSON Schema, OpenAI link:https://platform.openai.com/docs/guides/structured-outputs/all-fields-must-be-required#all-fields-must-be-required[mandates] required fields for the structured response to function correctly. Kotlin reflection is used to infer which property are required or not based on the nullability of types and default values of parameters, so for most use case `@get:JsonProperty(required = true)` is not needed. `@get:JsonProperty(value = \"custom_name\")` can be useful to customize the property name. Make sure to generate the annotation on the related getters with this `@get:` syntax, see link:https://kotlinlang.org/docs/annotations.html#annotation-use-site-targets[related documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Integrating with BeanOutputConverter Utilities", "heading_level": 4, "file_order": 22, "section_index": 19, "content_hash": "7c1612a77652645fa18952738c302f895265fd809a2903e498b502e5ca94f0d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:3e25fe18a96df921e402a8570724fe98120ee7250853ef79b52b418363f6b73e", "content": "Alternatively, when using the OpenAI auto-configuration, you can configure the desired response format through the following application properties:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=YOUR_API_KEY\nspring.ai.openai.chat.options.model=gpt-4o-mini\n\nspring.ai.openai.chat.options.response-format.type=JSON_SCHEMA\nspring.ai.openai.chat.options.response-format.name=MySchemaName\nspring.ai.openai.chat.options.response-format.schema={\"type\":\"object\",\"properties\":{\"steps\":{\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"explanation\":{\"type\":\"string\"},\"output\":{\"type\":\"string\"}},\"required\":[\"explanation\",\"output\"],\"additionalProperties\":false}},\"final_answer\":{\"type\":\"string\"}},\"required\":[\"steps\",\"final_answer\"],\"additionalProperties\":false}\nspring.ai.openai.chat.options.response-format.strict=true\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Configuring via Application Properties", "heading_level": 4, "file_order": 22, "section_index": 20, "content_hash": "3e25fe18a96df921e402a8570724fe98120ee7250853ef79b52b418363f6b73e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:6f1d7ea03a39826b9c683f74fcee50e2e2e5f427af74d9832cae72aec40901c4", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-openai` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file under the `src/main/resources` directory to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=YOUR_API_KEY\nspring.ai.openai.chat.options.model=gpt-4o\nspring.ai.openai.chat.options.temperature=0.7\n----\n\nTIP: Replace the `api-key` with your OpenAI credentials.\n\nThis will create an `OpenAiChatModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map<String,String> generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 22, "section_index": 21, "content_hash": "6f1d7ea03a39826b9c683f74fcee50e2e2e5f427af74d9832cae72aec40901c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:80ea8651c6e4ed0579fcc318882ebbf65ebbbc051db7232f2b8bf67a30dd57c1", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatModel.java[OpenAiChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the OpenAI service.\n\nAdd the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `OpenAiChatModel` and use it for text generations:\n\n[source,java]\n----\nvar openAiApi = OpenAiApi.builder()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\nvar openAiChatOptions = OpenAiChatOptions.builder()\n .model(\"gpt-3.5-turbo\")\n .temperature(0.4)\n .maxTokens(200)\n .build();\nvar chatModel = new OpenAiChatModel(this.openAiApi, this.openAiChatOptions);\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `OpenAiChatOptions` provides the configuration information for the chat requests.\nThe `OpenAiApi.Builder` and `OpenAiChatOptions.Builder` are fluent options-builders for API client and chat config respectively.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 22, "section_index": 22, "content_hash": "80ea8651c6e4ed0579fcc318882ebbf65ebbbc051db7232f2b8bf67a30dd57c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:b8eb100d1d1738e4ae059959e170277fe72273429319dd286dd8f23bc940818d", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/api/OpenAiApi.java[OpenAiApi] provides is lightweight Java client for OpenAI Chat API link:https://platform.openai.com/docs/api-reference/chat[OpenAI Chat API].\n\nFollowing class diagram illustrates the `OpenAiApi` chat interfaces and building blocks:\n\nimage::openai-chat-api.jpg[OpenAiApi Chat API Diagram, width=1000, align=\"center\"]\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nOpenAiApi openAiApi = OpenAiApi.builder()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nChatCompletionMessage chatCompletionMessage =\n new ChatCompletionMessage(\"Hello world\", Role.USER);\n\nResponseEntity<ChatCompletion> response = this.openAiApi.chatCompletionEntity(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), \"gpt-3.5-turbo\", 0.8, false));\n\nFlux<ChatCompletionChunk> streamResponse = this.openAiApi.chatCompletionStream(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), \"gpt-3.5-turbo\", 0.8, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/api/OpenAiApi.java[OpenAiApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Low-level OpenAiApi Client [[low-level-api]]", "heading_level": 2, "file_order": 22, "section_index": 23, "content_hash": "b8eb100d1d1738e4ae059959e170277fe72273429319dd286dd8f23bc940818d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:f62bf41c921e71cba248999320d2792a32ffb893311791e57db89c3164e13233", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/api/OpenAiApiIT.java[OpenAiApiIT.java] tests provide some general examples of how to use the lightweight library.\n\n* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/api/tool/OpenAiApiToolFunctionCallIT.java[OpenAiApiToolFunctionCallIT.java] tests show how to use the low-level API to call tool functions.\nBased on the link:https://platform.openai.com/docs/guides/function-calling/parallel-function-calling[OpenAI Function Calling] tutorial.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Low-level API Examples", "heading_level": 3, "file_order": 22, "section_index": 24, "content_hash": "f62bf41c921e71cba248999320d2792a32ffb893311791e57db89c3164e13233", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:b2f921b188f41b33c9cedc307eddba0c85d409fb2f26e4c85e9b6929484fdba5", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/api/OpenAiFileApi.java[OpenAiFileApi] provides a lightweight Java client for the OpenAI Files API, enabling file management operations such as uploading, listing, retrieving, deleting files, and accessing file contents. link:https://platform.openai.com/docs/api-reference/files[OpenAI File API]\n\nHere is a simple snippet showing how to use the API programmatically:\n\n[source,java]\n----\nOpenAiFileApi openAiFileApi = OpenAiFileApi.builder()\n .apiKey(new SimpleApiKey(System.getenv(\"OPENAI_API_KEY\")))\n .build();\n\nbyte[] fileBytes = Files.readAllBytes(Paths.get(\"evals.jsonl\"));\nOpenAiFileApi.UploadFileRequest uploadRequest = OpenAiFileApi.UploadFileRequest.builder()\n .file(fileBytes)\n .fileName(\"evals-data.jsonl\")\n .purpose(OpenAiFileApi.Purpose.EVALS)\n .build();\nResponseEntity<OpenAiFileApi.FileObject> uploadResponse = openAiFileApi.uploadFile(uploadRequest);\n\nOpenAiFileApi.ListFileRequest listRequest = OpenAiFileApi.ListFileRequest.builder()\n .purpose(OpenAiFileApi.Purpose.EVALS)\n .build();\nResponseEntity<OpenAiFileApi.FileObjectResponse> listResponse = openAiFileApi.listFiles(listRequest);\n\nResponseEntity<OpenAiFileApi.FileObject> fileInfo = openAiFileApi.retrieveFile(\"file-id\");\n\nResponseEntity<OpenAiFileApi.DeleteFileResponse> deleteResponse = openAiFileApi.deleteFile(\"file-id\");\n\nResponseEntity<String> fileContent = openAiFileApi.retrieveFileContent(\"file-id\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Low-level OpenAiFileApi Client [[low-level-file-api]]", "heading_level": 2, "file_order": 22, "section_index": 25, "content_hash": "b2f921b188f41b33c9cedc307eddba0c85d409fb2f26e4c85e9b6929484fdba5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:1f328b28c67ad6563f3db841554742a1d608d0ad613917c3928a72e4e9bfb0e2", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/api/OpenAiFileApiIT.java[OpenAiFileApiIT.java] tests provide some general examples of how to use the lightweight file api library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Low-level File API Examples", "heading_level": 3, "file_order": 22, "section_index": 26, "content_hash": "1f328b28c67ad6563f3db841554742a1d608d0ad613917c3928a72e4e9bfb0e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:db92d32a476c4100030ee0d529ae286e2e8c647732aab4fee7db0486fca47b53", "content": "Spring AI provides flexible API key management through the `ApiKey` interface and its implementations. The default implementation, `SimpleApiKey`, is suitable for most use cases, but you can also create custom implementations for more complex scenarios.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "API Key Management", "heading_level": 2, "file_order": 22, "section_index": 27, "content_hash": "db92d32a476c4100030ee0d529ae286e2e8c647732aab4fee7db0486fca47b53", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:39ec0875fba088a05d9e658a88239d34eece79c0542bfe0daccc5c7b46e8018b", "content": "By default, Spring Boot auto-configuration will create an API key bean using the `spring.ai.openai.api-key` property:\n\n[source,properties]\n----\nspring.ai.openai.api-key=your-api-key-here\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Default Configuration", "heading_level": 3, "file_order": 22, "section_index": 28, "content_hash": "39ec0875fba088a05d9e658a88239d34eece79c0542bfe0daccc5c7b46e8018b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:34e5f195bfaae0e40a8abafb16c0332546f11ce8194bd7ff22a9f73c9edd0cb9", "content": "You can create a custom instance of `OpenAiApi` with your own `ApiKey` implementation using the builder pattern:\n\n[source,java]\n----\nApiKey customApiKey = new ApiKey() {\n @Override\n public String getValue() {\n // Custom logic to retrieve API key\n return \"your-api-key-here\";\n }\n};\n\nOpenAiApi openAiApi = OpenAiApi.builder()\n .apiKey(customApiKey)\n .build();\n\nOpenAiChatModel chatModel = OpenAiChatModel.builder()\n .openAiApi(openAiApi)\n .build();\nChatClient openAiChatClient = ChatClient.builder(chatModel).build();\n----\n\nThis is useful when you need to:\n\n* Retrieve the API key from a secure key store\n* Rotate API keys dynamically\n* Implement custom API key selection logic", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Custom API Key Configuration", "heading_level": 3, "file_order": 22, "section_index": 29, "content_hash": "34e5f195bfaae0e40a8abafb16c0332546f11ce8194bd7ff22a9f73c9edd0cb9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:d512e167c34f6032aa06f17a107cecfb188ae1097e80e59042cf0ac5b77c28d6", "content": "OpenAI-compatible inference servers like vLLM, Ollama, and others often support additional parameters beyond those defined in OpenAI's standard API.\nFor example, these servers may accept parameters such as `top_k`, `repetition_penalty`, or other sampling controls that the official OpenAI API does not recognize.\n\nThe `extraBody` option allows you to pass arbitrary parameters to these servers.\nAny key-value pairs provided in `extraBody` are included at the top level of the JSON request, enabling you to leverage server-specific features while using Spring AI's OpenAI client.\n\n[IMPORTANT]\n====\nThe `extraBody` parameter is intended for use with OpenAI-compatible servers, not the official OpenAI API.\nWhile the official OpenAI API will ignore unknown parameters, they serve no purpose there.\nAlways consult your specific server's documentation to determine which parameters are supported.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Using Extra Parameters with OpenAI-Compatible Servers [[openai-compatible-servers]]", "heading_level": 2, "file_order": 22, "section_index": 30, "content_hash": "d512e167c34f6032aa06f17a107cecfb188ae1097e80e59042cf0ac5b77c28d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:e47f85003d75f79f1a6325fb95f3ee3fe1a16737691a2e0083de12446a428329", "content": "You can configure extra parameters using Spring Boot properties.\nEach property under `spring.ai.openai.chat.options.extra-body` becomes a top-level parameter in the request:\n\n[source,properties]\n----\nspring.ai.openai.base-url=http://localhost:8000\nspring.ai.openai.chat.options.model=meta-llama/Llama-3-8B-Instruct\nspring.ai.openai.chat.options.temperature=0.7\nspring.ai.openai.chat.options.extra-body.top_k=50\nspring.ai.openai.chat.options.extra-body.repetition_penalty=1.1\n----\n\nThis configuration would produce a JSON request like:\n\n[source,json]\n----\n{\n \"model\": \"meta-llama/Llama-3-8B-Instruct\",\n \"temperature\": 0.7,\n \"top_k\": 50,\n \"repetition_penalty\": 1.1,\n \"messages\": [...]\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Configuration with Properties", "heading_level": 3, "file_order": 22, "section_index": 31, "content_hash": "e47f85003d75f79f1a6325fb95f3ee3fe1a16737691a2e0083de12446a428329", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:a88e12990015f88bfb40aca7fe0d24e2d826258ec69130603da6166bb654dfef", "content": "You can also specify extra parameters at runtime using the options builder:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Tell me a creative story\",\n OpenAiChatOptions.builder()\n .model(\"meta-llama/Llama-3-8B-Instruct\")\n .temperature(0.7)\n .extraBody(Map.of(\n \"top_k\", 50,\n \"repetition_penalty\", 1.1,\n \"frequency_penalty\", 0.5\n ))\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Runtime Configuration with Builder", "heading_level": 3, "file_order": 22, "section_index": 32, "content_hash": "a88e12990015f88bfb40aca7fe0d24e2d826258ec69130603da6166bb654dfef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:b5de85234a81423198875cb69c73f21cb0f6d8f02734f340bcf307f96d505e04", "content": "When running vLLM with a Llama model, you might want to use sampling parameters specific to vLLM:\n\n[source,properties]\n----\nspring.ai.openai.base-url=http://localhost:8000\nspring.ai.openai.chat.options.model=meta-llama/Llama-3-70B-Instruct\nspring.ai.openai.chat.options.extra-body.top_k=40\nspring.ai.openai.chat.options.extra-body.top_p=0.95\nspring.ai.openai.chat.options.extra-body.repetition_penalty=1.05\nspring.ai.openai.chat.options.extra-body.min_p=0.05\n----\n\nRefer to the link:https://docs.vllm.ai/en/latest/[vLLM documentation] for a complete list of supported sampling parameters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Example: vLLM Server", "heading_level": 3, "file_order": 22, "section_index": 33, "content_hash": "b5de85234a81423198875cb69c73f21cb0f6d8f02734f340bcf307f96d505e04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:48903cd598671cb3b3d38d1c3f7cae3e9be04c67110c413ac1646e96b7bea5f2", "content": "When using Ollama through the OpenAI-compatible endpoint, you can pass Ollama-specific parameters:\n\n[source,java]\n----\nOpenAiChatOptions options = OpenAiChatOptions.builder()\n .model(\"llama3.2\")\n .extraBody(Map.of(\n \"num_predict\", 100,\n \"top_k\", 40,\n \"repeat_penalty\", 1.1\n ))\n .build();\n\nChatResponse response = chatModel.call(new Prompt(\"Generate text\", options));\n----\n\nConsult the link:https://github.com/ollama/ollama/blob/main/docs/api.md[Ollama API documentation] for available parameters.\n\n[NOTE]\n====\nThe `extraBody` parameter accepts any `Map<String, Object>`, allowing you to pass whatever parameters your target server supports.\nSpring AI does not validate these parameters—they are passed directly to the server.\nThis design provides maximum flexibility for working with diverse OpenAI-compatible implementations.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Example: Ollama Server", "heading_level": 3, "file_order": 22, "section_index": 34, "content_hash": "48903cd598671cb3b3d38d1c3f7cae3e9be04c67110c413ac1646e96b7bea5f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:9fdd9bc45f17a9af041fbf5edd32b13806c99ef2c26f66bcf7b7b78fa7414508", "content": "Some OpenAI-compatible servers that support reasoning models (such as DeepSeek R1, vLLM with reasoning parsers) expose the model's internal chain of thought via a `reasoning_content` field in their API responses.\nThis field contains the step-by-step reasoning process the model used to arrive at its final answer.\n\nSpring AI maps this field from the JSON response to the `reasoningContent` key in the AssistantMessage metadata.\n\n[IMPORTANT]\n====\n**Important distinction about `reasoning_content` availability:**\n\n* **OpenAI-compatible servers** (DeepSeek, vLLM): Expose `reasoning_content` in Chat Completions API responses ✅\n* **Official OpenAI models** (GPT-5, o1, o3): Do **NOT** expose reasoning text in Chat Completions API responses ❌\n\nOfficial OpenAI reasoning models hide the chain-of-thought content when using the Chat Completions API.\nThey only expose `reasoning_tokens` count in usage statistics.\nTo access actual reasoning text from official OpenAI models, you must use OpenAI's Responses API (a separate endpoint not currently supported by this client).\n\n**Fallback behavior:** When `reasoning_content` is not provided by the server (e.g., official OpenAI Chat Completions), the `reasoningContent` metadata field will be an empty string.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Reasoning Content from Reasoning Models", "heading_level": 3, "file_order": 22, "section_index": 35, "content_hash": "9fdd9bc45f17a9af041fbf5edd32b13806c99ef2c26f66bcf7b7b78fa7414508", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:f74aeb1289bcf6e8aa3a33552d70a98c3b78d6b557ea0abb2cc3dcd9bf6ef1c8", "content": "When using a compatible server, you can access the reasoning content from the response metadata.\n\n**Using ChatModel directly:**\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\"Which number is larger: 9.11 or 9.8?\")\n);\n\nAssistantMessage message = response.getResult().getOutput();\n\nString reasoning = message.getMetadata().get(\"reasoningContent\");\nif (reasoning != null && !reasoning.isEmpty()) {\n System.out.println(\"Model's reasoning process:\");\n System.out.println(reasoning);\n}\n\nSystem.out.println(\"\\nFinal answer:\");\nSystem.out.println(message.getContent());\n----\n\n**Using ChatClient:**\n\n[source,java]\n----\nChatClient chatClient = ChatClient.create(chatModel);\n\nString result = chatClient.prompt()\n .user(\"Which number is larger: 9.11 or 9.8?\")\n .call()\n .chatResponse()\n .getResult()\n .getOutput()\n .getContent();\n\nChatResponse response = chatClient.prompt()\n .user(\"Which number is larger: 9.11 or 9.8?\")\n .call()\n .chatResponse();\n\nAssistantMessage message = response.getResult().getOutput();\nString reasoning = message.getMetadata().get(\"reasoningContent\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Accessing Reasoning Content", "heading_level": 4, "file_order": 22, "section_index": 36, "content_hash": "f74aeb1289bcf6e8aa3a33552d70a98c3b78d6b557ea0abb2cc3dcd9bf6ef1c8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:b50987b04049033ca6e99b373017bdd4f6313cab3ae99a51cfac9e0f11eadd74", "content": "When using streaming responses, reasoning content is accumulated across chunks just like regular message content:\n\n[source,java]\n----\nFlux<ChatResponse> responseFlux = chatModel.stream(\n new Prompt(\"Solve this logic puzzle...\")\n);\n\nStringBuilder reasoning = new StringBuilder();\nStringBuilder answer = new StringBuilder();\n\nresponseFlux.subscribe(chunk -> {\n AssistantMessage message = chunk.getResult().getOutput();\n\n // Accumulate reasoning if present\n String reasoningChunk = message.getMetadata().get(\"reasoningContent\");\n if (reasoningChunk != null) {\n reasoning.append(reasoningChunk);\n }\n\n // Accumulate the final answer\n if (message.getContent() != null) {\n answer.append(message.getContent());\n }\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Streaming Reasoning Content", "heading_level": 4, "file_order": 22, "section_index": 37, "content_hash": "b50987b04049033ca6e99b373017bdd4f6313cab3ae99a51cfac9e0f11eadd74", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:c99263d825091d72ce673b17a5bc1c2d55aff88ce3a859f9115d77c7eb1fe9e5", "content": "DeepSeek R1 is a reasoning model that exposes its internal reasoning process:\n\n[source,properties]\n----\nspring.ai.openai.api-key=${DEEPSEEK_API_KEY}\nspring.ai.openai.base-url=https://api.deepseek.com\nspring.ai.openai.chat.options.model=deepseek-reasoner\n----\n\nWhen you make requests to DeepSeek R1, responses will include both the reasoning content (the model's thought process) and the final answer.\n\nRefer to the link:https://api-docs.deepseek.com/guides/reasoning_model[DeepSeek API documentation] for more details on reasoning models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Example: DeepSeek R1", "heading_level": 4, "file_order": 22, "section_index": 38, "content_hash": "c99263d825091d72ce673b17a5bc1c2d55aff88ce3a859f9115d77c7eb1fe9e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:975b51273dfa8978940d4cd431523265dd49396945f39c28b50ec489da0e402f", "content": "vLLM supports reasoning models when configured with a reasoning parser:\n\n[source,bash]\n----\nvllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \\\n --enable-reasoning \\\n --reasoning-parser deepseek_r1\n----\n\n[source,properties]\n----\nspring.ai.openai.base-url=http://localhost:8000\nspring.ai.openai.chat.options.model=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n----\n\nConsult the link:https://docs.vllm.ai/en/latest/features/reasoning_outputs.html[vLLM reasoning outputs documentation] for supported reasoning models and parsers.\n\n[NOTE]\n====\nThe availability of `reasoning_content` depends entirely on the inference server you're using.\nNot all OpenAI-compatible servers expose reasoning content, even when using reasoning-capable models.\nAlways refer to your server's API documentation to understand what fields are available in responses.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-chat.adoc", "title": "OpenAI Chat", "heading": "Example: vLLM with Reasoning Parser", "heading_level": 4, "file_order": 22, "section_index": 39, "content_hash": "975b51273dfa8978940d4cd431523265dd49396945f39c28b50ec489da0e402f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-chat.adoc"}}
{"id": "sha256:d593f701133df74f6fe580ee2904d189f076dc4bf019dc644c9bab4bbb3e0a03", "content": "Spring AI supports OpenAI's language models through the OpenAI Java SDK, providing a robust and officially-maintained integration with OpenAI's services including Microsoft Foundry and GitHub Models.\n\nNOTE: This implementation uses the official link:https://github.com/openai/openai-java[OpenAI Java SDK] from OpenAI. For the alternative Spring AI implementation, see xref:api/chat/openai-chat.adoc[OpenAI Chat].\n\nThe OpenAI SDK module automatically detects the service provider (OpenAI, Microsoft Foundry, or GitHub Models) based on the base URL you provide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "OpenAI SDK Chat (Official)", "heading_level": 1, "file_order": 23, "section_index": 0, "content_hash": "d593f701133df74f6fe580ee2904d189f076dc4bf019dc644c9bab4bbb3e0a03", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:6c5dc5e0e378a548c5ab14fb5feee49382b8c863531ad4385f5a2d93f22c3c5d", "content": "Authentication is done using a base URL and an API Key. The implementation provides flexible configuration options through Spring Boot properties or environment variables.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Authentication", "heading_level": 2, "file_order": 23, "section_index": 1, "content_hash": "6c5dc5e0e378a548c5ab14fb5feee49382b8c863531ad4385f5a2d93f22c3c5d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:9ca7b04c971a53c55524df97a0ca93f0929b855e757bd3f245c99ad3a833cca1", "content": "If you are using OpenAI directly, create an account at https://platform.openai.com/signup[OpenAI signup page] and generate an API key on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe base URL doesn't need to be set as it defaults to `https://api.openai.com/v1`:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=<your-openai-api-key>\n# base-url is optional, defaults to https://api.openai.com/v1\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_API_KEY=<your-openai-api-key>\n# OPENAI_BASE_URL is optional, defaults to https://api.openai.com/v1\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Using OpenAI", "heading_level": 3, "file_order": 23, "section_index": 2, "content_hash": "9ca7b04c971a53c55524df97a0ca93f0929b855e757bd3f245c99ad3a833cca1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:787002cafbc55e4fbd1d9a009f96334b2e34b82c9863fdf52167881e01cfa842", "content": "Microsoft Foundry is automatically detected when using a Microsoft Foundry URL. You can configure it using properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.api-key=<your-api-key>\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://<your-deployment-url>.openai.azure.com\nexport OPENAI_API_KEY=<your-api-key>\n----\n\n**Passwordless Authentication (Recommended for Azure):**\n\nMicrosoft Foundry supports passwordless authentication without providing an API key, which is more secure when running on Azure.\n\nTo enable passwordless authentication, add the `com.azure:azure-identity` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>com.azure</groupId>\n <artifactId>azure-identity</artifactId>\n</dependency>\n----\n\nThen configure without an API key:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n# No api-key needed - will use Azure credentials from environment\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Using Microsoft Foundry", "heading_level": 3, "file_order": 23, "section_index": 3, "content_hash": "787002cafbc55e4fbd1d9a009f96334b2e34b82c9863fdf52167881e01cfa842", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:de0a5a7c2b76d533820a39b51bd9b6ca5a6177363b3e178156adcd773398edee", "content": "GitHub Models is automatically detected when using the GitHub Models base URL. You'll need to create a GitHub Personal Access Token (PAT) with the `models:read` scope.\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://models.inference.ai.azure.com\nspring.ai.openai-sdk.api-key=github_pat_XXXXXXXXXXX\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://models.inference.ai.azure.com\nexport OPENAI_API_KEY=github_pat_XXXXXXXXXXX\n----\n\nTIP: For enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) in your properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=${OPENAI_API_KEY}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Using GitHub Models", "heading_level": 3, "file_order": 23, "section_index": 4, "content_hash": "de0a5a7c2b76d533820a39b51bd9b6ca5a6177363b3e178156adcd773398edee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:2daff73cc84193d019c7a64657d7f2e5208fc3696fe68a41da188144d8093c66", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 23, "section_index": 5, "content_hash": "2daff73cc84193d019c7a64657d7f2e5208fc3696fe68a41da188144d8093c66", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:5b42eed3d9fa4bd43cb40b28a061e1be8cb1f34ee9fb61e4dc6c8c7bb37f7475", "content": "Spring AI provides Spring Boot auto-configuration for the OpenAI SDK Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai-sdk</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai-sdk'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Auto-configuration", "heading_level": 2, "file_order": 23, "section_index": 6, "content_hash": "5b42eed3d9fa4bd43cb40b28a061e1be8cb1f34ee9fb61e4dc6c8c7bb37f7475", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:eda0671ca3b887e6acb8a9ece0128d8e0441ef7d50f2db26627910f208abf2b1", "content": "The prefix `spring.ai.openai-sdk` is used as the property prefix that lets you configure the OpenAI SDK client.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.base-url | The URL to connect to. Auto-detects from `OPENAI_BASE_URL` environment variable if not set. | https://api.openai.com/v1\n| spring.ai.openai-sdk.api-key | The API Key. Auto-detects from `OPENAI_API_KEY` environment variable if not set. | -\n| spring.ai.openai-sdk.organization-id | Optionally specify which organization to use for API requests. | -\n| spring.ai.openai-sdk.timeout | Request timeout duration. | -\n| spring.ai.openai-sdk.max-retries | Maximum number of retry attempts for failed requests. | -\n| spring.ai.openai-sdk.proxy | Proxy settings for OpenAI client (Java `Proxy` object). | -\n| spring.ai.openai-sdk.custom-headers | Custom HTTP headers to include in requests. Map of header name to header value. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Connection Properties", "heading_level": 4, "file_order": 23, "section_index": 7, "content_hash": "eda0671ca3b887e6acb8a9ece0128d8e0441ef7d50f2db26627910f208abf2b1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:444f73834c4e64c165efecc39f2f43c8c93b5fb5fa7100113cc430f6ca0d13e2", "content": "The OpenAI SDK implementation provides native support for Microsoft Foundry (Azure OpenAI) with automatic configuration:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.microsoft-foundry | Enable Microsoft Foundry mode. Auto-detected if base URL contains `openai.azure.com`, `cognitiveservices.azure.com`, or `.openai.microsoftFoundry.com`. | false\n| spring.ai.openai-sdk.microsoft-deployment-name | Microsoft Foundry deployment name. If not specified, the model name will be used. Also accessible via alias `deployment-name`. | -\n| spring.ai.openai-sdk.microsoft-foundry-service-version | Microsoft Foundry API service version. | -\n| spring.ai.openai-sdk.credential | Credential object for passwordless authentication (requires `com.azure:azure-identity` dependency). | -\n|====\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency and the implementation will automatically attempt to use Azure credentials from the environment when no API key is provided.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Microsoft Foundry (Azure OpenAI) Properties", "heading_level": 4, "file_order": 23, "section_index": 8, "content_hash": "444f73834c4e64c165efecc39f2f43c8c93b5fb5fa7100113cc430f6ca0d13e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:5e776c70888e2a7d866b06f23d67b0d2770f3afe1be8af8d7541ddbab2865a94", "content": "Native support for GitHub Models is available:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.github-models | Enable GitHub Models mode. Auto-detected if base URL contains `models.github.ai` or `models.inference.ai.azure.com`. | false\n|====\n\nTIP: GitHub Models requires a Personal Access Token with the `models:read` scope. Set it via the `OPENAI_API_KEY` environment variable or the `spring.ai.openai-sdk.api-key` property.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "GitHub Models Properties", "heading_level": 4, "file_order": 23, "section_index": 9, "content_hash": "5e776c70888e2a7d866b06f23d67b0d2770f3afe1be8af8d7541ddbab2865a94", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:2109ef878e62edea5aac73f3bca4e013def97ace6cd5db299e87591247095dde", "content": "The prefix `spring.ai.openai-sdk.chat` is the property prefix for configuring the chat model implementation:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.chat.options.model | Name of the OpenAI chat model to use. You can select between models such as: `gpt-5-mini`, `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `o1`, `o3-mini`, and more. See the https://platform.openai.com/docs/models[models] page for more information. | `gpt-5-mini`\n| spring.ai.openai-sdk.chat.options.temperature | The sampling temperature to use that controls the apparent creativity of generated completions. Higher values will make output more random while lower values will make results more focused and deterministic. It is not recommended to modify `temperature` and `top_p` for the same completions request as the interaction of these two settings is difficult to predict. | 1.0\n| spring.ai.openai-sdk.chat.options.frequency-penalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. | 0.0\n| spring.ai.openai-sdk.chat.options.logit-bias | Modify the likelihood of specified tokens appearing in the completion. | -\n| spring.ai.openai-sdk.chat.options.logprobs | Whether to return log probabilities of the output tokens. | false\n| spring.ai.openai-sdk.chat.options.top-logprobs | An integer between 0 and 5 specifying the number of most likely tokens to return at each token position. Requires `logprobs` to be true. | -\n| spring.ai.openai-sdk.chat.options.max-tokens | The maximum number of tokens to generate. *Use for non-reasoning models* (e.g., gpt-4o, gpt-3.5-turbo). *Cannot be used with reasoning models* (e.g., o1, o3, o4-mini series). *Mutually exclusive with maxCompletionTokens*. | -\n| spring.ai.openai-sdk.chat.options.max-completion-tokens | An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens. *Required for reasoning models* (e.g., o1, o3, o4-mini series). *Cannot be used with non-reasoning models*. *Mutually exclusive with maxTokens*. | -\n| spring.ai.openai-sdk.chat.options.n | How many chat completion choices to generate for each input message. | 1\n| spring.ai.openai-sdk.chat.options.output-modalities | List of output modalities. Can include \"text\" and \"audio\". | -\n| spring.ai.openai-sdk.chat.options.output-audio | Parameters for audio output. Use `AudioParameters` with voice (ALLOY, ASH, BALLAD, CORAL, ECHO, FABLE, ONYX, NOVA, SAGE, SHIMMER) and format (MP3, FLAC, OPUS, PCM16, WAV, AAC). | -\n| spring.ai.openai-sdk.chat.options.presence-penalty | Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far. | 0.0\n| spring.ai.openai-sdk.chat.options.response-format.type | Response format type: `TEXT`, `JSON_OBJECT`, or `JSON_SCHEMA`. | TEXT\n| spring.ai.openai-sdk.chat.options.response-format.json-schema | JSON schema for structured outputs when type is `JSON_SCHEMA`. | -\n| spring.ai.openai-sdk.chat.options.seed | If specified, the system will make a best effort to sample deterministically for reproducible results. | -\n| spring.ai.openai-sdk.chat.options.stop | Up to 4 sequences where the API will stop generating further tokens. | -\n| spring.ai.openai-sdk.chat.options.top-p | An alternative to sampling with temperature, called nucleus sampling. | -\n| spring.ai.openai-sdk.chat.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai-sdk.chat.options.parallel-tool-calls | Whether to enable parallel function calling during tool use. | true\n| spring.ai.openai-sdk.chat.options.reasoning-effort | Constrains effort on reasoning for reasoning models: `low`, `medium`, or `high`. | -\n| spring.ai.openai-sdk.chat.options.verbosity | Controls the verbosity of the model's response. | -\n| spring.ai.openai-sdk.chat.options.store | Whether to store the output of this chat completion request for use in OpenAI's model distillation or evals products. | false\n| spring.ai.openai-sdk.chat.options.metadata | Developer-defined tags and values used for filtering completions in the dashboard. | -\n| spring.ai.openai-sdk.chat.options.service-tier | Specifies the latency tier to use: `auto`, `default`, `flex`, or `priority`. | -\n| spring.ai.openai-sdk.chat.options.stream-options.include-usage | Whether to include usage statistics in streaming responses. | false\n| spring.ai.openai-sdk.chat.options.stream-options.include-obfuscation | Whether to include obfuscation in streaming responses. | false\n| spring.ai.openai-sdk.chat.options.tool-choice | Controls which (if any) function is called by the model. | -\n| spring.ai.openai-sdk.chat.options.internal-tool-execution-enabled | If false, Spring AI will proxy tool calls to the client for manual handling. If true (default), Spring AI handles function calls internally. | true\n|====\n\n[NOTE]\n====\nWhen using GPT-5 models such as `gpt-5`, `gpt-5-mini`, and `gpt-5-nano`, the `temperature` parameter is not supported.\nThese models are optimized for reasoning and do not use temperature.\nSpecifying a temperature value will result in an error.\nIn contrast, conversational models like `gpt-5-chat` do support the `temperature` parameter.\n====\n\nTIP: All properties prefixed with `spring.ai.openai-sdk.chat.options` can be overridden at runtime by adding request-specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Chat Model Properties", "heading_level": 4, "file_order": 23, "section_index": 10, "content_hash": "2109ef878e62edea5aac73f3bca4e013def97ace6cd5db299e87591247095dde", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:6112e971f9aba518cbdb119426147268f70426b319438168563bfc4927a8b37c", "content": "OpenAI provides two mutually exclusive parameters for controlling token generation limits:\n\n[cols=\"2,3,3\", stripes=even]\n|====\n| Parameter | Use Case | Compatible Models\n\n| `maxTokens` | Non-reasoning models | gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo\n| `maxCompletionTokens` | Reasoning models | o1, o1-mini, o1-preview, o3, o4-mini series\n|====\n\nIMPORTANT: These parameters are **mutually exclusive**. Setting both will result in an API error from OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Token Limit Parameters: Model-Specific Usage", "heading_level": 3, "file_order": 23, "section_index": 11, "content_hash": "6112e971f9aba518cbdb119426147268f70426b319438168563bfc4927a8b37c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:5fd7e225fddc1a0a7c25fdafa29017b394d2fe8f8f81808236729a9f9962d79a", "content": "**For non-reasoning models (gpt-4o, gpt-3.5-turbo):**\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Explain quantum computing in simple terms.\",\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o\")\n .maxTokens(150) // Use maxTokens for non-reasoning models\n .build()\n ));\n----\n\n**For reasoning models (o1, o3 series):**\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Solve this complex math problem step by step: ...\",\n OpenAiSdkChatOptions.builder()\n .model(\"o1-preview\")\n .maxCompletionTokens(1000) // Use maxCompletionTokens for reasoning models\n .build()\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Usage Examples", "heading_level": 4, "file_order": 23, "section_index": 12, "content_hash": "5fd7e225fddc1a0a7c25fdafa29017b394d2fe8f8f81808236729a9f9962d79a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:71b8ddb053704a44d25883212a125eb530f9af1ceb01f795e09f81147f3b1261", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkChatOptions.java[OpenAiSdkChatOptions.java] class provides model configurations such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiSdkChatModel(options)` constructor or the `spring.ai.openai-sdk.chat.options.*` properties.\n\nAt run-time, you can override the default options by adding new, request-specific options to the `Prompt` call.\nFor example, to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkChatOptions.java[OpenAiSdkChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 23, "section_index": 13, "content_hash": "71b8ddb053704a44d25883212a125eb530f9af1ceb01f795e09f81147f3b1261", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:fdd55a6cf87db7be4b4fca1d74c9d33ade125adcea76e424c06fc62f8c51593f", "content": "You can register custom Java functions or methods with the `OpenAiSdkChatModel` and have the OpenAI model intelligently choose to output a JSON object containing arguments to call one or many of the registered functions/tools.\nThis is a powerful technique to connect the LLM capabilities with external tools and APIs.\nRead more about xref:api/tools.adoc[Tool Calling].\n\nExample usage:\n\n[source,java]\n----\nvar chatOptions = OpenAiSdkChatOptions.builder()\n .toolCallbacks(List.of(\n FunctionToolCallback.builder(\"getCurrentWeather\", new WeatherService())\n .description(\"Get the weather in location\")\n .inputType(WeatherService.Request.class)\n .build()))\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\"What's the weather like in San Francisco?\", chatOptions));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Tool Calling", "heading_level": 2, "file_order": 23, "section_index": 14, "content_hash": "fdd55a6cf87db7be4b4fca1d74c9d33ade125adcea76e424c06fc62f8c51593f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:f40b9b0e1386d4aee11893d996cee4682311f1e3a290337433bc6ef2eaf84170", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Multimodal", "heading_level": 2, "file_order": 23, "section_index": 15, "content_hash": "f40b9b0e1386d4aee11893d996cee4682311f1e3a290337433bc6ef2eaf84170", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:c03c832741898e5b33472f8e811f97a49dc64cd074a149ecc60bc14974c1ac41", "content": "OpenAI models that offer vision multimodal support include `gpt-4`, `gpt-4o`, and `gpt-4o-mini`.\nRefer to the link:https://platform.openai.com/docs/guides/vision[Vision] guide for more information.\n\nSpring AI's link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] interface facilitates multimodal AI models by introducing the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-commons/src/main/java/org/springframework/ai/content/Media.java[Media] type.\n\nBelow is a code example illustrating the fusion of user text with an image:\n\n[source,java]\n----\nvar imageResource = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = new UserMessage(\n \"Explain what do you see on this picture?\",\n List.of(new Media(MimeTypeUtils.IMAGE_PNG, imageResource)));\n\nChatResponse response = chatModel.call(\n new Prompt(userMessage,\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o\")\n .build()));\n----\n\nOr using an image URL:\n\n[source,java]\n----\nvar userMessage = new UserMessage(\n \"Explain what do you see on this picture?\",\n List.of(Media.builder()\n .mimeType(MimeTypeUtils.IMAGE_PNG)\n .data(URI.create(\"https://docs.spring.io/spring-ai/reference/_images/multimodal.test.png\"))\n .build()));\n\nChatResponse response = chatModel.call(new Prompt(userMessage));\n----\n\nTIP: You can pass multiple images as well.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Vision", "heading_level": 3, "file_order": 23, "section_index": 16, "content_hash": "c03c832741898e5b33472f8e811f97a49dc64cd074a149ecc60bc14974c1ac41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:1752d676b0665844de1fb81358eea6cb0d13c7d0bb908403cd2ac055213f8d6e", "content": "OpenAI models that offer audio input support include `gpt-4o-audio-preview`.\nRefer to the link:https://platform.openai.com/docs/guides/audio[Audio] guide for more information.\n\nSpring AI supports base64-encoded audio files with the message.\nCurrently, OpenAI supports the following media types: `audio/mp3` and `audio/wav`.\n\nExample of audio input:\n\n[source,java]\n----\nvar audioResource = new ClassPathResource(\"speech1.mp3\");\n\nvar userMessage = new UserMessage(\n \"What is this recording about?\",\n List.of(new Media(MimeTypeUtils.parseMimeType(\"audio/mp3\"), audioResource)));\n\nChatResponse response = chatModel.call(\n new Prompt(userMessage,\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o-audio-preview\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Audio", "heading_level": 3, "file_order": 23, "section_index": 17, "content_hash": "1752d676b0665844de1fb81358eea6cb0d13c7d0bb908403cd2ac055213f8d6e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:722af86d33e33c1ca809e9e93a93137c3feeb069142cff26cf8f051fa3433d63", "content": "The `gpt-4o-audio-preview` model can generate audio responses.\n\nExample of generating audio output:\n\n[source,java]\n----\nvar userMessage = new UserMessage(\"Tell me a joke about Spring Framework\");\n\nChatResponse response = chatModel.call(\n new Prompt(userMessage,\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o-audio-preview\")\n .outputModalities(List.of(\"text\", \"audio\"))\n .outputAudio(new AudioParameters(Voice.ALLOY, AudioResponseFormat.WAV))\n .build()));\n\nString text = response.getResult().getOutput().getText(); // audio transcript\nbyte[] waveAudio = response.getResult().getOutput().getMedia().get(0).getDataAsByteArray(); // audio data\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Output Audio", "heading_level": 3, "file_order": 23, "section_index": 18, "content_hash": "722af86d33e33c1ca809e9e93a93137c3feeb069142cff26cf8f051fa3433d63", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:d59e0872b0589525887421f9c8530b6d58b358fad1fa79803e46196ac77c9657", "content": "OpenAI provides custom https://platform.openai.com/docs/guides/structured-outputs[Structured Outputs] APIs that ensure your model generates responses conforming strictly to your provided `JSON Schema`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Structured Outputs", "heading_level": 2, "file_order": 23, "section_index": 19, "content_hash": "d59e0872b0589525887421f9c8530b6d58b358fad1fa79803e46196ac77c9657", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:beccbb3310f45cb4f91065f56308a168d2b8432edd4a98813c3e1bddd466905d", "content": "You can set the response format programmatically with the `OpenAiSdkChatOptions` builder:\n\n[source,java]\n----\nString jsonSchema = \"\"\"\n {\n \"type\": \"object\",\n \"properties\": {\n \"steps\": {\n \"type\": \"array\",\n \"items\": {\n \"type\": \"object\",\n \"properties\": {\n \"explanation\": { \"type\": \"string\" },\n \"output\": { \"type\": \"string\" }\n },\n \"required\": [\"explanation\", \"output\"],\n \"additionalProperties\": false\n }\n },\n \"final_answer\": { \"type\": \"string\" }\n },\n \"required\": [\"steps\", \"final_answer\"],\n \"additionalProperties\": false\n }\n \"\"\";\n\nPrompt prompt = new Prompt(\n \"how can I solve 8x + 7 = -23\",\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o-mini\")\n .responseFormat(ResponseFormat.builder()\n .type(ResponseFormat.Type.JSON_SCHEMA)\n .jsonSchema(jsonSchema)\n .build())\n .build());\n\nChatResponse response = chatModel.call(prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Configuration", "heading_level": 3, "file_order": 23, "section_index": 20, "content_hash": "beccbb3310f45cb4f91065f56308a168d2b8432edd4a98813c3e1bddd466905d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:419258ae4f8377117f1165fc35a3a678f78648b69e80083dbac8b007f92b9580", "content": "You can leverage existing xref::api/structured-output-converter.adoc#_bean_output_converter[BeanOutputConverter] utilities:\n\n[source,java]\n----\nrecord MathReasoning(\n @JsonProperty(required = true, value = \"steps\") Steps steps,\n @JsonProperty(required = true, value = \"final_answer\") String finalAnswer) {\n\n record Steps(\n @JsonProperty(required = true, value = \"items\") Items[] items) {\n\n record Items(\n @JsonProperty(required = true, value = \"explanation\") String explanation,\n @JsonProperty(required = true, value = \"output\") String output) {\n }\n }\n}\n\nvar outputConverter = new BeanOutputConverter<>(MathReasoning.class);\nString jsonSchema = outputConverter.getJsonSchema();\n\nPrompt prompt = new Prompt(\n \"how can I solve 8x + 7 = -23\",\n OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o-mini\")\n .responseFormat(ResponseFormat.builder()\n .type(ResponseFormat.Type.JSON_SCHEMA)\n .jsonSchema(jsonSchema)\n .build())\n .build());\n\nChatResponse response = chatModel.call(prompt);\nMathReasoning mathReasoning = outputConverter.convert(\n response.getResult().getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Integrating with BeanOutputConverter", "heading_level": 3, "file_order": 23, "section_index": 21, "content_hash": "419258ae4f8377117f1165fc35a3a678f78648b69e80083dbac8b007f92b9580", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:dd37cde46f2437f2ae7d804cd62cd4fc0e3ce55659b9cbbcbded103fd83c8e89", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-openai-sdk` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file under the `src/main/resources` directory to configure the OpenAI SDK chat model:\n\n[source,application.properties]\n----\nspring.ai.openai-sdk.api-key=YOUR_API_KEY\nspring.ai.openai-sdk.chat.options.model=gpt-5-mini\nspring.ai.openai-sdk.chat.options.temperature=0.7\n----\n\nTIP: Replace the `api-key` with your OpenAI credentials.\n\nThis will create an `OpenAiSdkChatModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiSdkChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiSdkChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map<String,String> generate(\n @RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n public Flux<ChatResponse> generateStream(\n @RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Sample Controller", "heading_level": 2, "file_order": 23, "section_index": 22, "content_hash": "dd37cde46f2437f2ae7d804cd62cd4fc0e3ce55659b9cbbcbded103fd83c8e89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:2eb6b90d3426d8a0aaaa1ec6a7f466bd8d92be6d7a99b8b2b95e2e65a19673ab", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkChatModel.java[OpenAiSdkChatModel] implements the `ChatModel` and uses the official OpenAI Java SDK to connect to the OpenAI service.\n\nAdd the `spring-ai-openai-sdk` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai-sdk</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai-sdk'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `OpenAiSdkChatModel` and use it for text generations:\n\n[source,java]\n----\nvar chatOptions = OpenAiSdkChatOptions.builder()\n .model(\"gpt-4o\")\n .temperature(0.7)\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar chatModel = OpenAiSdkChatModel.builder()\n .options(chatOptions)\n .build();\n\nChatResponse response = chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> response = chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Manual Configuration", "heading_level": 2, "file_order": 23, "section_index": 23, "content_hash": "2eb6b90d3426d8a0aaaa1ec6a7f466bd8d92be6d7a99b8b2b95e2e65a19673ab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:3592b2a1b37d2bd062482908cef2e963136e266c5ffdde2630545df61becf62f", "content": "For Microsoft Foundry :\n\n[source,java]\n----\nvar chatOptions = OpenAiSdkChatOptions.builder()\n .baseUrl(\"https://your-resource.openai.azure.com\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .deploymentName(\"gpt-4\")\n .azureOpenAIServiceVersion(AzureOpenAIServiceVersion.V2024_10_01_PREVIEW)\n .azure(true) // Enables Microsoft Foundry mode\n .build();\n\nvar chatModel = OpenAiSdkChatModel.builder()\n .options(chatOptions)\n .build();\n----\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency to your project. If you don't provide an API key, the implementation will automatically attempt to use Azure credentials from your environment.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Microsoft Foundry Configuration", "heading_level": 3, "file_order": 23, "section_index": 24, "content_hash": "3592b2a1b37d2bd062482908cef2e963136e266c5ffdde2630545df61becf62f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:9fa68466c9666f2759d484f7b2455318431ed169f3a52b0eef706a569508c851", "content": "For GitHub Models:\n\n[source,java]\n----\nvar chatOptions = OpenAiSdkChatOptions.builder()\n .baseUrl(\"https://models.inference.ai.azure.com\")\n .apiKey(System.getenv(\"GITHUB_TOKEN\"))\n .model(\"gpt-4o\")\n .githubModels(true)\n .build();\n\nvar chatModel = OpenAiSdkChatModel.builder()\n .options(chatOptions)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "GitHub Models Configuration", "heading_level": 3, "file_order": 23, "section_index": 25, "content_hash": "9fa68466c9666f2759d484f7b2455318431ed169f3a52b0eef706a569508c851", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:0069bdc98ef3b04e690355d2464d6bee1ac1e816e1d1f0e5e829e31c351a4a23", "content": "This implementation differs from the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] implementation in several ways:\n\n[cols=\"2,3,3\", stripes=even]\n|====\n| Aspect | Official OpenAI SDK | Existing OpenAI\n\n| **HTTP Client** | OkHttp (via official SDK) | Spring RestClient/WebClient\n| **API Updates** | Automatic via SDK updates | Manual maintenance\n| **Azure Support** | Native with passwordless auth | Manual URL construction\n| **GitHub Models** | Native support | Not supported\n| **Audio/Moderation** | Not yet supported | Fully supported\n| **Retry Logic** | SDK-managed (exponential backoff) | Spring Retry (customizable)\n| **Dependencies** | Official OpenAI SDK | Spring WebFlux\n|====\n\n**When to use OpenAI SDK:**\n\n* You're starting a new project\n* You primarily use Microsoft Foundry or GitHub Models\n* You want automatic API updates from OpenAI\n* You don't need audio transcription or moderation features\n* You prefer official SDK support\n\n**When to use Spring AI OpenAI:**\n\n* You have an existing project using it\n* You need audio transcription or moderation features\n* You require fine-grained HTTP control\n* You want native Spring reactive support\n* You need custom retry strategies", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Key Differences from Spring AI OpenAI", "heading_level": 2, "file_order": 23, "section_index": 26, "content_hash": "0069bdc98ef3b04e690355d2464d6bee1ac1e816e1d1f0e5e829e31c351a4a23", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:68cada0343e39e9893825449e90636da5088556f34dfa48eae8132cb6cc53048", "content": "The OpenAI SDK implementation supports Spring AI's observability features through Micrometer.\nAll chat model operations are instrumented for monitoring and tracing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Observability", "heading_level": 2, "file_order": 23, "section_index": 27, "content_hash": "68cada0343e39e9893825449e90636da5088556f34dfa48eae8132cb6cc53048", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:7990fd6a01835eb55433ee303c1f4bb8c0c5730ac1eb0d107c10be450cc3d14f", "content": "The following features are not yet supported in the OpenAI SDK implementation:\n\n* Audio speech generation (TTS)\n* Audio transcription\n* Moderation API\n* File API operations\n\nThese features are available in the xref:api/chat/openai-chat.adoc[Spring AI OpenAI] implementation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Limitations", "heading_level": 2, "file_order": 23, "section_index": 28, "content_hash": "7990fd6a01835eb55433ee303c1f4bb8c0c5730ac1eb0d107c10be450cc3d14f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:d1aec93d3102483b7dde7c596dc2ba74f36345826093abb15b2cadf396647f17", "content": "* link:https://github.com/openai/openai-java[Official OpenAI Java SDK]\n* link:https://platform.openai.com/docs/api-reference/chat[OpenAI Chat API Documentation]\n* link:https://platform.openai.com/docs/models[OpenAI Models]\n* link:https://learn.microsoft.com/en-us/azure/ai-foundry/[Microsoft Foundry Documentation]\n* link:https://github.com/marketplace/models[GitHub Models]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc", "title": "OpenAI SDK Chat (Official)", "heading": "Additional Resources", "heading_level": 2, "file_order": 23, "section_index": 29, "content_hash": "d1aec93d3102483b7dde7c596dc2ba74f36345826093abb15b2cadf396647f17", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/openai-sdk-chat.adoc"}}
{"id": "sha256:a67e1dd414e98c7903fdf4786bb3a6f93399266a1689e9aa41b343fa19449e98", "content": "https://perplexity.ai/[Perplexity AI] provides a unique AI service that integrates its language models with real-time search capabilities. It offers a variety of models and supports streaming responses for conversational AI.\n\nSpring AI integrates with Perplexity AI by reusing the existing xref::api/chat/openai-chat.adoc[OpenAI] client. To get started, you'll need to obtain a https://docs.perplexity.ai/guides/getting-started[Perplexity API Key], configure the base URL, and select one of the supported https://docs.perplexity.ai/guides/model-cards[models].\n\nimage::spring-ai-perplexity-integration.jpg[w=800,align=\"center\"]\n\nNOTE: The Perplexity API is not fully compatible with the OpenAI API.\nPerplexity combines realtime web search results with its language model responses.\nUnlike OpenAI, Perplexity does not expose `toolCalls` - `function call` mechanisms.\nAdditionally, currently Perplexity doesn’t support multimodal messages.\n\nCheck the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/test/java/org/springframework/ai/openai/chat/proxy/PerplexityWithOpenAiChatModelIT.java[PerplexityWithOpenAiChatModelIT.java] tests for examples of using Perplexity with Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Perplexity Chat", "heading_level": 1, "file_order": 24, "section_index": 0, "content_hash": "a67e1dd414e98c7903fdf4786bb3a6f93399266a1689e9aa41b343fa19449e98", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:76bfdfab744d632df9e8922086162403069c1b8769d0a7c13ebba5c1242db088", "content": "* **Create an API Key**:\nVisit https://docs.perplexity.ai/guides/getting-started[here] to create an API Key.\nConfigure it using the `spring.ai.openai.api-key` property in your Spring AI project.\n\n* **Set the Perplexity Base URL**:\nSet the `spring.ai.openai.base-url` property to `+https://api.perplexity.ai+`.\n\n* **Select a Perplexity Model**:\nUse the `spring.ai.openai.chat.model=<model name>` property to specify the model.\nRefer to https://docs.perplexity.ai/guides/model-cards[Supported Models] for available options.\n\n* **Set the chat completions path**:\nSet the `spring.ai.openai.chat.completions-path` to `/chat/completions`.\nRefer to https://docs.perplexity.ai/api-reference/chat-completions[chat completions api] for more details.\n\nYou can set these configuration properties in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<your-perplexity-api-key>\nspring.ai.openai.base-url=https://api.perplexity.ai\nspring.ai.openai.chat.model=llama-3.1-sonar-small-128k-online\nspring.ai.openai.chat.completions-path=/chat/completions\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference custom environment variables:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${PERPLEXITY_API_KEY}\n base-url: ${PERPLEXITY_BASE_URL}\n chat:\n model: ${PERPLEXITY_MODEL}\n completions-path: ${PERPLEXITY_COMPLETIONS_PATH}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport PERPLEXITY_API_KEY=<your-perplexity-api-key>\nexport PERPLEXITY_BASE_URL=https://api.perplexity.ai\nexport PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online\nexport PERPLEXITY_COMPLETIONS_PATH=/chat/completions\n----\n\nYou can also set these configurations programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"PERPLEXITY_API_KEY\");\nString baseUrl = System.getenv(\"PERPLEXITY_BASE_URL\");\nString model = System.getenv(\"PERPLEXITY_MODEL\");\nString completionsPath = System.getenv(\"PERPLEXITY_COMPLETIONS_PATH\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 24, "section_index": 1, "content_hash": "76bfdfab744d632df9e8922086162403069c1b8769d0a7c13ebba5c1242db088", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:d67e79b6215662bcbf1874f35d0b75ceef17f7a7a3e56619fd83f6209eae3c0b", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 24, "section_index": 2, "content_hash": "d67e79b6215662bcbf1874f35d0b75ceef17f7a7a3e56619fd83f6209eae3c0b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:fcfb68971758de745a3e3c849310986e034a3b95b32ba3eae160629f6aa5e606", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 24, "section_index": 3, "content_hash": "fcfb68971758de745a3e3c849310986e034a3b95b32ba3eae160629f6aa5e606", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:ecef8b4dd08e4ecd98d47ae81e84cbaeca6567ed8f88be9b6ecef5c247500341", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 24, "section_index": 4, "content_hash": "ecef8b4dd08e4ecd98d47ae81e84cbaeca6567ed8f88be9b6ecef5c247500341", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:a0a0f65aa66ed179adb062fb4f64c219a3be1e714131bbeef28d514fa71a0dd2", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to. Must be set to `+https://api.perplexity.ai+` | -\n| spring.ai.openai.chat.api-key | Your Perplexity API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 24, "section_index": 5, "content_hash": "a0a0f65aa66ed179adb062fb4f64c219a3be1e714131bbeef28d514fa71a0dd2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:1e6baa215a1e5f04730165ed08c0ecb4263a3e17ad08534c297a5457a2451874", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=openai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.chat` is the property prefix that lets you configure the chat model implementation for OpenAI.\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.model.chat | Enable OpenAI chat model. | openai\n| spring.ai.openai.chat.model | One of the supported https://docs.perplexity.ai/guides/model-cards[Perplexity models]. Example: `llama-3.1-sonar-small-128k-online`. | -\n| spring.ai.openai.chat.base-url | Optional overrides the spring.ai.openai.base-url to provide chat specific url. Must be set to `+https://api.perplexity.ai+` | -\n| spring.ai.openai.chat.completions-path | Must be set to `/chat/completions` | `/v1/chat/completions`\n| spring.ai.openai.chat.options.temperature | The amount of randomness in the response, valued between 0 inclusive and 2 exclusive. Higher values are more random, and lower values are more deterministic. Required range: `0 < x < 2`. | 0.2\n| spring.ai.openai.chat.options.frequencyPenalty | A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. A value of 1.0 means no penalty. Incompatible with presence_penalty. Required range: `x > 0`. | 1\n| spring.ai.openai.chat.options.maxTokens | The maximum number of completion tokens returned by the API. The total number of tokens requested in max_tokens plus the number of prompt tokens sent in messages must not exceed the context window token limit of model requested. If left unspecified, then the model will generate tokens until either it reaches its stop token or the end of its context window. | -\n| spring.ai.openai.chat.options.presencePenalty | A value between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Incompatible with `frequency_penalty`. Required range: `-2 < x < 2` | 0\n| spring.ai.openai.chat.options.topP | The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass. We recommend either altering top_k or top_p, but not both. Required range: `0 < x < 1` | 0.9\n| spring.ai.openai.chat.options.stream-usage | (For streaming only) Set to add an additional chunk with token usage statistics for the entire request. The `choices` field for this chunk is an empty array and all other chunks will also include a usage field, but with a null value. | false\n|====\n\nTIP: All properties prefixed with `spring.ai.openai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 24, "section_index": 6, "content_hash": "1e6baa215a1e5f04730165ed08c0ecb4263a3e17ad08534c297a5457a2451874", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:c320a5b3cc7872b6eab50c12f4f487722fd444bcb2a71ba55fd3fc2a10595e43", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `OpenAiChatModel(api, options)` constructor or the `spring.ai.openai.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n OpenAiChatOptions.builder()\n .model(\"llama-3.1-sonar-large-128k-online\")\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiChatOptions.java[OpenAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 24, "section_index": 7, "content_hash": "c320a5b3cc7872b6eab50c12f4f487722fd444bcb2a71ba55fd3fc2a10595e43", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:bb82867df49ca1edfdcfcb7adb9712609b690c7faefd80aab10f6d776b4eb6ef", "content": "NOTE: Perplexity does not support explicit function calling. Instead, it integrates search results directly into responses.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Function Calling", "heading_level": 2, "file_order": 24, "section_index": 8, "content_hash": "bb82867df49ca1edfdcfcb7adb9712609b690c7faefd80aab10f6d776b4eb6ef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:f1daf95648829663872f84413add49e83e2f531399c1d567cdc3388227a48da6", "content": "NOTE: Currently, the Perplexity API doesn't support media content.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 24, "section_index": 9, "content_hash": "f1daf95648829663872f84413add49e83e2f531399c1d567cdc3388227a48da6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:5c0040c2193287fd15e1fa4ffafbd3dfc157fbcb3ba34878c30b5a73b672a40a", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-openai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the OpenAi chat model:\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=<PERPLEXITY_API_KEY>\nspring.ai.openai.base-url=https://api.perplexity.ai\nspring.ai.openai.chat.completions-path=/chat/completions\nspring.ai.openai.chat.options.model=llama-3.1-sonar-small-128k-online\nspring.ai.openai.chat.options.temperature=0.7\n\n# The Perplexity API doesn't support embeddings, so we need to disable it.\nspring.ai.openai.embedding.enabled=false\n----\n\nTIP: replace the `api-key` with your Perplexity Api key.\n\nThis will create a `OpenAiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final OpenAiChatModel chatModel;\n\n @Autowired\n public ChatController(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 24, "section_index": 10, "content_hash": "5c0040c2193287fd15e1fa4ffafbd3dfc157fbcb3ba34878c30b5a73b672a40a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:fe45bfd55ef17fb1e3f06489c3a418650a38b49e4e0883384225b143c34e979f", "content": "Perplexity supports several models optimized for search-enhanced conversational AI. Refer to https://docs.perplexity.ai/guides/model-cards[Supported Models] for details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "Supported Models", "heading_level": 2, "file_order": 24, "section_index": 11, "content_hash": "fe45bfd55ef17fb1e3f06489c3a418650a38b49e4e0883384225b143c34e979f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:e56ae356188242975e9749919a078735d8a34e135814cd974de1727cbf1312f6", "content": "* https://docs.perplexity.ai/home[Documentation Home]\n* https://docs.perplexity.ai/api-reference/chat-completions[API Reference]\n* https://docs.perplexity.ai/guides/getting-started[Getting Started]\n* https://docs.perplexity.ai/guides/rate-limits[Rate Limits]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc", "title": "Perplexity Chat", "heading": "References", "heading_level": 2, "file_order": 24, "section_index": 12, "content_hash": "e56ae356188242975e9749919a078735d8a34e135814cd974de1727cbf1312f6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/perplexity-chat.adoc"}}
{"id": "sha256:0d3e919e5479dd755a3874924162aa92be92c61c2412c6cd3427841ab86e0361", "content": "[[prompt-engineering]]\n\nPractical implementations of Prompt Engineering techniques based on the comprehensive link:https://www.kaggle.com/whitepaper-prompt-engineering[Prompt Engineering Guide].\nThe guide covers the theory, principles, and patterns of effective prompt engineering, while here we demonstrate how to translate those concepts into working Java code using Spring AI's fluent xref::api/chatclient.adoc[ChatClient API].\nThe demo source code used in this article is available at: link:https://github.com/spring-projects/spring-ai-examples/tree/main/prompt-engineering/prompt-engineering-patterns[Prompt Engineering Patterns Examples].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "prompt-engineering-patterns", "heading_level": 1, "file_order": 25, "section_index": 0, "content_hash": "0d3e919e5479dd755a3874924162aa92be92c61c2412c6cd3427841ab86e0361", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:a851f244884384375dc242221a23e06414e077ae813cd05d8079c46dcc8cd05f", "content": "The configuration section outlines how to set up and tune your Large Language Model (LLM) with Spring AI.\nIt covers selecting the right LLM provider for your use case and configuring important generation parameters that control the quality, style, and format of model outputs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "1. Configuration", "heading_level": 2, "file_order": 25, "section_index": 1, "content_hash": "a851f244884384375dc242221a23e06414e077ae813cd05d8079c46dcc8cd05f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:88c526c26c5acb8daf357b51e9a1ea957140643c1f6f46964b2648ff9260d77a", "content": "For prompt engineering, you will start by choosing a model.\nSpring AI supports xref::api/chat/comparison.adoc[multiple LLM providers] (such as OpenAI, Anthropic, Google Vertex AI, AWS Bedrock, Ollama and more), letting you switch providers without changing application code - just update your configuration.\nJust add the selected starter dependency `spring-ai-starter-model-<MODEL-PROVIDER-NAME>`.\nFor example, here is how to enable Anthropic Claude API:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-anthropic</artifactId>\n</dependency>\n----\n\nYou can specify the LLM model name like this:\n\n[source,java]\n----\n.options(ChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\") // Use Anthropic's Claude model\n .build())\n----\n\nFind detailed information for enabling each model in the xref::api/chatmodel.adoc[reference docs].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "LLM Provider Selection", "heading_level": 3, "file_order": 25, "section_index": 2, "content_hash": "88c526c26c5acb8daf357b51e9a1ea957140643c1f6f46964b2648ff9260d77a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:2f297b6e602d14f11f59a1c960087360c4bbb9c76642de89ff98bac15b56ac3d", "content": "image::https://docs.spring.io/spring-ai/reference/_images/chat-options-flow.jpg[width=500,float=right]\n\nBefore we dive into prompt engineering techniques, it's essential to understand how to configure the LLM's output behavior. Spring AI provides several configuration options that let you control various aspects of generation through the xref::api/chatmodel.adoc#_chat_options[ChatOptions] builder.\n\nAll configurations can be applied programmatically as demonstrated in the examples below or through Spring application properties at start time.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "LLM Output Configuration", "heading_level": 3, "file_order": 25, "section_index": 3, "content_hash": "2f297b6e602d14f11f59a1c960087360c4bbb9c76642de89ff98bac15b56ac3d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:12e533683ae7ff2b27b0d3051af06413dc23cea0aa82239162308386d801a375", "content": "Temperature controls the randomness or \"creativity\" of the model's response.\n\n* *Lower values (0.0-0.3)*: More deterministic, focused responses. Better for factual questions, classification, or tasks where consistency is critical.\n* *Medium values (0.4-0.7)*: Balanced between determinism and creativity. Good for general use cases.\n* *Higher values (0.8-1.0)*: More creative, varied, and potentially surprising responses. Better for creative writing, brainstorming, or generating diverse options.\n\n[source,java]\n----\n.options(ChatOptions.builder()\n .temperature(0.1) // Very deterministic output\n .build())\n----\n\nUnderstanding temperature is crucial for prompt engineering as different techniques benefit from different temperature settings.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Temperature", "heading_level": 4, "file_order": 25, "section_index": 4, "content_hash": "12e533683ae7ff2b27b0d3051af06413dc23cea0aa82239162308386d801a375", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:f74958a82e1a92002aa30f614ea870d320a073c090aacc38c79c0181d934c1b4", "content": "The `maxTokens` parameter limits how many tokens (word pieces) the model can generate in its response.\n\n* *Low values (5-25)*: For single words, short phrases, or classification labels.\n* *Medium values (50-500)*: For paragraphs or short explanations.\n* *High values (1000+)*: For long-form content, stories, or complex explanations.\n\n[source,java]\n----\n.options(ChatOptions.builder()\n .maxTokens(250) // Medium-length response\n .build())\n----\n\nSetting appropriate output length is important to ensure you get complete responses without unnecessary verbosity.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Output Length (MaxTokens)", "heading_level": 4, "file_order": 25, "section_index": 5, "content_hash": "f74958a82e1a92002aa30f614ea870d320a073c090aacc38c79c0181d934c1b4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:9474562df2870dff662f3b35761039b1a205fcccbe2106aeeddbddb49bfc0d28", "content": "These parameters give you fine-grained control over the token selection process during generation.\n\n* *Top-K*: Limits token selection to the K most likely next tokens. Higher values (e.g., 40-50) introduce more diversity.\n* *Top-P (nucleus sampling)*: Dynamically selects from the smallest set of tokens whose cumulative probability exceeds P. Values like 0.8-0.95 are common.\n\n[source,java]\n----\n.options(ChatOptions.builder()\n .topK(40) // Consider only the top 40 tokens\n .topP(0.8) // Sample from tokens that cover 80% of probability mass\n .build())\n----\n\nThese sampling controls work in conjunction with temperature to shape response characteristics.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Sampling Controls (Top-K and Top-P)", "heading_level": 4, "file_order": 25, "section_index": 6, "content_hash": "9474562df2870dff662f3b35761039b1a205fcccbe2106aeeddbddb49bfc0d28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:bbe4207aee13baa25f812e16251015c39b17a478d3e44c16c18a2438c60fd17c", "content": "Along with the plain text response (using `.content()`), Spring AI makes it easy to directly map LLM responses to Java objects using the `.entity()` method.\n\n[source,java]\n----\nenum Sentiment {\n POSITIVE, NEUTRAL, NEGATIVE\n}\n\nSentiment result = chatClient.prompt(\"...\")\n .call()\n .entity(Sentiment.class);\n----\n\nThis feature is particularly powerful when combined with system prompts that instruct the model to return structured data.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Structured Response Format", "heading_level": 4, "file_order": 25, "section_index": 7, "content_hash": "bbe4207aee13baa25f812e16251015c39b17a478d3e44c16c18a2438c60fd17c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:3c71ef8247ca61166c8f99254e1c40d3db62d7e4d4710255dec5987d0fd9687b", "content": "While the portable `ChatOptions` provides a consistent interface across different LLM providers, Spring AI also offers model-specific options classes that expose provider-specific features and configurations. These model-specific options allow you to leverage the unique capabilities of each LLM provider.\n\n[source,java]\n----\nOpenAiChatOptions openAiOptions = OpenAiChatOptions.builder()\n .model(\"gpt-4o\")\n .temperature(0.2)\n .frequencyPenalty(0.5) // OpenAI-specific parameter\n .presencePenalty(0.3) // OpenAI-specific parameter\n .responseFormat(new ResponseFormat(\"json_object\")) // OpenAI-specific JSON mode\n .seed(42) // OpenAI-specific deterministic generation\n .build();\n\nString result = chatClient.prompt(\"...\")\n .options(openAiOptions)\n .call()\n .content();\n\nAnthropicChatOptions anthropicOptions = AnthropicChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(0.2)\n .topK(40) // Anthropic-specific parameter\n .thinking(AnthropicApi.ThinkingType.ENABLED, 1000) // Anthropic-specific thinking configuration\n .build();\n\nString result = chatClient.prompt(\"...\")\n .options(anthropicOptions)\n .call()\n .content();\n----\n\nEach model provider has its own implementation of chat options (e.g., `OpenAiChatOptions`, `AnthropicChatOptions`, `MistralAiChatOptions`) that exposes provider-specific parameters while still implementing the common interface. This approach gives you the flexibility to use portable options for cross-provider compatibility or model-specific options when you need access to unique features of a particular provider.\n\nNote that when using model-specific options, your code becomes tied to that specific provider, reducing portability. It's a trade-off between accessing advanced provider-specific features versus maintaining provider independence in your application.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Model-Specific Options", "heading_level": 4, "file_order": 25, "section_index": 8, "content_hash": "3c71ef8247ca61166c8f99254e1c40d3db62d7e4d4710255dec5987d0fd9687b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:60100dc4f9a2169d57fed793247d5648265319373417b81eb683d38718a1fcf2", "content": "Each section below implements a specific prompt engineering technique from the guide.\nBy following both the \"Prompt Engineering\" guide and these implementations, you'll develop a thorough understanding of not just what prompt engineering techniques are available, but how to effectively implement them in production Java applications.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2. Prompt Engineering Techniques", "heading_level": 2, "file_order": 25, "section_index": 9, "content_hash": "60100dc4f9a2169d57fed793247d5648265319373417b81eb683d38718a1fcf2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:8c75fe0373d6b0a614a7ec7c8805310671cb705ace2f95f1a2e42cfa7f783e32", "content": "Zero-shot prompting involves asking an AI to perform a task without providing any examples. This approach tests the model's ability to understand and execute instructions from scratch. Large language models are trained on vast corpora of text, allowing them to understand what tasks like \"translation,\" \"summarization,\" or \"classification\" entail without explicit demonstrations.\n\nZero-shot is ideal for straightforward tasks where the model likely has seen similar examples during training, and when you want to minimize prompt length. However, performance may vary depending on task complexity and how well the instructions are formulated.\n\n[source,java]\n----\npublic void pt_zero_shot(ChatClient chatClient) {\n enum Sentiment {\n POSITIVE, NEUTRAL, NEGATIVE\n }\n\n Sentiment reviewSentiment = chatClient.prompt(\"\"\"\n Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n Review: \"Her\" is a disturbing study revealing the direction\n humanity is headed if AI is allowed to keep evolving,\n unchecked. I wish there were more movies like this masterpiece.\n Sentiment:\n \"\"\")\n .options(ChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(0.1)\n .maxTokens(5)\n .build())\n .call()\n .entity(Sentiment.class);\n\n System.out.println(\"Output: \" + reviewSentiment);\n}\n----\n\nThis example shows how to classify a movie review sentiment without providing examples. Note the low temperature (0.1) for more deterministic results and the direct `.entity(Sentiment.class)` mapping to a Java enum.\n\n*Reference:* Brown, T. B., et al. (2020). \"Language Models are Few-Shot Learners.\" arXiv:2005.14165. link:https://arxiv.org/abs/2005.14165[https://arxiv.org/abs/2005.14165]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.1 Zero-Shot Prompting", "heading_level": 3, "file_order": 25, "section_index": 10, "content_hash": "8c75fe0373d6b0a614a7ec7c8805310671cb705ace2f95f1a2e42cfa7f783e32", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:b099bfcd0f1451e97cd12f7d428fe886ac956d7db355de80654242bfc0847c0e", "content": "Few-shot prompting provides the model with one or more examples to help guide its responses, particularly useful for tasks requiring specific output formats. By showing the model examples of desired input-output pairs, it can learn the pattern and apply it to new inputs without explicit parameter updates.\n\nOne-shot provides a single example, which is useful when examples are costly or when the pattern is relatively simple. Few-shot uses multiple examples (typically 3-5) to help the model better understand patterns in more complex tasks or to illustrate different variations of correct outputs.\n\n[source,java]\n----\npublic void pt_one_shot_few_shots(ChatClient chatClient) {\n String pizzaOrder = chatClient.prompt(\"\"\"\n Parse a customer's pizza order into valid JSON\n\n EXAMPLE 1:\n I want a small pizza with cheese, tomato sauce, and pepperoni.\n JSON Response:\n ```\n {\n \"size\": \"small\",\n \"type\": \"normal\",\n \"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n }\n ```\n\n EXAMPLE 2:\n Can I get a large pizza with tomato sauce, basil and mozzarella.\n JSON Response:\n ```\n {\n \"size\": \"large\",\n \"type\": \"normal\",\n \"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n }\n ```\n\n Now, I would like a large pizza, with the first half cheese and mozzarella.\n And the other tomato sauce, ham and pineapple.\n \"\"\")\n .options(ChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(0.1)\n .maxTokens(250)\n .build())\n .call()\n .content();\n}\n----\n\nFew-shot prompting is especially effective for tasks requiring specific formatting, handling edge cases, or when the task definition might be ambiguous without examples. The quality and diversity of the examples significantly impact performance.\n\n*Reference:* Brown, T. B., et al. (2020). \"Language Models are Few-Shot Learners.\" arXiv:2005.14165. link:https://arxiv.org/abs/2005.14165[https://arxiv.org/abs/2005.14165]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.2 One-Shot & Few-Shot Prompting", "heading_level": 3, "file_order": 25, "section_index": 11, "content_hash": "b099bfcd0f1451e97cd12f7d428fe886ac956d7db355de80654242bfc0847c0e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:98811d997fa6602bfaf18c8eddb6756db6c3410127586f783255f26055953da2", "content": "System prompting sets the overall context and purpose for the language model, defining the \"big picture\" of what the model should be doing. It establishes the behavioral framework, constraints, and high-level objectives for the model's responses, separate from the specific user queries.\n\nSystem prompts act as a persistent \"mission statement\" throughout the conversation, allowing you to set global parameters like output format, tone, ethical boundaries, or role definitions. Unlike user prompts which focus on specific tasks, system prompts frame how all user prompts should be interpreted.\n\n[source,java]\n----\npublic void pt_system_prompting_1(ChatClient chatClient) {\n String movieReview = chatClient\n .prompt()\n .system(\"Classify movie reviews as positive, neutral or negative. Only return the label in uppercase.\")\n .user(\"\"\"\n Review: \"Her\" is a disturbing study revealing the direction\n humanity is headed if AI is allowed to keep evolving,\n unchecked. It's so disturbing I couldn't watch it.\n\n Sentiment:\n \"\"\")\n .options(ChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(1.0)\n .topK(40)\n .topP(0.8)\n .maxTokens(5)\n .build())\n .call()\n .content();\n}\n----\n\nSystem prompting is particularly powerful when combined with Spring AI's entity mapping capabilities:\n\n[source,java]\n----\nrecord MovieReviews(Movie[] movie_reviews) {\n enum Sentiment {\n POSITIVE, NEUTRAL, NEGATIVE\n }\n\n record Movie(Sentiment sentiment, String name) {\n }\n}\n\nMovieReviews movieReviews = chatClient\n .prompt()\n .system(\"\"\"\n Classify movie reviews as positive, neutral or negative. Return\n valid JSON.\n \"\"\")\n .user(\"\"\"\n Review: \"Her\" is a disturbing study revealing the direction\n humanity is headed if AI is allowed to keep evolving,\n unchecked. It's so disturbing I couldn't watch it.\n\n JSON Response:\n \"\"\")\n .call()\n .entity(MovieReviews.class);\n----\n\nSystem prompts are especially valuable for multi-turn conversations, ensuring consistent behavior across multiple queries, and for establishing format constraints like JSON output that should apply to all responses.\n\n*Reference:* OpenAI. (2022). \"System Message.\" link:https://platform.openai.com/docs/guides/chat/introduction[https://platform.openai.com/docs/guides/chat/introduction]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "System Prompting", "heading_level": 4, "file_order": 25, "section_index": 12, "content_hash": "98811d997fa6602bfaf18c8eddb6756db6c3410127586f783255f26055953da2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:836aed263acf1b2c7435dd3e958f63b072e6af1eaf3bd8b94b9409087e342e7f", "content": "Role prompting instructs the model to adopt a specific role or persona, which affects how it generates content. By assigning a particular identity, expertise, or perspective to the model, you can influence the style, tone, depth, and framing of its responses.\n\nRole prompting leverages the model's ability to simulate different expertise domains and communication styles. Common roles include expert (e.g., \"You are an experienced data scientist\"), professional (e.g., \"Act as a travel guide\"), or stylistic character (e.g., \"Explain like you're Shakespeare\").\n\n[source,java]\n----\npublic void pt_role_prompting_1(ChatClient chatClient) {\n String travelSuggestions = chatClient\n .prompt()\n .system(\"\"\"\n I want you to act as a travel guide. I will write to you\n about my location and you will suggest 3 places to visit near\n me. In some cases, I will also give you the type of places I\n will visit.\n \"\"\")\n .user(\"\"\"\n My suggestion: \"I am in Amsterdam and I want to visit only museums.\"\n Travel Suggestions:\n \"\"\")\n .call()\n .content();\n}\n----\n\nRole prompting can be enhanced with style instructions:\n\n[source,java]\n----\npublic void pt_role_prompting_2(ChatClient chatClient) {\n String humorousTravelSuggestions = chatClient\n .prompt()\n .system(\"\"\"\n I want you to act as a travel guide. I will write to you about\n my location and you will suggest 3 places to visit near me in\n a humorous style.\n \"\"\")\n .user(\"\"\"\n My suggestion: \"I am in Amsterdam and I want to visit only museums.\"\n Travel Suggestions:\n \"\"\")\n .call()\n .content();\n}\n----\n\nThis technique is particularly effective for specialized domain knowledge, achieving a consistent tone across responses, and creating more engaging, personalized interactions with users.\n\n*Reference:* Shanahan, M., et al. (2023). \"Role-Play with Large Language Models.\" arXiv:2305.16367. link:https://arxiv.org/abs/2305.16367[https://arxiv.org/abs/2305.16367]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Role Prompting", "heading_level": 4, "file_order": 25, "section_index": 13, "content_hash": "836aed263acf1b2c7435dd3e958f63b072e6af1eaf3bd8b94b9409087e342e7f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:73dbea06ac4c7752f8f806bb181135a8ba7eb3b6378308c48a5431f5eb1f3758", "content": "Contextual prompting provides additional background information to the model by passing context parameters. This technique enriches the model's understanding of the specific situation, enabling more relevant and tailored responses without cluttering the main instruction.\n\nBy supplying contextual information, you help the model understand the specific domain, audience, constraints, or background facts relevant to the current query. This leads to more accurate, relevant, and appropriately framed responses.\n\n[source,java]\n----\npublic void pt_contextual_prompting(ChatClient chatClient) {\n String articleSuggestions = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Suggest 3 topics to write an article about with a few lines of\n description of what this article should contain.\n\n Context: {context}\n \"\"\")\n .param(\"context\", \"You are writing for a blog about retro 80's arcade video games.\"))\n .call()\n .content();\n}\n----\n\nSpring AI makes contextual prompting clean with the param() method to inject context variables. This technique is particularly valuable when the model needs specific domain knowledge, when adapting responses to particular audiences or scenarios, and for ensuring responses are aligned with particular constraints or requirements.\n\n*Reference:* Liu, P., et al. (2021). \"What Makes Good In-Context Examples for GPT-3?\" arXiv:2101.06804. link:https://arxiv.org/abs/2101.06804[https://arxiv.org/abs/2101.06804]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Contextual Prompting", "heading_level": 4, "file_order": 25, "section_index": 14, "content_hash": "73dbea06ac4c7752f8f806bb181135a8ba7eb3b6378308c48a5431f5eb1f3758", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:17723811a93805c83e9944d3a14826d920a459522227e4c64cecc51c7f279636", "content": "Step-back prompting breaks complex requests into simpler steps by first acquiring background knowledge. This technique encourages the model to first \"step back\" from the immediate question to consider the broader context, fundamental principles, or general knowledge relevant to the problem before addressing the specific query.\n\nBy decomposing complex problems into more manageable components and establishing foundational knowledge first, the model can provide more accurate responses to difficult questions.\n\n[source,java]\n----\npublic void pt_step_back_prompting(ChatClient.Builder chatClientBuilder) {\n // Set common options for the chat client\n var chatClient = chatClientBuilder\n .defaultOptions(ChatOptions.builder()\n .model(\"claude-3-7-sonnet-latest\")\n .temperature(1.0)\n .topK(40)\n .topP(0.8)\n .maxTokens(1024)\n .build())\n .build();\n\n // First get high-level concepts\n String stepBack = chatClient\n .prompt(\"\"\"\n Based on popular first-person shooter action games, what are\n 5 fictional key settings that contribute to a challenging and\n engaging level storyline in a first-person shooter video game?\n \"\"\")\n .call()\n .content();\n\n // Then use those concepts in the main task\n String story = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Write a one paragraph storyline for a new level of a first-\n person shooter video game that is challenging and engaging.\n\n Context: {step-back}\n \"\"\")\n .param(\"step-back\", stepBack))\n .call()\n .content();\n}\n----\n\nStep-back prompting is particularly effective for complex reasoning tasks, problems requiring specialized domain knowledge, and when you want more comprehensive and thoughtful responses rather than immediate answers.\n\n*Reference:* Zheng, Z., et al. (2023). \"Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models.\" arXiv:2310.06117. link:https://arxiv.org/abs/2310.06117[https://arxiv.org/abs/2310.06117]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.4 Step-Back Prompting", "heading_level": 3, "file_order": 25, "section_index": 15, "content_hash": "17723811a93805c83e9944d3a14826d920a459522227e4c64cecc51c7f279636", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:dfefaa543a8767a73f3802f0692240fb349dbedcd38645ef6c1a04d14b7e7160", "content": "Chain of Thought prompting encourages the model to reason step-by-step through a problem, which improves accuracy for complex reasoning tasks. By explicitly asking the model to show its work or think through a problem in logical steps, you can dramatically improve performance on tasks requiring multi-step reasoning.\n\nCoT works by encouraging the model to generate intermediate reasoning steps before producing a final answer, similar to how humans solve complex problems. This makes the model's thinking process explicit and helps it arrive at more accurate conclusions.\n\n[source,java]\n----\npublic void pt_chain_of_thought_zero_shot(ChatClient chatClient) {\n String output = chatClient\n .prompt(\"\"\"\n When I was 3 years old, my partner was 3 times my age. Now,\n I am 20 years old. How old is my partner?\n\n Let's think step by step.\n \"\"\")\n .call()\n .content();\n}\n\npublic void pt_chain_of_thought_singleshot_fewshots(ChatClient chatClient) {\n String output = chatClient\n .prompt(\"\"\"\n Q: When my brother was 2 years old, I was double his age. Now\n I am 40 years old. How old is my brother? Let's think step\n by step.\n A: When my brother was 2 years, I was 2 * 2 = 4 years old.\n That's an age difference of 2 years and I am older. Now I am 40\n years old, so my brother is 40 - 2 = 38 years old. The answer\n is 38.\n Q: When I was 3 years old, my partner was 3 times my age. Now,\n I am 20 years old. How old is my partner? Let's think step\n by step.\n A:\n \"\"\")\n .call()\n .content();\n}\n----\n\nThe key phrase \"Let's think step by step\" triggers the model to show its reasoning process. CoT is especially valuable for mathematical problems, logical reasoning tasks, and any question requiring multi-step reasoning. It helps reduce errors by making intermediate reasoning explicit.\n\n*Reference:* Wei, J., et al. (2022). \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.\" arXiv:2201.11903. link:https://arxiv.org/abs/2201.11903[https://arxiv.org/abs/2201.11903]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.5 Chain of Thought (CoT)", "heading_level": 3, "file_order": 25, "section_index": 16, "content_hash": "dfefaa543a8767a73f3802f0692240fb349dbedcd38645ef6c1a04d14b7e7160", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:fea42aeac807fe62bf9abefa3101e86c6e77f4013b4ffd56f1e99c0abf38eeff", "content": "Self-consistency involves running the model multiple times and aggregating results for more reliable answers. This technique addresses the variability in LLM outputs by sampling diverse reasoning paths for the same problem and selecting the most consistent answer through majority voting.\n\nBy generating multiple reasoning paths with different temperature or sampling settings, then aggregating the final answers, self-consistency improves accuracy on complex reasoning tasks. It's essentially an ensemble method for LLM outputs.\n\n[source,java]\n----\npublic void pt_self_consistency(ChatClient chatClient) {\n String email = \"\"\"\n Hi,\n I have seen you use Wordpress for your website. A great open\n source content management system. I have used it in the past\n too. It comes with lots of great user plugins. And it's pretty\n easy to set up.\n I did notice a bug in the contact form, which happens when\n you select the name field. See the attached screenshot of me\n entering text in the name field. Notice the JavaScript alert\n box that I inv0k3d.\n But for the rest it's a great website. I enjoy reading it. Feel\n free to leave the bug in the website, because it gives me more\n interesting things to read.\n Cheers,\n Harry the Hacker.\n \"\"\";\n\n record EmailClassification(Classification classification, String reasoning) {\n enum Classification {\n IMPORTANT, NOT_IMPORTANT\n }\n }\n\n int importantCount = 0;\n int notImportantCount = 0;\n\n // Run the model 5 times with the same input\n for (int i = 0; i < 5; i++) {\n EmailClassification output = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Email: {email}\n Classify the above email as IMPORTANT or NOT IMPORTANT. Let's\n think step by step and explain why.\n \"\"\")\n .param(\"email\", email))\n .options(ChatOptions.builder()\n .temperature(1.0) // Higher temperature for more variation\n .build())\n .call()\n .entity(EmailClassification.class);\n\n // Count results\n if (output.classification() == EmailClassification.Classification.IMPORTANT) {\n importantCount++;\n } else {\n notImportantCount++;\n }\n }\n\n // Determine the final classification by majority vote\n String finalClassification = importantCount > notImportantCount ?\n \"IMPORTANT\" : \"NOT IMPORTANT\";\n}\n----\n\nSelf-consistency is particularly valuable for high-stakes decisions, complex reasoning tasks, and when you need more confident answers than a single response can provide. The trade-off is increased computational cost and latency due to multiple API calls.\n\n*Reference:* Wang, X., et al. (2022). \"Self-Consistency Improves Chain of Thought Reasoning in Language Models.\" arXiv:2203.11171. link:https://arxiv.org/abs/2203.11171[https://arxiv.org/abs/2203.11171]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.6 Self-Consistency", "heading_level": 3, "file_order": 25, "section_index": 17, "content_hash": "fea42aeac807fe62bf9abefa3101e86c6e77f4013b4ffd56f1e99c0abf38eeff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:173c46568130515b0c6c6b3d810cae2d0a8f56b0387ea6e59dce0ce6d2144c0f", "content": "Tree of Thoughts (ToT) is an advanced reasoning framework that extends Chain of Thought by exploring multiple reasoning paths simultaneously. It treats problem-solving as a search process where the model generates different intermediate steps, evaluates their promise, and explores the most promising paths.\n\nThis technique is particularly powerful for complex problems with multiple possible approaches or when the solution requires exploring various alternatives before finding the optimal path.\n\n[NOTE]\n====\nThe original \"Prompt Engineering\" guide doesn't provide implementation examples for ToT, likely due to its complexity. Below is a simplified example that demonstrates the core concept.\n====\n\nGame Solving ToT Example:\n\n[source,java]\n----\npublic void pt_tree_of_thoughts_game(ChatClient chatClient) {\n // Step 1: Generate multiple initial moves\n String initialMoves = chatClient\n .prompt(\"\"\"\n You are playing a game of chess. The board is in the starting position.\n Generate 3 different possible opening moves. For each move:\n 1. Describe the move in algebraic notation\n 2. Explain the strategic thinking behind this move\n 3. Rate the move's strength from 1-10\n \"\"\")\n .options(ChatOptions.builder()\n .temperature(0.7)\n .build())\n .call()\n .content();\n\n // Step 2: Evaluate and select the most promising move\n String bestMove = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Analyze these opening moves and select the strongest one:\n {moves}\n\n Explain your reasoning step by step, considering:\n 1. Position control\n 2. Development potential\n 3. Long-term strategic advantage\n\n Then select the single best move.\n \"\"\").param(\"moves\", initialMoves))\n .call()\n .content();\n\n // Step 3: Explore future game states from the best move\n String gameProjection = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Based on this selected opening move:\n {best_move}\n\n Project the next 3 moves for both players. For each potential branch:\n 1. Describe the move and counter-move\n 2. Evaluate the resulting position\n 3. Identify the most promising continuation\n\n Finally, determine the most advantageous sequence of moves.\n \"\"\").param(\"best_move\", bestMove))\n .call()\n .content();\n}\n----\n\n*Reference:* Yao, S., et al. (2023). \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models.\" arXiv:2305.10601. link:https://arxiv.org/abs/2305.10601[https://arxiv.org/abs/2305.10601]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.7 Tree of Thoughts (ToT)", "heading_level": 3, "file_order": 25, "section_index": 18, "content_hash": "173c46568130515b0c6c6b3d810cae2d0a8f56b0387ea6e59dce0ce6d2144c0f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:57f3d3bdb319123e1aa206a2c34a26d5a7bb6fc23839d7eb51eadfd9ef2d7126", "content": "Automatic Prompt Engineering uses the AI to generate and evaluate alternative prompts. This meta-technique leverages the language model itself to create, refine, and benchmark different prompt variations to find optimal formulations for specific tasks.\n\nBy systematically generating and evaluating prompt variations, APE can find more effective prompts than manual engineering, especially for complex tasks. It's a way of using AI to improve its own performance.\n\n[source,java]\n----\npublic void pt_automatic_prompt_engineering(ChatClient chatClient) {\n // Generate variants of the same request\n String orderVariants = chatClient\n .prompt(\"\"\"\n We have a band merchandise t-shirt webshop, and to train a\n chatbot we need various ways to order: \"One Metallica t-shirt\n size S\". Generate 10 variants, with the same semantics but keep\n the same meaning.\n \"\"\")\n .options(ChatOptions.builder()\n .temperature(1.0) // High temperature for creativity\n .build())\n .call()\n .content();\n\n // Evaluate and select the best variant\n String output = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Please perform BLEU (Bilingual Evaluation Understudy) evaluation on the following variants:\n ----\n {variants}\n ----\n\n Select the instruction candidate with the highest evaluation score.\n \"\"\").param(\"variants\", orderVariants))\n .call()\n .content();\n}\n----\n\nAPE is particularly valuable for optimizing prompts for production systems, addressing challenging tasks where manual prompt engineering has reached its limits, and for systematically improving prompt quality at scale.\n\n*Reference:* Zhou, Y., et al. (2022). \"Large Language Models Are Human-Level Prompt Engineers.\" arXiv:2211.01910. link:https://arxiv.org/abs/2211.01910[https://arxiv.org/abs/2211.01910]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.8 Automatic Prompt Engineering", "heading_level": 3, "file_order": 25, "section_index": 19, "content_hash": "57f3d3bdb319123e1aa206a2c34a26d5a7bb6fc23839d7eb51eadfd9ef2d7126", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:c5800a8f66913f98c15996d3719988448d7cad5380af968103fd86f084138c47", "content": "Code prompting refers to specialized techniques for code-related tasks. These techniques leverage LLMs' ability to understand and generate programming languages, enabling them to write new code, explain existing code, debug issues, and translate between languages.\n\nEffective code prompting typically involves clear specifications, appropriate context (libraries, frameworks, style guidelines), and sometimes examples of similar code. Temperature settings tend to be lower (0.1-0.3) for more deterministic outputs.\n\n[source,java]\n----\npublic void pt_code_prompting_writing_code(ChatClient chatClient) {\n String bashScript = chatClient\n .prompt(\"\"\"\n Write a code snippet in Bash, which asks for a folder name.\n Then it takes the contents of the folder and renames all the\n files inside by prepending the name draft to the file name.\n \"\"\")\n .options(ChatOptions.builder()\n .temperature(0.1) // Low temperature for deterministic code\n .build())\n .call()\n .content();\n}\n\npublic void pt_code_prompting_explaining_code(ChatClient chatClient) {\n String code = \"\"\"\n #!/bin/bash\n echo \"Enter the folder name: \"\n read folder_name\n if [ ! -d \"$folder_name\" ]; then\n echo \"Folder does not exist.\"\n exit 1\n fi\n files=( \"$folder_name\"/* )\n for file in \"${files[@]}\"; do\n new_file_name=\"draft_$(basename \"$file\")\"\n mv \"$file\" \"$new_file_name\"\n done\n echo \"Files renamed successfully.\"\n \"\"\";\n\n String explanation = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Explain to me the below Bash code:\n ```\n {code}\n ```\n \"\"\").param(\"code\", code))\n .call()\n .content();\n}\n\npublic void pt_code_prompting_translating_code(ChatClient chatClient) {\n String bashCode = \"\"\"\n #!/bin/bash\n echo \"Enter the folder name: \"\n read folder_name\n if [ ! -d \"$folder_name\" ]; then\n echo \"Folder does not exist.\"\n exit 1\n fi\n files=( \"$folder_name\"/* )\n for file in \"${files[@]}\"; do\n new_file_name=\"draft_$(basename \"$file\")\"\n mv \"$file\" \"$new_file_name\"\n done\n echo \"Files renamed successfully.\"\n \"\"\";\n\n String pythonCode = chatClient\n .prompt()\n .user(u -> u.text(\"\"\"\n Translate the below Bash code to a Python snippet:\n {code}\n \"\"\").param(\"code\", bashCode))\n .call()\n .content();\n}\n----\n\nCode prompting is especially valuable for automated code documentation, prototyping, learning programming concepts, and translating between programming languages. The effectiveness can be further enhanced by combining it with techniques like few-shot prompting or chain-of-thought.\n\n*Reference:* Chen, M., et al. (2021). \"Evaluating Large Language Models Trained on Code.\" arXiv:2107.03374. link:https://arxiv.org/abs/2107.03374[https://arxiv.org/abs/2107.03374]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "2.9 Code Prompting", "heading_level": 3, "file_order": 25, "section_index": 20, "content_hash": "c5800a8f66913f98c15996d3719988448d7cad5380af968103fd86f084138c47", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:72692e043348045a20b8d0b021189a677d0760370fc036deb822ee639547303f", "content": "Spring AI provides an elegant Java API for implementing all major prompt engineering techniques. By combining these techniques with Spring's powerful entity mapping and fluent API, developers can build sophisticated AI-powered applications with clean, maintainable code.\n\nThe most effective approach often involves combining multiple techniques - for example, using system prompts with few-shot examples, or chain-of-thought with role prompting. Spring AI's flexible API makes these combinations straightforward to implement.\n\nFor production applications, remember to:\n\n1. Test prompts with different parameters (temperature, top-k, top-p)\n2. Consider using self-consistency for critical decision-making\n3. Leverage Spring AI's entity mapping for type-safe responses\n4. Use contextual prompting to provide application-specific knowledge\n\nWith these techniques and Spring AI's powerful abstractions, you can create robust AI-powered applications that deliver consistent, high-quality results.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "Conclusion", "heading_level": 2, "file_order": 25, "section_index": 21, "content_hash": "72692e043348045a20b8d0b021189a677d0760370fc036deb822ee639547303f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:1ff490c7685f547db5c39cb34683d8539ea42259a24da3f1c3666ebff52e57a8", "content": "1. Brown, T. B., et al. (2020). \"Language Models are Few-Shot Learners.\" arXiv:2005.14165.\n2. Wei, J., et al. (2022). \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.\" arXiv:2201.11903.\n3. Wang, X., et al. (2022). \"Self-Consistency Improves Chain of Thought Reasoning in Language Models.\" arXiv:2203.11171.\n4. Yao, S., et al. (2023). \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models.\" arXiv:2305.10601.\n5. Zhou, Y., et al. (2022). \"Large Language Models Are Human-Level Prompt Engineers.\" arXiv:2211.01910.\n6. Zheng, Z., et al. (2023). \"Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models.\" arXiv:2310.06117.\n7. Liu, P., et al. (2021). \"What Makes Good In-Context Examples for GPT-3?\" arXiv:2101.06804.\n8. Shanahan, M., et al. (2023). \"Role-Play with Large Language Models.\" arXiv:2305.16367.\n9. Chen, M., et al. (2021). \"Evaluating Large Language Models Trained on Code.\" arXiv:2107.03374.\n10. link:https://docs.spring.io/spring-ai/reference/index.html[Spring AI Documentation]\n11. link:https://docs.spring.io/spring-ai/reference/api/chatclient.html[ChatClient API Reference]\n12. link:https://www.kaggle.com/whitepaper-prompt-engineering[Google's Prompt Engineering Guide]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc", "title": "prompt-engineering-patterns", "heading": "References", "heading_level": 2, "file_order": 25, "section_index": 22, "content_hash": "1ff490c7685f547db5c39cb34683d8539ea42259a24da3f1c3666ebff52e57a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/prompt-engineering-patterns.adoc"}}
{"id": "sha256:f64bb226119df9770e320773469b404e8ef84cf156e02ab8e1b7aeec082fe4d6", "content": "This functionality has been moved to the Spring AI Community repository.\n\nPlease visit https://github.com/spring-ai-community/qianfan for the latest version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/qianfan-chat.adoc", "title": "QianFan Chat", "heading": "QianFan Chat", "heading_level": 1, "file_order": 26, "section_index": 0, "content_hash": "f64bb226119df9770e320773469b404e8ef84cf156e02ab8e1b7aeec082fe4d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/qianfan-chat.adoc"}}
{"id": "sha256:8e35b000172f379fa770b9490bf4ea345e7d94f242ec7fdf9baa81c7286216e9", "content": "The https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview[Vertex AI Gemini API] allows developers to build generative AI applications using the Gemini model.\nThe Vertex AI Gemini API supports multimodal prompts as input and output text or code.\nA multimodal model is a model that is capable of processing information from multiple modalities, including images, videos, and text. For example, you can send the model a photo of a plate of cookies and ask it to give you a recipe for those cookies.\n\nGemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to the link:https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash[Gemini 2.0 Flash] and link:https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash-lite[Gemini 2.0 Flash-Lite].\nFor specifications of the Vertex AI Gemini API models, see link:https://cloud.google.com/vertex-ai/generative-ai/docs/models#gemini-models[Model information].\n\nlink:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference[Gemini API Reference]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "VertexAI Gemini Chat", "heading_level": 1, "file_order": 27, "section_index": 0, "content_hash": "8e35b000172f379fa770b9490bf4ea345e7d94f242ec7fdf9baa81c7286216e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:7473e5fa174ecb61cbc32cd14b1e90195d6f16184dec9e4d76142099f0375c34", "content": "- Install the link:https://cloud.google.com/sdk/docs/install[gcloud] CLI, appropriate for you OS.\n- Authenticate by running the following command.\nReplace `PROJECT_ID` with your Google Cloud project ID and `ACCOUNT` with your Google Cloud username.\n\n[source]\n----\ngcloud config set project <PROJECT_ID> &&\ngcloud auth application-default login <ACCOUNT>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 27, "section_index": 1, "content_hash": "7473e5fa174ecb61cbc32cd14b1e90195d6f16184dec9e4d76142099f0375c34", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:769ea63d11ab1b464ab56e4374a12239ac420547f5a569c7fe04109fbff3bd4d", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the VertexAI Gemini Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-vertex-ai-gemini</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-vertex-ai-gemini'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 27, "section_index": 2, "content_hash": "769ea63d11ab1b464ab56e4374a12239ac420547f5a569c7fe04109fbff3bd4d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:33cfcf380d5f1afd37ac593ce36f8aebcb3f63bd24c683d6ddcd2a65f08a45ff", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=vertexai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match vertexai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.vertex.ai.gemini` is used as the property prefix that lets you connect to VertexAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.model.chat | Enable Chat Model client | vertexai\n| spring.ai.vertex.ai.gemini.project-id | Google Cloud Platform project ID | -\n| spring.ai.vertex.ai.gemini.location | Region | -\n| spring.ai.vertex.ai.gemini.credentials-uri | URI to Vertex AI Gemini credentials. When provided it is used to create an a `GoogleCredentials` instance to authenticate the `VertexAI`. | -\n| spring.ai.vertex.ai.gemini.api-endpoint | Vertex AI Gemini API endpoint. | -\n| spring.ai.vertex.ai.gemini.scopes | | -\n| spring.ai.vertex.ai.gemini.transport | API transport. GRPC or REST. | GRPC\n|====\n\nThe prefix `spring.ai.vertex.ai.gemini.chat` is the property prefix that lets you configure the chat model implementation for VertexAI Gemini Chat.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.vertex.ai.gemini.chat.options.model | Supported https://cloud.google.com/vertex-ai/generative-ai/docs/models#gemini-models[Vertex AI Gemini Chat model] to use include the `gemini-2.0-flash`, `gemini-2.0-flash-lite` and the new `gemini-2.5-pro-preview-03-25`, `gemini-2.5-flash-preview-04-17` models. | gemini-2.0-flash\n| spring.ai.vertex.ai.gemini.chat.options.response-mime-type | Output response mimetype of the generated candidate text. | `text/plain`: (default) Text output or `application/json`: JSON response.\n| spring.ai.vertex.ai.gemini.chat.options.response-schema | String, containing the output response schema in OpenAPI format, as described in https://ai.google.dev/gemini-api/docs/structured-output#json-schemas. | -\n| spring.ai.vertex.ai.gemini.chat.options.google-search-retrieval | Use Google search Grounding feature | `true` or `false`, default `false`.\n| spring.ai.vertex.ai.gemini.chat.options.temperature | Controls the randomness of the output. Values can range over [0.0,1.0], inclusive. A value closer to 1.0 will produce responses that are more varied, while a value closer to 0.0 will typically result in less surprising responses from the generative. This value specifies default to be used by the backend while making the call to the generative. | -\n| spring.ai.vertex.ai.gemini.chat.options.top-k | The maximum number of tokens to consider when sampling. The generative uses combined Top-k and nucleus sampling. Top-k sampling considers the set of topK most probable tokens. | -\n| spring.ai.vertex.ai.gemini.chat.options.top-p | The maximum cumulative probability of tokens to consider when sampling. The generative uses combined Top-k and nucleus sampling. Nucleus sampling considers the smallest set of tokens whose probability sum is at least topP. | -\n| spring.ai.vertex.ai.gemini.chat.options.candidate-count | The number of generated response messages to return. This value must be between [1, 8], inclusive. Defaults to 1. | 1\n| spring.ai.vertex.ai.gemini.chat.options.max-output-tokens | The maximum number of tokens to generate. | -\n| spring.ai.vertex.ai.gemini.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.vertex.ai.gemini.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.vertex.ai.gemini.chat.options.internal-tool-execution-enabled | If true, the tool execution should be performed, otherwise the response from the model is returned back to the user. Default is null, but if it's null, `ToolCallingChatOptions.DEFAULT_TOOL_EXECUTION_ENABLED` which is true will take into account | -\n| spring.ai.vertex.ai.gemini.chat.options.safety-settings | List of safety settings to control safety filters, as defined by https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters[Vertex AI Safety Filters]. Each safety setting can have a method, threshold, and category. | -\n\n|====\n\nTIP: All properties prefixed with `spring.ai.vertex.ai.gemini.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Chat Properties", "heading_level": 3, "file_order": 27, "section_index": 3, "content_hash": "33cfcf380d5f1afd37ac593ce36f8aebcb3f63bd24c683d6ddcd2a65f08a45ff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:8e010b959c1c6b76bf973dd919397ab54f3f8dc75c056d1756856bee11ac548f", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-vertex-ai-gemini/src/main/java/org/springframework/ai/vertexai/gemini/VertexAiGeminiChatOptions.java[VertexAiGeminiChatOptions.java] provides model configurations, such as the temperature, the topK, etc.\n\nOn start-up, the default options can be configured with the `VertexAiGeminiChatModel(api, options)` constructor or the `spring.ai.vertex.ai.chat.options.*` properties.\n\nAt runtime, you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example, to override the default temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n VertexAiGeminiChatOptions.builder()\n .temperature(0.4)\n .build()\n ));\n----\n\nTIP: In addition to the model specific `VertexAiGeminiChatOptions` you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Runtime options [[chat-options]]", "heading_level": 2, "file_order": 27, "section_index": 4, "content_hash": "8e010b959c1c6b76bf973dd919397ab54f3f8dc75c056d1756856bee11ac548f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:b0a4356cc62913d7ec8a0536781118705defea5d48588622edd29803d8b912fd", "content": "The Vertex AI Gemini model supports tool calling (in Google Gemini context, it's called `function calling`) capabilities, allowing models to use tools during conversations.\nHere's an example of how to define and use `@Tool`-based tools:\n\n[source,java]\n----\n\npublic class WeatherService {\n\n @Tool(description = \"Get the weather in location\")\n public String weatherByLocation(@ToolParam(description= \"City or state name\") String location) {\n ...\n }\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .tools(new WeatherService())\n .call()\n .content();\n----\n\nYou can use the java.util.function beans as tools as well:\n\n[source,java]\n----\n@Bean\n@Description(\"Get the weather in location. Return temperature in 36°F or 36°C format.\")\npublic Function<Request, Response> weatherFunction() {\n return new MockWeatherService();\n}\n\nString response = ChatClient.create(this.chatModel)\n .prompt(\"What's the weather like in Boston?\")\n .toolNames(\"weatherFunction\")\n .inputType(Request.class)\n .call()\n .content();\n----\n\nFind more in xref:api/tools.adoc[Tools] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Tool Calling", "heading_level": 2, "file_order": 27, "section_index": 5, "content_hash": "b0a4356cc62913d7ec8a0536781118705defea5d48588622edd29803d8b912fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:bee3347cadf71fcd7dd1cc21b272d426899dc772560776072157225c5d3afcec", "content": "Multimodality refers to a model's ability to simultaneously understand and process information from various (input) sources, including `text`, `pdf`, `images`, `audio`, and other data formats.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Multimodal", "heading_level": 2, "file_order": 27, "section_index": 6, "content_hash": "bee3347cadf71fcd7dd1cc21b272d426899dc772560776072157225c5d3afcec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:2293449fa0d7653e9e28c46a34668e5aefcea90b3448e7f1095433927fde132c", "content": "Google's Gemini AI models support this capability by comprehending and integrating text, code, audio, images, and video.\nFor more details, refer to the blog post https://blog.google/technology/ai/google-gemini-ai/#introducing-gemini[Introducing Gemini].\n\nSpring AI's `Message` interface supports multimodal AI models by introducing the Media type.\nThis type contains data and information about media attachments in messages, using Spring's `org.springframework.util.MimeType` and a `java.lang.Object` for the raw media data.\n\nBelow is a simple code example extracted from https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-vertex-ai-gemini/src/test/java/org/springframework/ai/vertexai/gemini/VertexAiGeminiChatModelIT.java[VertexAiGeminiChatModelIT#multiModalityTest()], demonstrating the combination of user text with an image.\n\n[source,java]\n----\nbyte[] data = new ClassPathResource(\"/vertex-test.png\").getContentAsByteArray();\n\nvar userMessage = new UserMessage(\"Explain what do you see on this picture?\",\n List.of(new Media(MimeTypeUtils.IMAGE_PNG, this.data)));\n\nChatResponse response = chatModel.call(new Prompt(List.of(this.userMessage)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Image, Audio, Video", "heading_level": 3, "file_order": 27, "section_index": 7, "content_hash": "2293449fa0d7653e9e28c46a34668e5aefcea90b3448e7f1095433927fde132c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:c1ca9f8bcd72c58c56d50fba03e7666cc024b46a7531db2aca8a9812d3d73409", "content": "Latest Vertex Gemini provides support for PDF input types..\nUse the `application/pdf` media type to attach a PDF file to the message:\n\n[source,java]\n----\nvar pdfData = new ClassPathResource(\"/spring-ai-reference-overview.pdf\");\n\nvar userMessage = new UserMessage(\n \"You are a very professional document summarization specialist. Please summarize the given document.\",\n List.of(new Media(new MimeType(\"application\", \"pdf\"), pdfData)));\n\nvar response = this.chatModel.call(new Prompt(List.of(userMessage)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "PDF", "heading_level": 3, "file_order": 27, "section_index": 8, "content_hash": "c1ca9f8bcd72c58c56d50fba03e7666cc024b46a7531db2aca8a9812d3d73409", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:12433cb84ba5fd2118e77f874006eec2b15f7601f0c17ea4ac1cc10e443ba004", "content": "The Vertex AI Gemini API provides safety filtering capabilities to help you control harmful content in both prompts and responses.\nFor more details, see the https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters[Vertex AI Safety Filters documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Safety Settings and Safety Ratings", "heading_level": 2, "file_order": 27, "section_index": 9, "content_hash": "12433cb84ba5fd2118e77f874006eec2b15f7601f0c17ea4ac1cc10e443ba004", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:9ee4e6264d67807f97ceaece3e57dbf551c19233b3df5c1aacd3230761ce4372", "content": "You can configure safety settings to control the threshold at which content is blocked for different harm categories.\nThe available harm categories are:\n\n* `HARM_CATEGORY_HATE_SPEECH` - Hate speech content\n* `HARM_CATEGORY_DANGEROUS_CONTENT` - Dangerous content\n* `HARM_CATEGORY_HARASSMENT` - Harassment content\n* `HARM_CATEGORY_SEXUALLY_EXPLICIT` - Sexually explicit content\n* `HARM_CATEGORY_CIVIC_INTEGRITY` - Civic integrity content\n\nThe available threshold levels are:\n\n* `BLOCK_LOW_AND_ABOVE` - Block when low, medium, or high probability of unsafe content\n* `BLOCK_MEDIUM_AND_ABOVE` - Block when medium or high probability of unsafe content\n* `BLOCK_ONLY_HIGH` - Block only when high probability of unsafe content\n* `BLOCK_NONE` - Never block (use with caution)\n\n[source,java]\n----\nList<VertexAiGeminiSafetySetting> safetySettings = List.of(\n VertexAiGeminiSafetySetting.builder()\n .withCategory(VertexAiGeminiSafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT)\n .withThreshold(VertexAiGeminiSafetySetting.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE)\n .build(),\n VertexAiGeminiSafetySetting.builder()\n .withCategory(VertexAiGeminiSafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH)\n .withThreshold(VertexAiGeminiSafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE)\n .build());\n\nChatResponse response = chatModel.call(new Prompt(\"Your prompt here\",\n VertexAiGeminiChatOptions.builder()\n .safetySettings(safetySettings)\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Configuring Safety Settings", "heading_level": 3, "file_order": 27, "section_index": 10, "content_hash": "9ee4e6264d67807f97ceaece3e57dbf551c19233b3df5c1aacd3230761ce4372", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:eb0bc7e197b81152d4bedcb9419a7d4be171cd760061ebdcbda0b1ed501c5ec3", "content": "When safety settings are configured, the Gemini API returns safety ratings for each response candidate.\nThese ratings indicate the probability and severity of harmful content in each category.\n\nSafety ratings are available in the `AssistantMessage` metadata under the key `\"safetyRatings\"`:\n\n[source,java]\n----\nChatResponse response = chatModel.call(new Prompt(prompt,\n VertexAiGeminiChatOptions.builder()\n .safetySettings(safetySettings)\n .build()));\n\nList<VertexAiGeminiSafetyRating> safetyRatings =\n (List<VertexAiGeminiSafetyRating>) response.getResult()\n .getOutput()\n .getMetadata()\n .get(\"safetyRatings\");\n\nfor (VertexAiGeminiSafetyRating rating : safetyRatings) {\n System.out.println(\"Category: \" + rating.category());\n System.out.println(\"Probability: \" + rating.probability());\n System.out.println(\"Severity: \" + rating.severity());\n System.out.println(\"Blocked: \" + rating.blocked());\n}\n----\n\nThe `VertexAiGeminiSafetyRating` record contains:\n\n* `category` - The harm category (e.g., `HARM_CATEGORY_HARASSMENT`)\n* `probability` - The probability level (`NEGLIGIBLE`, `LOW`, `MEDIUM`, `HIGH`)\n* `blocked` - Whether the content was blocked due to this rating\n* `probabilityScore` - The raw probability score (0.0 to 1.0)\n* `severity` - The severity level (`HARM_SEVERITY_NEGLIGIBLE`, `HARM_SEVERITY_LOW`, `HARM_SEVERITY_MEDIUM`, `HARM_SEVERITY_HIGH`)\n* `severityScore` - The raw severity score (0.0 to 1.0)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Accessing Safety Ratings in Responses", "heading_level": 3, "file_order": 27, "section_index": 11, "content_hash": "eb0bc7e197b81152d4bedcb9419a7d4be171cd760061ebdcbda0b1ed501c5ec3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:b949ede061f4c872f6f09a1c805bbd13a173e9d1f5859cc78c07791a669f1003", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-vertex-ai-gemini` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the VertexAi chat model:\n\n[source,application.properties]\n----\nspring.ai.vertex.ai.gemini.project-id=PROJECT_ID\nspring.ai.vertex.ai.gemini.location=LOCATION\nspring.ai.vertex.ai.gemini.chat.options.model=gemini-2.0-flash\nspring.ai.vertex.ai.gemini.chat.options.temperature=0.5\n----\n\nTIP: Replace the `project-id` with your Google Cloud Project ID and `location` is Google Cloud Region\nlike `us-central1`, `europe-west1`, etc...\n\n[NOTE]\n====\nEach model has its own set of supported regions, you can find the list of supported regions in the model page.\n\nFor example, model=`gemini-2.5-flash` is currently available in `us-central1` region only, you must set location=`us-central1`,\nfollowing the model page link:https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash[Gemini 2.5 Flash - Supported Regions].\n====\n\nThis will create a `VertexAiGeminiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final VertexAiGeminiChatModel chatModel;\n\n @Autowired\n public ChatController(VertexAiGeminiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(\"/ai/generateStream\")\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n Prompt prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 27, "section_index": 12, "content_hash": "b949ede061f4c872f6f09a1c805bbd13a173e9d1f5859cc78c07791a669f1003", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:123be679ddda12a79b15200fcaff9bb950c8f1ac98d050d0a9ddc79850a087e0", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-vertex-ai-gemini/src/main/java/org/springframework/ai/vertexai/gemini/VertexAiGeminiChatModel.java[VertexAiGeminiChatModel] implements the `ChatModel` and uses the `VertexAI` to connect to the Vertex AI Gemini service.\n\nAdd the `spring-ai-vertex-ai-gemini` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-gemini</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-vertex-ai-gemini'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `VertexAiGeminiChatModel` and use it for text generations:\n\n[source,java]\n----\nVertexAI vertexApi = new VertexAI(projectId, location);\n\nvar chatModel = new VertexAiGeminiChatModel(this.vertexApi,\n VertexAiGeminiChatOptions.builder()\n .model(ChatModel.GEMINI_2_0_FLASH)\n .temperature(0.4)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `VertexAiGeminiChatOptions` provides the configuration information for the chat requests.\nThe `VertexAiGeminiChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 27, "section_index": 13, "content_hash": "123be679ddda12a79b15200fcaff9bb950c8f1ac98d050d0a9ddc79850a087e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:55f96389834fbf999781a97ec0b15d07f90eeedc9055eb0c036aa640b15054c5", "content": "Following class diagram illustrates the Vertex AI Gemini native Java API:\n\nimage::vertex-ai-gemini-native-api.jpg[w=800,align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc", "title": "VertexAI Gemini Chat", "heading": "Low-level Java Client [[low-level-api]]", "heading_level": 2, "file_order": 27, "section_index": 14, "content_hash": "55f96389834fbf999781a97ec0b15d07f90eeedc9055eb0c036aa640b15054c5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/vertexai-gemini-chat.adoc"}}
{"id": "sha256:97bf6a4f51271559579b267789055069e2300dd54278ab0fbd3b64f9cac836bf", "content": "Spring AI supports the various AI language models from ZhiPu AI. You can interact with ZhiPu AI language models and create a multilingual conversational assistant based on ZhiPuAI models.\n\nIf you're not a Chinese speaker, you can visit ZhiPuAI's international site https://z.ai/model-api[Z.ai]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "ZhiPu AI Chat", "heading_level": 1, "file_order": 28, "section_index": 0, "content_hash": "97bf6a4f51271559579b267789055069e2300dd54278ab0fbd3b64f9cac836bf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:e4edae80f04be72b9ca774c23aafdf5c4528cd4dd9d5ff8051fb85e849799dcf", "content": "You will need to create an API with ZhiPuAI to access ZhiPu AI language models.\n\nCreate an account at https://open.bigmodel.cn/login[ZhiPu AI registration page] (or https://chat.z.ai/auth[Z.ai registration page]) and generate the token on the https://open.bigmodel.cn/usercenter/apikeys[API Keys page] (or https://z.ai/manage-apikey/apikey-list[Z.ai API Keys page]).\n\nThe Spring AI project defines a configuration property named `spring.ai.zhipuai.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.zhipuai.api-key=<your-zhipuai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n zhipuai:\n api-key: ${ZHIPUAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport ZHIPUAI_API_KEY=<your-zhipuai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"ZHIPUAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 28, "section_index": 1, "content_hash": "e4edae80f04be72b9ca774c23aafdf5c4528cd4dd9d5ff8051fb85e849799dcf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:07df3e525d552a0ce025fcf670025931345deea78d7fae495a1f86a5c2b5f0ca", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 28, "section_index": 2, "content_hash": "07df3e525d552a0ce025fcf670025931345deea78d7fae495a1f86a5c2b5f0ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:74a0509704541beb05740e899ad2824279872d1908acd9a454e1ee15ec2527cd", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the ZhiPuAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-zhipuai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-zhipuai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 28, "section_index": 3, "content_hash": "74a0509704541beb05740e899ad2824279872d1908acd9a454e1ee15ec2527cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:40dc35264c7ae0e7577c1a1862356e187f3d67e2ea27da777f3a130d83aab9ca", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the ZhiPu AI chat model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 28, "section_index": 4, "content_hash": "40dc35264c7ae0e7577c1a1862356e187f3d67e2ea27da777f3a130d83aab9ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:2fd8569824356b8408369294d183c53aa138ab8b2f5b34712e0f9da9121db703", "content": "The prefix `spring.ai.zhipuai` is used as the property prefix that lets you connect to ZhiPuAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.zhipuai.base-url | The URL to connect to ZhiPuAI API. +\nIf you are using the Z.ai Platform, you need to set it to `https://api.z.ai/api/paas[https://api.z.ai/api/paas]`. | `https://open.bigmodel.cn/api/paas[https://open.bigmodel.cn/api/paas]`\n| spring.ai.zhipuai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 28, "section_index": 5, "content_hash": "2fd8569824356b8408369294d183c53aa138ab8b2f5b34712e0f9da9121db703", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:056841d650d9a6ee9bdf14d1bca944c52c0598be48560391c56c98a719103e7d", "content": "[NOTE]\n====\nEnabling and disabling of the chat auto-configurations are now configured via top level properties with the prefix `spring.ai.model.chat`.\n\nTo enable, spring.ai.model.chat=zhipuai (It is enabled by default)\n\nTo disable, spring.ai.model.chat=none (or any value which doesn't match zhipuai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.zhipuai.chat` is the property prefix that lets you configure the chat model implementation for ZhiPuAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.zhipuai.chat.enabled (Removed and no longer valid) | Enable ZhiPuAI chat model. | true\n| spring.ai.model.chat | Enable ZhiPuAI chat model. | zhipuai\n| spring.ai.zhipuai.chat.base-url | Optional overrides the spring.ai.zhipuai.base-url to provide chat specific url. +\nIf you are using the Z.ai Platform, you need to set it to `https://api.z.ai/api/paas[https://api.z.ai/api/paas]`. | `https://open.bigmodel.cn/api/paas[https://open.bigmodel.cn/api/paas]`\n| spring.ai.zhipuai.chat.api-key | Optional overrides the spring.ai.zhipuai.api-key to provide chat specific api-key. | -\n| spring.ai.zhipuai.chat.options.model | This is the ZhiPuAI Chat model to use. You can select between models such as: `glm-4.6`, `glm-4.5`, `glm-4-air`, and more. | `glm-4-air`\n| spring.ai.zhipuai.chat.options.maxTokens | The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. | -\n| spring.ai.zhipuai.chat.options.temperature | What sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both. | -\n| spring.ai.zhipuai.chat.options.topP | An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.. | 1.0\n| spring.ai.zhipuai.chat.options.stop | The model will stop generating characters specified by stop, and currently only supports a single stop word in the format of [\"stop_word1\"] | -\n| spring.ai.zhipuai.chat.options.user | A unique identifier representing your end-user, which can help ZhiPuAI to monitor and detect abuse. | -\n| spring.ai.zhipuai.chat.options.requestId | The parameter is passed by the client and must ensure uniqueness. It is used to distinguish the unique identifier for each request. If the client does not provide it, the platform will generate it by default. | -\n| spring.ai.zhipuai.chat.options.doSample | When do_sample is set to true, the sampling strategy is enabled. If do_sample is false, the sampling strategy parameters temperature and top_p will not take effect. | true\n| spring.ai.zhipuai.chat.options.response-format.type | Control the format of the model output. Set to `json_object` to ensure the message is a valid JSON object. Available options: `text` or `json_object`. | -\n| spring.ai.zhipuai.chat.options.thinking.type | Control whether to enable the large model's chain of thought. Available options: `enabled` or `disabled`. | -\n| spring.ai.zhipuai.chat.options.tool-names | List of tools, identified by their names, to enable for function calling in a single prompt request. Tools with those names must exist in the ToolCallback registry. | -\n| spring.ai.zhipuai.chat.options.tool-callbacks | Tool Callbacks to register with the ChatModel. | -\n| spring.ai.zhipuai.chat.options.internal-tool-execution-enabled | If false, the Spring AI will not handle the tool calls internally, but will proxy them to the client. Then it is the client's responsibility to handle the tool calls, dispatch them to the appropriate function, and return the results. If true (the default), the Spring AI will handle the function calls internally. Applicable only for chat models with function calling support | true\n|====\n\nNOTE: You can override the common `spring.ai.zhipuai.base-url` and `spring.ai.zhipuai.api-key` for the `ChatModel` implementations.\nThe `spring.ai.zhipuai.chat.base-url` and `spring.ai.zhipuai.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different ZhiPuAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.zhipuai.chat.options` can be overridden at runtime by adding a request specific <<chat-options>> to the `Prompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 28, "section_index": 6, "content_hash": "056841d650d9a6ee9bdf14d1bca944c52c0598be48560391c56c98a719103e7d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:b95f1203913bca2ec6858fbb31c5fa4e996b20436c29983dff36b4be0db075c1", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiChatOptions.java[ZhiPuAiChatOptions.java] provides model configurations, such as the model to use, the temperature, the frequency penalty, etc.\n\nOn start-up, the default options can be configured with the `ZhiPuAiChatModel(api, options)` constructor or the `spring.ai.zhipuai.chat.options.*` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `Prompt` call.\nFor example to override the default model and temperature for a specific request:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\n \"Generate the names of 5 famous pirates.\",\n ZhiPuAiChatOptions.builder()\n .model(ZhiPuAiApi.ChatModel.GLM_4_Air.getValue())\n .temperature(0.5)\n .build()\n ));\n----\n\nTIP: In addition to the model specific link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiChatOptions.java[ZhiPuAiChatOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Runtime Options [[chat-options]]", "heading_level": 2, "file_order": 28, "section_index": 7, "content_hash": "b95f1203913bca2ec6858fbb31c5fa4e996b20436c29983dff36b4be0db075c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:f38742ddd8052a179003c947596cc57cc99bf36eab871d7bf1db4385f045ac4c", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-zhipuai` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the ZhiPuAi chat model:\n\n[source,application.properties]\n----\nspring.ai.zhipuai.api-key=YOUR_API_KEY\nspring.ai.zhipuai.chat.options.model=glm-4-air\nspring.ai.zhipuai.chat.options.temperature=0.7\n----\n\nTIP: replace the `api-key` with your ZhiPuAI credentials.\n\nThis will create a `ZhiPuAiChatModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class ChatController {\n\n private final ZhiPuAiChatModel chatModel;\n\n @Autowired\n public ChatController(ZhiPuAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @GetMapping(\"/ai/generate\")\n public Map generate(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"generation\", this.chatModel.call(message));\n }\n\n @GetMapping(value = \"/ai/generateStream\", produces = MediaType.TEXT_EVENT_STREAM_VALUE)\n\tpublic Flux<ChatResponse> generateStream(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var prompt = new Prompt(new UserMessage(message));\n return this.chatModel.stream(prompt);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 28, "section_index": 8, "content_hash": "f38742ddd8052a179003c947596cc57cc99bf36eab871d7bf1db4385f045ac4c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:1534b191f119d64318687df223f99653bef8519d091219f69c36e9620d76a281", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiChatModel.java[ZhiPuAiChatModel] implements the `ChatModel` and `StreamingChatModel` and uses the <<low-level-api>> to connect to the ZhiPuAI service.\n\nAdd the `spring-ai-zhipuai` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-zhipuai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-zhipuai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `ZhiPuAiChatModel` and use it for text generations:\n\n[source,java]\n----\nvar zhiPuAiApi = new ZhiPuAiApi(System.getenv(\"ZHIPU_AI_API_KEY\"));\n\nvar chatModel = new ZhiPuAiChatModel(this.zhiPuAiApi, ZhiPuAiChatOptions.builder()\n .model(ZhiPuAiApi.ChatModel.GLM_4_Air.getValue())\n .temperature(0.4)\n .maxTokens(200)\n .build());\n\nChatResponse response = this.chatModel.call(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n\nFlux<ChatResponse> streamResponse = this.chatModel.stream(\n new Prompt(\"Generate the names of 5 famous pirates.\"));\n----\n\nThe `ZhiPuAiChatOptions` provides the configuration information for the chat requests.\nThe `ZhiPuAiChatOptions.Builder` is fluent options builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 28, "section_index": 9, "content_hash": "1534b191f119d64318687df223f99653bef8519d091219f69c36e9620d76a281", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:ff9f1d311d558a1a1faece134ab50b38e6ab6e634cc81de33a21c5ac74571d72", "content": "The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/api/ZhiPuAiApi.java[ZhiPuAiApi] provides is lightweight Java client for link:https://open.bigmodel.cn/dev/api[ZhiPu AI API].\n\nHere is a simple snippet how to use the api programmatically:\n\n[source,java]\n----\nZhiPuAiApi zhiPuAiApi =\n new ZhiPuAiApi(System.getenv(\"ZHIPU_AI_API_KEY\"));\n\nChatCompletionMessage chatCompletionMessage =\n new ChatCompletionMessage(\"Hello world\", Role.USER);\n\nResponseEntity<ChatCompletion> response = this.zhiPuAiApi.chatCompletionEntity(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), ZhiPuAiApi.ChatModel.GLM_4_Air.getValue(), 0.7, false));\n\nFlux<ChatCompletionChunk> streamResponse = this.zhiPuAiApi.chatCompletionStream(\n new ChatCompletionRequest(List.of(this.chatCompletionMessage), ZhiPuAiApi.ChatModel.GLM_4_Air.getValue(), 0.7, true));\n----\n\nFollow the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/api/ZhiPuAiApi.java[ZhiPuAiApi.java]'s JavaDoc for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "Low-level ZhiPuAiApi Client [[low-level-api]]", "heading_level": 3, "file_order": 28, "section_index": 10, "content_hash": "ff9f1d311d558a1a1faece134ab50b38e6ab6e634cc81de33a21c5ac74571d72", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:dd7abbe7e2c5a51f7f0e3b04ec7884fd83d33724f69449f3817b1061a0b4da3e", "content": "* The link:https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/test/java/org/springframework/ai/zhipuai/api/ZhiPuAiApiIT.java[ZhiPuAiApiIT.java] test provides some general examples how to use the lightweight library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc", "title": "ZhiPu AI Chat", "heading": "ZhiPuAiApi Samples", "heading_level": 4, "file_order": 28, "section_index": 11, "content_hash": "dd7abbe7e2c5a51f7f0e3b04ec7884fd83d33724f69449f3817b1061a0b4da3e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat/zhipuai-chat.adoc"}}
{"id": "sha256:7befd18fdc05a089cf047892a84c37de262a0b332f46f1315443e832d0236ef3", "content": "Azure's OpenAI extends the OpenAI capabilities, offering safe text generation and Embeddings computation models for various task:\n\n- Similarity embeddings are good at capturing semantic similarity between two or more pieces of text.\n- Text search embeddings help measure whether long documents are relevant to a short query.\n- Code search embeddings are useful for embedding code snippets and embedding natural language search queries.\n\nThe Azure OpenAI embeddings rely on `cosine similarity` to compute similarity between documents and a query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Azure OpenAI Embeddings", "heading_level": 1, "file_order": 29, "section_index": 0, "content_hash": "7befd18fdc05a089cf047892a84c37de262a0b332f46f1315443e832d0236ef3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:514474e0e220eea327a81a7dd661cf87564f6bc495689001f1c67ebe4e447251", "content": "The Azure OpenAI client offers three options to connect: using an Azure API key or using an OpenAI API Key, or using Microsoft Entra ID.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 29, "section_index": 1, "content_hash": "514474e0e220eea327a81a7dd661cf87564f6bc495689001f1c67ebe4e447251", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:2a6ad2510514ada47c5e650b179d394b02ff1888138c18f4f2150b4d43fdf12b", "content": "Obtain your Azure OpenAI `endpoint` and `api-key` from the Azure OpenAI Service section on the https://portal.azure.com[Azure Portal].\n\nSpring AI defines two configuration properties:\n\n1. `spring.ai.azure.openai.api-key`: Set this to the value of the `API Key` obtained from Azure.\n2. `spring.ai.azure.openai.endpoint`: Set this to the endpoint URL obtained when provisioning your model in Azure.\n\nYou can set these configuration properties in your `application.properties` or `application.yml` file:\n\n[source,properties]\n----\nspring.ai.azure.openai.api-key=<your-azure-api-key>\nspring.ai.azure.openai.endpoint=<your-azure-endpoint-url>\n----\n\nIf you prefer to use environment variables for sensitive information like API keys, you can use Spring Expression Language (SpEL) in your configuration:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n azure:\n openai:\n api-key: ${AZURE_OPENAI_API_KEY}\n endpoint: ${AZURE_OPENAI_ENDPOINT}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>\nexport AZURE_OPENAI_ENDPOINT=<your-azure-endpoint-url>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Azure API Key & Endpoint", "heading_level": 3, "file_order": 29, "section_index": 2, "content_hash": "2a6ad2510514ada47c5e650b179d394b02ff1888138c18f4f2150b4d43fdf12b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:d5cd55fd0b191d49a6296c50435e5c62d2fcc3111d02aee2eda570204befba81", "content": "To authenticate with the OpenAI service (not Azure), provide an OpenAI API key.\nThis will automatically set the endpoint to https://api.openai.com/v1.\n\nWhen using this approach, set the `spring.ai.azure.openai.chat.options.deployment-name` property to the name of the https://platform.openai.com/docs/models[OpenAI model] you wish to use.\n\nIn your application configuration:\n\n[source,properties]\n----\nspring.ai.azure.openai.openai-api-key=<your-azure-openai-key>\nspring.ai.azure.openai.chat.options.deployment-name=<openai-model-name>\n----\n\nUsing environment variables with SpEL:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n azure:\n openai:\n openai-api-key: ${AZURE_OPENAI_API_KEY}\n chat:\n options:\n deployment-name: ${OPENAI_MODEL_NAME}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AZURE_OPENAI_API_KEY=<your-openai-key>\nexport OPENAI_MODEL_NAME=<openai-model-name>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "OpenAI Key", "heading_level": 3, "file_order": 29, "section_index": 3, "content_hash": "d5cd55fd0b191d49a6296c50435e5c62d2fcc3111d02aee2eda570204befba81", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:0df907be55ba9dff9a2bac941070200c921b2d4a6158bdd5d6be97428498503a", "content": "For keyless authentication using Microsoft Entra ID (formerly Azure Active Directory), set _only_ the `spring.ai.azure.openai.endpoint` configuration property and _not_ the api-key property mentioned above.\n\nFinding only the endpoint property, your application will evaluate several different options for retrieving credentials and an `OpenAIClient` instance will be created using the token credentials.\n\nNOTE: It is no longer necessary to create a `TokenCredential` bean; it is configured for you automatically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Microsoft Entra ID", "heading_level": 3, "file_order": 29, "section_index": 4, "content_hash": "0df907be55ba9dff9a2bac941070200c921b2d4a6158bdd5d6be97428498503a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:637139e3a3cf9dac6489d49fc285982be1410bd50ad4108ba2c15fc4301e4261", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 29, "section_index": 5, "content_hash": "637139e3a3cf9dac6489d49fc285982be1410bd50ad4108ba2c15fc4301e4261", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:7178424ef541518f50dfc9d16bc342507468929054d840d8175fb3f82403bd10", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure OpenAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 29, "section_index": 6, "content_hash": "7178424ef541518f50dfc9d16bc342507468929054d840d8175fb3f82403bd10", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:7693cf40d6412552a735ac4849872e65826313eb9d2f32a984e64de6d31f2388", "content": "The prefix `spring.ai.azure.openai` is the property prefix to configure the connection to Azure OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.azure.openai.api-key | The Key from Azure AI OpenAI `Keys and Endpoint` section under `Resource Management` | -\n| spring.ai.azure.openai.endpoint | The endpoint from the Azure AI OpenAI `Keys and Endpoint` section under `Resource Management` | -\n| spring.ai.azure.openai.openai-api-key | (non Azure) OpenAI API key. Used to authenticate with the OpenAI service, instead of Azure OpenAI.\nThis automatically sets the endpoint to https://api.openai.com/v1. Use either `api-key` or `openai-api-key` property.\nWith this configuration the `spring.ai.azure.openai.embedding.options.deployment-name` is treated as an https://platform.openai.com/docs/models[OpenAi Model] name.| -\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=azure-openai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match azure-openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.azure.openai.embedding` is the property prefix that configures the `EmbeddingModel` implementation for Azure OpenAI\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.azure.openai.embedding.enabled (Removed and no longer valid) | Enable Azure OpenAI embedding model. | true\n| spring.ai.model.embedding | Enable Azure OpenAI embedding model. | azure-openai\n| spring.ai.azure.openai.embedding.metadata-mode | Document content extraction mode | EMBED\n| spring.ai.azure.openai.embedding.options.deployment-name | This is the value of the 'Deployment Name' as presented in the Azure AI Portal | text-embedding-ada-002\n| spring.ai.azure.openai.embedding.options.user | An identifier for the caller or end user of the operation. This may be used for tracking or rate-limiting purposes. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.azure.openai.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 29, "section_index": 7, "content_hash": "7693cf40d6412552a735ac4849872e65826313eb9d2f32a984e64de6d31f2388", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:af2f263de42cfd659dd53458edf5d923532be8c49cc07d467ef5a8662a74385a", "content": "The `AzureOpenAiEmbeddingOptions` provides the configuration information for the embedding requests.\nThe `AzureOpenAiEmbeddingOptions` offers a builder to create the options.\n\nAt start time use the `AzureOpenAiEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, by passing a `AzureOpenAiEmbeddingOptions` instance with your to the `EmbeddingRequest` request.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n AzureOpenAiEmbeddingOptions.builder()\n .model(\"Different-Embedding-Model-Deployment-Name\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 29, "section_index": 8, "content_hash": "af2f263de42cfd659dd53458edf5d923532be8c49cc07d467ef5a8662a74385a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:6d5f363554163c0eca3be46fa18a2242791a32c9101aca9527cc32fb9d2f0b5a", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.azure.openai.api-key=YOUR_API_KEY\nspring.ai.azure.openai.endpoint=YOUR_ENDPOINT\nspring.ai.azure.openai.embedding.options.model=text-embedding-ada-002\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Sample Code", "heading_level": 2, "file_order": 29, "section_index": 9, "content_hash": "6d5f363554163c0eca3be46fa18a2242791a32c9101aca9527cc32fb9d2f0b5a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:3d94e50ff81d896fe441480b6763c31000a176c6bae7e964b0a2ffafae7077ee", "content": "If you prefer not to use the Spring Boot auto-configuration, you can manually configure the `AzureOpenAiEmbeddingModel` in your application.\nFor this add the `spring-ai-azure-openai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-azure-openai` dependency also provide the access to the `AzureOpenAiEmbeddingModel`. For more information about the `AzureOpenAiChatModel` refer to the link:../embeddings/azure-openai-embeddings.html[Azure OpenAI Embeddings] section.\n\nNext, create an `AzureOpenAiEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar openAIClient = OpenAIClientBuilder()\n .credential(new AzureKeyCredential(System.getenv(\"AZURE_OPENAI_API_KEY\")))\n .endpoint(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n .buildClient();\n\nvar embeddingModel = new AzureOpenAiEmbeddingModel(this.openAIClient)\n .withDefaultOptions(AzureOpenAiEmbeddingOptions.builder()\n .model(\"text-embedding-ada-002\")\n .user(\"user-6\")\n .build());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nNOTE: the `text-embedding-ada-002` is actually the `Deployment Name` as presented in the Azure AI Portal.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc", "title": "Azure OpenAI Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 29, "section_index": 10, "content_hash": "3d94e50ff81d896fe441480b6763c31000a176c6bae7e964b0a2ffafae7077ee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/azure-openai-embeddings.adoc"}}
{"id": "sha256:d31174ee73a2ecc2bf74a239d4179da659d9edd2fd07f2ab430109b18dff1175", "content": "Provides Bedrock Cohere Embedding model.\nIntegrate generative AI capabilities into essential apps and workflows that improve business outcomes.\n\nThe https://aws.amazon.com/bedrock/cohere-command-embed/[AWS Bedrock Cohere Model Page] and https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html[Amazon Bedrock User Guide] contains detailed information on how to use the AWS hosted model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Cohere Embeddings", "heading_level": 1, "file_order": 30, "section_index": 0, "content_hash": "d31174ee73a2ecc2bf74a239d4179da659d9edd2fd07f2ab430109b18dff1175", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:a01b0eceb2f537ffe82705f4a9f0cd41c291ece6282092d39eabbbb9747f981a", "content": "Refer to the xref:api/bedrock.adoc[Spring AI documentation on Amazon Bedrock] for setting up API access.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 30, "section_index": 1, "content_hash": "a01b0eceb2f537ffe82705f4a9f0cd41c291ece6282092d39eabbbb9747f981a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:0089ed256052453bda2492a74f7f42b0681fa34b9a7cb43fc6419224b30b9b28", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 30, "section_index": 2, "content_hash": "0089ed256052453bda2492a74f7f42b0681fa34b9a7cb43fc6419224b30b9b28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:013a4ddabf5e4d6c108db7d5a46c325ef95767df05dfb94219f32aba2039b595", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the `spring-ai-starter-model-bedrock` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-bedrock</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 30, "section_index": 3, "content_hash": "013a4ddabf5e4d6c108db7d5a46c325ef95767df05dfb94219f32aba2039b595", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:e76efef6a5678d4e7548599c298de50d1433976d7257147587d57fa0751f5de8", "content": "By default, the Cohere embedding model is disabled.\nTo enable it, set the `spring.ai.model.embedding` property to `bedrock-cohere` in your application configuration:\n\n[source,properties]\n----\nspring.ai.model.embedding=bedrock-cohere\n----\n\nAlternatively, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n model:\n embedding: ${AI_MODEL_EMBEDDING}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AI_MODEL_EMBEDDING=bedrock-cohere\n----\n\nYou can also set this property using Java system properties when starting your application:\n\n[source,shell]\n----\njava -Dspring.ai.model.embedding=bedrock-cohere -jar your-application.jar\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Enable Cohere Embedding Support", "heading_level": 3, "file_order": 30, "section_index": 4, "content_hash": "e76efef6a5678d4e7548599c298de50d1433976d7257147587d57fa0751f5de8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:504739ce8287ca1025713cb46c8048c11690f6b24b0a6c44c4dc16b08416fc30", "content": "The prefix `spring.ai.bedrock.aws` is the property prefix to configure the connection to AWS Bedrock.\n\n[cols=\"3,4,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.bedrock.aws.region | AWS region to use. | us-east-1\n| spring.ai.bedrock.aws.access-key | AWS access key. | -\n| spring.ai.bedrock.aws.secret-key | AWS secret key. | -\n| spring.ai.bedrock.aws.profile.name | AWS profile name. | -\n| spring.ai.bedrock.aws.profile.credentials-path | AWS credentials file path. | -\n| spring.ai.bedrock.aws.profile.configuration-path | AWS config file path. | -\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=bedrock-cohere (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match bedrock-cohere)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.bedrock.cohere.embedding` (defined in `BedrockCohereEmbeddingProperties`) is the property prefix that configures the embedding model implementation for Cohere.\n\n[cols=\"3,4,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.model.embedding | Enable or disable support for Cohere | bedrock-cohere\n| spring.ai.bedrock.cohere.embedding.enabled (Removed and no longer valid) | Enable or disable support for Cohere | false\n| spring.ai.bedrock.cohere.embedding.model | The model id to use. See the https://github.com/spring-projects/spring-ai/blob/056b95a00efa5b014a1f488329fbd07a46c02378/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/api/CohereEmbeddingBedrockApi.java#L150[CohereEmbeddingModel] for the supported models. | cohere.embed-multilingual-v3\n| spring.ai.bedrock.cohere.embedding.options.input-type | Prepends special tokens to differentiate each type from one another. You should not mix different types together, except when mixing types for search and retrieval. In this case, embed your corpus with the search_document type and embedded queries with type search_query type. | SEARCH_DOCUMENT\n| spring.ai.bedrock.cohere.embedding.options.truncate | Specifies how the API handles inputs longer than the maximum token length. If you specify LEFT or RIGHT, the model discards the input until the remaining input is exactly the maximum input token length for the model. | NONE\n|====\n\nNOTE: When accessing Cohere via Amazon Bedrock, the functionality of truncating is not available. This is an issue with Amazon Bedrock. The Spring AI class `BedrockCohereEmbeddingModel` will truncate to 2048 character length, which is the maximum supported by the model.\n\nLook at the https://github.com/spring-projects/spring-ai/blob/056b95a00efa5b014a1f488329fbd07a46c02378/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/api/CohereEmbeddingBedrockApi.java#L150[CohereEmbeddingModel] for other model IDs.\nSupported values are: `cohere.embed-multilingual-v3` and `cohere.embed-english-v3`.\nModel ID values can also be found in the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html[AWS Bedrock documentation for base model IDs].\n\nTIP: All properties prefixed with `spring.ai.bedrock.cohere.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 30, "section_index": 5, "content_hash": "504739ce8287ca1025713cb46c8048c11690f6b24b0a6c44c4dc16b08416fc30", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:1cffaf4d73d12535810967fd0a40c9f5d1ffcf6be862acb1f36c34e6937113fd", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/BedrockCohereEmbeddingOptions.java[BedrockCohereEmbeddingOptions.java] provides model configurations, such as `input-type` or `truncate`.\n\nOn start-up, the default options can be configured with the `BedrockCohereEmbeddingModel(api, options)` constructor or the `spring.ai.bedrock.cohere.embedding.options.*` properties.\n\nAt runtime you can override the default options by adding new, request-specific, options to the `EmbeddingRequest` call.\nFor example to override the default input type for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n BedrockCohereEmbeddingOptions.builder()\n .inputType(InputType.SEARCH_DOCUMENT)\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 30, "section_index": 6, "content_hash": "1cffaf4d73d12535810967fd0a40c9f5d1ffcf6be862acb1f36c34e6937113fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:3204c8c4076bffed78c0c8aa9a418070a08f23b29b9da1a11c79392ea8fd76bf", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-bedrock` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the Cohere Embedding model:\n\n[source]\n----\nspring.ai.bedrock.aws.region=eu-central-1\nspring.ai.bedrock.aws.access-key=${AWS_ACCESS_KEY_ID}\nspring.ai.bedrock.aws.secret-key=${AWS_SECRET_ACCESS_KEY}\n\nspring.ai.model.embedding=bedrock-cohere\nspring.ai.bedrock.cohere.embedding.options.input-type=search-document\n----\n\nTIP: replace the `regions`, `access-key` and `secret-key` with your AWS credentials.\n\nThis will create a `BedrockCohereEmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 30, "section_index": 7, "content_hash": "3204c8c4076bffed78c0c8aa9a418070a08f23b29b9da1a11c79392ea8fd76bf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:7a30e068f5f80dec4a078d0b3163256bb7d07eb841805a17575798666db51d41", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/BedrockCohereEmbeddingModel.java[BedrockCohereEmbeddingModel] implements the `EmbeddingModel` and uses the <<low-level-api>> to connect to the Bedrock Cohere service.\n\nAdd the `spring-ai-bedrock` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-bedrock</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/BedrockCohereEmbeddingModel.java[BedrockCohereEmbeddingModel] and use it for text embeddings:\n\n[source,java]\n----\nvar cohereEmbeddingApi =new CohereEmbeddingBedrockApi(\n CohereEmbeddingModel.COHERE_EMBED_MULTILINGUAL_V1.id(),\n EnvironmentVariableCredentialsProvider.create(), Region.US_EAST_1.id(), new ObjectMapper());\n\nvar embeddingModel = new BedrockCohereEmbeddingModel(this.cohereEmbeddingApi);\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 30, "section_index": 8, "content_hash": "7a30e068f5f80dec4a078d0b3163256bb7d07eb841805a17575798666db51d41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:6d26e82a8fe0bbc5b74ef1fdab30bc94580d02ef2e7a356cdb37a20c7185b35f", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/cohere/api/CohereEmbeddingBedrockApi.java[CohereEmbeddingBedrockApi] provides is lightweight Java client on top of AWS Bedrock https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-cohere-command.html[Cohere Command models].\n\nFollowing class diagram illustrates the CohereEmbeddingBedrockApi interface and building blocks:\n\nimage::bedrock/bedrock-cohere-embedding-low-level-api.jpg[align=\"center\", width=\"800px\"]\n\nThe CohereEmbeddingBedrockApi supports the `cohere.embed-english-v3` and `cohere.embed-multilingual-v3` models for single and batch embedding computation.\n\nHere is a simple snippet how to use the api programmatically:\n\n[source,java]\n----\nCohereEmbeddingBedrockApi api = new CohereEmbeddingBedrockApi(\n CohereEmbeddingModel.COHERE_EMBED_MULTILINGUAL_V1.id(),\n EnvironmentVariableCredentialsProvider.create(),\n Region.US_EAST_1.id(), new ObjectMapper());\n\nCohereEmbeddingRequest request = new CohereEmbeddingRequest(\n List.of(\"I like to eat apples\", \"I like to eat oranges\"),\n CohereEmbeddingRequest.InputType.search_document,\n CohereEmbeddingRequest.Truncate.NONE);\n\nCohereEmbeddingResponse response = this.api.embedding(this.request);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc", "title": "Cohere Embeddings", "heading": "Low-level CohereEmbeddingBedrockApi Client [[low-level-api]]", "heading_level": 2, "file_order": 30, "section_index": 9, "content_hash": "6d26e82a8fe0bbc5b74ef1fdab30bc94580d02ef2e7a356cdb37a20c7185b35f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-cohere-embedding.adoc"}}
{"id": "sha256:664cb8ecf753ea29a69e2be7188dd3bc294382102f0aa3d1107b985795558b57", "content": "Provides Bedrock Titan Embedding model.\nlink:https://aws.amazon.com/bedrock/titan/[Amazon Titan] foundation models (FMs) provide customers with a breadth of high-performing image, multimodal embeddings, and text model choices, via a fully managed API.\nAmazon Titan models are created by AWS and pretrained on large datasets, making them powerful, general-purpose models built to support a variety of use cases, while also supporting the responsible use of AI.\nUse them as is or privately customize them with your own data.\n\nNOTE: Bedrock Titan Embedding supports Text and Image embedding.\n\nNOTE: Bedrock Titan Embedding does NOT support batch embedding.\n\nThe https://aws.amazon.com/bedrock/titan/[AWS Bedrock Titan Model Page] and https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html[Amazon Bedrock User Guide] contains detailed information on how to use the AWS hosted model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Titan Embeddings", "heading_level": 1, "file_order": 31, "section_index": 0, "content_hash": "664cb8ecf753ea29a69e2be7188dd3bc294382102f0aa3d1107b985795558b57", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:b6a95feb74d7f1e1e177280593b8c4b047ed01effc3b09b5dc19323a619aa959", "content": "Refer to the xref:api/bedrock.adoc[Spring AI documentation on Amazon Bedrock] for setting up API access.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 31, "section_index": 1, "content_hash": "b6a95feb74d7f1e1e177280593b8c4b047ed01effc3b09b5dc19323a619aa959", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:23c0fc16ed803bae49b2afb63a041e2cda7fc225407063d768911152479d0ed5", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 31, "section_index": 2, "content_hash": "23c0fc16ed803bae49b2afb63a041e2cda7fc225407063d768911152479d0ed5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:c0a6ecc87817ad78d3b53d2687c61f70c3ec41335547203d6f68c83f27598ba0", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the `spring-ai-starter-model-bedrock` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-bedrock</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 31, "section_index": 3, "content_hash": "c0a6ecc87817ad78d3b53d2687c61f70c3ec41335547203d6f68c83f27598ba0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:d1ed78150184d8ee2559aa7b500517742c4232e8b13e16e6b7c5e101e00d246d", "content": "By default, the Titan embedding model is disabled.\nTo enable it, set the `spring.ai.model.embedding` property to `bedrock-titan` in your application configuration:\n\n[source,properties]\n----\nspring.ai.model.embedding=bedrock-titan\n----\n\nAlternatively, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n model:\n embedding: ${AI_MODEL_EMBEDDING}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AI_MODEL_EMBEDDING=bedrock-titan\n----\n\nYou can also set this property using Java system properties when starting your application:\n\n[source,shell]\n----\njava -Dspring.ai.model.embedding=bedrock-titan -jar your-application.jar\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Enable Titan Embedding Support", "heading_level": 3, "file_order": 31, "section_index": 4, "content_hash": "d1ed78150184d8ee2559aa7b500517742c4232e8b13e16e6b7c5e101e00d246d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:386caf163812df2c3cf9bc9c06babf4d434d73d7f669f9e5bbe16443000862f4", "content": "The prefix `spring.ai.bedrock.aws` is the property prefix to configure the connection to AWS Bedrock.\n\n[cols=\"3,4,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.bedrock.aws.region | AWS region to use. | us-east-1\n| spring.ai.bedrock.aws.access-key | AWS access key. | -\n| spring.ai.bedrock.aws.secret-key | AWS secret key. | -\n| spring.ai.bedrock.aws.profile.name | AWS profile name. | -\n| spring.ai.bedrock.aws.profile.credentials-path | AWS credentials file path. | -\n| spring.ai.bedrock.aws.profile.configuration-path | AWS config file path. | -\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=bedrock-titan (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match bedrock-titan)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.bedrock.titan.embedding` (defined in `BedrockTitanEmbeddingProperties`) is the property prefix that configures the embedding model implementation for Titan.\n\n[cols=\"3,4,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.bedrock.titan.embedding.enabled (Removed and no longer valid) | Enable or disable support for Titan embedding | false\n| spring.ai.model.embedding | Enable or disable support for Titan embedding | bedrock-titan\n| spring.ai.bedrock.titan.embedding.model | The model id to use. See the `TitanEmbeddingModel` for the supported models. | amazon.titan-embed-image-v1\n|====\n\nSupported values are: `amazon.titan-embed-image-v1`, `amazon.titan-embed-text-v1` and `amazon.titan-embed-text-v2:0`.\nModel ID values can also be found in the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html[AWS Bedrock documentation for base model IDs].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 31, "section_index": 5, "content_hash": "386caf163812df2c3cf9bc9c06babf4d434d73d7f669f9e5bbe16443000862f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:dd93bf02cb2c76ad04968c8cccc3a42aa938019943185e5495a58b09bb657761", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/titan/BedrockTitanEmbeddingOptions.java[BedrockTitanEmbeddingOptions.java] provides model configurations, such as `input-type`.\nOn start-up, the default options can be configured with the `BedrockTitanEmbeddingOptions.builder().inputType(type).build()` method or the `spring.ai.bedrock.titan.embedding.input-type` properties.\n\nAt run-time you can override the default options by adding new, request specific, options to the `EmbeddingRequest` call.\nFor example to override the default temperature for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n BedrockTitanEmbeddingOptions.builder()\n .inputType(InputType.TEXT)\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 31, "section_index": 6, "content_hash": "dd93bf02cb2c76ad04968c8cccc3a42aa938019943185e5495a58b09bb657761", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:b5ac46523780c37583143070c55a7b439fba378e6664cae4ba5a21f0aa14c4dc", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-bedrock` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the Titan Embedding model:\n\n[source]\n----\nspring.ai.bedrock.aws.region=eu-central-1\nspring.ai.bedrock.aws.access-key=${AWS_ACCESS_KEY_ID}\nspring.ai.bedrock.aws.secret-key=${AWS_SECRET_ACCESS_KEY}\n\nspring.ai.model.embedding=bedrock-titan\n----\n\nTIP: replace the `regions`, `access-key` and `secret-key` with your AWS credentials.\n\nThis will create a `EmbeddingController` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the chat model for text generations.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 31, "section_index": 7, "content_hash": "b5ac46523780c37583143070c55a7b439fba378e6664cae4ba5a21f0aa14c4dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:411a6223c54291692de8b5d8b2b115146196e99399056b15962931c36950de34", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/titan/BedrockTitanEmbeddingModel.java[BedrockTitanEmbeddingModel] implements the `EmbeddingModel` and uses the <<low-level-api>> to connect to the Bedrock Titan service.\n\nAdd the `spring-ai-bedrock` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-bedrock</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/titan/BedrockTitanEmbeddingModel.java[BedrockTitanEmbeddingModel] and use it for text embeddings:\n\n[source,java]\n----\nvar titanEmbeddingApi = new TitanEmbeddingBedrockApi(\n\tTitanEmbeddingModel.TITAN_EMBED_IMAGE_V1.id(), Region.US_EAST_1.id());\n\nvar embeddingModel = new BedrockTitanEmbeddingModel(this.titanEmbeddingApi);\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\")); // NOTE titan does not support batch embedding.\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 31, "section_index": 8, "content_hash": "411a6223c54291692de8b5d8b2b115146196e99399056b15962931c36950de34", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:e2ede7f64a191b7bbec270695469a35b6961d6caa33602c1eadbffd1a11cd8a2", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-bedrock/src/main/java/org/springframework/ai/bedrock/titan/api/TitanEmbeddingBedrockApi.java[TitanEmbeddingBedrockApi] provides is lightweight Java client on top of AWS Bedrock https://docs.aws.amazon.com/bedrock/latest/userguide/titan-multiemb-models.html[Titan Embedding models].\n\nFollowing class diagram illustrates the TitanEmbeddingBedrockApi interface and building blocks:\n\nimage::bedrock/bedrock-titan-embedding-low-level-api.jpg[align=\"center\", width=\"500px\"]\n\nThe TitanEmbeddingBedrockApi supports the `amazon.titan-embed-image-v1` and `amazon.titan-embed-image-v1` models for single and batch embedding computation.\n\nHere is a simple snippet how to use the api programmatically:\n\n[source,java]\n----\nTitanEmbeddingBedrockApi titanEmbedApi = new TitanEmbeddingBedrockApi(\n TitanEmbeddingModel.TITAN_EMBED_TEXT_V1.id(), Region.US_EAST_1.id());\n\nTitanEmbeddingRequest request = TitanEmbeddingRequest.builder()\n\t.withInputText(\"I like to eat apples.\")\n\t.build();\n\nTitanEmbeddingResponse response = this.titanEmbedApi.embedding(this.request);\n----\n\nTo embed an image you need to convert it into `base64` format:\n\n[source,java]\n----\nTitanEmbeddingBedrockApi titanEmbedApi = new TitanEmbeddingBedrockApi(\n TitanEmbeddingModel.TITAN_EMBED_IMAGE_V1.id(), Region.US_EAST_1.id());\n\nbyte[] image = new DefaultResourceLoader()\n\t.getResource(\"classpath:/spring_framework.png\")\n\t.getContentAsByteArray();\n\nTitanEmbeddingRequest request = TitanEmbeddingRequest.builder()\n\t.withInputImage(Base64.getEncoder().encodeToString(this.image))\n\t.build();\n\nTitanEmbeddingResponse response = this.titanEmbedApi.embedding(this.request);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc", "title": "Titan Embeddings", "heading": "Low-level TitanEmbeddingBedrockApi Client [[low-level-api]]", "heading_level": 2, "file_order": 31, "section_index": 9, "content_hash": "e2ede7f64a191b7bbec270695469a35b6961d6caa33602c1eadbffd1a11cd8a2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/bedrock-titan-embedding.adoc"}}
{"id": "sha256:a4d71181a7d259b03903e9c4b113c441c716b9ecac252cb14f2550010b894231", "content": "The https://ai.google.dev/gemini-api/docs/embeddings[Google GenAI Embeddings API] provides text embedding generation using Google's embedding models through either the Gemini Developer API or Vertex AI.\nThis document describes how to create text embeddings using the Google GenAI Text embeddings API.\n\nGoogle GenAI text embeddings API uses dense vector representations.\nUnlike sparse vectors, which tend to directly map words to numbers, dense vectors are designed to better represent the meaning of a piece of text.\nThe benefit of using dense vector embeddings in generative AI is that instead of searching for direct word or syntax matches, you can better search for passages that align to the meaning of the query, even if the passages don't use the same language.\n\n[NOTE]\n====\nCurrently, the Google GenAI SDK supports text embeddings only. Multimodal embeddings support is pending and will be added when available in the SDK.\n====\n\nThis implementation provides two authentication modes:\n\n- **Gemini Developer API**: Use an API key for quick prototyping and development\n- **Vertex AI**: Use Google Cloud credentials for production deployments with enterprise features", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Google GenAI Text Embeddings", "heading_level": 1, "file_order": 32, "section_index": 0, "content_hash": "a4d71181a7d259b03903e9c4b113c441c716b9ecac252cb14f2550010b894231", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:781521d88f965cb4c82be78e95276d62dffd55ea69e89ac92068361e9c1e6886", "content": "Choose one of the following authentication methods:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 32, "section_index": 1, "content_hash": "781521d88f965cb4c82be78e95276d62dffd55ea69e89ac92068361e9c1e6886", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:c91e91fa05ee7c1ac992e669c5369f3306fcc823e3e81de5ecb1311eae1b3b28", "content": "- Obtain an API key from the https://aistudio.google.com/app/apikey[Google AI Studio]\n- Set the API key as an environment variable or in your application properties", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Option 1: Gemini Developer API (API Key)", "heading_level": 3, "file_order": 32, "section_index": 2, "content_hash": "c91e91fa05ee7c1ac992e669c5369f3306fcc823e3e81de5ecb1311eae1b3b28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:c6a2d05408384441e76f2eae3856c650c53a17cb1384ae8ba9bd3b71065acc57", "content": "- Install the link:https://cloud.google.com/sdk/docs/install[gcloud] CLI, appropriate for your OS.\n- Authenticate by running the following command.\nReplace `PROJECT_ID` with your Google Cloud project ID and `ACCOUNT` with your Google Cloud username.\n\n[source]\n----\ngcloud config set project <PROJECT_ID> &&\ngcloud auth application-default login <ACCOUNT>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Option 2: Vertex AI (Google Cloud)", "heading_level": 3, "file_order": 32, "section_index": 3, "content_hash": "c6a2d05408384441e76f2eae3856c650c53a17cb1384ae8ba9bd3b71065acc57", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:59f09a7caa829660ebe32a978dce3589d9e7e52ed6e3c9cbbf2d350217588c89", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 32, "section_index": 4, "content_hash": "59f09a7caa829660ebe32a978dce3589d9e7e52ed6e3c9cbbf2d350217588c89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:91c834757b41f59e002e61fe3640a7633695453e3acf6aa496bee4cde990b0fb", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Google GenAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-google-genai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-google-genai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 32, "section_index": 5, "content_hash": "91c834757b41f59e002e61fe3640a7633695453e3acf6aa496bee4cde990b0fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:0e10497e1a05772f6b27d23ec82b21a78463ba50d51ed2185114011ccbfb3b83", "content": "The prefix `spring.ai.google.genai.embedding` is used as the property prefix that lets you connect to Google GenAI Embedding API.\n\n[NOTE]\n====\nThe connection properties are shared with the Google GenAI Chat module. If you're using both chat and embeddings, you only need to configure the connection once using either `spring.ai.google.genai` prefix (for chat) or `spring.ai.google.genai.embedding` prefix (for embeddings).\n====\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.google.genai.embedding.api-key | API key for Gemini Developer API. When provided, the client uses the Gemini Developer API instead of Vertex AI. | -\n| spring.ai.google.genai.embedding.project-id | Google Cloud Platform project ID (required for Vertex AI mode) | -\n| spring.ai.google.genai.embedding.location | Google Cloud region (required for Vertex AI mode) | -\n| spring.ai.google.genai.embedding.credentials-uri | URI to Google Cloud credentials. When provided it is used to create a `GoogleCredentials` instance for authentication. | -\n\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding.text=google-genai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding.text=none (or any value which doesn't match google-genai)\n\nThis change is done to allow configuration of multiple models.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Connection Properties", "heading_level": 4, "file_order": 32, "section_index": 6, "content_hash": "0e10497e1a05772f6b27d23ec82b21a78463ba50d51ed2185114011ccbfb3b83", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:1c94e373dcf47e25b88fd4b004e1d584cb8d07b8335e6597e6f3d1750084e63a", "content": "The prefix `spring.ai.google.genai.embedding.text` is the property prefix that lets you configure the embedding model implementation for Google GenAI Text Embedding.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.model.embedding.text | Enable Google GenAI Embedding API model. | google-genai\n| spring.ai.google.genai.embedding.text.options.model | The https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding[Google GenAI Text Embedding model] to use. Supported models include `text-embedding-004` and `text-multilingual-embedding-002` | text-embedding-004\n| spring.ai.google.genai.embedding.text.options.task-type | The intended downstream application to help the model produce better quality embeddings. Available link:https://ai.google.dev/api/embeddings#tasktype[task-types]: `RETRIEVAL_QUERY`, `RETRIEVAL_DOCUMENT`, `SEMANTIC_SIMILARITY`, `CLASSIFICATION`, `CLUSTERING`, `QUESTION_ANSWERING`, `FACT_VERIFICATION` | `RETRIEVAL_DOCUMENT`\n| spring.ai.google.genai.embedding.text.options.title | Optional title, only valid with task_type=RETRIEVAL_DOCUMENT. | -\n| spring.ai.google.genai.embedding.text.options.dimensions | The number of dimensions the resulting output embeddings should have. Supported for model version 004 and later. You can use this parameter to reduce the embedding size, for example, for storage optimization. | -\n| spring.ai.google.genai.embedding.text.options.auto-truncate | When set to true, input text will be truncated. When set to false, an error is returned if the input text is longer than the maximum length supported by the model. | true\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Text Embedding Properties", "heading_level": 4, "file_order": 32, "section_index": 7, "content_hash": "1c94e373dcf47e25b88fd4b004e1d584cb8d07b8335e6597e6f3d1750084e63a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:67f5228e1f7e7ffe11d797ef9ef55028b80309c76b7bc6828c5c37d8171dccd0", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-google-genai-embedding` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the Google GenAI embedding model:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 32, "section_index": 8, "content_hash": "67f5228e1f7e7ffe11d797ef9ef55028b80309c76b7bc6828c5c37d8171dccd0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:079386e7480f4a314f22df5ca2db2a578055c7dd7c5671f756f747436264c549", "content": "[source,application.properties]\n----\nspring.ai.google.genai.embedding.api-key=YOUR_API_KEY\nspring.ai.google.genai.embedding.text.options.model=text-embedding-004\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Using Gemini Developer API (API Key)", "heading_level": 3, "file_order": 32, "section_index": 9, "content_hash": "079386e7480f4a314f22df5ca2db2a578055c7dd7c5671f756f747436264c549", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:8f597467615bca7f20bbe45259084978df83fee72cdbbe9fc2b433cdbf5cdefa", "content": "[source,application.properties]\n----\nspring.ai.google.genai.embedding.project-id=YOUR_PROJECT_ID\nspring.ai.google.genai.embedding.location=YOUR_PROJECT_LOCATION\nspring.ai.google.genai.embedding.text.options.model=text-embedding-004\n----\n\nThis will create a `GoogleGenAiTextEmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the embedding model for embeddings generations.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Using Vertex AI", "heading_level": 3, "file_order": 32, "section_index": 10, "content_hash": "8f597467615bca7f20bbe45259084978df83fee72cdbbe9fc2b433cdbf5cdefa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:d2e0c4784908935598a82eaf38d4bba49ea17215d5eff283abfdfcd28b587b73", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-google-genai-embedding/src/main/java/org/springframework/ai/google/genai/text/GoogleGenAiTextEmbeddingModel.java[GoogleGenAiTextEmbeddingModel] implements the `EmbeddingModel`.\n\nAdd the `spring-ai-google-genai-embedding` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-google-genai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-google-genai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `GoogleGenAiTextEmbeddingModel` and use it for text embeddings:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 32, "section_index": 11, "content_hash": "d2e0c4784908935598a82eaf38d4bba49ea17215d5eff283abfdfcd28b587b73", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:729f927f102e8cd5ec4bbe09adb4ae5c63528f0ab76a1f042494c1781f98ba38", "content": "[source,java]\n----\nGoogleGenAiEmbeddingConnectionDetails connectionDetails =\n GoogleGenAiEmbeddingConnectionDetails.builder()\n .apiKey(System.getenv(\"GOOGLE_API_KEY\"))\n .build();\n\nGoogleGenAiTextEmbeddingOptions options = GoogleGenAiTextEmbeddingOptions.builder()\n .model(GoogleGenAiTextEmbeddingOptions.DEFAULT_MODEL_NAME)\n .taskType(TaskType.RETRIEVAL_DOCUMENT)\n .build();\n\nvar embeddingModel = new GoogleGenAiTextEmbeddingModel(connectionDetails, options);\n\nEmbeddingResponse embeddingResponse = embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Using API Key", "heading_level": 3, "file_order": 32, "section_index": 12, "content_hash": "729f927f102e8cd5ec4bbe09adb4ae5c63528f0ab76a1f042494c1781f98ba38", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:ea1810db0d6fa2615853cde4a062568d979f65c16715acc636dd441c2ce487a7", "content": "[source,java]\n----\nGoogleGenAiEmbeddingConnectionDetails connectionDetails =\n GoogleGenAiEmbeddingConnectionDetails.builder()\n .projectId(System.getenv(\"GOOGLE_CLOUD_PROJECT\"))\n .location(System.getenv(\"GOOGLE_CLOUD_LOCATION\"))\n .build();\n\nGoogleGenAiTextEmbeddingOptions options = GoogleGenAiTextEmbeddingOptions.builder()\n .model(GoogleGenAiTextEmbeddingOptions.DEFAULT_MODEL_NAME)\n .taskType(TaskType.RETRIEVAL_DOCUMENT)\n .build();\n\nvar embeddingModel = new GoogleGenAiTextEmbeddingModel(connectionDetails, options);\n\nEmbeddingResponse embeddingResponse = embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Using Vertex AI", "heading_level": 3, "file_order": 32, "section_index": 13, "content_hash": "ea1810db0d6fa2615853cde4a062568d979f65c16715acc636dd441c2ce487a7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:38a122f6bf22b9c03685a3e00716deb055e4a47fe75c0d6855f2a88a2bc64fd3", "content": "The Google GenAI embeddings API supports different task types to optimize embeddings for specific use cases:\n\n- `RETRIEVAL_QUERY`: Optimized for search queries in retrieval systems\n- `RETRIEVAL_DOCUMENT`: Optimized for documents in retrieval systems\n- `SEMANTIC_SIMILARITY`: Optimized for measuring semantic similarity between texts\n- `CLASSIFICATION`: Optimized for text classification tasks\n- `CLUSTERING`: Optimized for clustering similar texts\n- `QUESTION_ANSWERING`: Optimized for question-answering systems\n- `FACT_VERIFICATION`: Optimized for fact verification tasks\n\nExample of using different task types:\n\n[source,java]\n----\nGoogleGenAiTextEmbeddingOptions docOptions = GoogleGenAiTextEmbeddingOptions.builder()\n .model(\"text-embedding-004\")\n .taskType(TaskType.RETRIEVAL_DOCUMENT)\n .title(\"Product Documentation\") // Optional title for documents\n .build();\n\nGoogleGenAiTextEmbeddingOptions queryOptions = GoogleGenAiTextEmbeddingOptions.builder()\n .model(\"text-embedding-004\")\n .taskType(TaskType.RETRIEVAL_QUERY)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Task Types", "heading_level": 2, "file_order": 32, "section_index": 14, "content_hash": "38a122f6bf22b9c03685a3e00716deb055e4a47fe75c0d6855f2a88a2bc64fd3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:eb4a7eaab701b3a620cc8cb9f1fbb1a11de85c4fa7f5fe9f124c185b22e89524", "content": "For model version 004 and later, you can reduce the embedding dimensions for storage optimization:\n\n[source,java]\n----\nGoogleGenAiTextEmbeddingOptions options = GoogleGenAiTextEmbeddingOptions.builder()\n .model(\"text-embedding-004\")\n .dimensions(256) // Reduce from default 768 to 256 dimensions\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Dimension Reduction", "heading_level": 2, "file_order": 32, "section_index": 15, "content_hash": "eb4a7eaab701b3a620cc8cb9f1fbb1a11de85c4fa7f5fe9f124c185b22e89524", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:1c0fa616a512304f24743f029acf181d628e47b55ae7210d18711e1d384baeb5", "content": "If you're currently using the Vertex AI Text Embeddings implementation (`spring-ai-vertex-ai-embedding`), you can migrate to Google GenAI with minimal changes:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Migration from Vertex AI Text Embeddings", "heading_level": 2, "file_order": 32, "section_index": 16, "content_hash": "1c0fa616a512304f24743f029acf181d628e47b55ae7210d18711e1d384baeb5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:86473287db6177834f12d1856f01bcce68edb72717372f2e7059b186f80ca666", "content": "1. **SDK**: Google GenAI uses the new `com.google.genai.Client` instead of Vertex AI SDK\n2. **Authentication**: Supports both API key and Google Cloud credentials\n3. **Package Names**: Classes are in `org.springframework.ai.google.genai.text` instead of `org.springframework.ai.vertexai.embedding`\n4. **Property Prefix**: Uses `spring.ai.google.genai.embedding` instead of `spring.ai.vertex.ai.embedding`\n5. **Connection Details**: Uses `GoogleGenAiEmbeddingConnectionDetails` instead of `VertexAiEmbeddingConnectionDetails`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "Key Differences", "heading_level": 3, "file_order": 32, "section_index": 17, "content_hash": "86473287db6177834f12d1856f01bcce68edb72717372f2e7059b186f80ca666", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:04c85f43006811b96ef35e280eee1c30d0dcb47411de45685017bdf68bd88763", "content": "**Use Google GenAI Embeddings when:**\n- You want quick prototyping with API keys\n- You need the latest embedding features from the Developer API\n- You want flexibility to switch between API key and Vertex AI modes\n- You're already using Google GenAI for chat\n\n**Use Vertex AI Text Embeddings when:**\n- You have existing Vertex AI infrastructure\n- You need multimodal embeddings (currently only available in Vertex AI)\n- Your organization requires Google Cloud-only deployment", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc", "title": "Google GenAI Text Embeddings", "heading": "When to Use Google GenAI vs Vertex AI Text Embeddings", "heading_level": 3, "file_order": 32, "section_index": 18, "content_hash": "04c85f43006811b96ef35e280eee1c30d0dcb47411de45685017bdf68bd88763", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/google-genai-embeddings-text.adoc"}}
{"id": "sha256:93caac96270ab9022346bdf993b46c3c98500669f0f0cf822d0f0b6ea362018a", "content": "Spring AI supports the various AI language models from MiniMax. You can interact with MiniMax language models and create a multilingual conversational assistant based on MiniMax models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "MiniMax Chat", "heading_level": 1, "file_order": 33, "section_index": 0, "content_hash": "93caac96270ab9022346bdf993b46c3c98500669f0f0cf822d0f0b6ea362018a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:5e610be757513b2fba73f43085360d895758b4c4b0597ad1e184a9701754412b", "content": "You will need to create an API with MiniMax to access MiniMax language models.\n\nCreate an account at https://www.minimaxi.com/login[MiniMax registration page] and generate the token on the https://www.minimaxi.com/user-center/basic-information/interface-key[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.minimax.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.minimax.api-key=<your-minimax-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n minimax:\n api-key: ${MINIMAX_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport MINIMAX_API_KEY=<your-minimax-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"MINIMAX_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Prerequisites", "heading_level": 2, "file_order": 33, "section_index": 1, "content_hash": "5e610be757513b2fba73f43085360d895758b4c4b0597ad1e184a9701754412b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:975d1f252e62162847ac9475444cf5eab182e0525158be165cd75d0d1ef1bd97", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 33, "section_index": 2, "content_hash": "975d1f252e62162847ac9475444cf5eab182e0525158be165cd75d0d1ef1bd97", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:00c7774f087fe455ac00efdb35a8e1e643b8471746770013b563e7a9366a50fb", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure MiniMax Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-minimax</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-minimax'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Auto-configuration", "heading_level": 2, "file_order": 33, "section_index": 3, "content_hash": "00c7774f087fe455ac00efdb35a8e1e643b8471746770013b563e7a9366a50fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:3bcaaa78d4a7c85393110b489c9b4278d1005b62ed640bf3d162f1e707af325a", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the MiniMax Embedding model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Retry Properties", "heading_level": 4, "file_order": 33, "section_index": 4, "content_hash": "3bcaaa78d4a7c85393110b489c9b4278d1005b62ed640bf3d162f1e707af325a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:c7bcb4533553785d3d117de1aea37a606b2238611ac1a5d69d749328d17c32fe", "content": "The prefix `spring.ai.minimax` is used as the property prefix that lets you connect to MiniMax.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.minimax.base-url | The URL to connect to | https://api.minimax.chat\n| spring.ai.minimax.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Connection Properties", "heading_level": 4, "file_order": 33, "section_index": 5, "content_hash": "c7bcb4533553785d3d117de1aea37a606b2238611ac1a5d69d749328d17c32fe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:e02c8f6764f38c72ddaa41db8ed7c1ac8ce007bd7bb793d4dcd86225b1184882", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=minimax (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match minimax)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.minimax.embedding` is property prefix that configures the `EmbeddingModel` implementation for MiniMax.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.minimax.embedding.enabled (Removed and no longer valid) | Enable MiniMax embedding model. | true\n| spring.ai.model.embedding | Enable MiniMax embedding model. | minimax\n| spring.ai.minimax.embedding.base-url | Optional overrides the spring.ai.minimax.base-url to provide embedding specific url | -\n| spring.ai.minimax.embedding.api-key | Optional overrides the spring.ai.minimax.api-key to provide embedding specific api-key | -\n| spring.ai.minimax.embedding.options.model | The model to use | embo-01\n|====\n\nNOTE: You can override the common `spring.ai.minimax.base-url` and `spring.ai.minimax.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.minimax.embedding.base-url` and `spring.ai.minimax.embedding.api-key` properties if set take precedence over the common properties.\nSimilarly, the `spring.ai.minimax.chat.base-url` and `spring.ai.minimax.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different MiniMax accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.minimax.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Configuration Properties", "heading_level": 4, "file_order": 33, "section_index": 6, "content_hash": "e02c8f6764f38c72ddaa41db8ed7c1ac8ce007bd7bb793d4dcd86225b1184882", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:4604fb4c7af090753880c77a54ce5459d9eebd939b97b134b1434f272596a244", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-minimax/src/main/java/org/springframework/ai/minimax/MiniMaxEmbeddingOptions.java[MiniMaxEmbeddingOptions.java] provides the MiniMax configurations, such as the model to use and etc.\n\nThe default options can be configured using the `spring.ai.minimax.embedding.options` properties as well.\n\nAt start-time use the `MiniMaxEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, using a `MiniMaxEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n MiniMaxEmbeddingOptions.builder()\n .model(\"Different-Embedding-Model-Deployment-Name\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 33, "section_index": 7, "content_hash": "4604fb4c7af090753880c77a54ce5459d9eebd939b97b134b1434f272596a244", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:8354ee67f89adcea525919cb4fd6e73c84108c30b825c25ca3b7ec95002a515e", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingC` implementation.\n\n[source,application.properties]\n----\nspring.ai.minimax.api-key=YOUR_API_KEY\nspring.ai.minimax.embedding.options.model=embo-01\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Sample Controller", "heading_level": 2, "file_order": 33, "section_index": 8, "content_hash": "8354ee67f89adcea525919cb4fd6e73c84108c30b825c25ca3b7ec95002a515e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:d6a3240ee23744632b061ae3d28777f940bf5cb22cf9bd3324af5f5c9b717322", "content": "If you are not using Spring Boot, you can manually configure the MiniMax Embedding Model.\nFor this add the `spring-ai-minimax` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-minimax</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-minimax'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-minimax` dependency provides access also to the `MiniMaxChatModel`.\nFor more information about the `MiniMaxChatModel refer to the link:../chat/minimax-chat.html[MiniMax Chat Client] section.\n\nNext, create an `MiniMaxEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar miniMaxApi = new MiniMaxApi(System.getenv(\"MINIMAX_API_KEY\"));\n\nvar embeddingModel = new MiniMaxEmbeddingModel(minimaxApi, MetadataMode.EMBED,\nMiniMaxEmbeddingOptions.builder().model(\"embo-01\").build());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nThe `MiniMaxEmbeddingOptions` provides the configuration information for the embedding requests.\nThe options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc", "title": "MiniMax Chat", "heading": "Manual Configuration", "heading_level": 2, "file_order": 33, "section_index": 9, "content_hash": "d6a3240ee23744632b061ae3d28777f940bf5cb22cf9bd3324af5f5c9b717322", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/minimax-embeddings.adoc"}}
{"id": "sha256:3c5f7cdb66ee2b435bfcef1c62212059b4ace3bbdbf51ac362527bf5b93d8b57", "content": "Spring AI supports the Mistral AI's text embeddings models.\nEmbeddings are vectorial representations of text that capture the semantic meaning of paragraphs through their position in a high dimensional vector space. Mistral AI Embeddings API offers cutting-edge, state-of-the-art embeddings for text, which can be used for many NLP tasks.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Mistral AI Embeddings", "heading_level": 1, "file_order": 34, "section_index": 0, "content_hash": "3c5f7cdb66ee2b435bfcef1c62212059b4ace3bbdbf51ac362527bf5b93d8b57", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:94c1352985db4c65e24ada2c124c8097bb2bdfe12c88044579cf9acd8f14d0a3", "content": "Mistral AI provides two embedding models, each optimized for different use cases:\n\n[cols=\"2,2,1,4\", stripes=even]\n|====\n| Model | Dimensions | Use Case | Description\n\n| `mistral-embed`\n| 1024\n| General text\n| General-purpose embedding model suitable for semantic search, clustering, and text similarity tasks. Ideal for natural language content.\n\n| `codestral-embed`\n| 1536\n| Code\n| Specialized embedding model optimized for code similarity, code search, and retrieval-augmented generation (RAG) with code repositories. Provides higher-dimensional embeddings specifically designed for understanding code semantics.\n|====\n\nWhen choosing a model:\n\n* Use `mistral-embed` for general text content such as documents, articles, or user queries\n* Use `codestral-embed` when working with code, technical documentation, or building code-aware RAG systems", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Available Models", "heading_level": 2, "file_order": 34, "section_index": 1, "content_hash": "94c1352985db4c65e24ada2c124c8097bb2bdfe12c88044579cf9acd8f14d0a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:820bb94e24cf9403bdaad4e999052a8f4cd742234339d3e4478f30737970a945", "content": "You will need to create an API with MistralAI to access MistralAI embeddings models.\n\nCreate an account at https://auth.mistral.ai/ui/registration[MistralAI registration page] and generate the token on the https://console.mistral.ai/api-keys/[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.mistralai.api-key` that you should set to the value of the `API Key` obtained from console.mistral.ai.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.mistralai.api-key=<your-mistralai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n mistralai:\n api-key: ${MISTRALAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport MISTRALAI_API_KEY=<your-mistralai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"MISTRALAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 34, "section_index": 2, "content_hash": "820bb94e24cf9403bdaad4e999052a8f4cd742234339d3e4478f30737970a945", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:081c7344e977d4ae011d6972ee27113c16e215973cd33f666706067e9b644979", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 34, "section_index": 3, "content_hash": "081c7344e977d4ae011d6972ee27113c16e215973cd33f666706067e9b644979", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:1a2e28260a67d7bb8d8abcdb861693883ddf68e386b17875b7c0ef7248d0897d", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the MistralAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 34, "section_index": 4, "content_hash": "1a2e28260a67d7bb8d8abcdb861693883ddf68e386b17875b7c0ef7248d0897d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:494fece79d394eca49570c30e509e5a2ae3235b1fb44d100d68b0d7347acf478", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the Mistral AI Embedding model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Retry Properties", "heading_level": 4, "file_order": 34, "section_index": 5, "content_hash": "494fece79d394eca49570c30e509e5a2ae3235b1fb44d100d68b0d7347acf478", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:beb8860219557d0468448d8fdd2bf5ef32b33252226d9790acad154f9583e102", "content": "The prefix `spring.ai.mistralai` is used as the property prefix that lets you connect to MistralAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.mistralai.base-url | The URL to connect to | https://api.mistral.ai\n| spring.ai.mistralai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Connection Properties", "heading_level": 4, "file_order": 34, "section_index": 6, "content_hash": "beb8860219557d0468448d8fdd2bf5ef32b33252226d9790acad154f9583e102", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:133f65f1429561f856db89af47d4a208700ce369ab150cd018cea78ba78c158f", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=mistral (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match mistral)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.mistralai.embedding` is property prefix that configures the `EmbeddingModel` implementation for MistralAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.mistralai.embedding.enabled (Removed and no longer valid) | Enable OpenAI embedding model. | true\n| spring.ai.model.embedding | Enable OpenAI embedding model. | mistral\n| spring.ai.mistralai.embedding.base-url | Optional overrides the spring.ai.mistralai.base-url to provide embedding specific url | -\n| spring.ai.mistralai.embedding.api-key | Optional overrides the spring.ai.mistralai.api-key to provide embedding specific api-key | -\n| spring.ai.mistralai.embedding.metadata-mode | Document content extraction mode. | EMBED\n| spring.ai.mistralai.embedding.options.model | The model to use | mistral-embed\n| spring.ai.mistralai.embedding.options.encodingFormat | The format to return the embeddings in. Can be either float or base64. | -\n|====\n\nNOTE: You can override the common `spring.ai.mistralai.base-url` and `spring.ai.mistralai.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.mistralai.embedding.base-url` and `spring.ai.mistralai.embedding.api-key` properties if set take precedence over the common properties.\nSimilarly, the `spring.ai.mistralai.chat.base-url` and `spring.ai.mistralai.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different MistralAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.mistralai.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Configuration Properties", "heading_level": 4, "file_order": 34, "section_index": 7, "content_hash": "133f65f1429561f856db89af47d4a208700ce369ab150cd018cea78ba78c158f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:adf8b5d4402d37e0abfe883af18f79fc0cfeecbc1153c27e349b598d0c291f72", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/MistralAiEmbeddingOptions.java[MistralAiEmbeddingOptions.java] provides the MistralAI configurations, such as the model to use and etc.\n\nThe default options can be configured using the `spring.ai.mistralai.embedding.options` properties as well.\n\nAt start-time use the `MistralAiEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, using a `MistralAiEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse textEmbeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n MistralAiEmbeddingOptions.builder()\n .withModel(\"mistral-embed\")\n .build()));\n\nEmbeddingResponse codeEmbeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"public class HelloWorld {}\", \"def hello_world():\"),\n MistralAiEmbeddingOptions.builder()\n .withModel(\"codestral-embed\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 34, "section_index": 8, "content_hash": "adf8b5d4402d37e0abfe883af18f79fc0cfeecbc1153c27e349b598d0c291f72", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:8661c223c784d1b6fb2ded052cb0729661423cc3622fc93a69e14af598cd33af", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.mistralai.api-key=YOUR_API_KEY\nspring.ai.mistralai.embedding.options.model=mistral-embed\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n var embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 34, "section_index": 9, "content_hash": "8661c223c784d1b6fb2ded052cb0729661423cc3622fc93a69e14af598cd33af", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:ce9ae13d34fc55e956f7b5f66eaa5ccb87607250830a6eea1eb28d96a6f8db43", "content": "If you are not using Spring Boot, you can manually configure the OpenAI Embedding Model.\nFor this add the `spring-ai-mistral-ai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-mistral-ai` dependency provides access also to the `MistralAiChatModel`.\nFor more information about the `MistralAiChatModel` refer to the link:../chat/mistralai-chat.html[MistralAI Chat Client] section.\n\nNext, create an `MistralAiEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar mistralAiApi = new MistralAiApi(System.getenv(\"MISTRAL_AI_API_KEY\"));\n\nvar embeddingModel = new MistralAiEmbeddingModel(this.mistralAiApi,\n MistralAiEmbeddingOptions.builder()\n .withModel(\"mistral-embed\")\n .withEncodingFormat(\"float\")\n .build());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n .embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nThe `MistralAiEmbeddingOptions` provides the configuration information for the embedding requests.\nThe options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc", "title": "Mistral AI Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 34, "section_index": 10, "content_hash": "ce9ae13d34fc55e956f7b5f66eaa5ccb87607250830a6eea1eb28d96a6f8db43", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/mistralai-embeddings.adoc"}}
{"id": "sha256:e302a0df5964e5446fea98e483c34a7cfa8f94ec12bcac089dfdaa2be7794fc5", "content": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/[OCI GenAI Service] offers text embedding with on-demand models, or dedicated AI clusters.\n\nThe https://docs.oracle.com/en-us/iaas/Content/generative-ai/embed-models.htm[OCI Embedding Models Page] and https://docs.oracle.com/en-us/iaas/Content/generative-ai/use-playground-embed.htm[OCI Text Embeddings Page] provide detailed information about using and hosting embedding models on OCI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading_level": 1, "file_order": 35, "section_index": 0, "content_hash": "e302a0df5964e5446fea98e483c34a7cfa8f94ec12bcac089dfdaa2be7794fc5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:fad167ffa46d1c54a26f2e688a6db32c61ebd097595114977f4cce7dcbae0a62", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 35, "section_index": 1, "content_hash": "fad167ffa46d1c54a26f2e688a6db32c61ebd097595114977f4cce7dcbae0a62", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:6ed2726aa645f875eac6604eeb439b63f87e00182c14104791bcb49f9270ff96", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OCI GenAI Embedding Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-oci-genai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-oci-genai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 35, "section_index": 2, "content_hash": "6ed2726aa645f875eac6604eeb439b63f87e00182c14104791bcb49f9270ff96", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:961a99bedb3b61d7511b5ba931b0dde51d36f2e73199ee1a4d6458d3183f300f", "content": "The prefix `spring.ai.oci.genai` is the property prefix to configure the connection to OCI GenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.oci.genai.authenticationType | The type of authentication to use when authenticating to OCI. May be `file`, `instance-principal`, `workload-identity`, or `simple`. | file\n| spring.ai.oci.genai.region | OCI service region. | us-chicago-1\n| spring.ai.oci.genai.tenantId | OCI tenant OCID, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.userId | OCI user OCID, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.fingerprint | Private key fingerprint, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.privateKey | Private key content, used when authenticating with `simple` auth. | -\n| spring.ai.oci.genai.passPhrase | Optional private key passphrase, used when authenticating with `simple` auth and a passphrase protected private key. | -\n| spring.ai.oci.genai.file | Path to OCI config file. Used when authenticating with `file` auth. | <user's home directory>/.oci/config\n| spring.ai.oci.genai.profile | OCI profile name. Used when authenticating with `file` auth. | DEFAULT\n| spring.ai.oci.genai.endpoint | Optional OCI GenAI endpoint. | -\n\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=oci-genai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match oci-genai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.oci.genai.embedding` is the property prefix that configures the `EmbeddingModel` implementation for OCI GenAI\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.oci.genai.embedding.enabled (Removed and no longer valid) | Enable OCI GenAI embedding model. | true\n| spring.ai.model.embedding | Enable OCI GenAI embedding model. | oci-genai\n| spring.ai.oci.genai.embedding.compartment | Model compartment OCID. | -\n| spring.ai.oci.genai.embedding.servingMode | The model serving mode to be used. May be `on-demand`, or `dedicated`. | on-demand\n| spring.ai.oci.genai.embedding.truncate | How to truncate text if it overruns the embedding context. May be `START`, or `END`. | END\n| spring.ai.oci.genai.embedding.model | The model or model endpoint used for embeddings. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.oci.genai.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 35, "section_index": 3, "content_hash": "961a99bedb3b61d7511b5ba931b0dde51d36f2e73199ee1a4d6458d3183f300f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:353b7b9c98778b044a9f66a8ef38644a726838d956197325b1f357251733e9bc", "content": "The `OCIEmbeddingOptions` provides the configuration information for the embedding requests.\nThe `OCIEmbeddingOptions` offers a builder to create the options.\n\nAt start time use the `OCIEmbeddingOptions` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, by passing a `OCIEmbeddingOptions` instance with your to the `EmbeddingRequest` request.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n OCIEmbeddingOptions.builder()\n .model(\"my-other-embedding-model\")\n .build()\n));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 35, "section_index": 4, "content_hash": "353b7b9c98778b044a9f66a8ef38644a726838d956197325b1f357251733e9bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:0f96889f0e285dbe06e242042fb09bbb1a95580e94a3f0ef372e454f1a07dba2", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.oci.genai.embedding.model=<your model>\nspring.ai.oci.genai.embedding.compartment=<your model compartment>\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Sample Code", "heading_level": 2, "file_order": 35, "section_index": 5, "content_hash": "0f96889f0e285dbe06e242042fb09bbb1a95580e94a3f0ef372e454f1a07dba2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:9252f47f4bddbb6037803ea807b84180b7b0f91dc007eb79621e97fdf47e1d67", "content": "If you prefer not to use the Spring Boot auto-configuration, you can manually configure the `OCIEmbeddingModel` in your application.\nFor this add the `spring-oci-genai-openai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-oci-genai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,gradle]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-oci-genai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `OCIEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nfinal String EMBEDDING_MODEL = \"cohere.embed-english-light-v2.0\";\nfinal String CONFIG_FILE = Paths.get(System.getProperty(\"user.home\"), \".oci\", \"config\").toString();\nfinal String PROFILE = \"DEFAULT\";\nfinal String REGION = \"us-chicago-1\";\nfinal String COMPARTMENT_ID = System.getenv(\"OCI_COMPARTMENT_ID\");\n\nvar authProvider = new ConfigFileAuthenticationDetailsProvider(\n this.CONFIG_FILE, this.PROFILE);\nvar aiClient = GenerativeAiInferenceClient.builder()\n .region(Region.valueOf(this.REGION))\n .build(this.authProvider);\nvar options = OCIEmbeddingOptions.builder()\n .model(this.EMBEDDING_MODEL)\n .compartment(this.COMPARTMENT_ID)\n .servingMode(\"on-demand\")\n .build();\nvar embeddingModel = new OCIEmbeddingModel(this.aiClient, this.options);\nList<Double> embedding = this.embeddingModel.embed(new Document(\"How many provinces are in Canada?\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc", "title": "Oracle Cloud Infrastructure (OCI) GenAI Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 35, "section_index": 6, "content_hash": "9252f47f4bddbb6037803ea807b84180b7b0f91dc007eb79621e97fdf47e1d67", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/oci-genai-embeddings.adoc"}}
{"id": "sha256:96e1a12766fb6e99ce2479ac0a642929a61045ce14a68fd70e4b7087448bb3e6", "content": "With https://ollama.ai/[Ollama] you can run various https://ollama.com/search?c=embedding[AI Models] locally and generate embeddings from them.\nAn embedding is a vector (list) of floating point numbers.\nThe distance between two vectors measures their relatedness.\nSmall distances suggest high relatedness and large distances suggest low relatedness.\n\nThe `OllamaEmbeddingModel` implementation leverages the Ollama https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings[Embeddings API] endpoint.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Ollama Embeddings", "heading_level": 1, "file_order": 36, "section_index": 0, "content_hash": "96e1a12766fb6e99ce2479ac0a642929a61045ce14a68fd70e4b7087448bb3e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:efa2165b17452136431f02fb8240c28e5aa284b7ffbab5ed4446409e3db96891", "content": "You first need access to an Ollama instance. There are a few options, including the following:\n\n* link:https://ollama.com/download[Download and install Ollama] on your local machine.\n* Configure and xref:api/testcontainers.adoc[run Ollama via Testcontainers].\n* Bind to an Ollama instance via xref:api/cloud-bindings.adoc[Kubernetes Service Bindings].\n\nYou can pull the models you want to use in your application from the https://ollama.com/search?c=embedding[Ollama model library]:\n\n[source,shellscript]\n----\nollama pull <model-name>\n----\n\nYou can also pull any of the thousands, free, link:https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face Models]:\n\n[source,shellscript]\n----\nollama pull hf.co/<username>/<model-repository>\n----\n\nAlternatively, you can enable the option to download automatically any needed model: xref:auto-pulling-models[Auto-pulling Models].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 36, "section_index": 1, "content_hash": "efa2165b17452136431f02fb8240c28e5aa284b7ffbab5ed4446409e3db96891", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:e2886dd914a63c2d79fc9c69e187ad9d0ab49b0473dfef25ab7627ea6353917a", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure Ollama Embedding Model.\nTo enable it add the following dependency to your Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-ollama</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-ollama'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\nSpring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the Repositories section to add these repositories to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 36, "section_index": 2, "content_hash": "e2886dd914a63c2d79fc9c69e187ad9d0ab49b0473dfef25ab7627ea6353917a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:c5b58f839c3b7b4df5c853643fede9d2aa837c0d051e7e2bfb37d02dcc26fa28", "content": "The prefix `spring.ai.ollama` is the property prefix to configure the connection to Ollama\n\n[cols=\"3,6,1\"]\n|====\n| Property | Description | Default\n| spring.ai.ollama.base-url | Base URL where Ollama API server is running. | `+http://localhost:11434+`\n|====\n\nHere are the properties for initializing the Ollama integration and xref:auto-pulling-models[auto-pulling models].\n\n[cols=\"3,6,1\"]\n|====\n| Property | Description | Default\n| spring.ai.ollama.init.pull-model-strategy | Whether to pull models at startup-time and how. | `never`\n| spring.ai.ollama.init.timeout | How long to wait for a model to be pulled. | `5m`\n| spring.ai.ollama.init.max-retries | Maximum number of retries for the model pull operation. | `0`\n| spring.ai.ollama.init.embedding.include | Include this type of models in the initialization task. | `true`\n| spring.ai.ollama.init.embedding.additional-models | Additional models to initialize besides the ones configured via default properties. | `[]`\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Base Properties", "heading_level": 3, "file_order": 36, "section_index": 3, "content_hash": "c5b58f839c3b7b4df5c853643fede9d2aa837c0d051e7e2bfb37d02dcc26fa28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:a23ab1af7efac50f4920553b9f7e0a81293932a5b2bd43cbb9d921404bfeaec9", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=ollama (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match ollama)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.ollama.embedding.options` is the property prefix that configures the Ollama embedding model.\nIt includes the Ollama request (advanced) parameters such as the `model`, `keep-alive`, and `truncate` as well as the Ollama model `options` properties.\n\nHere are the advanced request parameter for the Ollama embedding model:\n\n[cols=\"4,5,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.ollama.embedding.enabled (Removed and no longer valid) | Enables the Ollama embedding model auto-configuration. | true\n| spring.ai.model.embedding | Enables the Ollama embedding model auto-configuration. | ollama\n| spring.ai.ollama.embedding.options.model | The name of the https://github.com/ollama/ollama?tab=readme-ov-file#model-library[supported model] to use.\nYou can use dedicated https://ollama.com/search?c=embedding[Embedding Model] types | mxbai-embed-large\n| spring.ai.ollama.embedding.options.keep_alive | Controls how long the model will stay loaded into memory following the request | 5m\n| spring.ai.ollama.embedding.options.truncate | Truncates the end of each input to fit within context length. Returns error if false and context length is exceeded. | true\n|====\n\nThe remaining `options` properties are based on the link:https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values[Ollama Valid Parameters and Values] and link:https://github.com/ollama/ollama/blob/main/api/types.go[Ollama Types]. The default values are based on: link:https://github.com/ollama/ollama/blob/b538dc3858014f94b099730a592751a5454cab0a/api/types.go#L364[Ollama type defaults].\n\n[cols=\"4,5,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.ollama.embedding.options.numa | Whether to use NUMA. | false\n| spring.ai.ollama.embedding.options.num-ctx | Sets the size of the context window used to generate the next token. | 2048\n| spring.ai.ollama.embedding.options.num-batch | Prompt processing maximum batch size. | 512\n| spring.ai.ollama.embedding.options.num-gpu | The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to disable. 1 here indicates that NumGPU should be set dynamically | -1\n| spring.ai.ollama.embedding.options.main-gpu | When using multiple GPUs this option controls which GPU is used for small tensors for which the overhead of splitting the computation across all GPUs is not worthwhile. The GPU in question will use slightly more VRAM to store a scratch buffer for temporary results. | 0\n| spring.ai.ollama.embedding.options.low-vram | - | false\n| spring.ai.ollama.embedding.options.f16-kv | - | true\n| spring.ai.ollama.embedding.options.logits-all | Return logits for all the tokens, not just the last one. To enable completions to return logprobs, this must be true. | -\n| spring.ai.ollama.embedding.options.vocab-only | Load only the vocabulary, not the weights. | -\n| spring.ai.ollama.embedding.options.use-mmap | By default, models are mapped into memory, which allows the system to load only the necessary parts of the model as needed. However, if the model is larger than your total amount of RAM or if your system is low on available memory, using mmap might increase the risk of pageouts, negatively impacting performance. Disabling mmap results in slower load times but may reduce pageouts if you're not using mlock. Note that if the model is larger than the total amount of RAM, turning off mmap would prevent the model from loading at all. | null\n| spring.ai.ollama.embedding.options.use-mlock | Lock the model in memory, preventing it from being swapped out when memory-mapped. This can improve performance but trades away some of the advantages of memory-mapping by requiring more RAM to run and potentially slowing down load times as the model loads into RAM. | false\n| spring.ai.ollama.embedding.options.num-thread | Sets the number of threads to use during computation. By default, Ollama will detect this for optimal performance. It is recommended to set this value to the number of physical CPU cores your system has (as opposed to the logical number of cores). 0 = let the runtime decide | 0\n| spring.ai.ollama.embedding.options.num-keep | - | 4\n| spring.ai.ollama.embedding.options.seed | Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt. | -1\n| spring.ai.ollama.embedding.options.num-predict | Maximum number of tokens to predict when generating text. (-1 = infinite generation, -2 = fill context) | -1\n| spring.ai.ollama.embedding.options.top-k | Reduces the probability of generating nonsense. A higher value (e.g., 100) will give more diverse answers, while a lower value (e.g., 10) will be more conservative. | 40\n| spring.ai.ollama.embedding.options.top-p | Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. | 0.9\n| spring.ai.ollama.embedding.options.min-p | Alternative to the top_p, and aims to ensure a balance of quality and variety. The parameter p represents the minimum probability for a token to be considered, relative to the probability of the most likely token. For example, with p=0.05 and the most likely token having a probability of 0.9, logits with a value less than 0.045 are filtered out. | 0.0\n| spring.ai.ollama.embedding.options.tfs-z | Tail-free sampling is used to reduce the impact of less probable tokens from the output. A higher value (e.g., 2.0) will reduce the impact more, while a value of 1.0 disables this setting. | 1.0\n| spring.ai.ollama.embedding.options.typical-p | - | 1.0\n| spring.ai.ollama.embedding.options.repeat-last-n | Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx) | 64\n| spring.ai.ollama.embedding.options.temperature | The temperature of the model. Increasing the temperature will make the model answer more creatively. | 0.8\n| spring.ai.ollama.embedding.options.repeat-penalty | Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. | 1.1\n| spring.ai.ollama.embedding.options.presence-penalty | - | 0.0\n| spring.ai.ollama.embedding.options.frequency-penalty | - | 0.0\n| spring.ai.ollama.embedding.options.mirostat | Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0) | 0\n| spring.ai.ollama.embedding.options.mirostat-tau | Controls the balance between coherence and diversity of the output. A lower value will result in more focused and coherent text. | 5.0\n| spring.ai.ollama.embedding.options.mirostat-eta | Influences how quickly the algorithm responds to feedback from the generated text. A lower learning rate will result in slower adjustments, while a higher learning rate will make the algorithm more responsive. | 0.1\n| spring.ai.ollama.embedding.options.penalize-newline | - | true\n| spring.ai.ollama.embedding.options.stop | Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Multiple stop patterns may be set by specifying multiple separate stop parameters in a modelfile. | -\n| spring.ai.ollama.embedding.options.functions | List of functions, identified by their names, to enable for function calling in a single prompt requests. Functions with those names must exist in the functionCallbacks registry. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.ollama.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 36, "section_index": 4, "content_hash": "a23ab1af7efac50f4920553b9f7e0a81293932a5b2bd43cbb9d921404bfeaec9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:6badf7a2899f10196b57d8e0082a9f2b5920e78f24a75c923f9551afe3011a77", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-ollama/src/main/java/org/springframework/ai/ollama/api/OllamaEmbeddingOptions.java[OllamaEmbeddingOptions.java] provides the Ollama configurations, such as the model to use, the low level GPU and CPU tuning, etc.\n\nIMPORTANT: The `OllamaOptions` class has been deprecated. Use `OllamaChatOptions` for chat models and `OllamaEmbeddingOptions` for embedding models instead. The new classes provide type-safe, model-specific configuration options.\n\nThe default options can be configured using the `spring.ai.ollama.embedding.options` properties as well.\n\nAt start-time use the `OllamaEmbeddingModel(OllamaApi ollamaApi, OllamaEmbeddingOptions defaultOptions)` to configure the default options used for all embedding requests.\nAt run-time you can override the default options, using a `OllamaEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n OllamaEmbeddingOptions.builder()\n .model(\"Different-Embedding-Model-Deployment-Name\"))\n .truncates(false)\n .build());\n----\n\n[[auto-pulling-models]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 36, "section_index": 5, "content_hash": "6badf7a2899f10196b57d8e0082a9f2b5920e78f24a75c923f9551afe3011a77", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:89eaba41195641ca3cbff016d70c66284350e24f7f6cede39a86e5466d8b3f0a", "content": "Spring AI Ollama can automatically pull models when they are not available in your Ollama instance.\nThis feature is particularly useful for development and testing as well as for deploying your applications to new environments.\n\nTIP: You can also pull, by name, any of the thousands, free, link:https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face Models].\n\nThere are three strategies for pulling models:\n\n* `always` (defined in `PullModelStrategy.ALWAYS`): Always pull the model, even if it's already available. Useful to ensure you're using the latest version of the model.\n* `when_missing` (defined in `PullModelStrategy.WHEN_MISSING`): Only pull the model if it's not already available. This may result in using an older version of the model.\n* `never` (defined in `PullModelStrategy.NEVER`): Never pull the model automatically.\n\nCAUTION: Due to potential delays while downloading models, automatic pulling is not recommended for production environments. Instead, consider assessing and pre-downloading the necessary models in advance.\n\nAll models defined via configuration properties and default options can be automatically pulled at startup time.\nYou can configure the pull strategy, timeout, and maximum number of retries using configuration properties:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n timeout: 60s\n max-retries: 1\n----\n\nCAUTION: The application will not complete its initialization until all specified models are available in Ollama. Depending on the model size and internet connection speed, this may significantly slow down your application's startup time.\n\nYou can initialize additional models at startup, which is useful for models used dynamically at runtime:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n embedding:\n additional-models:\n - mxbai-embed-large\n - nomic-embed-text\n----\n\nIf you want to apply the pulling strategy only to specific types of models, you can exclude embedding models from the initialization task:\n\n[source,yaml]\n----\nspring:\n ai:\n ollama:\n init:\n pull-model-strategy: always\n embedding:\n include: false\n----\n\nThis configuration will apply the pulling strategy to all models except embedding models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Auto-pulling Models", "heading_level": 2, "file_order": 36, "section_index": 6, "content_hash": "89eaba41195641ca3cbff016d70c66284350e24f7f6cede39a86e5466d8b3f0a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:a543fd355ce2ee313efab22fe1ea74d6b1ed13075b42206c787320d036822409", "content": "Ollama can access, out of the box, all https://huggingface.co/models?library=gguf&sort=trending[GGUF Hugging Face] Embedding models.\nYou can pull any of these models by name: `ollama pull hf.co/<username>/<model-repository>` or configure the auto-pulling strategy: xref:auto-pulling-models[Auto-pulling Models]:\n\n[source]\n----\nspring.ai.ollama.embedding.options.model=hf.co/mixedbread-ai/mxbai-embed-large-v1\nspring.ai.ollama.init.pull-model-strategy=always\n----\n\n- `spring.ai.ollama.embedding.options.model`: Specifies the https://huggingface.co/models?library=gguf&sort=trending[Hugging Face GGUF model] to use.\n- `spring.ai.ollama.init.pull-model-strategy=always`: (optional) Enables automatic model pulling at startup time.\nFor production, you should pre-download the models to avoid delays: `ollama pull hf.co/mixedbread-ai/mxbai-embed-large-v1`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "HuggingFace Models", "heading_level": 2, "file_order": 36, "section_index": 7, "content_hash": "a543fd355ce2ee313efab22fe1ea74d6b1ed13075b42206c787320d036822409", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:5d117d2e1c26ecee28d0fa0fa2c1fabedd22be7f8cdf7ccd341ba2f6b91a5364", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 36, "section_index": 8, "content_hash": "5d117d2e1c26ecee28d0fa0fa2c1fabedd22be7f8cdf7ccd341ba2f6b91a5364", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:6e3a4d053a6c5d2bdd42b4616f65f1b544287333fe1842448159175452a114d6", "content": "If you are not using Spring Boot, you can manually configure the `OllamaEmbeddingModel`.\nFor this add the spring-ai-ollama dependency to your project’s Maven pom.xml or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-ollama</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-ollama'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-ollama` dependency provides access also to the `OllamaChatModel`.\nFor more information about the `OllamaChatModel` refer to the link:../chat/ollama-chat.html[Ollama Chat Client] section.\n\nNext, create an `OllamaEmbeddingModel` instance and use it to compute the embeddings for two input texts using a dedicated `chroma/all-minilm-l6-v2-f32` embedding models:\n\n[source,java]\n----\nvar ollamaApi = OllamaApi.builder().build();\n\nvar embeddingModel = new OllamaEmbeddingModel(this.ollamaApi,\n OllamaEmbeddingOptions.builder()\n .model(OllamaModel.MISTRAL.id())\n .build());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n OllamaEmbeddingOptions.builder()\n .model(\"chroma/all-minilm-l6-v2-f32\"))\n .truncate(false)\n .build());\n----\n\nThe `OllamaEmbeddingOptions` provides the configuration information for all embedding requests.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc", "title": "Ollama Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 36, "section_index": 9, "content_hash": "6e3a4d053a6c5d2bdd42b4616f65f1b544287333fe1842448159175452a114d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/ollama-embeddings.adoc"}}
{"id": "sha256:eadc6c7d352d4bf0acf3ee0e5d7f84294fe9d51d8febfac06fcf40530dd9fea2", "content": "The `TransformersEmbeddingModel` is an `EmbeddingModel` implementation that locally computes https://www.sbert.net/examples/applications/computing-embeddings/README.html#sentence-embeddings-with-transformers[sentence embeddings] using a selected https://www.sbert.net/[sentence transformer].\n\nYou can use any link:https://huggingface.co/spaces/mteb/leaderboard[HuggingFace Embedding model].\n\nIt uses https://www.sbert.net/docs/pretrained_models.html[pre-trained] transformer models, serialized into the https://onnx.ai/[Open Neural Network Exchange (ONNX)] format.\n\nThe https://djl.ai/[Deep Java Library] and the Microsoft https://onnxruntime.ai/docs/get-started/with-java.html[ONNX Java Runtime] libraries are applied to run the ONNX models and compute the embeddings in Java.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Transformers (ONNX) Embeddings", "heading_level": 1, "file_order": 37, "section_index": 0, "content_hash": "eadc6c7d352d4bf0acf3ee0e5d7f84294fe9d51d8febfac06fcf40530dd9fea2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:3904ef73a75dc0c24acff20b2add9f22bc70381671d2b86f90675ae747207b77", "content": "To run things in Java, we need to *serialize the Tokenizer and the Transformer Model* into `ONNX` format.\n\nSerialize with optimum-cli - One, quick, way to achieve this, is to use the https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli[optimum-cli] command line tool.\nThe following snippet prepares a python virtual environment, installs the required packages and serializes (e.g. exports) the specified model using `optimum-cli` :\n\n[source,bash]\n----\npython3 -m venv venv\nsource ./venv/bin/activate\n(venv) pip install --upgrade pip\n(venv) pip install optimum onnx onnxruntime sentence-transformers\n(venv) optimum-cli export onnx --model sentence-transformers/all-MiniLM-L6-v2 onnx-output-folder\n----\n\nThe snippet exports the https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2[sentence-transformers/all-MiniLM-L6-v2] transformer into the `onnx-output-folder` folder. The latter includes the `tokenizer.json` and `model.onnx` files used by the embedding model.\n\nIn place of the all-MiniLM-L6-v2 you can pick any huggingface transformer identifier or provide direct file path.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 37, "section_index": 1, "content_hash": "3904ef73a75dc0c24acff20b2add9f22bc70381671d2b86f90675ae747207b77", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:3f1891096d4d52f1338ba3429f6e20897f77d96120edf9d1d0b9d8e4921f2a12", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the ONNX Transformer Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-transformers</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-transformers'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo configure it, use the `spring.ai.embedding.transformer.*` properties.\n\nFor example, add this to your _application.properties_ file to configure the client with the https://huggingface.co/intfloat/e5-small-v2[intfloat/e5-small-v2] text embedding model:\n\n----\nspring.ai.embedding.transformer.onnx.modelUri=https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx\nspring.ai.embedding.transformer.tokenizer.uri=https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json\n----\n\nThe complete list of supported properties are:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 37, "section_index": 2, "content_hash": "3f1891096d4d52f1338ba3429f6e20897f77d96120edf9d1d0b9d8e4921f2a12", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:b0ea47581bdb1438cb7606ec7a9cacbb8bee60a8fbd74cdc4e99929aa104cd7b", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=transformers (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match transformers)\n\nThis change is done to allow configuration of multiple models.\n====\n\n[cols=\"3*\"\", stripes=even]\n|===\n| Property | Description | Default\n\n| spring.ai.embedding.transformer.enabled (Removed and no longer valid) | Enable the Transformer Embedding model. | true\n| spring.ai.model.embedding | Enable the Transformer Embedding model. | transformers\n| spring.ai.embedding.transformer.tokenizer.uri | URI of a pre-trained HuggingFaceTokenizer created by the ONNX engine (e.g. tokenizer.json). | onnx/all-MiniLM-L6-v2/tokenizer.json\n| spring.ai.embedding.transformer.tokenizer.options | HuggingFaceTokenizer options such as '`addSpecialTokens`', '`modelMaxLength`', '`truncation`', '`padding`', '`maxLength`', '`stride`', '`padToMultipleOf`'. Leave empty to fallback to the defaults. | empty\n| spring.ai.embedding.transformer.cache.enabled | Enable remote Resource caching. | true\n| spring.ai.embedding.transformer.cache.directory | Directory path to cache remote resources, such as the ONNX models | ${java.io.tmpdir}/spring-ai-onnx-model\n| spring.ai.embedding.transformer.onnx.modelUri | Existing, pre-trained ONNX model. | onnx/all-MiniLM-L6-v2/model.onnx\n| spring.ai.embedding.transformer.onnx.modelOutputName | The ONNX model's output node name, which we'll use for embedding calculation. | last_hidden_state\n| spring.ai.embedding.transformer.onnx.gpuDeviceId | The GPU device ID to execute on. Only applicable if >= 0. Ignored otherwise.(Requires additional onnxruntime_gpu dependency) | -1\n| spring.ai.embedding.transformer.metadataMode | Specifies what parts of the Documents content and metadata will be used for computing the embeddings. | NONE\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 37, "section_index": 3, "content_hash": "b0ea47581bdb1438cb7606ec7a9cacbb8bee60a8fbd74cdc4e99929aa104cd7b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:c44b8ba36669caddfbdbd7189aac3e0a335b7c7b74ac1dfe38c9e8749f518d55", "content": "[NOTE]\n====\nIf you see an error like `Caused by: ai.onnxruntime.OrtException: Supplied array is ragged,..`, you need to also enable the tokenizer padding in `application.properties` as follows:\n\n----\nspring.ai.embedding.transformer.tokenizer.options.padding=true\n----\n====\n\n[NOTE]\n====\nIf you get an error like `The generative output names don't contain expected: last_hidden_state. Consider one of the available model outputs: token_embeddings, ....`, you need to set the model output name to a correct value per your models.\nConsider the names listed in the error message.\nFor example:\n\n----\nspring.ai.embedding.transformer.onnx.modelOutputName=token_embeddings\n----\n====\n\n[NOTE]\n====\nIf you get an error like `ai.onnxruntime.OrtException: Error code - ORT_FAIL - message: Deserialize tensor onnx::MatMul_10319 failed.GetFileLength for ./model.onnx_data failed:Invalid fd was supplied: -1`,\nthat means that you model is larger than 2GB and is serialized in two files: `model.onnx` and `model.onnx_data`.\n\nThe `model.onnx_data` is called link:https://onnx.ai/onnx/repo-docs/ExternalData.html#external-data[External Data] and is expected to be under the same directory of the `model.onnx`.\n\nCurrently the only workaround is to copy the large `model.onnx_data` in the folder you run your Boot application.\n====\n\n[NOTE]\n====\nIf you get an error like `ai.onnxruntime.OrtException: Error code - ORT_EP_FAIL - message: Failed to find CUDA shared provider`,\nthat means that you are using the GPU parameters `spring.ai.embedding.transformer.onnx.gpuDeviceId` , but the onnxruntime_gpu dependency are missing.\n----\n<dependency>\n <groupId>com.microsoft.onnxruntime</groupId>\n <artifactId>onnxruntime_gpu</artifactId>\n</dependency>\n----\nPlease select the appropriate onnxruntime_gpu version based on the CUDA version(link:https://onnxruntime.ai/docs/get-started/with-java.html[ONNX Java Runtime]).\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Errors and special cases", "heading_level": 3, "file_order": 37, "section_index": 4, "content_hash": "c44b8ba36669caddfbdbd7189aac3e0a335b7c7b74ac1dfe38c9e8749f518d55", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:9866055c60daa33a7a541675348240855c195e0919810432feebff8be8ec5f4f", "content": "If you are not using Spring Boot, you can manually configure the Onnx Transformers Embedding Model.\nFor this add the `spring-ai-transformers` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-transformers</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nthen create a new `TransformersEmbeddingModel` instance and use the `setTokenizerResource(tokenizerJsonUri)` and `setModelResource(modelOnnxUri)` methods to set the URIs of the exported `tokenizer.json` and `model.onnx` files. (`classpath:`, `file:` or `https:` URI schemas are supported).\n\nIf the model is not explicitly set, `TransformersEmbeddingModel` defaults to https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2[sentence-transformers/all-MiniLM-L6-v2]:\n\n[cols=\"2*\"]\n|===\n| Dimensions | 384\n| Avg. performance | 58.80\n| Speed | 14200 sentences/sec\n| Size | 80MB\n|===\n\nThe following snippet illustrates how to use the `TransformersEmbeddingModel` manually:\n\n[source,java]\n----\nTransformersEmbeddingModel embeddingModel = new TransformersEmbeddingModel();\n\nembeddingModel.setTokenizerResource(\"classpath:/onnx/all-MiniLM-L6-v2/tokenizer.json\");\n\nembeddingModel.setModelResource(\"classpath:/onnx/all-MiniLM-L6-v2/model.onnx\");\n\nembeddingModel.setResourceCacheDirectory(\"/tmp/onnx-zoo\");\n\nembeddingModel.setTokenizerOptions(Map.of(\"padding\", \"true\"));\n\nembeddingModel.afterPropertiesSet();\n\nList<List<Double>> embeddings = this.embeddingModel.embed(List.of(\"Hello world\", \"World is big\"));\n\n----\n\nNOTE: If you create an instance of `TransformersEmbeddingModel` manually, you must call the `afterPropertiesSet()` method after setting the properties and before using the client.\n\nThe first `embed()` call downloads the large ONNX model and caches it on the local file system.\nTherefore, the first call might take longer than usual.\nUse the `#setResourceCacheDirectory(<path>)` method to set the local folder where the ONNX models as stored.\nThe default cache folder is `${java.io.tmpdir}/spring-ai-onnx-model`.\n\nIt is more convenient (and preferred) to create the TransformersEmbeddingModel as a `Bean`.\nThen you don't have to call the `afterPropertiesSet()` manually.\n\n[source,java]\n----\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new TransformersEmbeddingModel();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/onnx.adoc", "title": "Transformers (ONNX) Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 37, "section_index": 5, "content_hash": "9866055c60daa33a7a541675348240855c195e0919810432feebff8be8ec5f4f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/onnx.adoc"}}
{"id": "sha256:e22fb930ae592d4771f1d007fe44076babba754fd7214a4a0cb7f9a8a283c792", "content": "Spring AI supports the OpenAI's text embeddings models.\nOpenAI’s text embeddings measure the relatedness of text strings.\nAn embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "OpenAI Embeddings", "heading_level": 1, "file_order": 38, "section_index": 0, "content_hash": "e22fb930ae592d4771f1d007fe44076babba754fd7214a4a0cb7f9a8a283c792", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:7d6e69055080741b6d068fd38cd8f83c3a60a71e17f360bb0231b69c291d6573", "content": "You will need to create an API with OpenAI to access OpenAI embeddings models.\n\nCreate an account at https://platform.openai.com/signup[OpenAI signup page] and generate the token on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from openai.com.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<your-openai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${OPENAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport OPENAI_API_KEY=<your-openai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"OPENAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 38, "section_index": 1, "content_hash": "7d6e69055080741b6d068fd38cd8f83c3a60a71e17f360bb0231b69c291d6573", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:0a68b0f9cfef4a34b0c3ac5c9e66700fb6e743a4a00c0a5b9745e1206412200e", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 38, "section_index": 2, "content_hash": "0a68b0f9cfef4a34b0c3ac5c9e66700fb6e743a4a00c0a5b9745e1206412200e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:530e2562aaf1fb48ac5a92f43d8ee7501ac60d8b71fa99cdfa773e00902b5e07", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 38, "section_index": 3, "content_hash": "530e2562aaf1fb48ac5a92f43d8ee7501ac60d8b71fa99cdfa773e00902b5e07", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:77721a874fba8eaa1a42a76dd43234b57d0af331e53025cbc56ccdb3f035b311", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI Embedding model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Retry Properties", "heading_level": 4, "file_order": 38, "section_index": 4, "content_hash": "77721a874fba8eaa1a42a76dd43234b57d0af331e53025cbc56ccdb3f035b311", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:e29973cd8cf7bdba665ba545c8ac588227d8d805a40f93ff0e8e6ea15e458123", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.base-url | The URL to connect to | +https://api.openai.com+\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project is used for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), optionally, you can specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Connection Properties", "heading_level": 4, "file_order": 38, "section_index": 5, "content_hash": "e29973cd8cf7bdba665ba545c8ac588227d8d805a40f93ff0e8e6ea15e458123", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:b7b942aec94eee29611d74ad9a9b578a15d3b30238d463a981064bf599b86c85", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=openai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.embedding` is property prefix that configures the `EmbeddingModel` implementation for OpenAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai.embedding.enabled (Required and no longer valid) | Enable OpenAI embedding model. | true\n| spring.ai.model.embedding | Enable OpenAI embedding model. | openai\n| spring.ai.openai.embedding.base-url | Optional overrides the spring.ai.openai.base-url to provide embedding specific url | -\n| spring.ai.openai.embedding.embeddings-path | The path to append to the base-url | `/v1/embeddings`\n| spring.ai.openai.embedding.api-key | Optional overrides the spring.ai.openai.api-key to provide embedding specific api-key | -\n| spring.ai.openai.embedding.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.embedding.project-id | Optionally, you can specify which project is used for an API request. | -\n| spring.ai.openai.embedding.metadata-mode | Document content extraction mode. | EMBED\n| spring.ai.openai.embedding.options.model | The model to use | text-embedding-ada-002 (other options: text-embedding-3-large, text-embedding-3-small)\n| spring.ai.openai.embedding.options.encodingFormat | The format to return the embeddings in. Can be either float or base64. | -\n| spring.ai.openai.embedding.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai.embedding.options.dimensions | The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models. | -\n|====\n\nNOTE: You can override the common `spring.ai.openai.base-url` and `spring.ai.openai.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.openai.embedding.base-url` and `spring.ai.openai.embedding.api-key` properties if set take precedence over the common properties.\nSimilarly, the `spring.ai.openai.chat.base-url` and `spring.ai.openai.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Configuration Properties", "heading_level": 4, "file_order": 38, "section_index": 6, "content_hash": "b7b942aec94eee29611d74ad9a9b578a15d3b30238d463a981064bf599b86c85", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:0d5f60e75d71535add4ef2d93956b263b937a66c04014d6aa14d07b46efbe872", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiEmbeddingOptions.java[OpenAiEmbeddingOptions.java] provides the OpenAI configurations, such as the model to use and etc.\n\nThe default options can be configured using the `spring.ai.openai.embedding.options` properties as well.\n\nAt start-time use the `OpenAiEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, using a `OpenAiEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n OpenAiEmbeddingOptions.builder()\n .model(\"Different-Embedding-Model-Deployment-Name\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 38, "section_index": 7, "content_hash": "0d5f60e75d71535add4ef2d93956b263b937a66c04014d6aa14d07b46efbe872", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:4d70587fa12cb47d0ef5e8218f4fcb02e881e4b63e5205e695f8d7a9bf89ad5e", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.openai.api-key=YOUR_API_KEY\nspring.ai.openai.embedding.options.model=text-embedding-ada-002\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 38, "section_index": 8, "content_hash": "4d70587fa12cb47d0ef5e8218f4fcb02e881e4b63e5205e695f8d7a9bf89ad5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:f7809f34f8ddccb59997e6fdd7b4d2184a8c1531914b872bcd5dd53b1f69d7ca", "content": "If you are not using Spring Boot, you can manually configure the OpenAI Embedding Model.\nFor this add the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-openai` dependency provides access also to the `OpenAiChatModel`.\nFor more information about the `OpenAiChatModel` refer to the link:../chat/openai-chat.html[OpenAI Chat Client] section.\n\nNext, create an `OpenAiEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar openAiApi = OpenAiApi.builder()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar embeddingModel = new OpenAiEmbeddingModel(\n this.openAiApi,\n MetadataMode.EMBED,\n OpenAiEmbeddingOptions.builder()\n .model(\"text-embedding-ada-002\")\n .user(\"user-6\")\n .build(),\n RetryUtils.DEFAULT_RETRY_TEMPLATE);\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n .embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nThe `OpenAiEmbeddingOptions` provides the configuration information for the embedding requests.\nThe api and options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc", "title": "OpenAI Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 38, "section_index": 9, "content_hash": "f7809f34f8ddccb59997e6fdd7b4d2184a8c1531914b872bcd5dd53b1f69d7ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-embeddings.adoc"}}
{"id": "sha256:ebe1df394fa8fe5e9563d52a112e2e022b6615c25428317e28a6a88749f7b273", "content": "Spring AI supports OpenAI's text embeddings models through the OpenAI Java SDK, providing a robust and officially-maintained integration with OpenAI's services including Microsoft Foundry and GitHub Models.\n\nNOTE: This implementation uses the official link:https://github.com/openai/openai-java[OpenAI Java SDK] from OpenAI. For the alternative Spring AI implementation, see xref:api/embeddings/openai-embeddings.adoc[OpenAI Embeddings].\n\nOpenAI's text embeddings measure the relatedness of text strings.\nAn embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.\n\nThe OpenAI SDK module automatically detects the service provider (OpenAI, Microsoft Foundry, or GitHub Models) based on the base URL you provide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "OpenAI SDK Embeddings (Official)", "heading_level": 1, "file_order": 39, "section_index": 0, "content_hash": "ebe1df394fa8fe5e9563d52a112e2e022b6615c25428317e28a6a88749f7b273", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:3978301e1fc0da55dad06efc56fdc2722b04de1a85b57d38d1f98df6d0be5caf", "content": "Authentication is done using a base URL and an API Key. The implementation provides flexible configuration options through Spring Boot properties or environment variables.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Authentication", "heading_level": 2, "file_order": 39, "section_index": 1, "content_hash": "3978301e1fc0da55dad06efc56fdc2722b04de1a85b57d38d1f98df6d0be5caf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:afaa13798de1a82cc93cc53cbf5371944c565d3c28a761347667cdb6293cecc6", "content": "If you are using OpenAI directly, create an account at https://platform.openai.com/signup[OpenAI signup page] and generate an API key on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe base URL doesn't need to be set as it defaults to `https://api.openai.com/v1`:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=<your-openai-api-key>\n# base-url is optional, defaults to https://api.openai.com/v1\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_API_KEY=<your-openai-api-key>\n# OPENAI_BASE_URL is optional, defaults to https://api.openai.com/v1\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Using OpenAI", "heading_level": 3, "file_order": 39, "section_index": 2, "content_hash": "afaa13798de1a82cc93cc53cbf5371944c565d3c28a761347667cdb6293cecc6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:1412e6bbdbaa6b789dd422763e441b6e1cad2efb6d991dc6dcd452acc740361e", "content": "Microsoft Foundry is automatically detected when using a Microsoft Foundry URL. You can configure it using properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.api-key=<your-api-key>\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://<your-deployment-url>.openai.azure.com\nexport OPENAI_API_KEY=<your-api-key>\n----\n\n**Passwordless Authentication (Recommended for Azure):**\n\nMicrosoft Foundry supports passwordless authentication without providing an API key, which is more secure when running on Azure.\n\nTo enable passwordless authentication, add the `com.azure:azure-identity` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>com.azure</groupId>\n <artifactId>azure-identity</artifactId>\n</dependency>\n----\n\nThen configure without an API key:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n# No api-key needed - will use Azure credentials from environment\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Using Microsoft Foundry", "heading_level": 3, "file_order": 39, "section_index": 3, "content_hash": "1412e6bbdbaa6b789dd422763e441b6e1cad2efb6d991dc6dcd452acc740361e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:c376e2a0b32af3d9c292fa02b51278dbb51d13fa6d33d3c55d66157139539612", "content": "GitHub Models is automatically detected when using the GitHub Models base URL. You'll need to create a GitHub Personal Access Token (PAT) with the `models:read` scope.\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://models.inference.ai.azure.com\nspring.ai.openai-sdk.api-key=github_pat_XXXXXXXXXXX\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://models.inference.ai.azure.com\nexport OPENAI_API_KEY=github_pat_XXXXXXXXXXX\n----\n\nTIP: For enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) in your properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=${OPENAI_API_KEY}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Using GitHub Models", "heading_level": 3, "file_order": 39, "section_index": 4, "content_hash": "c376e2a0b32af3d9c292fa02b51278dbb51d13fa6d33d3c55d66157139539612", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:3b808aae0e1c744c922b0cba6a7652f1ced5a4ae5b17f2ff8b0a95da3c32a95c", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 39, "section_index": 5, "content_hash": "3b808aae0e1c744c922b0cba6a7652f1ced5a4ae5b17f2ff8b0a95da3c32a95c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:937b16a66043009d32d22279d3ac9b942e3af4534e19d6b9183535179e4c2ea5", "content": "Spring AI provides Spring Boot auto-configuration for the OpenAI SDK Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai-sdk</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai-sdk'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Auto-configuration", "heading_level": 2, "file_order": 39, "section_index": 6, "content_hash": "937b16a66043009d32d22279d3ac9b942e3af4534e19d6b9183535179e4c2ea5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:d3c8b0921f779a115c018a51edf5482b5bce1310cc1f99c60adfc8cf87595ebc", "content": "The prefix `spring.ai.openai-sdk` is used as the property prefix that lets you configure the OpenAI SDK client.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.base-url | The URL to connect to. Auto-detects from `OPENAI_BASE_URL` environment variable if not set. | https://api.openai.com/v1\n| spring.ai.openai-sdk.api-key | The API Key. Auto-detects from `OPENAI_API_KEY` environment variable if not set. | -\n| spring.ai.openai-sdk.organization-id | Optionally specify which organization to use for API requests. | -\n| spring.ai.openai-sdk.timeout | Request timeout duration. | -\n| spring.ai.openai-sdk.max-retries | Maximum number of retry attempts for failed requests. | -\n| spring.ai.openai-sdk.proxy | Proxy settings for OpenAI client (Java `Proxy` object). | -\n| spring.ai.openai-sdk.custom-headers | Custom HTTP headers to include in requests. Map of header name to header value. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Connection Properties", "heading_level": 4, "file_order": 39, "section_index": 7, "content_hash": "d3c8b0921f779a115c018a51edf5482b5bce1310cc1f99c60adfc8cf87595ebc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:1c431e8db52c8acb479a2ab27dae40a664bf596655cadf8e089cc4c4d2b8d397", "content": "The OpenAI SDK implementation provides native support for Microsoft Foundry with automatic configuration:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.microsoft-foundry | Enable Microsoft Foundry mode. Auto-detected if base URL contains `openai.azure.com`, `cognitiveservices.azure.com`, or `.openai.microsoftFoundry.com`. | false\n| spring.ai.openai-sdk.microsoft-deployment-name | Microsoft Foundry deployment name. If not specified, the model name will be used. Also accessible via alias `deployment-name`. | -\n| spring.ai.openai-sdk.microsoft-foundry-service-version | Microsoft Foundry API service version. | -\n| spring.ai.openai-sdk.credential | Credential object for passwordless authentication (requires `com.azure:azure-identity` dependency). | -\n|====\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency and the implementation will automatically attempt to use Azure credentials from the environment when no API key is provided.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Microsoft Foundry Properties", "heading_level": 4, "file_order": 39, "section_index": 8, "content_hash": "1c431e8db52c8acb479a2ab27dae40a664bf596655cadf8e089cc4c4d2b8d397", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:4db86ce74a94a3252cf254fdec3c8687dc9e2565925973fc365661c885b208a9", "content": "Native support for GitHub Models is available:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.github-models | Enable GitHub Models mode. Auto-detected if base URL contains `models.github.ai` or `models.inference.ai.azure.com`. | false\n|====\n\nTIP: GitHub Models requires a Personal Access Token with the `models:read` scope. Set it via the `OPENAI_API_KEY` environment variable or the `spring.ai.openai-sdk.api-key` property.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "GitHub Models Properties", "heading_level": 4, "file_order": 39, "section_index": 9, "content_hash": "4db86ce74a94a3252cf254fdec3c8687dc9e2565925973fc365661c885b208a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:4dd1dcec5ff84526db6b5baee84e6ef2eb9bb803d2d7e4f79b3f36d9e15d6492", "content": "The prefix `spring.ai.openai-sdk.embedding` is the property prefix for configuring the embedding model implementation:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.embedding.metadata-mode | Document content extraction mode. | EMBED\n| spring.ai.openai-sdk.embedding.options.model | The model to use. You can select between models such as: `text-embedding-ada-002`, `text-embedding-3-small`, `text-embedding-3-large`. See the https://platform.openai.com/docs/models[models] page for more information. | `text-embedding-ada-002`\n| spring.ai.openai-sdk.embedding.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n| spring.ai.openai-sdk.embedding.options.dimensions | The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.openai-sdk.embedding.options` can be overridden at runtime by adding request-specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Embedding Model Properties", "heading_level": 4, "file_order": 39, "section_index": 10, "content_hash": "4dd1dcec5ff84526db6b5baee84e6ef2eb9bb803d2d7e4f79b3f36d9e15d6492", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:5e19635cbe9616af52b49d79c715d0327388e4541893d900436e2b9ce27c713b", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkEmbeddingOptions.java[OpenAiSdkEmbeddingOptions.java] provides the OpenAI configurations, such as the model to use, dimensions, and user identifier.\n\nThe default options can be configured using the `spring.ai.openai-sdk.embedding.options` properties as well.\n\nAt start-time use the `OpenAiSdkEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, using a `OpenAiSdkEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n OpenAiSdkEmbeddingOptions.builder()\n .model(\"text-embedding-3-large\")\n .dimensions(1024)\n .build()));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkEmbeddingOptions.java[OpenAiSdkEmbeddingOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/embedding/EmbeddingOptions.java[EmbeddingOptions] instance, created with the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 39, "section_index": 11, "content_hash": "5e19635cbe9616af52b49d79c715d0327388e4541893d900436e2b9ce27c713b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:40aada801eeda18319c5be14b8445399a9486ac1ed30f9a413e9e2c20aadbd67", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-openai-sdk` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file under the `src/main/resources` directory to configure the OpenAI SDK embedding model:\n\n[source,application.properties]\n----\nspring.ai.openai-sdk.api-key=YOUR_API_KEY\nspring.ai.openai-sdk.embedding.options.model=text-embedding-ada-002\n----\n\nTIP: Replace the `api-key` with your OpenAI credentials.\n\nThis will create an `OpenAiSdkEmbeddingModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the embedding model.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map<String, Object> embed(\n @RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Sample Controller", "heading_level": 2, "file_order": 39, "section_index": 12, "content_hash": "40aada801eeda18319c5be14b8445399a9486ac1ed30f9a413e9e2c20aadbd67", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:00ced5768db068668e7b09bc391fc8d6a7a8fe3d453a7cbfd974e3e74106f0c1", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkEmbeddingModel.java[OpenAiSdkEmbeddingModel] implements the `EmbeddingModel` and uses the official OpenAI Java SDK to connect to the OpenAI service.\n\nIf you are not using Spring Boot auto-configuration, you can manually configure the OpenAI SDK Embedding Model.\nFor this add the `spring-ai-openai-sdk` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai-sdk</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai-sdk'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-openai-sdk` dependency provides access also to the `OpenAiSdkChatModel` and `OpenAiSdkImageModel`.\nFor more information about the `OpenAiSdkChatModel` refer to the xref:api/chat/openai-sdk-chat.adoc[OpenAI SDK Chat] section.\n\nNext, create an `OpenAiSdkEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar embeddingOptions = OpenAiSdkEmbeddingOptions.builder()\n .model(\"text-embedding-ada-002\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar embeddingModel = new OpenAiSdkEmbeddingModel(embeddingOptions);\n\nEmbeddingResponse embeddingResponse = embeddingModel\n .embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nThe `OpenAiSdkEmbeddingOptions` provides the configuration information for the embedding requests.\nThe options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Manual Configuration", "heading_level": 2, "file_order": 39, "section_index": 13, "content_hash": "00ced5768db068668e7b09bc391fc8d6a7a8fe3d453a7cbfd974e3e74106f0c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:8c8087a913cf32219bcb50ad3891af08df420560df4c25fe07af79b4fb1fcccc", "content": "For Microsoft Foundry:\n\n[source,java]\n----\nvar embeddingOptions = OpenAiSdkEmbeddingOptions.builder()\n .baseUrl(\"https://your-resource.openai.azure.com\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .deploymentName(\"text-embedding-ada-002\")\n .azureOpenAIServiceVersion(AzureOpenAIServiceVersion.V2024_10_01_PREVIEW)\n .azure(true) // Enables Microsoft Foundry mode\n .build();\n\nvar embeddingModel = new OpenAiSdkEmbeddingModel(embeddingOptions);\n----\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency to your project. If you don't provide an API key, the implementation will automatically attempt to use Azure credentials from your environment.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Microsoft Foundry Configuration", "heading_level": 3, "file_order": 39, "section_index": 14, "content_hash": "8c8087a913cf32219bcb50ad3891af08df420560df4c25fe07af79b4fb1fcccc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:8ba49ee91ebcf9be739e8d98ced9aa2391c3ffe0a51d79b1fddae1adb755078f", "content": "For GitHub Models:\n\n[source,java]\n----\nvar embeddingOptions = OpenAiSdkEmbeddingOptions.builder()\n .baseUrl(\"https://models.inference.ai.azure.com\")\n .apiKey(System.getenv(\"GITHUB_TOKEN\"))\n .model(\"text-embedding-3-large\")\n .githubModels(true)\n .build();\n\nvar embeddingModel = new OpenAiSdkEmbeddingModel(embeddingOptions);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "GitHub Models Configuration", "heading_level": 3, "file_order": 39, "section_index": 15, "content_hash": "8ba49ee91ebcf9be739e8d98ced9aa2391c3ffe0a51d79b1fddae1adb755078f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:11549bd8017abde7ccaa565edc81d62dcf099eb76f215ad70d47f71f90bc0487", "content": "The OpenAI SDK implementation supports Spring AI's observability features through Micrometer.\nAll embedding model operations are instrumented for monitoring and tracing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Observability", "heading_level": 2, "file_order": 39, "section_index": 16, "content_hash": "11549bd8017abde7ccaa565edc81d62dcf099eb76f215ad70d47f71f90bc0487", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:bae5cfee86e88f2c4c737cd90b825d4787b9a48e57d2fc1fe92ee34183381bf3", "content": "* link:https://github.com/openai/openai-java[Official OpenAI Java SDK]\n* link:https://platform.openai.com/docs/api-reference/embeddings[OpenAI Embeddings API Documentation]\n* link:https://platform.openai.com/docs/models[OpenAI Models]\n* link:https://learn.microsoft.com/en-us/azure/ai-foundry/[Microsoft Foundry Documentation]\n* link:https://github.com/marketplace/models[GitHub Models]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc", "title": "OpenAI SDK Embeddings (Official)", "heading": "Additional Resources", "heading_level": 2, "file_order": 39, "section_index": 17, "content_hash": "bae5cfee86e88f2c4c737cd90b825d4787b9a48e57d2fc1fe92ee34183381bf3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/openai-sdk-embeddings.adoc"}}
{"id": "sha256:eceff0665567458668555013f65636c0c868db70245a1490f0ea711a9a332153", "content": "Spring AI supports the PostgresML text embeddings models.\n\nEmbeddings are a numeric representation of text.\nThey are used to represent words and sentences as vectors, an array of numbers.\nEmbeddings can be used to find similar pieces of text, by comparing the similarity of the numeric vectors using a distance measure, or they can be used as input features for other machine learning models, since most algorithms can't use text directly.\n\nMany pre-trained LLMs can be used to generate embeddings from text within PostgresML.\nYou can browse all the https://huggingface.co/models?library=sentence-transformers[models] available to find the best solution on Hugging Face.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "PostgresML Embeddings", "heading_level": 1, "file_order": 40, "section_index": 0, "content_hash": "eceff0665567458668555013f65636c0c868db70245a1490f0ea711a9a332153", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:aeb65d796a858b9c026180e954911f1ce672b11580e94bad6c195a6d2f9147c8", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Add Repositories and BOM", "heading_level": 2, "file_order": 40, "section_index": 1, "content_hash": "aeb65d796a858b9c026180e954911f1ce672b11580e94bad6c195a6d2f9147c8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:bf6b14f261e70b8de53ad853026dcb8bf8c632dfbba5ff6a1d662758e85bd59c", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure PostgresML Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-postgresml-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-postgresml-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nUse the `spring.ai.postgresml.embedding.options.*` properties to configure your `PostgresMlEmbeddingModel`. links", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 40, "section_index": 2, "content_hash": "bf6b14f261e70b8de53ad853026dcb8bf8c632dfbba5ff6a1d662758e85bd59c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:fafdddc2915926f2a73f9609010c24f12fcef9d74e64a5e8a1f47ae3d3adbd9a", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=postgresml (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match postgresml)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.postgresml.embedding` is property prefix that configures the `EmbeddingModel` implementation for PostgresML embeddings.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n| spring.ai.postgresml.embedding.enabled (Removed and no longer valid) | Enable PostgresML embedding model. | true\n| spring.ai.model.embedding | Enable PostgresML embedding model. | postgresml\n| spring.ai.postgresml.embedding.create-extension | Execute the SQL 'CREATE EXTENSION IF NOT EXISTS pgml' to enable the extension | false\n| spring.ai.postgresml.embedding.options.transformer | The Hugging Face transformer model to use for the embedding. | distilbert-base-uncased\n| spring.ai.postgresml.embedding.options.kwargs | Additional transformer specific options. | empty map\n| spring.ai.postgresml.embedding.options.vectorType | PostgresML vector type to use for the embedding. Two options are supported: `PG_ARRAY` and `PG_VECTOR`. | PG_ARRAY\n| spring.ai.postgresml.embedding.options.metadataMode | Document metadata aggregation mode | EMBED\n|====\n\nTIP: All properties prefixed with `spring.ai.postgresml.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 40, "section_index": 3, "content_hash": "fafdddc2915926f2a73f9609010c24f12fcef9d74e64a5e8a1f47ae3d3adbd9a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:01ad7bd637e6a08a67921e3d81dbbb51759df1df0b616a38aedb7c361559ee1f", "content": "Use the https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/postgresml/PostgresMlEmbeddingOptions.java[PostgresMlEmbeddingOptions.java] to configure the `PostgresMlEmbeddingModel` with options, such as the model to use and etc.\n\nOn start you can pass a `PostgresMlEmbeddingOptions` to the `PostgresMlEmbeddingModel` constructor to configure the default options used for all embedding requests.\n\nAt run-time you can override the default options, using a `PostgresMlEmbeddingOptions` in your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\n\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n PostgresMlEmbeddingOptions.builder()\n .transformer(\"intfloat/e5-small\")\n .vectorType(VectorType.PG_ARRAY)\n .kwargs(Map.of(\"device\", \"gpu\"))\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 40, "section_index": 4, "content_hash": "01ad7bd637e6a08a67921e3d81dbbb51759df1df0b616a38aedb7c361559ee1f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:3abe50d4d2e6940da12171b6b9e5e26796fc38b424aa8ebbf51b1e4fae92c4e9", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.postgresml.embedding.options.transformer=distilbert-base-uncased\nspring.ai.postgresml.embedding.options.vectorType=PG_ARRAY\nspring.ai.postgresml.embedding.options.metadataMode=EMBED\nspring.ai.postgresml.embedding.options.kwargs.device=cpu\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 40, "section_index": 5, "content_hash": "3abe50d4d2e6940da12171b6b9e5e26796fc38b424aa8ebbf51b1e4fae92c4e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:de17a1b8af7d1dc4251208483797cac48ceccf8c5e0d0d0cce1ff4a0e6a4850b", "content": "Instead of using the Spring Boot auto-configuration, you can create the `PostgresMlEmbeddingModel` manually.\nFor this add the `spring-ai-postgresml` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-postgresml</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-postgresml'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an `PostgresMlEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar jdbcTemplate = new JdbcTemplate(dataSource); // your posgresml data source\n\nPostgresMlEmbeddingModel embeddingModel = new PostgresMlEmbeddingModel(this.jdbcTemplate,\n PostgresMlEmbeddingOptions.builder()\n .transformer(\"distilbert-base-uncased\") // huggingface transformer model name.\n .vectorType(VectorType.PG_VECTOR) //vector type in PostgreSQL.\n .kwargs(Map.of(\"device\", \"cpu\")) // optional arguments.\n .metadataMode(MetadataMode.EMBED) // Document metadata mode.\n .build());\n\nembeddingModel.afterPropertiesSet(); // initialize the jdbc template and database.\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nNOTE: When created manually, you must call the `afterPropertiesSet()` after setting the properties and before using the client.\nIt is more convenient (and preferred) to create the PostgresMlEmbeddingModel as a `@Bean`.\nThen you don’t have to call the `afterPropertiesSet()` manually:\n\n[source,java]\n----\n@Bean\npublic EmbeddingModel embeddingModel(JdbcTemplate jdbcTemplate) {\n return new PostgresMlEmbeddingModel(jdbcTemplate,\n PostgresMlEmbeddingOptions.builder()\n ....\n .build());\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc", "title": "PostgresML Embeddings", "heading": "Manual configuration", "heading_level": 2, "file_order": 40, "section_index": 6, "content_hash": "de17a1b8af7d1dc4251208483797cac48ceccf8c5e0d0d0cce1ff4a0e6a4850b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/postgresml-embeddings.adoc"}}
{"id": "sha256:531a160c43f6d52b675fe99f09ef8ba90848dc555268dba0f2852d35b290725b", "content": "This functionality has been moved to the Spring AI Community repository.\n\nPlease visit https://github.com/spring-ai-community/qianfan for the latest version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/qianfan-embeddings.adoc", "title": "QianFan Embeddings", "heading": "QianFan Embeddings", "heading_level": 1, "file_order": 41, "section_index": 0, "content_hash": "531a160c43f6d52b675fe99f09ef8ba90848dc555268dba0f2852d35b290725b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/qianfan-embeddings.adoc"}}
{"id": "sha256:97ff782b948429ed10e45d76bd97768d22a663be7b0273708bc87937c1e61211", "content": "NOTE: EXPERIMENTAL. Used for experimental purposes only. Not compatible yet with the `VectorStores`.\n\nVertex AI supports two types of embeddings models, text and multimodal.\nThis document describes how to create a multimodal embedding using the Vertex AI link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings[Multimodal embeddings API].\n\nThe multimodal embeddings model generates 1408-dimension vectors based on the input you provide, which can include a combination of image, text, and video data.\nThe embedding vectors can then be used for subsequent tasks like image classification or video content moderation.\n\nThe image embedding vector and text embedding vector are in the same semantic space with the same dimensionality.\nConsequently, these vectors can be used interchangeably for use cases like searching image by text, or searching video by image.\n\nNOTE: The VertexAI Multimodal API imposes the link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings#api-limits[following limits].\n\nTIP: For text-only embedding use cases, we recommend using the xref:api/embeddings/vertexai-embeddings-text.adoc[Vertex AI text-embeddings model] instead.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Google VertexAI Multimodal Embeddings", "heading_level": 1, "file_order": 42, "section_index": 0, "content_hash": "97ff782b948429ed10e45d76bd97768d22a663be7b0273708bc87937c1e61211", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:7775aac4929bde54625779fe374e343eeeba90829f2a6bef664bf07cf85f4e92", "content": "- Install the link:https://cloud.google.com/sdk/docs/install[gcloud] CLI, appropriate for you OS.\n- Authenticate by running the following command.\nReplace `PROJECT_ID` with your Google Cloud project ID and `ACCOUNT` with your Google Cloud username.\n\n[source]\n----\ngcloud config set project <PROJECT_ID> &&\ngcloud auth application-default login <ACCOUNT>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 42, "section_index": 1, "content_hash": "7775aac4929bde54625779fe374e343eeeba90829f2a6bef664bf07cf85f4e92", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:f06c9ead3b1918c08f4b65a8a2aeca430dfdbfceb5a4fb80a0a098257f155463", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 42, "section_index": 2, "content_hash": "f06c9ead3b1918c08f4b65a8a2aeca430dfdbfceb5a4fb80a0a098257f155463", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:c70c138d8ad584cf54eae7873070ad63b4eada14b7ba8cdf652f92dde4870e7d", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the VertexAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-vertex-ai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-vertex-ai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 42, "section_index": 3, "content_hash": "c70c138d8ad584cf54eae7873070ad63b4eada14b7ba8cdf652f92dde4870e7d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:7540886e8c8d733b582b7fb011090bf481dd4ed0b9d50daac65a54e6ba0a1e14", "content": "The prefix `spring.ai.vertex.ai.embedding` is used as the property prefix that lets you connect to VertexAI Embedding API.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.vertex.ai.embedding.project-id | Google Cloud Platform project ID | -\n| spring.ai.vertex.ai.embedding.location | Region | -\n| spring.ai.vertex.ai.embedding.apiEndpoint | Vertex AI Embedding API endpoint. | -\n\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding.multimodal=vertexai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding.multimodal=none (or any value which doesn't match vertexai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.vertex.ai.embedding.multimodal` is the property prefix that lets you configure the embedding model implementation for VertexAI Multimodal Embedding.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.vertex.ai.embedding.multimodal.enabled (Removed and no longer valid) | Enable Vertex AI Embedding API model. | true\n| spring.ai.model.embedding.multimodal=vertexai | Enable Vertex AI Embedding API model. | vertexai\n| spring.ai.vertex.ai.embedding.multimodal.options.model | You can get multimodal embeddings by using the following model: | multimodalembedding@001\n| spring.ai.vertex.ai.embedding.multimodal.options.dimensions | Specify lower-dimension embeddings. By default, an embedding request returns a 1408 float vector for a data type. You can also specify lower-dimension embeddings (128, 256, or 512 float vectors) for text and image data. | 1408\n| spring.ai.vertex.ai.embedding.multimodal.options.video-start-offset-sec | The start offset of the video segment in seconds. If not specified, it's calculated with max(0, endOffsetSec - 120). | -\n| spring.ai.vertex.ai.embedding.multimodal.options.video-end-offset-sec | The end offset of the video segment in seconds. If not specified, it's calculated with min(video length, startOffSec + 120). If both startOffSec and endOffSec are specified, endOffsetSec is adjusted to min(startOffsetSec+120, endOffsetSec). | -\n| spring.ai.vertex.ai.embedding.multimodal.options.video-interval-sec | The interval of the video the embedding will be generated. The minimum value for interval_sec is 4.\nIf the interval is less than 4, an InvalidArgumentError is returned. There are no limitations on the maximum value\nof the interval. However, if the interval is larger than min(video length, 120s), it impacts the quality of the generated embeddings. Default value: 16. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 42, "section_index": 4, "content_hash": "7540886e8c8d733b582b7fb011090bf481dd4ed0b9d50daac65a54e6ba0a1e14", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:8b6126906aac2e87586a264d0fc68f555566233252ddaf65967d258c1619cb16", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-vertex-ai-embedding/src/main/java/org/springframework/ai/vertexai/embedding/VertexAiMultimodalEmbeddingModel.java[VertexAiMultimodalEmbeddingModel] implements the `DocumentEmbeddingModel`.\n\nAdd the `spring-ai-vertex-ai-embedding` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-vertex-ai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `VertexAiMultimodalEmbeddingModel` and use it for embeddings generations:\n\n[source,java]\n----\nVertexAiEmbeddingConnectionDetails connectionDetails =\n VertexAiEmbeddingConnectionDetails.builder()\n .projectId(System.getenv(<VERTEX_AI_GEMINI_PROJECT_ID>))\n .location(System.getenv(<VERTEX_AI_GEMINI_LOCATION>))\n .build();\n\nVertexAiMultimodalEmbeddingOptions options = VertexAiMultimodalEmbeddingOptions.builder()\n .model(VertexAiMultimodalEmbeddingOptions.DEFAULT_MODEL_NAME)\n .build();\n\nvar embeddingModel = new VertexAiMultimodalEmbeddingModel(this.connectionDetails, this.options);\n\nMedia imageMedial = new Media(MimeTypeUtils.IMAGE_PNG, new ClassPathResource(\"/test.image.png\"));\nMedia videoMedial = new Media(new MimeType(\"video\", \"mp4\"), new ClassPathResource(\"/test.video.mp4\"));\n\nvar document = new Document(\"Explain what do you see on this video?\", List.of(this.imageMedial, this.videoMedial), Map.of());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n\nDocumentEmbeddingRequest embeddingRequest = new DocumentEmbeddingRequest(List.of(this.document),\n EmbeddingOptions.EMPTY);\n\nEmbeddingResponse embeddingResponse = multiModelEmbeddingModel.call(this.embeddingRequest);\n\nassertThat(embeddingResponse.getResults()).hasSize(3);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc", "title": "Google VertexAI Multimodal Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 42, "section_index": 5, "content_hash": "8b6126906aac2e87586a264d0fc68f555566233252ddaf65967d258c1619cb16", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-multimodal.adoc"}}
{"id": "sha256:b7f9f9a261492871cf230853c0f8ee4bb9f0f567a4731429774b873ce6ba3c4d", "content": "Vertex AI supports two types of embeddings models, text and multimodal.\nThis document describes how to create a text embedding using the Vertex AI link:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api[Text embeddings API].\n\nVertex AI text embeddings API uses dense vector representations.\nUnlike sparse vectors, which tend to directly map words to numbers, dense vectors are designed to better represent the meaning of a piece of text.\nThe benefit of using dense vector embeddings in generative AI is that instead of searching for direct word or syntax matches, you can better search for passages that align to the meaning of the query, even if the passages don't use the same language.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Google VertexAI Text Embeddings", "heading_level": 1, "file_order": 43, "section_index": 0, "content_hash": "b7f9f9a261492871cf230853c0f8ee4bb9f0f567a4731429774b873ce6ba3c4d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:d18972c61d8339e114a5aa5028a797220caacd617f4c21ab5fdd895d97a5213f", "content": "- Install the link:https://cloud.google.com/sdk/docs/install[gcloud] CLI, appropriate for you OS.\n- Authenticate by running the following command.\nReplace `PROJECT_ID` with your Google Cloud project ID and `ACCOUNT` with your Google Cloud username.\n\n[source]\n----\ngcloud config set project <PROJECT_ID> &&\ngcloud auth application-default login <ACCOUNT>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 43, "section_index": 1, "content_hash": "d18972c61d8339e114a5aa5028a797220caacd617f4c21ab5fdd895d97a5213f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:bd4dfca009d417ab3af71366363a5bcdcbc07bce79ebdac0529d910ede058deb", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 43, "section_index": 2, "content_hash": "bd4dfca009d417ab3af71366363a5bcdcbc07bce79ebdac0529d910ede058deb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:0aa598e13b03b8fbfe91326ad9e9442d4fbd4c710504833ead471284686b2079", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the VertexAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-vertex-ai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-vertex-ai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 43, "section_index": 3, "content_hash": "0aa598e13b03b8fbfe91326ad9e9442d4fbd4c710504833ead471284686b2079", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:7603582f632901a05ab7cd4c7d49197f5ca6ea73befe3c304b97a15b44553263", "content": "The prefix `spring.ai.vertex.ai.embedding` is used as the property prefix that lets you connect to VertexAI Embedding API.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.vertex.ai.embedding.project-id | Google Cloud Platform project ID | -\n| spring.ai.vertex.ai.embedding.location | Region | -\n| spring.ai.vertex.ai.embedding.apiEndpoint | Vertex AI Embedding API endpoint. | -\n\n|====\n\n[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding.text=vertexai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding.text=none (or any value which doesn't match vertexai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.vertex.ai.embedding.text` is the property prefix that lets you configure the embedding model implementation for VertexAI Text Embedding.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.vertex.ai.embedding.text.enabled (Removed and no longer valid) | Enable Vertex AI Embedding API model. | true\n| spring.ai.model.embedding.text | Enable Vertex AI Embedding API model. | vertexai\n| spring.ai.vertex.ai.embedding.text.options.model | This is the link:https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#supported-models[Vertex Text Embedding model] to use | text-embedding-004\n| spring.ai.vertex.ai.embedding.text.options.task-type | The intended downstream application to help the model produce better quality embeddings. Available link:https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#request_body[task-types] | `RETRIEVAL_DOCUMENT`\n| spring.ai.vertex.ai.embedding.text.options.title | Optional title, only valid with task_type=RETRIEVAL_DOCUMENT. | -\n| spring.ai.vertex.ai.embedding.text.options.dimensions | The number of dimensions the resulting output embeddings should have. Supported for model version 004 and later. You can use this parameter to reduce the embedding size, for example, for storage optimization. | -\n| spring.ai.vertex.ai.embedding.text.options.auto-truncate | When set to true, input text will be truncated. When set to false, an error is returned if the input text is longer than the maximum length supported by the model. | true\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Embedding Properties", "heading_level": 3, "file_order": 43, "section_index": 4, "content_hash": "7603582f632901a05ab7cd4c7d49197f5ca6ea73befe3c304b97a15b44553263", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:a5939e85a9e6cf1e17832198abd83e671318dfbd47f1bffb0db0f8e639c249b5", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-starter-model-vertex-ai-embedding` to your pom (or gradle) dependencies.\n\nAdd a `application.properties` file, under the `src/main/resources` directory, to enable and configure the VertexAi chat model:\n\n[source,application.properties]\n----\nspring.ai.vertex.ai.embedding.project-id=<YOUR_PROJECT_ID>\nspring.ai.vertex.ai.embedding.location=<YOUR_PROJECT_LOCATION>\nspring.ai.vertex.ai.embedding.text.options.model=text-embedding-004\n----\n\nThis will create a `VertexAiTextEmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the embedding model for embeddings generations.\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 43, "section_index": 5, "content_hash": "a5939e85a9e6cf1e17832198abd83e671318dfbd47f1bffb0db0f8e639c249b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:7a1a72909f2c2b8d5620965b12f25ba26acd05c70132902e48e7e24e30e477ce", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-vertex-ai-embedding/src/main/java/org/springframework/ai/vertexai/embedding/VertexAiTextEmbeddingModel.java[VertexAiTextEmbeddingModel] implements the `EmbeddingModel`.\n\nAdd the `spring-ai-vertex-ai-embedding` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-embedding</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-vertex-ai-embedding'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create a `VertexAiTextEmbeddingModel` and use it for text generations:\n\n[source,java]\n----\nVertexAiEmbeddingConnectionDetails connectionDetails =\n VertexAiEmbeddingConnectionDetails.builder()\n .projectId(System.getenv(<VERTEX_AI_GEMINI_PROJECT_ID>))\n .location(System.getenv(<VERTEX_AI_GEMINI_LOCATION>))\n .build();\n\nVertexAiTextEmbeddingOptions options = VertexAiTextEmbeddingOptions.builder()\n .model(VertexAiTextEmbeddingOptions.DEFAULT_MODEL_NAME)\n .build();\n\nvar embeddingModel = new VertexAiTextEmbeddingModel(this.connectionDetails, this.options);\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 43, "section_index": 6, "content_hash": "7a1a72909f2c2b8d5620965b12f25ba26acd05c70132902e48e7e24e30e477ce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:9006a0d017d1756021e92b8af300657dbd21015adf79fc9e1d42f8b3a5235e99", "content": "To programmatically load the GoogleCredentials from a Service Account json file, you can use the following:\n\n[source,java]\n----\nGoogleCredentials credentials = GoogleCredentials.fromStream(<INPUT_STREAM_TO_CREDENTIALS_JSON>)\n .createScoped(\"https://www.googleapis.com/auth/cloud-platform\");\ncredentials.refreshIfExpired();\n\nVertexAiEmbeddingConnectionDetails connectionDetails =\n VertexAiEmbeddingConnectionDetails.builder()\n .projectId(System.getenv(<VERTEX_AI_GEMINI_PROJECT_ID>))\n .location(System.getenv(<VERTEX_AI_GEMINI_LOCATION>))\n .apiEndpoint(endpoint)\n .predictionServiceSettings(\n PredictionServiceSettings.newBuilder()\n .setEndpoint(endpoint)\n .setCredentialsProvider(FixedCredentialsProvider.create(credentials))\n .build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc", "title": "Google VertexAI Text Embeddings", "heading": "Load credentials from a Google Service Account", "heading_level": 3, "file_order": 43, "section_index": 7, "content_hash": "9006a0d017d1756021e92b8af300657dbd21015adf79fc9e1d42f8b3a5235e99", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/vertexai-embeddings-text.adoc"}}
{"id": "sha256:35b4236ebedaaa524d9aa14e524b8e72e65be19fbb1774b8817dca4cc6c25236", "content": "Spring AI supports the ZhiPuAI's text embeddings models.\nZhiPuAI’s text embeddings measure the relatedness of text strings.\nAn embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "ZhiPuAI Embeddings", "heading_level": 1, "file_order": 44, "section_index": 0, "content_hash": "35b4236ebedaaa524d9aa14e524b8e72e65be19fbb1774b8817dca4cc6c25236", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:f0d955c0f2a44f89edf627972ae4b9d36bf82f7b527396e89e3f7556059edcde", "content": "You will need to create an API with ZhiPuAI to access ZhiPu AI language models.\n\nCreate an account at https://open.bigmodel.cn/login[ZhiPu AI registration page] and generate the token on the https://open.bigmodel.cn/usercenter/apikeys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.zhipuai.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.zhipuai.api-key=<your-zhipuai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n zhipuai:\n api-key: ${ZHIPUAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport ZHIPUAI_API_KEY=<your-zhipuai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"ZHIPUAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Prerequisites", "heading_level": 2, "file_order": 44, "section_index": 1, "content_hash": "f0d955c0f2a44f89edf627972ae4b9d36bf82f7b527396e89e3f7556059edcde", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:52dce0b3d77d4af858b33cec89575df3af47eb2d7d1119254378e7ed000bde68", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 44, "section_index": 2, "content_hash": "52dce0b3d77d4af858b33cec89575df3af47eb2d7d1119254378e7ed000bde68", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:f749626214c1626c829424995082774bd2ebadc3aeee8d4a525e601109c7134b", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure ZhiPuAI Embedding Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-zhipuai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-zhipuai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Auto-configuration", "heading_level": 2, "file_order": 44, "section_index": 3, "content_hash": "f749626214c1626c829424995082774bd2ebadc3aeee8d4a525e601109c7134b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:69d837c7fd381a4cfb30db8538c20a5949b913f6582c441b36a7666c4f95c264", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the ZhiPuAI Embedding model.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Retry Properties", "heading_level": 4, "file_order": 44, "section_index": 4, "content_hash": "69d837c7fd381a4cfb30db8538c20a5949b913f6582c441b36a7666c4f95c264", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:59384c218968e42b38006b8797e457cf984abe111146e98c6d4d0a799ffdb0e4", "content": "The prefix `spring.ai.zhipuai` is used as the property prefix that lets you connect to ZhiPuAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.zhipuai.base-url | The URL to connect to | https://open.bigmodel.cn/api/paas\n| spring.ai.zhipuai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Connection Properties", "heading_level": 4, "file_order": 44, "section_index": 5, "content_hash": "59384c218968e42b38006b8797e457cf984abe111146e98c6d4d0a799ffdb0e4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:8a35425824b0d7eb1a5c981a01b5001e1284e8f033568cb6e715dd6d329f24c0", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding`.\n\nTo enable, spring.ai.model.embedding=zhipuai (It is enabled by default)\n\nTo disable, spring.ai.model.embedding=none (or any value which doesn't match zhipuai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.zhipuai.embedding` is property prefix that configures the `EmbeddingModel` implementation for ZhiPuAI.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.zhipuai.embedding.enabled (Removed and no longer valid) | Enable ZhiPuAI embedding model. | true\n| spring.ai.model.embedding | Enable ZhiPuAI embedding model. | zhipuai\n| spring.ai.zhipuai.embedding.base-url | Optional overrides the spring.ai.zhipuai.base-url to provide embedding specific url | -\n| spring.ai.zhipuai.embedding.api-key | Optional overrides the spring.ai.zhipuai.api-key to provide embedding specific api-key | -\n| spring.ai.zhipuai.embedding.options.model | The model to use | embedding-2\n| spring.ai.zhipuai.embedding.options.dimensions | The number of dimensions, the default value is 2048 when the model is embedding-3 | -\n|====\n\nNOTE: You can override the common `spring.ai.zhipuai.base-url` and `spring.ai.zhipuai.api-key` for the `ChatModel` and `EmbeddingModel` implementations.\nThe `spring.ai.zhipuai.embedding.base-url` and `spring.ai.zhipuai.embedding.api-key` properties if set take precedence over the common properties.\nSimilarly, the `spring.ai.zhipuai.chat.base-url` and `spring.ai.zhipuai.chat.api-key` properties if set take precedence over the common properties.\nThis is useful if you want to use different ZhiPuAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.zhipuai.embedding.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `EmbeddingRequest` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Configuration Properties", "heading_level": 4, "file_order": 44, "section_index": 6, "content_hash": "8a35425824b0d7eb1a5c981a01b5001e1284e8f033568cb6e715dd6d329f24c0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:321c63cd0021e7483f725850e0f309bc46d9a30a51dd7951a5ad1e611b77c187", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiEmbeddingOptions.java[ZhiPuAiEmbeddingOptions.java] provides the ZhiPuAI configurations, such as the model to use and etc.\n\nThe default options can be configured using the `spring.ai.zhipuai.embedding.options` properties as well.\n\nAt start-time use the `ZhiPuAiEmbeddingModel` constructor to set the default options used for all embedding requests.\nAt run-time you can override the default options, using a `ZhiPuAiEmbeddingOptions` instance as part of your `EmbeddingRequest`.\n\nFor example to override the default model name for a specific request:\n\n[source,java]\n----\nEmbeddingResponse embeddingResponse = embeddingModel.call(\n new EmbeddingRequest(List.of(\"Hello World\", \"World is big and salvation is near\"),\n ZhiPuAiEmbeddingOptions.builder()\n .model(\"Different-Embedding-Model-Deployment-Name\")\n .build()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Runtime Options [[embedding-options]]", "heading_level": 2, "file_order": 44, "section_index": 7, "content_hash": "321c63cd0021e7483f725850e0f309bc46d9a30a51dd7951a5ad1e611b77c187", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:09f5d856dca5f225a2342aa8bd01686399036d034b07ef23764a4e6376a9bc56", "content": "This will create a `EmbeddingModel` implementation that you can inject into your class.\nHere is an example of a simple `@Controller` class that uses the `EmbeddingModel` implementation.\n\n[source,application.properties]\n----\nspring.ai.zhipuai.api-key=YOUR_API_KEY\nspring.ai.zhipuai.embedding.options.model=embedding-2\n----\n\n[source,java]\n----\n@RestController\npublic class EmbeddingController {\n\n private final EmbeddingModel embeddingModel;\n\n @Autowired\n public EmbeddingController(EmbeddingModel embeddingModel) {\n this.embeddingModel = embeddingModel;\n }\n\n @GetMapping(\"/ai/embedding\")\n public Map embed(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n EmbeddingResponse embeddingResponse = this.embeddingModel.embedForResponse(List.of(message));\n return Map.of(\"embedding\", embeddingResponse);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Sample Controller", "heading_level": 2, "file_order": 44, "section_index": 8, "content_hash": "09f5d856dca5f225a2342aa8bd01686399036d034b07ef23764a4e6376a9bc56", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:497a12a4583b0618b17b8bd511527f2e2fab38e1f876181f42a67610763aa8cb", "content": "If you are not using Spring Boot, you can manually configure the ZhiPuAI Embedding Model.\nFor this add the `spring-ai-zhipuai` dependency to your project's Maven `pom.xml` file:\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-zhipuai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-zhipuai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-zhipuai` dependency provides access also to the `ZhiPuAiChatModel`.\nFor more information about the `ZhiPuAiChatModel` refer to the link:../chat/zhipuai-chat.html[ZhiPuAI Chat Client] section.\n\nNext, create an `ZhiPuAiEmbeddingModel` instance and use it to compute the similarity between two input texts:\n\n[source,java]\n----\nvar zhiPuAiApi = new ZhiPuAiApi(System.getenv(\"ZHIPUAI_API_KEY\"));\n\nvar embeddingModel = new ZhiPuAiEmbeddingModel(api, MetadataMode.EMBED,\n ZhiPuAiEmbeddingOptions.builder()\n .model(\"embedding-3\")\n .dimensions(1536)\n .build());\n\nEmbeddingResponse embeddingResponse = this.embeddingModel\n\t.embedForResponse(List.of(\"Hello World\", \"World is big and salvation is near\"));\n----\n\nThe `ZhiPuAiEmbeddingOptions` provides the configuration information for the embedding requests.\nThe options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc", "title": "ZhiPuAI Embeddings", "heading": "Manual Configuration", "heading_level": 2, "file_order": 44, "section_index": 9, "content_hash": "497a12a4583b0618b17b8bd511527f2e2fab38e1f876181f42a67610763aa8cb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings/zhipuai-embeddings.adoc"}}
{"id": "sha256:a31086fb020975e6d035754a8f9e8dbcc31747aa0e4b9aaa8dc1c51e88f57580", "content": "Spring AI supports DALL-E, the Image generation model from Azure OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Azure OpenAI Image Generation", "heading_level": 1, "file_order": 45, "section_index": 0, "content_hash": "a31086fb020975e6d035754a8f9e8dbcc31747aa0e4b9aaa8dc1c51e88f57580", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:3042788d02f4565afbe4231f290df56c00cf025a9e85f07f99bc779bb05d34c6", "content": "Obtain your Azure OpenAI `endpoint` and `api-key` from the Azure OpenAI Service section on the link:https://portal.azure.com[Azure Portal].\n\nSpring AI defines two configuration properties:\n\n1. `spring.ai.azure.openai.api-key`: Set this to the value of the `API Key` obtained from Azure.\n2. `spring.ai.azure.openai.endpoint`: Set this to the endpoint URL obtained when provisioning your model in Azure.\n\nYou can set these configuration properties in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.azure.openai.api-key=<your-azure-openai-api-key>\nspring.ai.azure.openai.endpoint=<your-azure-openai-endpoint>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference custom environment variables:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n azure:\n openai:\n api-key: ${AZURE_OPENAI_API_KEY}\n endpoint: ${AZURE_OPENAI_ENDPOINT}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>\nexport AZURE_OPENAI_ENDPOINT=<your-azure-openai-endpoint>\n----\n\nYou can also set these configurations programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"AZURE_OPENAI_API_KEY\");\nString endpoint = System.getenv(\"AZURE_OPENAI_ENDPOINT\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Prerequisites", "heading_level": 2, "file_order": 45, "section_index": 1, "content_hash": "3042788d02f4565afbe4231f290df56c00cf025a9e85f07f99bc779bb05d34c6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:67fe8107a576426657255c37b1e35590203b887e3f75c7c84b8a126df13d0691", "content": "To use run Azure AI applications, create an Azure AI Deployment through the [Azure AI Portal](https://oai.azure.com/portal).\n\nIn Azure, each client must specify a `Deployment Name` to connect to the Azure OpenAI service.\n\nIt's essential to understand that the `Deployment Name` is different from the model you choose to deploy\n\nFor instance, a deployment named 'MyImgAiDeployment' could be configured to use either the `Dalle3` model or the `Dalle2` model.\n\nFor now, to keep things simple, you can create a deployment using the following settings:\n\nDeployment Name: `MyImgAiDeployment`\nModel Name: `Dalle3`\n\nThis Azure configuration will align with the default configurations of the Spring Boot Azure AI Starter and its Autoconfiguration feature.\n\nIf you use a different Deployment Name, update the configuration property accordingly:\n\n```\nspring.ai.azure.openai.image.options.deployment-name=<my deployment name>\n```\n\nThe different deployment structures of Azure OpenAI and OpenAI leads to a property in the Azure OpenAI client library named `deploymentOrModelName`.\nThis is because in OpenAI there is no `Deployment Name`, only a `Model Name`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Deployment Name", "heading_level": 3, "file_order": 45, "section_index": 2, "content_hash": "67fe8107a576426657255c37b1e35590203b887e3f75c7c84b8a126df13d0691", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:4750f4e7e8799325053cba735fde89c8879e7acdb29d99fbb2f523386a5eee33", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 45, "section_index": 3, "content_hash": "4750f4e7e8799325053cba735fde89c8879e7acdb29d99fbb2f523386a5eee33", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:ab67b5fbb70b8e043a90e232c02ee644239324ad1a65d2ebf1b9ebc6c151df0e", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Azure OpenAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-azure-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-azure-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 45, "section_index": 4, "content_hash": "ab67b5fbb70b8e043a90e232c02ee644239324ad1a65d2ebf1b9ebc6c151df0e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:86683195eadcd13f82028f3bf46150ffb7615b0d49e33828374ff935cb357e39", "content": "[NOTE]\n====\nEnabling and disabling of the image auto-configurations are now configured via top level properties with the prefix `spring.ai.model.image`.\n\nTo enable, spring.ai.model.image=azure-openai (It is enabled by default)\n\nTo disable, spring.ai.model.image=none (or any value which doesn't match azure-openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.image` is the property prefix that lets you configure the `ImageModel` implementation for OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.azure.openai.image.enabled (Removed and no longer valid) | Enable OpenAI image model. | true\n| spring.ai.model.image | Enable OpenAI image model. | azure-openai\n| spring.ai.azure.openai.image.options.n | The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported. | -\n| spring.ai.azure.openai.image.options.model | The model to use for image generation. | AzureOpenAiImageOptions.DEFAULT_IMAGE_MODEL\n| spring.ai.azure.openai.image.options.quality | The quality of the image that will be generated. HD creates images with finer details and greater consistency across the image. This parameter is only supported for dall-e-3. | -\n| spring.ai.azure.openai.image.options.response_format | The format in which the generated images are returned. Must be one of URL or b64_json. | -\n| `spring.ai.openai.image.options.size` | The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models. | -\n| `spring.ai.openai.image.options.size_width` | The width of the generated images. Must be one of 256, 512, or 1024 for dall-e-2. | -\n| `spring.ai.openai.image.options.size_height`| The height of the generated images. Must be one of 256, 512, or 1024 for dall-e-2. | -\n| `spring.ai.openai.image.options.style` | The style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This parameter is only supported for dall-e-3. | -\n| `spring.ai.openai.image.options.user` | A unique identifier representing your end-user, which can help Azure OpenAI to monitor and detect abuse. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Image Generation Properties", "heading_level": 3, "file_order": 45, "section_index": 5, "content_hash": "86683195eadcd13f82028f3bf46150ffb7615b0d49e33828374ff935cb357e39", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:4d27469d46960467ff32dd21707c8449f2f837da17d6f6e94978c7eff4185478", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to Azure OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.azure.openai.endpoint | The URL to connect to | https://my-dalle3.openai.azure.com/\n| spring.ai.azure.openai.apiKey | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Connection Properties", "heading_level": 4, "file_order": 45, "section_index": 6, "content_hash": "4d27469d46960467ff32dd21707c8449f2f837da17d6f6e94978c7eff4185478", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:640d08ab3114f49a26cd1fc680c0211e886393e1466a3f80b84f7321772f3af3", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiImageOptions.java[OpenAiImageOptions.java] provides model configurations, such as the model to use, the quality, the size, etc.\n\nOn start-up, the default options can be configured with the `AzureOpenAiImageModel(OpenAiImageApi openAiImageApi)` constructor and the `withDefaultOptions(OpenAiImageOptions defaultOptions)` method. Alternatively, use the `spring.ai.azure.openai.image.options.*` properties described previously.\n\nAt runtime you can override the default options by adding new, request specific, options to the `ImagePrompt` call.\nFor example to override the OpenAI specific options such as quality and the number of images to create, use the following code example:\n\n[source,java]\n----\nImageResponse response = azureOpenaiImageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n OpenAiImageOptions.builder()\n .quality(\"hd\")\n .N(4)\n .height(1024)\n .width(1024).build())\n\n);\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-azure-openai/src/main/java/org/springframework/ai/azure/openai/AzureOpenAiImageOptions.java[AzureOpenAiImageOptions] you can use a portable https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptions.java[ImageOptions] instance, created with the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptionsBuilder.java[ImageOptionsBuilder#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/azure-openai-image.adoc", "title": "Azure OpenAI Image Generation", "heading": "Runtime Options [[image-options]]", "heading_level": 2, "file_order": 45, "section_index": 7, "content_hash": "640d08ab3114f49a26cd1fc680c0211e886393e1466a3f80b84f7321772f3af3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/azure-openai-image.adoc"}}
{"id": "sha256:e2016666804d812d252eb366bb5b52c1b6e4d8138d9463d466d1210eafa7a1c9", "content": "Spring AI supports DALL-E, the Image generation model from OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "OpenAI Image Generation", "heading_level": 1, "file_order": 46, "section_index": 0, "content_hash": "e2016666804d812d252eb366bb5b52c1b6e4d8138d9463d466d1210eafa7a1c9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:00b6256b28720039cfca5d7edacd19f29d607043a39f97fc66cc9b2b36ababc9", "content": "You will need to create an API key with OpenAI to access ChatGPT models.\n\nCreate an account at https://platform.openai.com/signup[OpenAI signup page] and generate the token on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.openai.api-key` that you should set to the value of the `API Key` obtained from openai.com.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<your-openai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${OPENAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport OPENAI_API_KEY=<your-openai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"OPENAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Prerequisites", "heading_level": 2, "file_order": 46, "section_index": 1, "content_hash": "00b6256b28720039cfca5d7edacd19f29d607043a39f97fc66cc9b2b36ababc9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:f829f249571b9cfba145244dfe58296593d46e4854a842718eedf53291eaa266", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Image Generation Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 46, "section_index": 2, "content_hash": "f829f249571b9cfba145244dfe58296593d46e4854a842718eedf53291eaa266", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:41f7f0b4f60b8eb835e1b6da5f54e1fd1e468843ab441cbe00f69485bac0cbfc", "content": "The prefix `spring.ai.openai` is used as the property prefix that lets you connect to OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.openai.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project is used for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), optionally, you can specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Connection Properties", "heading_level": 4, "file_order": 46, "section_index": 3, "content_hash": "41f7f0b4f60b8eb835e1b6da5f54e1fd1e468843ab441cbe00f69485bac0cbfc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:47ab31befdb4c607d7bbe20307f52af3b91a2fb6f117d9ff67c458c8c77a3073", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the OpenAI Image client.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Retry Properties", "heading_level": 4, "file_order": 46, "section_index": 4, "content_hash": "47ab31befdb4c607d7bbe20307f52af3b91a2fb6f117d9ff67c458c8c77a3073", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:acf24897c956d90212c570a323962d87be0f85df9892ad0ec0b90825242a5cbe", "content": "[NOTE]\n====\nEnabling and disabling of the image auto-configurations are now configured via top level properties with the prefix `spring.ai.model.image`.\n\nTo enable, spring.ai.model.image=openai (It is enabled by default)\n\nTo disable, spring.ai.model.image=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.openai.image` is the property prefix that lets you configure the `ImageModel` implementation for OpenAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.openai.image.enabled (Removed and no longer valid) | Enable OpenAI image model. | true\n| spring.ai.model.image | Enable OpenAI image model. | openai\n| spring.ai.openai.image.base-url | Optional overrides the spring.ai.openai.base-url to provide chat specific url | -\n| spring.ai.openai.image.api-key | Optional overrides the spring.ai.openai.api-key to provide chat specific api-key | -\n| spring.ai.openai.image.organization-id | Optionally you can specify which organization used for an API request. | -\n| spring.ai.openai.image.project-id | Optionally, you can specify which project is used for an API request. | -\n| spring.ai.openai.image.options.n | The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported. | -\n| spring.ai.openai.image.options.model | The model to use for image generation. | OpenAiImageApi.DEFAULT_IMAGE_MODEL\n| spring.ai.openai.image.options.quality | The quality of the image that will be generated. HD creates images with finer details and greater consistency across the image. This parameter is only supported for dall-e-3. | -\n| spring.ai.openai.image.options.response_format | The format in which the generated images are returned. Must be one of URL or b64_json. | -\n| `spring.ai.openai.image.options.size` | The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models. | -\n| `spring.ai.openai.image.options.size_width` | The width of the generated images. Must be one of 256, 512, or 1024 for dall-e-2. | -\n| `spring.ai.openai.image.options.size_height`| The height of the generated images. Must be one of 256, 512, or 1024 for dall-e-2. | -\n| `spring.ai.openai.image.options.style` | The style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This parameter is only supported for dall-e-3. | -\n| `spring.ai.openai.image.options.user` | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n|====\n\nNOTE: You can override the common `spring.ai.openai.base-url`, `spring.ai.openai.api-key`, `spring.ai.openai.organization-id` and `spring.ai.openai.project-id` properties.\nThe `spring.ai.openai.image.base-url`, `spring.ai.openai.image.api-key`, `spring.ai.openai.image.organization-id` and `spring.ai.openai.image.project-id` properties if set take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.image.options` can be overridden at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Configuration Properties", "heading_level": 4, "file_order": 46, "section_index": 5, "content_hash": "acf24897c956d90212c570a323962d87be0f85df9892ad0ec0b90825242a5cbe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:af4fe878c1d6d97177da74eded77b516f56e69e8717de9e249cfa0f5d43fd1d3", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiImageOptions.java[OpenAiImageOptions.java] provides model configurations, such as the model to use, the quality, the size, etc.\n\nOn start-up, the default options can be configured with the `OpenAiImageModel(OpenAiImageApi openAiImageApi)` constructor and the `withDefaultOptions(OpenAiImageOptions defaultOptions)` method. Alternatively, use the `spring.ai.openai.image.options.*` properties described previously.\n\nAt runtime you can override the default options by adding new, request specific, options to the `ImagePrompt` call.\nFor example to override the OpenAI specific options such as quality and the number of images to create, use the following code example:\n\n[source,java]\n----\nImageResponse response = openaiImageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n OpenAiImageOptions.builder()\n .quality(\"hd\")\n .N(4)\n .height(1024)\n .width(1024).build())\n\n);\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiImageOptions.java[OpenAiImageOptions] you can use a portable https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptions.java[ImageOptions] instance, created with the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptionsBuilder.java[ImageOptionsBuilder#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-image.adoc", "title": "OpenAI Image Generation", "heading": "Runtime Options [[image-options]]", "heading_level": 2, "file_order": 46, "section_index": 6, "content_hash": "af4fe878c1d6d97177da74eded77b516f56e69e8717de9e249cfa0f5d43fd1d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-image.adoc"}}
{"id": "sha256:20cbd64a5bce1aad4bbf115fcfd5ec60c917689ddcdd8c5fec5e2b3b3c962bb5", "content": "Spring AI supports OpenAI's DALL-E image generation models through the OpenAI Java SDK, providing a robust and officially-maintained integration with OpenAI's services including Microsoft Foundry and GitHub Models.\n\nNOTE: This implementation uses the official link:https://github.com/openai/openai-java[OpenAI Java SDK] from OpenAI. For the alternative Spring AI implementation, see xref:api/image/openai-image.adoc[OpenAI Image Generation].\n\nDALL-E is a state-of-the-art image generation model from OpenAI that can create realistic images and art from natural language descriptions.\n\nThe OpenAI SDK module automatically detects the service provider (OpenAI, Microsoft Foundry, or GitHub Models) based on the base URL you provide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "OpenAI SDK Image Generation (Official)", "heading_level": 1, "file_order": 47, "section_index": 0, "content_hash": "20cbd64a5bce1aad4bbf115fcfd5ec60c917689ddcdd8c5fec5e2b3b3c962bb5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:fd438814b7c19685393fe4df027dc13b6e23bce4a17ab49ad39e87455275ce20", "content": "Authentication is done using a base URL and an API Key. The implementation provides flexible configuration options through Spring Boot properties or environment variables.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Authentication", "heading_level": 2, "file_order": 47, "section_index": 1, "content_hash": "fd438814b7c19685393fe4df027dc13b6e23bce4a17ab49ad39e87455275ce20", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:bf2c8ef15774c306690a79f09ae70fb972b6412b612c08c4a7e1bc8a2881117b", "content": "If you are using OpenAI directly, create an account at https://platform.openai.com/signup[OpenAI signup page] and generate an API key on the https://platform.openai.com/account/api-keys[API Keys page].\n\nThe base URL doesn't need to be set as it defaults to `https://api.openai.com/v1`:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=<your-openai-api-key>\n# base-url is optional, defaults to https://api.openai.com/v1\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_API_KEY=<your-openai-api-key>\n# OPENAI_BASE_URL is optional, defaults to https://api.openai.com/v1\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Using OpenAI", "heading_level": 3, "file_order": 47, "section_index": 2, "content_hash": "bf2c8ef15774c306690a79f09ae70fb972b6412b612c08c4a7e1bc8a2881117b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:49b8122f5379d116587d284d5861389f1b79e60739f26dbb5da32bba21772bba", "content": "Microsoft Foundry is automatically detected when using a Microsoft Foundry URL. You can configure it using properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.api-key=<your-api-key>\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://<your-deployment-url>.openai.azure.com\nexport OPENAI_API_KEY=<your-api-key>\n----\n\n**Passwordless Authentication (Recommended for Azure):**\n\nMicrosoft Foundry supports passwordless authentication without providing an API key, which is more secure when running on Azure.\n\nTo enable passwordless authentication, add the `com.azure:azure-identity` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>com.azure</groupId>\n <artifactId>azure-identity</artifactId>\n</dependency>\n----\n\nThen configure without an API key:\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://<your-deployment-url>.openai.azure.com\nspring.ai.openai-sdk.microsoft-deployment-name=<your-deployment-name>\n# No api-key needed - will use Azure credentials from environment\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Using Microsoft Foundry", "heading_level": 3, "file_order": 47, "section_index": 3, "content_hash": "49b8122f5379d116587d284d5861389f1b79e60739f26dbb5da32bba21772bba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:80a58b6753302d1ca64ce79cd0d5956abfd2e8d8d6fd4b5b63970ffc3b89c7fb", "content": "GitHub Models is automatically detected when using the GitHub Models base URL. You'll need to create a GitHub Personal Access Token (PAT) with the `models:read` scope.\n\n[source,properties]\n----\nspring.ai.openai-sdk.base-url=https://models.inference.ai.azure.com\nspring.ai.openai-sdk.api-key=github_pat_XXXXXXXXXXX\n----\n\nOr using environment variables:\n\n[source,bash]\n----\nexport OPENAI_BASE_URL=https://models.inference.ai.azure.com\nexport OPENAI_API_KEY=github_pat_XXXXXXXXXXX\n----\n\nTIP: For enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) in your properties:\n\n[source,properties]\n----\nspring.ai.openai-sdk.api-key=${OPENAI_API_KEY}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Using GitHub Models", "heading_level": 3, "file_order": 47, "section_index": 4, "content_hash": "80a58b6753302d1ca64ce79cd0d5956abfd2e8d8d6fd4b5b63970ffc3b89c7fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:1cb69fd73b29c951f9a805230dde73ac8d3cb1ad0f8c1ea9a5a0ba43b3ce9bdf", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 47, "section_index": 5, "content_hash": "1cb69fd73b29c951f9a805230dde73ac8d3cb1ad0f8c1ea9a5a0ba43b3ce9bdf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:625d951f23f6075df552b93e96b98f3aa73bdc14818e9f88ba2a99b5822967d8", "content": "Spring AI provides Spring Boot auto-configuration for the OpenAI SDK Image Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai-sdk</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai-sdk'\n}\n----\n======\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Auto-configuration", "heading_level": 2, "file_order": 47, "section_index": 6, "content_hash": "625d951f23f6075df552b93e96b98f3aa73bdc14818e9f88ba2a99b5822967d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:d5c26132b53af7b90ed75d60e133e0fad9f6a41f40e67d80be77180610d3b08b", "content": "The prefix `spring.ai.openai-sdk` is used as the property prefix that lets you configure the OpenAI SDK client.\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.base-url | The URL to connect to. Auto-detects from `OPENAI_BASE_URL` environment variable if not set. | https://api.openai.com/v1\n| spring.ai.openai-sdk.api-key | The API Key. Auto-detects from `OPENAI_API_KEY` environment variable if not set. | -\n| spring.ai.openai-sdk.organization-id | Optionally specify which organization to use for API requests. | -\n| spring.ai.openai-sdk.timeout | Request timeout duration. | -\n| spring.ai.openai-sdk.max-retries | Maximum number of retry attempts for failed requests. | -\n| spring.ai.openai-sdk.proxy | Proxy settings for OpenAI client (Java `Proxy` object). | -\n| spring.ai.openai-sdk.custom-headers | Custom HTTP headers to include in requests. Map of header name to header value. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Connection Properties", "heading_level": 4, "file_order": 47, "section_index": 7, "content_hash": "d5c26132b53af7b90ed75d60e133e0fad9f6a41f40e67d80be77180610d3b08b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:9e30108c5aaccb129ef8671fdf145c2ec0bbb8993e7098c049cbf80e8662cc27", "content": "The OpenAI SDK implementation provides native support for Microsoft Foundry with automatic configuration:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.microsoft-foundry | Enable Microsoft Foundry mode. Auto-detected if base URL contains `openai.azure.com`, `cognitiveservices.azure.com`, or `.openai.microsoftFoundry.com`. | false\n| spring.ai.openai-sdk.microsoft-deployment-name | Microsoft Foundry deployment name. If not specified, the model name will be used. Also accessible via alias `deployment-name`. | -\n| spring.ai.openai-sdk.microsoft-foundry-service-version | Microsoft Foundry API service version. | -\n| spring.ai.openai-sdk.credential | Credential object for passwordless authentication (requires `com.azure:azure-identity` dependency). | -\n|====\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency and the implementation will automatically attempt to use Azure credentials from the environment when no API key is provided.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Microsoft Foundry Properties", "heading_level": 4, "file_order": 47, "section_index": 8, "content_hash": "9e30108c5aaccb129ef8671fdf145c2ec0bbb8993e7098c049cbf80e8662cc27", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:46ec15bc74dae57b73d253c53a9d0827a0c799869a7fa2a4ad2216df9054ebb4", "content": "Native support for GitHub Models is available:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.github-models | Enable GitHub Models mode. Auto-detected if base URL contains `models.github.ai` or `models.inference.ai.azure.com`. | false\n|====\n\nTIP: GitHub Models requires a Personal Access Token with the `models:read` scope. Set it via the `OPENAI_API_KEY` environment variable or the `spring.ai.openai-sdk.api-key` property.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "GitHub Models Properties", "heading_level": 4, "file_order": 47, "section_index": 9, "content_hash": "46ec15bc74dae57b73d253c53a9d0827a0c799869a7fa2a4ad2216df9054ebb4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:49ffe773079f608e3aa56f6cd87cea5c30cef37a456e39b13febf4afd4d254bb", "content": "The prefix `spring.ai.openai-sdk.image` is the property prefix for configuring the image model implementation:\n\n[cols=\"3,5,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| spring.ai.openai-sdk.image.options.model | The model to use for image generation. Available models: `dall-e-2`, `dall-e-3`. See the https://platform.openai.com/docs/models[models] page for more information. | `dall-e-3`\n| spring.ai.openai-sdk.image.options.n | The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only n=1 is supported. | -\n| spring.ai.openai-sdk.image.options.quality | The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This parameter is only supported for `dall-e-3`. Available values: `standard`, `hd`. | -\n| spring.ai.openai-sdk.image.options.response-format | The format in which the generated images are returned. Must be one of `url` or `b64_json`. | -\n| spring.ai.openai-sdk.image.options.size | The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models. | -\n| spring.ai.openai-sdk.image.options.width | The width of the generated images. Must be one of 256, 512, or 1024 for `dall-e-2`. | -\n| spring.ai.openai-sdk.image.options.height | The height of the generated images. Must be one of 256, 512, or 1024 for `dall-e-2`. | -\n| spring.ai.openai-sdk.image.options.style | The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This parameter is only supported for `dall-e-3`. | -\n| spring.ai.openai-sdk.image.options.user | A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. | -\n|====\n\nTIP: All properties prefixed with `spring.ai.openai-sdk.image.options` can be overridden at runtime by adding request-specific <<image-options>> to the `ImagePrompt` call.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Image Model Properties", "heading_level": 4, "file_order": 47, "section_index": 10, "content_hash": "49ffe773079f608e3aa56f6cd87cea5c30cef37a456e39b13febf4afd4d254bb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:561e2ad947ed2fb18b627593d4fb445842257b4f57cc5921a44a40aa48c42114", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkImageOptions.java[OpenAiSdkImageOptions.java] provides the OpenAI configurations, such as the model to use, quality, size, style, and number of images to generate.\n\nThe default options can be configured using the `spring.ai.openai-sdk.image.options` properties as well.\n\nAt start-time use the `OpenAiSdkImageModel` constructor to set the default options used for all image generation requests.\nAt run-time you can override the default options, using a `OpenAiSdkImageOptions` instance as part of your `ImagePrompt`.\n\nFor example to override the default model and quality for a specific request:\n\n[source,java]\n----\nImageResponse response = imageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n OpenAiSdkImageOptions.builder()\n .model(\"dall-e-3\")\n .quality(\"hd\")\n .N(1)\n .width(1024)\n .height(1024)\n .style(\"vivid\")\n .build()));\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkImageOptions.java[OpenAiSdkImageOptions] you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptions.java[ImageOptions] instance, created with the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptionsBuilder.java[ImageOptionsBuilder#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Runtime Options [[image-options]]", "heading_level": 2, "file_order": 47, "section_index": 11, "content_hash": "561e2ad947ed2fb18b627593d4fb445842257b4f57cc5921a44a40aa48c42114", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:a31542296726a660bcc4198e07b25884622671bf9595ff0ccb030de6213f2e04", "content": "https://start.spring.io/[Create] a new Spring Boot project and add the `spring-ai-openai-sdk` to your pom (or gradle) dependencies.\n\nAdd an `application.properties` file under the `src/main/resources` directory to configure the OpenAI SDK image model:\n\n[source,application.properties]\n----\nspring.ai.openai-sdk.api-key=YOUR_API_KEY\nspring.ai.openai-sdk.image.options.model=dall-e-3\n----\n\nTIP: Replace the `api-key` with your OpenAI credentials.\n\nThis will create an `OpenAiSdkImageModel` implementation that you can inject into your classes.\nHere is an example of a simple `@RestController` class that uses the image model.\n\n[source,java]\n----\n@RestController\npublic class ImageController {\n\n private final ImageModel imageModel;\n\n @Autowired\n public ImageController(ImageModel imageModel) {\n this.imageModel = imageModel;\n }\n\n @GetMapping(\"/ai/image\")\n public Map<String, Object> generateImage(\n @RequestParam(value = \"prompt\", defaultValue = \"A light cream colored mini golden doodle\") String prompt) {\n ImageResponse response = this.imageModel.call(\n new ImagePrompt(prompt,\n OpenAiSdkImageOptions.builder()\n .quality(\"hd\")\n .N(1)\n .width(1024)\n .height(1024)\n .build()));\n\n String imageUrl = response.getResult().getOutput().getUrl();\n return Map.of(\"url\", imageUrl);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Sample Controller", "heading_level": 2, "file_order": 47, "section_index": 12, "content_hash": "a31542296726a660bcc4198e07b25884622671bf9595ff0ccb030de6213f2e04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:a66dc0b795c880025629aa8a5457d239224cbe47576ff96718a883fd6743bed6", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-openai-sdk/src/main/java/org/springframework/ai/openaisdk/OpenAiSdkImageModel.java[OpenAiSdkImageModel] implements the `ImageModel` and uses the official OpenAI Java SDK to connect to the OpenAI service.\n\nIf you are not using Spring Boot auto-configuration, you can manually configure the OpenAI SDK Image Model.\nFor this add the `spring-ai-openai-sdk` dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai-sdk</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai-sdk'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNOTE: The `spring-ai-openai-sdk` dependency provides access also to the `OpenAiSdkChatModel` and `OpenAiSdkEmbeddingModel`.\nFor more information about the `OpenAiSdkChatModel` refer to the xref:api/chat/openai-sdk-chat.adoc[OpenAI SDK Chat] section.\n\nNext, create an `OpenAiSdkImageModel` instance and use it to generate images:\n\n[source,java]\n----\nvar imageOptions = OpenAiSdkImageOptions.builder()\n .model(\"dall-e-3\")\n .quality(\"hd\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\nvar imageModel = new OpenAiSdkImageModel(imageOptions);\n\nImageResponse response = imageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n OpenAiSdkImageOptions.builder()\n .N(1)\n .width(1024)\n .height(1024)\n .build()));\n----\n\nThe `OpenAiSdkImageOptions` provides the configuration information for the image generation requests.\nThe options class offers a `builder()` for easy options creation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Manual Configuration", "heading_level": 2, "file_order": 47, "section_index": 13, "content_hash": "a66dc0b795c880025629aa8a5457d239224cbe47576ff96718a883fd6743bed6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:b54c134811eb3d7413710a23a9e546ad864c82c8d9a2753b5f3f2ad8218938dd", "content": "For Microsoft Foundry:\n\n[source,java]\n----\nvar imageOptions = OpenAiSdkImageOptions.builder()\n .baseUrl(\"https://your-resource.openai.azure.com\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .deploymentName(\"dall-e-3\")\n .azureOpenAIServiceVersion(AzureOpenAIServiceVersion.V2024_10_01_PREVIEW)\n .azure(true) // Enables Microsoft Foundry mode\n .build();\n\nvar imageModel = new OpenAiSdkImageModel(imageOptions);\n----\n\nTIP: Microsoft Foundry supports passwordless authentication. Add the `com.azure:azure-identity` dependency to your project. If you don't provide an API key, the implementation will automatically attempt to use Azure credentials from your environment.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Microsoft Foundry Configuration", "heading_level": 3, "file_order": 47, "section_index": 14, "content_hash": "b54c134811eb3d7413710a23a9e546ad864c82c8d9a2753b5f3f2ad8218938dd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:1e982812c8eb2b80d5ba18f31cd9df909559b9ce775054bcae1b466d77b1e7d8", "content": "For GitHub Models:\n\n[source,java]\n----\nvar imageOptions = OpenAiSdkImageOptions.builder()\n .baseUrl(\"https://models.inference.ai.azure.com\")\n .apiKey(System.getenv(\"GITHUB_TOKEN\"))\n .model(\"dall-e-3\")\n .githubModels(true)\n .build();\n\nvar imageModel = new OpenAiSdkImageModel(imageOptions);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "GitHub Models Configuration", "heading_level": 3, "file_order": 47, "section_index": 15, "content_hash": "1e982812c8eb2b80d5ba18f31cd9df909559b9ce775054bcae1b466d77b1e7d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:9615bf54868febd9a5415643089d21725459a2d20299dd694575b4426fe2b18d", "content": "The OpenAI SDK implementation supports Spring AI's observability features through Micrometer.\nAll image model operations are instrumented for monitoring and tracing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Observability", "heading_level": 2, "file_order": 47, "section_index": 16, "content_hash": "9615bf54868febd9a5415643089d21725459a2d20299dd694575b4426fe2b18d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:be745c68e0daedf6a015a10f7b4481ef33abe9723ddd47f00d912bb43d79e0cb", "content": "* link:https://github.com/openai/openai-java[Official OpenAI Java SDK]\n* link:https://platform.openai.com/docs/api-reference/images[OpenAI Images API Documentation]\n* link:https://platform.openai.com/docs/guides/images[OpenAI Image Generation Guide]\n* link:https://platform.openai.com/docs/models[OpenAI Models]\n* link:https://learn.microsoft.com/en-us/azure/ai-foundry/[Microsoft Foundry Documentation]\n* link:https://github.com/marketplace/models[GitHub Models]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc", "title": "OpenAI SDK Image Generation (Official)", "heading": "Additional Resources", "heading_level": 2, "file_order": 47, "section_index": 17, "content_hash": "be745c68e0daedf6a015a10f7b4481ef33abe9723ddd47f00d912bb43d79e0cb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/openai-sdk-image.adoc"}}
{"id": "sha256:70669056b0ffe7f876705b14a5b8d5e96d426d5a3a3d670b991d213ee377785e", "content": "This functionality has been moved to the Spring AI Community repository.\n\nPlease visit https://github.com/spring-ai-community/qianfan for the latest version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/qianfan-image.adoc", "title": "QianFan Image", "heading": "QianFan Image", "heading_level": 1, "file_order": 48, "section_index": 0, "content_hash": "70669056b0ffe7f876705b14a5b8d5e96d426d5a3a3d670b991d213ee377785e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/qianfan-image.adoc"}}
{"id": "sha256:f6e66a28edfb225473e06049b210f663ae6bf215addabe82ffb0041a688a5522", "content": "Spring AI supports Stability AI's https://platform.stability.ai/docs/api-reference#tag/v1generation[text to image generation model].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/stabilityai-image.adoc", "title": "Stability AI Image Generation", "heading": "Stability AI Image Generation", "heading_level": 1, "file_order": 49, "section_index": 0, "content_hash": "f6e66a28edfb225473e06049b210f663ae6bf215addabe82ffb0041a688a5522", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/stabilityai-image.adoc"}}
{"id": "sha256:8aec58b2799387568dcc474ee9356c7ae2c7c867084985852931ab01d60b73d5", "content": "You will need to create an API key with Stability AI to access their AI models. Follow their https://platform.stability.ai/docs/getting-started/authentication[Getting Started documentation] to obtain your API key.\n\nThe Spring AI project defines a configuration property named `spring.ai.stabilityai.api-key` that you should set to the value of the `API Key` obtained from Stability AI.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.stabilityai.api-key=<your-stabilityai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n stabilityai:\n api-key: ${STABILITYAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport STABILITYAI_API_KEY=<your-stabilityai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"STABILITYAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/stabilityai-image.adoc", "title": "Stability AI Image Generation", "heading": "Prerequisites", "heading_level": 2, "file_order": 49, "section_index": 1, "content_hash": "8aec58b2799387568dcc474ee9356c7ae2c7c867084985852931ab01d60b73d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/stabilityai-image.adoc"}}
{"id": "sha256:af2fe22e6f65419eae90673f30cd6b7e652fb51a9d05f3fcb5840df22ad8a7b3", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Stability AI Image Generation Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-stability-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-stability-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/stabilityai-image.adoc", "title": "Stability AI Image Generation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 49, "section_index": 2, "content_hash": "af2fe22e6f65419eae90673f30cd6b7e652fb51a9d05f3fcb5840df22ad8a7b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/stabilityai-image.adoc"}}
{"id": "sha256:ccfe3ae4079616ea8a7b09be4ade15f49d70605e35396fd9e89a3497d37caf0a", "content": "The prefix `spring.ai.stabilityai` is used as the property prefix that lets you connect to Stability AI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.stabilityai.base-url | The URL to connect to | https://api.stability.ai/v1\n| spring.ai.stabilityai.api-key | The API Key | -\n|====\n\n[NOTE]\n====\nEnabling and disabling of the image auto-configurations are now configured via top level properties with the prefix `spring.ai.model.image`.\n\nTo enable, spring.ai.model.image=stabilityai (It is enabled by default)\n\nTo disable, spring.ai.model.image=none (or any value which doesn't match stabilityai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.stabilityai.image` is the property prefix that lets you configure the `ImageModel` implementation for Stability AI.\n\n[cols=\"2,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.stabilityai.image.enabled (Removed and no longer valid) | Enable Stability AI image model. | true\n| spring.ai.model.image | Enable Stability AI image model. | stabilityai\n| spring.ai.stabilityai.image.base-url | Optional overrides the spring.ai.openai.base-url to provide a specific url | `+https://api.stability.ai/v1+`\n| spring.ai.stabilityai.image.api-key | Optional overrides the spring.ai.openai.api-key to provide a specific api-key | -\n| spring.ai.stabilityai.image.option.n | The number of images to be generated. Must be between 1 and 10. | 1\n| spring.ai.stabilityai.image.option.model | The engine/model to use in Stability AI. The model is passed in the URL as a path parameter. | `stable-diffusion-v1-6`\n| spring.ai.stabilityai.image.option.width | Width of the image to generate, in pixels, in an increment divisible by 64. Engine-specific dimension validation applies. | 512\n| spring.ai.stabilityai.image.option.height | Height of the image to generate, in pixels, in an increment divisible by 64. Engine-specific dimension validation applies.| 512\n| spring.ai.stabilityai.image.option.responseFormat | The format in which the generated images are returned. Must be \"application/json\" or \"image/png\". | -\n| spring.ai.stabilityai.image.option.cfg_scale | The strictness level of the diffusion process adherence to the prompt text. Range: 0 to 35. | 7\n| spring.ai.stabilityai.image.option.clip_guidance_preset | Pass in a style preset to guide the image model towards a particular style. This list of style presets is subject to change. | `NONE`\n| spring.ai.stabilityai.image.option.sampler | Which sampler to use for the diffusion process. If this value is omitted, an appropriate sampler will be automatically selected. | -\n| spring.ai.stabilityai.image.option.seed | Random noise seed (omit this option or use 0 for a random seed). Valid range: 0 to 4294967295. | 0\n| spring.ai.stabilityai.image.option.steps | Number of diffusion steps to run. Valid range: 10 to 50. | 30\n| spring.ai.stabilityai.image.option.style_preset | Pass in a style preset to guide the image model towards a particular style. This list of style presets is subject to change. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/stabilityai-image.adoc", "title": "Stability AI Image Generation", "heading": "Image Generation Properties", "heading_level": 3, "file_order": 49, "section_index": 3, "content_hash": "ccfe3ae4079616ea8a7b09be4ade15f49d70605e35396fd9e89a3497d37caf0a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/stabilityai-image.adoc"}}
{"id": "sha256:9379d78e287076014d6bdfe3e174e1d8906248cf3d5e27b00d7d1004a7c4e45e", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-stabilityai/src/main/java/org/springframework/ai/stabilityai/api/StabilityAiImageOptions.java[StabilityAiImageOptions.java] provides model configurations, such as the model to use, the style, the size, etc.\n\nOn start-up, the default options can be configured with the `StabilityAiImageModel(StabilityAiApi stabilityAiApi, StabilityAiImageOptions options)` constructor. Alternatively, use the `spring.ai.openai.image.options.*` properties described previously.\n\nAt runtime, you can override the default options by adding new, request specific, options to the `ImagePrompt` call.\nFor example to override the Stability AI specific options such as quality and the number of images to create, use the following code example:\n\n[source,java]\n----\nImageResponse response = stabilityaiImageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n StabilityAiImageOptions.builder()\n .stylePreset(\"cinematic\")\n .N(4)\n .height(1024)\n .width(1024).build())\n\n);\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-stabilityai/src/main/java/org/springframework/ai/stabilityai/api/StabilityAiImageOptions.java[StabilityAiImageOptions] you can use a portable https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptions.java[ImageOptions] instance, created with the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptionsBuilder.java[ImageOptionsBuilder#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/stabilityai-image.adoc", "title": "Stability AI Image Generation", "heading": "Runtime Options [[image-options]]", "heading_level": 2, "file_order": 49, "section_index": 4, "content_hash": "9379d78e287076014d6bdfe3e174e1d8906248cf3d5e27b00d7d1004a7c4e45e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/stabilityai-image.adoc"}}
{"id": "sha256:7f1b1f5d71b97fc9e21cad4bc2bf5b5543df567d175bdc3175555bccf5b94d27", "content": "Spring AI supports CogView, the Image generation model from ZhiPuAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "ZhiPuAI Image Generation", "heading_level": 1, "file_order": 50, "section_index": 0, "content_hash": "7f1b1f5d71b97fc9e21cad4bc2bf5b5543df567d175bdc3175555bccf5b94d27", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:08d3026e1e579009f6cdde11103e62470ec32dfd98033c13759b669bed1d9494", "content": "You will need to create an API with ZhiPuAI to access ZhiPu AI language models.\n\nCreate an account at https://open.bigmodel.cn/login[ZhiPu AI registration page] and generate the token on the https://open.bigmodel.cn/usercenter/apikeys[API Keys page].\n\nThe Spring AI project defines a configuration property named `spring.ai.zhipuai.api-key` that you should set to the value of the `API Key` obtained from the API Keys page.\n\nYou can set this configuration property in your `application.properties` file:\n\n[source,properties]\n----\nspring.ai.zhipuai.api-key=<your-zhipuai-api-key>\n----\n\nFor enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference a custom environment variable:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n zhipuai:\n api-key: ${ZHIPUAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport ZHIPUAI_API_KEY=<your-zhipuai-api-key>\n----\n\nYou can also set this configuration programmatically in your application code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"ZHIPUAI_API_KEY\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Prerequisites", "heading_level": 2, "file_order": 50, "section_index": 1, "content_hash": "08d3026e1e579009f6cdde11103e62470ec32dfd98033c13759b669bed1d9494", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:6bb525ce833b8eaee75fb110294237b088aeccbe39c612dcb24519740ae4c04b", "content": "Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.\n\nTo help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Add Repositories and BOM", "heading_level": 3, "file_order": 50, "section_index": 2, "content_hash": "6bb525ce833b8eaee75fb110294237b088aeccbe39c612dcb24519740ae4c04b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:e172b776becb1beda4371ae37bbf3881a28bebf3ecc4d8af9a4f4e083f759b04", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the ZhiPuAI Chat Client.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-zhipuai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-zhipuai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 50, "section_index": 3, "content_hash": "e172b776becb1beda4371ae37bbf3881a28bebf3ecc4d8af9a4f4e083f759b04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:11a4901edd30db3a077f3b9f200649bd95adbe5dc6e2e1742f32b4ecdc9e1d81", "content": "[NOTE]\n====\nEnabling and disabling of the image auto-configurations are now configured via top level properties with the prefix `spring.ai.model.image`.\n\nTo enable, spring.ai.model.image=stabilityai (It is enabled by default)\n\nTo disable, spring.ai.model.image=none (or any value which doesn't match stabilityai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix `spring.ai.zhipuai.image` is the property prefix that lets you configure the `ImageModel` implementation for ZhiPuAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.zhipuai.image.enabled (Removed and no longer valid) | Enable ZhiPuAI image model. | true\n| spring.ai.model.image | Enable ZhiPuAI image model. | zhipuai\n| spring.ai.zhipuai.image.base-url | Optional overrides the spring.ai.zhipuai.base-url to provide chat specific url | -\n| spring.ai.zhipuai.image.api-key | Optional overrides the spring.ai.zhipuai.api-key to provide chat specific api-key | -\n| spring.ai.zhipuai.image.options.model | The model to use for image generation. | cogview-3\n| spring.ai.zhipuai.image.options.user | A unique identifier representing your end-user, which can help ZhiPuAI to monitor and detect abuse. | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Image Generation Properties", "heading_level": 3, "file_order": 50, "section_index": 4, "content_hash": "11a4901edd30db3a077f3b9f200649bd95adbe5dc6e2e1742f32b4ecdc9e1d81", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:b5e0e40232a87739a715159e9047f54b47687597c092df886c666177d8e98e5c", "content": "The prefix `spring.ai.zhipuai` is used as the property prefix that lets you connect to ZhiPuAI.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.zhipuai.base-url | The URL to connect to | https://open.bigmodel.cn/api/paas\n| spring.ai.zhipuai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Connection Properties", "heading_level": 4, "file_order": 50, "section_index": 5, "content_hash": "b5e0e40232a87739a715159e9047f54b47687597c092df886c666177d8e98e5c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:60d15ecbe3628bde219b4c1fe4029b4ac1cd23b0dd628e27556026e3630f6eac", "content": "The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the ZhiPuAI Image client.\n\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n\n| spring.ai.retry.max-attempts | Maximum number of retry attempts. | 10\n| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. | 2 sec.\n| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. | 5\n| spring.ai.retry.backoff.max-interval | Maximum backoff duration. | 3 min.\n| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false\n| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty\n| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Retry Properties", "heading_level": 4, "file_order": 50, "section_index": 6, "content_hash": "60d15ecbe3628bde219b4c1fe4029b4ac1cd23b0dd628e27556026e3630f6eac", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:3f4368e86f4eaf42709a1fbd94ebde3ff3c50dff624e72012c1bbaf0a63d2d67", "content": "The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiImageOptions.java[ZhiPuAiImageOptions.java] provides model configurations, such as the model to use, the quality, the size, etc.\n\nOn start-up, the default options can be configured with the `ZhiPuAiImageModel(ZhiPuAiImageApi zhiPuAiImageApi)` constructor and the `withDefaultOptions(ZhiPuAiImageOptions defaultOptions)` method. Alternatively, use the `spring.ai.zhipuai.image.options.*` properties described previously.\n\nAt runtime you can override the default options by adding new, request specific, options to the `ImagePrompt` call.\nFor example to override the ZhiPuAI specific options such as quality and the number of images to create, use the following code example:\n\n[source,java]\n----\nImageResponse response = zhiPuAiImageModel.call(\n new ImagePrompt(\"A light cream colored mini golden doodle\",\n ZhiPuAiImageOptions.builder()\n .quality(\"hd\")\n .N(4)\n .height(1024)\n .width(1024).build())\n\n);\n----\n\nTIP: In addition to the model specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-zhipuai/src/main/java/org/springframework/ai/zhipuai/ZhiPuAiImageOptions.java[ZhiPuAiImageOptions] you can use a portable https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptions.java[ImageOptions] instance, created with the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageOptionsBuilder.java[ImageOptionsBuilder#builder()].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/image/zhipuai-image.adoc", "title": "ZhiPuAI Image Generation", "heading": "Runtime Options [[image-options]]", "heading_level": 2, "file_order": 50, "section_index": 7, "content_hash": "3f4368e86f4eaf42709a1fbd94ebde3ff3c50dff624e72012c1bbaf0a63d2d67", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/image/zhipuai-image.adoc"}}
{"id": "sha256:5c51b3cbfc7468e2bf418fbc00e25a93105c1e151898f110ad7ac96ca5f42d30", "content": "The MCP Client Annotations provide a declarative way to implement MCP client handlers using Java annotations.\nThese annotations simplify the handling of server notifications and client-side operations.\n\n[IMPORTANT]\n**All MCP client annotations MUST include a `clients` parameter** to associate the handler with a specific MCP client connection. The `clients` must match the connection name configured in your application properties.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "MCP Client Annotations", "heading_level": 1, "file_order": 51, "section_index": 0, "content_hash": "5c51b3cbfc7468e2bf418fbc00e25a93105c1e151898f110ad7ac96ca5f42d30", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:dd15b1b6edd74d4840555c7be3087d4d6aafb0f3e957838567d1cc11a0645e4f", "content": "The `@McpLogging` annotation handles logging message notifications from MCP servers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpLogging", "heading_level": 3, "file_order": 51, "section_index": 1, "content_hash": "dd15b1b6edd74d4840555c7be3087d4d6aafb0f3e957838567d1cc11a0645e4f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:ffc21c1d9aed797d383e9d5a8e4bf0e1c97f476f6b7e3d268aa9580552b030b0", "content": "[source,java]\n----\n@Component\npublic class LoggingHandler {\n\n @McpLogging(clients = \"my-mcp-server\")\n public void handleLoggingMessage(LoggingMessageNotification notification) {\n System.out.println(\"Received log: \" + notification.level() +\n \" - \" + notification.data());\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 2, "content_hash": "ffc21c1d9aed797d383e9d5a8e4bf0e1c97f476f6b7e3d268aa9580552b030b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:f939512250a45e0ea7fc7ed4ce7ab57f47fa22f1cc26c90266e422c5c97ae39f", "content": "[source,java]\n----\n@McpLogging(clients = \"my-mcp-server\")\npublic void handleLoggingWithParams(LoggingLevel level, String logger, String data) {\n System.out.println(String.format(\"[%s] %s: %s\", level, logger, data));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "With Individual Parameters", "heading_level": 4, "file_order": 51, "section_index": 3, "content_hash": "f939512250a45e0ea7fc7ed4ce7ab57f47fa22f1cc26c90266e422c5c97ae39f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:331c5ee4519d48bcaf9856f3c14293d7c89efc30111edb73c001379b8a9ff2cc", "content": "The `@McpSampling` annotation handles sampling requests from MCP servers for LLM completions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpSampling", "heading_level": 3, "file_order": 51, "section_index": 4, "content_hash": "331c5ee4519d48bcaf9856f3c14293d7c89efc30111edb73c001379b8a9ff2cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:081f88a80fda753e35d2b16dbee585d106c13d23c73af3280b7f131c7b2edc81", "content": "[source,java]\n----\n@Component\npublic class SamplingHandler {\n\n @McpSampling(clients = \"llm-server\")\n public CreateMessageResult handleSamplingRequest(CreateMessageRequest request) {\n // Process the request and generate a response\n String response = generateLLMResponse(request);\n\n return CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response))\n .model(\"gpt-4\")\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Synchronous Implementation", "heading_level": 4, "file_order": 51, "section_index": 5, "content_hash": "081f88a80fda753e35d2b16dbee585d106c13d23c73af3280b7f131c7b2edc81", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:ae9b96461d9f1362050071578d0e8b0263b8fd23724192fcafa1c843de554159", "content": "[source,java]\n----\n@Component\npublic class AsyncSamplingHandler {\n\n @McpSampling(clients = \"llm-server\")\n public Mono<CreateMessageResult> handleAsyncSampling(CreateMessageRequest request) {\n return Mono.fromCallable(() -> {\n String response = generateLLMResponse(request);\n\n return CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response))\n .model(\"gpt-4\")\n .build();\n }).subscribeOn(Schedulers.boundedElastic());\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Asynchronous Implementation", "heading_level": 4, "file_order": 51, "section_index": 6, "content_hash": "ae9b96461d9f1362050071578d0e8b0263b8fd23724192fcafa1c843de554159", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:001b010de971204691daa52bbfbeb45dc08c896cb6823a4642c8c0853ad9e8c7", "content": "The `@McpElicitation` annotation handles elicitation requests to gather additional information from users.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpElicitation", "heading_level": 3, "file_order": 51, "section_index": 7, "content_hash": "001b010de971204691daa52bbfbeb45dc08c896cb6823a4642c8c0853ad9e8c7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:f6077c8482999d058f747bcb9d689c106ebca36444f768b853e4e08833431a4e", "content": "[source,java]\n----\n@Component\npublic class ElicitationHandler {\n\n @McpElicitation(clients = \"interactive-server\")\n public ElicitResult handleElicitationRequest(ElicitRequest request) {\n // Present the request to the user and gather input\n Map<String, Object> userData = presentFormToUser(request.requestedSchema());\n\n if (userData != null) {\n return new ElicitResult(ElicitResult.Action.ACCEPT, userData);\n } else {\n return new ElicitResult(ElicitResult.Action.DECLINE, null);\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 8, "content_hash": "f6077c8482999d058f747bcb9d689c106ebca36444f768b853e4e08833431a4e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:7a1962ce0f9a311551918e7e47b911ae601226a389fe5b7705b51d5004d11f61", "content": "[source,java]\n----\n@McpElicitation(clients = \"interactive-server\")\npublic ElicitResult handleInteractiveElicitation(ElicitRequest request) {\n Map<String, Object> schema = request.requestedSchema();\n Map<String, Object> userData = new HashMap<>();\n\n // Check what information is being requested\n if (schema != null && schema.containsKey(\"properties\")) {\n @SuppressWarnings(\"unchecked\")\n Map<String, Object> properties = (Map<String, Object>) schema.get(\"properties\");\n\n // Gather user input based on schema\n if (properties.containsKey(\"name\")) {\n userData.put(\"name\", promptUser(\"Enter your name:\"));\n }\n if (properties.containsKey(\"email\")) {\n userData.put(\"email\", promptUser(\"Enter your email:\"));\n }\n if (properties.containsKey(\"preferences\")) {\n userData.put(\"preferences\", gatherPreferences());\n }\n }\n\n return new ElicitResult(ElicitResult.Action.ACCEPT, userData);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "With User Interaction", "heading_level": 4, "file_order": 51, "section_index": 9, "content_hash": "7a1962ce0f9a311551918e7e47b911ae601226a389fe5b7705b51d5004d11f61", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:9ae1bf8da1c1e4c5e3878ae1d7bd54c022748174d634481858ac30ba5e971295", "content": "[source,java]\n----\n@McpElicitation(clients = \"interactive-server\")\npublic Mono<ElicitResult> handleAsyncElicitation(ElicitRequest request) {\n return Mono.fromCallable(() -> {\n // Async user interaction\n Map<String, Object> userData = asyncGatherUserInput(request);\n return new ElicitResult(ElicitResult.Action.ACCEPT, userData);\n }).timeout(Duration.ofSeconds(30))\n .onErrorReturn(new ElicitResult(ElicitResult.Action.CANCEL, null));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Async Elicitation", "heading_level": 4, "file_order": 51, "section_index": 10, "content_hash": "9ae1bf8da1c1e4c5e3878ae1d7bd54c022748174d634481858ac30ba5e971295", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:f2f8ddd389af8eabdad3d3b088ded5c201c680859d69df4906b86a5c6fa134df", "content": "The `@McpProgress` annotation handles progress notifications for long-running operations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpProgress", "heading_level": 3, "file_order": 51, "section_index": 11, "content_hash": "f2f8ddd389af8eabdad3d3b088ded5c201c680859d69df4906b86a5c6fa134df", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:a5749d1bdef098d9efa80ca32e3f035afea86359fc7e6e090465e0271fa307e0", "content": "[source,java]\n----\n@Component\npublic class ProgressHandler {\n\n @McpProgress(clients = \"my-mcp-server\")\n public void handleProgressNotification(ProgressNotification notification) {\n double percentage = notification.progress() * 100;\n System.out.println(String.format(\"Progress: %.2f%% - %s\",\n percentage, notification.message()));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 12, "content_hash": "a5749d1bdef098d9efa80ca32e3f035afea86359fc7e6e090465e0271fa307e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:f1e3655fe2b29b2d2a24d5cc6774bb5400e4bab48ca6633c63051d6aaf9118e7", "content": "[source,java]\n----\n@McpProgress(clients = \"my-mcp-server\")\npublic void handleProgressWithDetails(\n String progressToken,\n double progress,\n Double total,\n String message) {\n\n if (total != null) {\n System.out.println(String.format(\"[%s] %.0f/%.0f - %s\",\n progressToken, progress, total, message));\n } else {\n System.out.println(String.format(\"[%s] %.2f%% - %s\",\n progressToken, progress * 100, message));\n }\n\n // Update UI progress bar\n updateProgressBar(progressToken, progress);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "With Individual Parameters", "heading_level": 4, "file_order": 51, "section_index": 13, "content_hash": "f1e3655fe2b29b2d2a24d5cc6774bb5400e4bab48ca6633c63051d6aaf9118e7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:c9ae23a2b9bf1306bda28c3c99aabb588a4789afe9f8c793cf1adae8f9b1b18b", "content": "[source,java]\n----\n@McpProgress(clients = \"long-running-server\")\npublic void handleLongRunningProgress(ProgressNotification notification) {\n // Track progress for specific server\n progressTracker.update(\"long-running-server\", notification);\n\n // Send notifications if needed\n if (notification.progress() >= 1.0) {\n notifyCompletion(notification.progressToken());\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Client-Specific Progress", "heading_level": 4, "file_order": 51, "section_index": 14, "content_hash": "c9ae23a2b9bf1306bda28c3c99aabb588a4789afe9f8c793cf1adae8f9b1b18b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:e2e6343738211ab88d34746d77219d9d6347e45fe8497d8689549ed80496d9d3", "content": "The `@McpToolListChanged` annotation handles notifications when the server's tool list changes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpToolListChanged", "heading_level": 3, "file_order": 51, "section_index": 15, "content_hash": "e2e6343738211ab88d34746d77219d9d6347e45fe8497d8689549ed80496d9d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:233cd7134241bf00fc830240f609b2c13ff80934e065dacdc37ff5a9ebb89828", "content": "[source,java]\n----\n@Component\npublic class ToolListChangedHandler {\n\n @McpToolListChanged(clients = \"tool-server\")\n public void handleToolListChanged(List<McpSchema.Tool> updatedTools) {\n System.out.println(\"Tool list updated: \" + updatedTools.size() + \" tools available\");\n\n // Update local tool registry\n toolRegistry.updateTools(updatedTools);\n\n // Log new tools\n for (McpSchema.Tool tool : updatedTools) {\n System.out.println(\" - \" + tool.name() + \": \" + tool.description());\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 16, "content_hash": "233cd7134241bf00fc830240f609b2c13ff80934e065dacdc37ff5a9ebb89828", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:67da389de9078bf73e2af9ce2ad862374c90f086c74cda1be50fec8108dff544", "content": "[source,java]\n----\n@McpToolListChanged(clients = \"tool-server\")\npublic Mono<Void> handleAsyncToolListChanged(List<McpSchema.Tool> updatedTools) {\n return Mono.fromRunnable(() -> {\n // Process tool list update asynchronously\n processToolListUpdate(updatedTools);\n\n // Notify interested components\n eventBus.publish(new ToolListUpdatedEvent(updatedTools));\n }).then();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Async Handling", "heading_level": 4, "file_order": 51, "section_index": 17, "content_hash": "67da389de9078bf73e2af9ce2ad862374c90f086c74cda1be50fec8108dff544", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:44fb7851f9f04c5192331b582d0f0de3485060190de9e72f3b76018e2e2b44ca", "content": "[source,java]\n----\n@McpToolListChanged(clients = \"dynamic-server\")\npublic void handleDynamicServerToolUpdate(List<McpSchema.Tool> updatedTools) {\n // Handle tools from a specific server that frequently changes its tools\n dynamicToolManager.updateServerTools(\"dynamic-server\", updatedTools);\n\n // Re-evaluate tool availability\n reevaluateToolCapabilities();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Client-Specific Tool Updates", "heading_level": 4, "file_order": 51, "section_index": 18, "content_hash": "44fb7851f9f04c5192331b582d0f0de3485060190de9e72f3b76018e2e2b44ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:2102a3534b6ac41d69d47d3f68bfb79dfa6e9357a3df9feedc567a3a1d1f5491", "content": "The `@McpResourceListChanged` annotation handles notifications when the server's resource list changes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpResourceListChanged", "heading_level": 3, "file_order": 51, "section_index": 19, "content_hash": "2102a3534b6ac41d69d47d3f68bfb79dfa6e9357a3df9feedc567a3a1d1f5491", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:882c7eb1e918c3cfed99e522e2d05f553922233ff2bd36d548eb378efaeedbee", "content": "[source,java]\n----\n@Component\npublic class ResourceListChangedHandler {\n\n @McpResourceListChanged(clients = \"resource-server\")\n public void handleResourceListChanged(List<McpSchema.Resource> updatedResources) {\n System.out.println(\"Resources updated: \" + updatedResources.size());\n\n // Update resource cache\n resourceCache.clear();\n for (McpSchema.Resource resource : updatedResources) {\n resourceCache.register(resource);\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 20, "content_hash": "882c7eb1e918c3cfed99e522e2d05f553922233ff2bd36d548eb378efaeedbee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:06a393675aa7d123b17433d3cd14702f5be9e279d3104d9b054641842e796a9e", "content": "[source,java]\n----\n@McpResourceListChanged(clients = \"resource-server\")\npublic void analyzeResourceChanges(List<McpSchema.Resource> updatedResources) {\n // Analyze what changed\n Set<String> newUris = updatedResources.stream()\n .map(McpSchema.Resource::uri)\n .collect(Collectors.toSet());\n\n Set<String> removedUris = previousUris.stream()\n .filter(uri -> !newUris.contains(uri))\n .collect(Collectors.toSet());\n\n if (!removedUris.isEmpty()) {\n handleRemovedResources(removedUris);\n }\n\n // Update tracking\n previousUris = newUris;\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "With Resource Analysis", "heading_level": 4, "file_order": 51, "section_index": 21, "content_hash": "06a393675aa7d123b17433d3cd14702f5be9e279d3104d9b054641842e796a9e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:7c889cfcfa6ed8b1137e813cc1e1265427bc862d87a9a32518265335d5018346", "content": "The `@McpPromptListChanged` annotation handles notifications when the server's prompt list changes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "@McpPromptListChanged", "heading_level": 3, "file_order": 51, "section_index": 22, "content_hash": "7c889cfcfa6ed8b1137e813cc1e1265427bc862d87a9a32518265335d5018346", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:fc43c8799f819b609ec3b11347a20242f08c171aa6d3ad88cdd4b4439307756b", "content": "[source,java]\n----\n@Component\npublic class PromptListChangedHandler {\n\n @McpPromptListChanged(clients = \"prompt-server\")\n public void handlePromptListChanged(List<McpSchema.Prompt> updatedPrompts) {\n System.out.println(\"Prompts updated: \" + updatedPrompts.size());\n\n // Update prompt catalog\n promptCatalog.updatePrompts(updatedPrompts);\n\n // Refresh UI if needed\n if (uiController != null) {\n uiController.refreshPromptList(updatedPrompts);\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 51, "section_index": 23, "content_hash": "fc43c8799f819b609ec3b11347a20242f08c171aa6d3ad88cdd4b4439307756b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:bf3bdbc695586bb5a633408525f010727958819b38ea081eb17bd907db3f5a6d", "content": "[source,java]\n----\n@McpPromptListChanged(clients = \"prompt-server\")\npublic Mono<Void> handleAsyncPromptUpdate(List<McpSchema.Prompt> updatedPrompts) {\n return Flux.fromIterable(updatedPrompts)\n .flatMap(prompt -> validatePrompt(prompt))\n .collectList()\n .doOnNext(validPrompts -> {\n promptRepository.saveAll(validPrompts);\n })\n .then();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Async Processing", "heading_level": 4, "file_order": 51, "section_index": 24, "content_hash": "bf3bdbc695586bb5a633408525f010727958819b38ea081eb17bd907db3f5a6d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:b772e97daab54c6cb352328f54fd912224576504980b87490cb779d8dad94fdb", "content": "With Spring Boot auto-configuration, client handlers are automatically detected and registered:\n\n[source,java]\n----\n@SpringBootApplication\npublic class McpClientApplication {\n public static void main(String[] args) {\n SpringApplication.run(McpClientApplication.class, args);\n }\n}\n\n@Component\npublic class MyClientHandlers {\n\n @McpLogging(clients = \"my-server\")\n public void handleLogs(LoggingMessageNotification notification) {\n // Handle logs\n }\n\n @McpSampling(clients = \"my-server\")\n public CreateMessageResult handleSampling(CreateMessageRequest request) {\n // Handle sampling\n }\n\n @McpProgress(clients = \"my-server\")\n public void handleProgress(ProgressNotification notification) {\n // Handle progress\n }\n}\n----\n\nThe auto-configuration will:\n\n1. Scan for beans with MCP client annotations\n2. Create appropriate specifications\n3. Register them with the MCP client\n4. Support both sync and async implementations\n5. Handle multiple clients with client-specific handlers", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Spring Boot Integration", "heading_level": 2, "file_order": 51, "section_index": 25, "content_hash": "b772e97daab54c6cb352328f54fd912224576504980b87490cb779d8dad94fdb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:d32a698bcc2b548282700495bfd011cd8d029fb7c9e6f0019527736cbb802688", "content": "Configure the client annotation scanner and client connections:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n type: SYNC # or ASYNC\n annotation-scanner:\n enabled: true\n # Configure client connections - the connection names become clients values\n sse:\n connections:\n my-server: # This becomes the clients\n url: http://localhost:8080\n tool-server: # Another clients\n url: http://localhost:8081\n stdio:\n connections:\n local-server: # This becomes the clients\n command: /path/to/mcp-server\n args:\n - --mode=production\n----\n\n[IMPORTANT]\nThe `clients` parameter in annotations must match the connection names defined in your configuration. In the example above, valid `clients` values would be: `\"my-server\"`, `\"tool-server\"`, and `\"local-server\"`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Configuration Properties", "heading_level": 2, "file_order": 51, "section_index": 26, "content_hash": "d32a698bcc2b548282700495bfd011cd8d029fb7c9e6f0019527736cbb802688", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:1a71f697c57eb254434c2d62e9b789d152d157202f8e8b185f53d9e6987b05a3", "content": "The annotated handlers are automatically integrated with the MCP client:\n\n[source,java]\n----\n@Autowired\nprivate List<McpSyncClient> mcpClients;\n\n----\n\nFor each MCP client connection, handlers with matching `clients` will be automatically registered and invoked when the corresponding events occur.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Usage with MCP Client", "heading_level": 2, "file_order": 51, "section_index": 27, "content_hash": "1a71f697c57eb254434c2d62e9b789d152d157202f8e8b185f53d9e6987b05a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:e7bf736d81771e1e7478be46798822fa04303f595aac87d4559e772c85c5b901", "content": "* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Overview]\n* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations]\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters]\n* xref:api/mcp/mcp-client-boot-starter-docs.adoc[MCP Client Boot Starter]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc", "title": "MCP Client Annotations", "heading": "Additional Resources", "heading_level": 2, "file_order": 51, "section_index": 28, "content_hash": "e7bf736d81771e1e7478be46798822fa04303f595aac87d4559e772c85c5b901", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-client.adoc"}}
{"id": "sha256:d10c321a15957b8d570be2c36c7d1c12bdc245150c203c6a79b4ca25dfd3413e", "content": "This page provides comprehensive examples of using MCP annotations in Spring AI applications.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "MCP Annotations Examples", "heading_level": 1, "file_order": 52, "section_index": 0, "content_hash": "d10c321a15957b8d570be2c36c7d1c12bdc245150c203c6a79b4ca25dfd3413e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:55c81ac260693386b09fa3cecc8d7b195f29ebccebba500e86e1df62ce6a95d8", "content": "A complete example of an MCP server providing calculator tools:\n\n[source,java]\n----\n@SpringBootApplication\npublic class CalculatorServerApplication {\n public static void main(String[] args) {\n SpringApplication.run(CalculatorServerApplication.class, args);\n }\n}\n\n@Component\npublic class CalculatorTools {\n\n @McpTool(name = \"add\", description = \"Add two numbers\")\n public double add(\n @McpToolParam(description = \"First number\", required = true) double a,\n @McpToolParam(description = \"Second number\", required = true) double b) {\n return a + b;\n }\n\n @McpTool(name = \"subtract\", description = \"Subtract two numbers\")\n public double subtract(\n @McpToolParam(description = \"First number\", required = true) double a,\n @McpToolParam(description = \"Second number\", required = true) double b) {\n return a - b;\n }\n\n @McpTool(name = \"multiply\", description = \"Multiply two numbers\")\n public double multiply(\n @McpToolParam(description = \"First number\", required = true) double a,\n @McpToolParam(description = \"Second number\", required = true) double b) {\n return a * b;\n }\n\n @McpTool(name = \"divide\", description = \"Divide two numbers\")\n public double divide(\n @McpToolParam(description = \"Dividend\", required = true) double dividend,\n @McpToolParam(description = \"Divisor\", required = true) double divisor) {\n if (divisor == 0) {\n throw new IllegalArgumentException(\"Division by zero\");\n }\n return dividend / divisor;\n }\n\n @McpTool(name = \"calculate-expression\",\n description = \"Calculate a complex mathematical expression\")\n public CallToolResult calculateExpression(\n CallToolRequest request,\n McpSyncRequestContext context) {\n\n Map<String, Object> args = request.arguments();\n String expression = (String) args.get(\"expression\");\n\n // Use convenient logging method\n context.info(\"Calculating: \" + expression);\n\n try {\n double result = evaluateExpression(expression);\n return CallToolResult.builder()\n .addTextContent(\"Result: \" + result)\n .build();\n } catch (Exception e) {\n return CallToolResult.builder()\n .isError(true)\n .addTextContent(\"Error: \" + e.getMessage())\n .build();\n }\n }\n}\n----\n\nConfiguration:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n name: calculator-server\n version: 1.0.0\n type: SYNC\n protocol: SSE # or STDIO, STREAMABLE\n capabilities:\n tool: true\n resource: true\n prompt: true\n completion: true\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Simple Calculator Server", "heading_level": 3, "file_order": 52, "section_index": 1, "content_hash": "55c81ac260693386b09fa3cecc8d7b195f29ebccebba500e86e1df62ce6a95d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:f7f81feb6fea8bfcc946f8a18d11f83e5e7c9cdc524e5a470fadced992372e25", "content": "An example of a document processing server with resources and prompts:\n\n[source,java]\n----\n@Component\npublic class DocumentServer {\n\n private final Map<String, Document> documents = new ConcurrentHashMap<>();\n\n @McpResource(\n uri = \"document://{id}\",\n name = \"Document\",\n description = \"Access stored documents\")\n public ReadResourceResult getDocument(String id, McpMeta meta) {\n Document doc = documents.get(id);\n\n if (doc == null) {\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"document://\" + id,\n \"text/plain\", \"Document not found\")\n ));\n }\n\n // Check access permissions from metadata\n String accessLevel = (String) meta.get(\"accessLevel\");\n if (\"restricted\".equals(doc.getClassification()) &&\n !\"admin\".equals(accessLevel)) {\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"document://\" + id,\n \"text/plain\", \"Access denied\")\n ));\n }\n\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"document://\" + id,\n doc.getMimeType(), doc.getContent())\n ));\n }\n\n @McpTool(name = \"analyze-document\",\n description = \"Analyze document content\")\n public String analyzeDocument(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Document ID\", required = true) String docId,\n @McpToolParam(description = \"Analysis type\", required = false) String type) {\n\n Document doc = documents.get(docId);\n if (doc == null) {\n return \"Document not found\";\n }\n\n // Access progress token from context\n String progressToken = context.request().progressToken();\n\n if (progressToken != null) {\n context.progress(p -> p.progress(0.0).total(1.0).message(\"Starting analysis\"));\n }\n\n // Perform analysis\n String analysisType = type != null ? type : \"summary\";\n String result = performAnalysis(doc, analysisType);\n\n if (progressToken != null) {\n context.progress(p -> p.progress(1.0).total(1.0).message(\"Analysis complete\"));\n }\n\n return result;\n }\n\n @McpPrompt(\n name = \"document-summary\",\n description = \"Generate document summary prompt\")\n public GetPromptResult documentSummaryPrompt(\n @McpArg(name = \"docId\", required = true) String docId,\n @McpArg(name = \"length\", required = false) String length) {\n\n Document doc = documents.get(docId);\n if (doc == null) {\n return new GetPromptResult(\"Error\",\n List.of(new PromptMessage(Role.SYSTEM,\n new TextContent(\"Document not found\"))));\n }\n\n String promptText = String.format(\n \"Please summarize the following document in %s:\\n\\n%s\",\n length != null ? length : \"a few paragraphs\",\n doc.getContent()\n );\n\n return new GetPromptResult(\"Document Summary\",\n List.of(new PromptMessage(Role.USER, new TextContent(promptText))));\n }\n\n @McpComplete(prompt = \"document-summary\")\n public List<String> completeDocumentId(String prefix) {\n return documents.keySet().stream()\n .filter(id -> id.startsWith(prefix))\n .sorted()\n .limit(10)\n .toList();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Document Processing Server", "heading_level": 3, "file_order": 52, "section_index": 2, "content_hash": "f7f81feb6fea8bfcc946f8a18d11f83e5e7c9cdc524e5a470fadced992372e25", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:d1b44e968de6fc6f4187879299251cbdf5d5ee309d7b6ea42fa12d33f73de652", "content": "A complete MCP client application with various handlers:\n\n[source,java]\n----\n@SpringBootApplication\npublic class McpClientApplication {\n public static void main(String[] args) {\n SpringApplication.run(McpClientApplication.class, args);\n }\n}\n\n@Component\npublic class ClientHandlers {\n\n private final Logger logger = LoggerFactory.getLogger(ClientHandlers.class);\n private final ProgressTracker progressTracker = new ProgressTracker();\n private final ChatModel chatModel;\n\n public ClientHandlers(@Lazy ChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n @McpLogging(clients = \"server1\")\n public void handleLogging(LoggingMessageNotification notification) {\n switch (notification.level()) {\n case ERROR:\n logger.error(\"[MCP] {} - {}\", notification.logger(), notification.data());\n break;\n case WARNING:\n logger.warn(\"[MCP] {} - {}\", notification.logger(), notification.data());\n break;\n case INFO:\n logger.info(\"[MCP] {} - {}\", notification.logger(), notification.data());\n break;\n default:\n logger.debug(\"[MCP] {} - {}\", notification.logger(), notification.data());\n }\n }\n\n @McpSampling(clients = \"server1\")\n public CreateMessageResult handleSampling(CreateMessageRequest request) {\n // Use Spring AI ChatModel for sampling\n List<Message> messages = request.messages().stream()\n .map(msg -> {\n if (msg.role() == Role.USER) {\n return new UserMessage(((TextContent) msg.content()).text());\n } else {\n return AssistantMessage.builder()\n .content(((TextContent) msg.content()).text())\n .build();\n }\n })\n .toList();\n\n ChatResponse response = chatModel.call(new Prompt(messages));\n\n return CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response.getResult().getOutput().getText()))\n .model(request.modelPreferences().hints().get(0).name())\n .build();\n }\n\n @McpElicitation(clients = \"server1\")\n public ElicitResult handleElicitation(ElicitRequest request) {\n // In a real application, this would show a UI dialog\n Map<String, Object> userData = new HashMap<>();\n\n logger.info(\"Elicitation requested: {}\", request.message());\n\n // Simulate user input based on schema\n Map<String, Object> schema = request.requestedSchema();\n if (schema != null && schema.containsKey(\"properties\")) {\n @SuppressWarnings(\"unchecked\")\n Map<String, Object> properties = (Map<String, Object>) schema.get(\"properties\");\n\n properties.forEach((key, value) -> {\n // In real app, prompt user for each field\n userData.put(key, getDefaultValueForProperty(key, value));\n });\n }\n\n return new ElicitResult(ElicitResult.Action.ACCEPT, userData);\n }\n\n @McpProgress(clients = \"server1\")\n public void handleProgress(ProgressNotification notification) {\n progressTracker.update(\n notification.progressToken(),\n notification.progress(),\n notification.total(),\n notification.message()\n );\n\n // Update UI or send websocket notification\n broadcastProgress(notification);\n }\n\n @McpToolListChanged(clients = \"server1\")\n public void handleServer1ToolsChanged(List<McpSchema.Tool> tools) {\n logger.info(\"Server1 tools updated: {} tools available\", tools.size());\n\n // Update tool registry\n toolRegistry.updateServerTools(\"server1\", tools);\n\n // Notify UI to refresh tool list\n eventBus.publish(new ToolsUpdatedEvent(\"server1\", tools));\n }\n\n @McpResourceListChanged(clients = \"server1\")\n public void handleServer1ResourcesChanged(List<McpSchema.Resource> resources) {\n logger.info(\"Server1 resources updated: {} resources available\", resources.size());\n\n // Clear resource cache for this server\n resourceCache.clearServer(\"server1\");\n\n // Register new resources\n resources.forEach(resource ->\n resourceCache.register(\"server1\", resource));\n }\n}\n----\n\nConfiguration:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n type: SYNC\n initialized: true\n request-timeout: 30s\n annotation-scanner:\n enabled: true\n sse:\n connections:\n server1:\n url: http://localhost:8080\n stdio:\n connections:\n local-tool:\n command: /usr/local/bin/mcp-tool\n args:\n - --mode=production\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "MCP Client with Handlers", "heading_level": 3, "file_order": 52, "section_index": 3, "content_hash": "d1b44e968de6fc6f4187879299251cbdf5d5ee309d7b6ea42fa12d33f73de652", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:a408518178a9d188bb04560e28cbbe3a4eadff9677105ddeae89a3d22aa8b04e", "content": "[source,java]\n----\n@Component\npublic class AsyncDataProcessor {\n\n @McpTool(name = \"fetch-data\", description = \"Fetch data from external source\")\n public Mono<DataResult> fetchData(\n @McpToolParam(description = \"Data source URL\", required = true) String url,\n @McpToolParam(description = \"Timeout in seconds\", required = false) Integer timeout) {\n\n Duration timeoutDuration = Duration.ofSeconds(timeout != null ? timeout : 30);\n\n return WebClient.create()\n .get()\n .uri(url)\n .retrieve()\n .bodyToMono(String.class)\n .map(data -> new DataResult(url, data, System.currentTimeMillis()))\n .timeout(timeoutDuration)\n .onErrorReturn(new DataResult(url, \"Error fetching data\", 0L));\n }\n\n @McpTool(name = \"process-stream\", description = \"Process data stream\")\n public Flux<String> processStream(\n McpAsyncRequestContext context,\n @McpToolParam(description = \"Item count\", required = true) int count) {\n\n // Access progress token from context\n String progressToken = context.request().progressToken();\n\n return Flux.range(1, count)\n .delayElements(Duration.ofMillis(100))\n .flatMap(i -> {\n if (progressToken != null) {\n double progress = (double) i / count;\n return context.progress(p -> p.progress(progress).total(1.0).message(\"Processing item \" + i))\n .thenReturn(\"Processed item \" + i);\n }\n return Mono.just(\"Processed item \" + i);\n });\n }\n\n @McpResource(uri = \"async-data://{id}\", name = \"Async Data\")\n public Mono<ReadResourceResult> getAsyncData(String id) {\n return Mono.fromCallable(() -> loadDataAsync(id))\n .subscribeOn(Schedulers.boundedElastic())\n .map(data -> new ReadResourceResult(List.of(\n new TextResourceContents(\"async-data://\" + id,\n \"application/json\", data)\n )));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Async Tool Server", "heading_level": 3, "file_order": 52, "section_index": 4, "content_hash": "a408518178a9d188bb04560e28cbbe3a4eadff9677105ddeae89a3d22aa8b04e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:923b3af18af2cb1b8d650aa0c029996c4fe5e7fb0304ea685d29eb35a425e5d7", "content": "[source,java]\n----\n@Component\npublic class AsyncClientHandlers {\n\n @McpSampling(clients = \"async-server\")\n public Mono<CreateMessageResult> handleAsyncSampling(CreateMessageRequest request) {\n return Mono.fromCallable(() -> {\n // Prepare request for LLM\n String prompt = extractPrompt(request);\n return prompt;\n })\n .flatMap(prompt -> callLLMAsync(prompt))\n .map(response -> CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response))\n .model(\"gpt-4\")\n .build())\n .timeout(Duration.ofSeconds(30));\n }\n\n @McpProgress(clients = \"async-server\")\n public Mono<Void> handleAsyncProgress(ProgressNotification notification) {\n return Mono.fromRunnable(() -> {\n // Update progress tracking\n updateProgressAsync(notification);\n })\n .then(broadcastProgressAsync(notification))\n .subscribeOn(Schedulers.parallel());\n }\n\n @McpElicitation(clients = \"async-server\")\n public Mono<ElicitResult> handleAsyncElicitation(ElicitRequest request) {\n return showUserDialogAsync(request)\n .map(userData -> {\n if (userData != null && !userData.isEmpty()) {\n return new ElicitResult(ElicitResult.Action.ACCEPT, userData);\n } else {\n return new ElicitResult(ElicitResult.Action.DECLINE, null);\n }\n })\n .timeout(Duration.ofMinutes(5))\n .onErrorReturn(new ElicitResult(ElicitResult.Action.CANCEL, null));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Async Client Handlers", "heading_level": 3, "file_order": 52, "section_index": 5, "content_hash": "923b3af18af2cb1b8d650aa0c029996c4fe5e7fb0304ea685d29eb35a425e5d7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:4665e183fc06976724cc76e8f9ae63001f967f55936b6e59fe14dcc3d735fecf", "content": "[source,java]\n----\n@Component\npublic class StatelessTools {\n\n // Simple stateless tool\n @McpTool(name = \"format-text\", description = \"Format text\")\n public String formatText(\n @McpToolParam(description = \"Text to format\", required = true) String text,\n @McpToolParam(description = \"Format type\", required = true) String format) {\n\n return switch (format.toLowerCase()) {\n case \"uppercase\" -> text.toUpperCase();\n case \"lowercase\" -> text.toLowerCase();\n case \"title\" -> toTitleCase(text);\n case \"reverse\" -> new StringBuilder(text).reverse().toString();\n default -> text;\n };\n }\n\n // Stateless with transport context\n @McpTool(name = \"validate-json\", description = \"Validate JSON\")\n public CallToolResult validateJson(\n McpTransportContext context,\n @McpToolParam(description = \"JSON string\", required = true) String json) {\n\n try {\n ObjectMapper mapper = new ObjectMapper();\n mapper.readTree(json);\n\n return CallToolResult.builder()\n .addTextContent(\"Valid JSON\")\n .structuredContent(Map.of(\"valid\", true))\n .build();\n } catch (Exception e) {\n return CallToolResult.builder()\n .addTextContent(\"Invalid JSON: \" + e.getMessage())\n .structuredContent(Map.of(\"valid\", false, \"error\", e.getMessage()))\n .build();\n }\n }\n\n @McpResource(uri = \"static://{path}\", name = \"Static Resource\")\n public String getStaticResource(String path) {\n // Simple stateless resource\n return loadStaticContent(path);\n }\n\n @McpPrompt(name = \"template\", description = \"Template prompt\")\n public GetPromptResult templatePrompt(\n @McpArg(name = \"template\", required = true) String templateName,\n @McpArg(name = \"variables\", required = false) String variables) {\n\n String template = loadTemplate(templateName);\n if (variables != null) {\n template = substituteVariables(template, variables);\n }\n\n return new GetPromptResult(\"Template: \" + templateName,\n List.of(new PromptMessage(Role.USER, new TextContent(template))));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Stateless Server Examples", "heading_level": 2, "file_order": 52, "section_index": 6, "content_hash": "4665e183fc06976724cc76e8f9ae63001f967f55936b6e59fe14dcc3d735fecf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:55523dd6537edf71077060e064d280e1f3b12769e5dad8ee34abb0e32d458b58", "content": "This example demonstrates how to use MCP Sampling to generate creative content from multiple LLM providers, showcasing the annotation-based approach for both server and client implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "MCP Sampling with Multiple LLM Providers", "heading_level": 2, "file_order": 52, "section_index": 7, "content_hash": "55523dd6537edf71077060e064d280e1f3b12769e5dad8ee34abb0e32d458b58", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:64307328ed2ad58b6e8102abe39dba28346f2e90381396ba269f59abc9aee209", "content": "The server provides a weather tool that uses MCP Sampling to generate poems from different LLM providers:\n\n[source,java]\n----\n@Service\npublic class WeatherService {\n\n private final RestClient restClient = RestClient.create();\n\n public record WeatherResponse(Current current) {\n public record Current(LocalDateTime time, int interval, double temperature_2m) {\n }\n }\n\n @McpTool(description = \"Get the temperature (in celsius) for a specific location\")\n public String getTemperature2(McpSyncServerExchange exchange,\n @McpToolParam(description = \"The location latitude\") double latitude,\n @McpToolParam(description = \"The location longitude\") double longitude) {\n\n // Fetch weather data\n WeatherResponse weatherResponse = restClient\n .get()\n .uri(\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m\",\n latitude, longitude)\n .retrieve()\n .body(WeatherResponse.class);\n\n StringBuilder openAiWeatherPoem = new StringBuilder();\n StringBuilder anthropicWeatherPoem = new StringBuilder();\n\n // Send logging notification\n exchange.loggingNotification(LoggingMessageNotification.builder()\n .level(LoggingLevel.INFO)\n .data(\"Start sampling\")\n .build());\n\n // Check if client supports sampling\n if (exchange.getClientCapabilities().sampling() != null) {\n var messageRequestBuilder = McpSchema.CreateMessageRequest.builder()\n .systemPrompt(\"You are a poet!\")\n .messages(List.of(new McpSchema.SamplingMessage(McpSchema.Role.USER,\n new McpSchema.TextContent(\n \"Please write a poem about this weather forecast (temperature is in Celsius). Use markdown format :\\n \"\n + ModelOptionsUtils.toJsonStringPrettyPrinter(weatherResponse)))));\n\n // Request poem from OpenAI\n var openAiLlmMessageRequest = messageRequestBuilder\n .modelPreferences(ModelPreferences.builder().addHint(\"openai\").build())\n .build();\n CreateMessageResult openAiLlmResponse = exchange.createMessage(openAiLlmMessageRequest);\n openAiWeatherPoem.append(((McpSchema.TextContent) openAiLlmResponse.content()).text());\n\n // Request poem from Anthropic\n var anthropicLlmMessageRequest = messageRequestBuilder\n .modelPreferences(ModelPreferences.builder().addHint(\"anthropic\").build())\n .build();\n CreateMessageResult anthropicAiLlmResponse = exchange.createMessage(anthropicLlmMessageRequest);\n anthropicWeatherPoem.append(((McpSchema.TextContent) anthropicAiLlmResponse.content()).text());\n }\n\n exchange.loggingNotification(LoggingMessageNotification.builder()\n .level(LoggingLevel.INFO)\n .data(\"Finish Sampling\")\n .build());\n\n // Combine results\n String responseWithPoems = \"OpenAI poem about the weather: \" + openAiWeatherPoem.toString() + \"\\n\\n\" +\n \"Anthropic poem about the weather: \" + anthropicWeatherPoem.toString() + \"\\n\"\n + ModelOptionsUtils.toJsonStringPrettyPrinter(weatherResponse);\n\n return responseWithPoems;\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Sampling Server Implementation", "heading_level": 3, "file_order": 52, "section_index": 8, "content_hash": "64307328ed2ad58b6e8102abe39dba28346f2e90381396ba269f59abc9aee209", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:4522c69c1cc573e8de451714fd8fdd7ba54240729f039a1ffbbb867dc53a9606", "content": "The client handles sampling requests by routing them to appropriate LLM providers based on model hints:\n\n[source,java]\n----\n@Service\npublic class McpClientHandlers {\n\n private static final Logger logger = LoggerFactory.getLogger(McpClientHandlers.class);\n\n @Autowired\n Map<String, ChatClient> chatClients;\n\n @McpProgress(clients = \"server1\")\n public void progressHandler(ProgressNotification progressNotification) {\n logger.info(\"MCP PROGRESS: [{}] progress: {} total: {} message: {}\",\n progressNotification.progressToken(), progressNotification.progress(),\n progressNotification.total(), progressNotification.message());\n }\n\n @McpLogging(clients = \"server1\")\n public void loggingHandler(LoggingMessageNotification loggingMessage) {\n logger.info(\"MCP LOGGING: [{}] {}\", loggingMessage.level(), loggingMessage.data());\n }\n\n @McpSampling(clients = \"server1\")\n public CreateMessageResult samplingHandler(CreateMessageRequest llmRequest) {\n logger.info(\"MCP SAMPLING: {}\", llmRequest);\n\n // Extract user prompt and model hint\n var userPrompt = ((McpSchema.TextContent) llmRequest.messages().get(0).content()).text();\n String modelHint = llmRequest.modelPreferences().hints().get(0).name();\n\n // Find appropriate ChatClient based on model hint\n ChatClient hintedChatClient = chatClients.entrySet().stream()\n .filter(e -> e.getKey().contains(modelHint))\n .findFirst()\n .orElseThrow()\n .getValue();\n\n // Generate response using the selected model\n String response = hintedChatClient.prompt()\n .system(llmRequest.systemPrompt())\n .user(userPrompt)\n .call()\n .content();\n\n return CreateMessageResult.builder()\n .content(new McpSchema.TextContent(response))\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Sampling Client Implementation", "heading_level": 3, "file_order": 52, "section_index": 9, "content_hash": "4522c69c1cc573e8de451714fd8fdd7ba54240729f039a1ffbbb867dc53a9606", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:4d2a1581401bc4da642da5af759b59d392ccb4e089e178a8acaeae5f700487c0", "content": "Register the MCP tools and handlers in the client application:\n\n[source,java]\n----\n@SpringBootApplication\npublic class McpClientApplication {\n\n public static void main(String[] args) {\n SpringApplication.run(McpClientApplication.class, args).close();\n }\n\n @Bean\n public CommandLineRunner predefinedQuestions(OpenAiChatModel openAiChatModel,\n ToolCallbackProvider mcpToolProvider) {\n\n return args -> {\n\n ChatClient chatClient = ChatClient.builder(openAiChatModel)\n .defaultToolCallbacks(mcpToolProvider)\n .build();\n\n String userQuestion = \"\"\"\n What is the weather in Amsterdam right now?\n Please incorporate all creative responses from all LLM providers.\n After the other providers add a poem that synthesizes the poems from all the other providers.\n \"\"\";\n\n System.out.println(\"> USER: \" + userQuestion);\n System.out.println(\"> ASSISTANT: \" + chatClient.prompt(userQuestion).call().content());\n };\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Client Application Setup", "heading_level": 3, "file_order": 52, "section_index": 10, "content_hash": "4d2a1581401bc4da642da5af759b59d392ccb4e089e178a8acaeae5f700487c0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:1d0e145aa40a47c386e99bed4573153230ac2b40903348a0bcb9e2bdae2d6eab", "content": "[source,yaml]\n----\n# Server application.properties\nspring.ai.mcp.server.name=mcp-sampling-server-annotations\nspring.ai.mcp.server.version=0.0.1\nspring.ai.mcp.server.protocol=STREAMABLE\nspring.main.banner-mode=off\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Server Configuration", "heading_level": 4, "file_order": 52, "section_index": 11, "content_hash": "1d0e145aa40a47c386e99bed4573153230ac2b40903348a0bcb9e2bdae2d6eab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:455e784cd85d1fdb0be01653c16c356ccc21c2ce9d65d9294e1a953ddff5c9e8", "content": "[source,yaml]\n----\n# Client application.properties\nspring.application.name=mcp\nspring.main.web-application-type=none\n\n# Disable default chat client auto-configuration for multiple models\nspring.ai.chat.client.enabled=false\n\n# API keys\nspring.ai.openai.api-key=${OPENAI_API_KEY}\nspring.ai.anthropic.api-key=${ANTHROPIC_API_KEY}\n\n# MCP client connection using stateless-http transport\nspring.ai.mcp.client.streamable-http.connections.server1.url=http://localhost:8080\n\n# Disable tool callback to prevent cyclic dependencies\nspring.ai.mcp.client.toolcallback.enabled=false\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Client Configuration", "heading_level": 4, "file_order": 52, "section_index": 12, "content_hash": "455e784cd85d1fdb0be01653c16c356ccc21c2ce9d65d9294e1a953ddff5c9e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:ae95cdd097c6473ce1ff341151173b0ca888a053b507f13f47d7c8a44274bd63", "content": "1. **Multi-Model Sampling**: Server requests content from multiple LLM providers using model hints\n2. **Annotation-Based Handlers**: Client uses `@McpSampling`, `@McpLogging`, and `@McpProgress` annotations\n3. **Stateless HTTP Transport**: Uses the streamable protocol for communication\n4. **Creative Content Generation**: Generates poems about weather data from different models\n5. **Unified Response Handling**: Combines responses from multiple providers into a single result", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Key Features Demonstrated", "heading_level": 3, "file_order": 52, "section_index": 13, "content_hash": "ae95cdd097c6473ce1ff341151173b0ca888a053b507f13f47d7c8a44274bd63", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:60066e0e918607a23476b3edf6063436f25f304034d91846a2b182c5b53ef92d", "content": "When running the client, you'll see output like:\n\n[source]\n----\n> USER: What is the weather in Amsterdam right now?\nPlease incorporate all creative responses from all LLM providers.\nAfter the other providers add a poem that synthesizes the poems from all the other providers.\n\n> ASSISTANT:\nOpenAI poem about the weather:\n**Amsterdam's Winter Whisper**\n*Temperature: 4.2°C*\n\nIn Amsterdam's embrace, where canals reflect the sky,\nA gentle chill of 4.2 degrees drifts by...\n\nAnthropic poem about the weather:\n**Canal-Side Contemplation**\n*Current conditions: 4.2°C*\n\nAlong the waterways where bicycles rest,\nThe winter air puts Amsterdam to test...\n\nWeather Data:\n{\n \"current\": {\n \"time\": \"2025-01-23T11:00\",\n \"interval\": 900,\n \"temperature_2m\": 4.2\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Sample Output", "heading_level": 3, "file_order": 52, "section_index": 14, "content_hash": "60066e0e918607a23476b3edf6063436f25f304034d91846a2b182c5b53ef92d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:b931ee60378368db1b84dd78557fd6e7845dfd1936a047ea03b7ede0c5f758b6", "content": "Example showing MCP tools integrated with Spring AI's function calling:\n\n[source,java]\n----\n@RestController\n@RequestMapping(\"/chat\")\npublic class ChatController {\n\n private final ChatModel chatModel;\n private final SyncMcpToolCallbackProvider toolCallbackProvider;\n\n public ChatController(ChatModel chatModel,\n SyncMcpToolCallbackProvider toolCallbackProvider) {\n this.chatModel = chatModel;\n this.toolCallbackProvider = toolCallbackProvider;\n }\n\n @PostMapping\n public ChatResponse chat(@RequestBody ChatRequest request) {\n // Get MCP tools as Spring AI function callbacks\n ToolCallback[] mcpTools = toolCallbackProvider.getToolCallbacks();\n\n // Create prompt with MCP tools\n Prompt prompt = new Prompt(\n request.getMessage(),\n ChatOptionsBuilder.builder()\n .withTools(mcpTools)\n .build()\n );\n\n // Call chat model with MCP tools available\n return chatModel.call(prompt);\n }\n}\n\n@Component\npublic class WeatherTools {\n\n @McpTool(name = \"get-weather\", description = \"Get current weather\")\n public WeatherInfo getWeather(\n @McpToolParam(description = \"City name\", required = true) String city,\n @McpToolParam(description = \"Units (metric/imperial)\", required = false) String units) {\n\n String unit = units != null ? units : \"metric\";\n\n // Call weather API\n return weatherService.getCurrentWeather(city, unit);\n }\n\n @McpTool(name = \"get-forecast\", description = \"Get weather forecast\")\n public ForecastInfo getForecast(\n @McpToolParam(description = \"City name\", required = true) String city,\n @McpToolParam(description = \"Days (1-7)\", required = false) Integer days) {\n\n int forecastDays = days != null ? days : 3;\n\n return weatherService.getForecast(city, forecastDays);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Integration with Spring AI", "heading_level": 2, "file_order": 52, "section_index": 15, "content_hash": "b931ee60378368db1b84dd78557fd6e7845dfd1936a047ea03b7ede0c5f758b6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:ccd2c256e4d7820c9c536af66b5b9946b6e48589e972512047936bdc502bdeec", "content": "* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Overview]\n* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations Reference]\n* xref:api/mcp/mcp-annotations-client.adoc[Client Annotations Reference]\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters Reference]\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol[Spring AI MCP Examples on GitHub]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc", "title": "MCP Annotations Examples", "heading": "Additional Resources", "heading_level": 2, "file_order": 52, "section_index": 16, "content_hash": "ccd2c256e4d7820c9c536af66b5b9946b6e48589e972512047936bdc502bdeec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-examples.adoc"}}
{"id": "sha256:70b35f8eb54ddfe728e351772b06c3e13aa8c94c15e21c90a48def7061e1fe1d", "content": "The Spring AI MCP Annotations module provides annotation-based method handling for link:https://github.com/modelcontextprotocol/spec[Model Context Protocol (MCP)] servers and clients in Java.\nIt simplifies the creation and registration of MCP server methods and client handlers through a clean, declarative approach using Java annotations.\n\n The MCP Annotations enable developers to create and register MCP operation handlers using declarative annotations.\nThis approach simplifies implementing MCP server and client functionality by reducing boilerplate code and improving maintainability.\n\nThis library builds on top of the link:https://github.com/modelcontextprotocol/java-sdk[MCP Java SDK] to provide a higher-level, annotation-based programming model for implementing MCP servers and clients.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "MCP Annotations", "heading_level": 1, "file_order": 53, "section_index": 0, "content_hash": "70b35f8eb54ddfe728e351772b06c3e13aa8c94c15e21c90a48def7061e1fe1d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:1da133906fe56ce299a6d82e7d3e55ef4f450afdfd27e675be0f3af7ff0ab391", "content": "The MCP Annotations module consists of:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Architecture", "heading_level": 2, "file_order": 53, "section_index": 1, "content_hash": "1da133906fe56ce299a6d82e7d3e55ef4f450afdfd27e675be0f3af7ff0ab391", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:e9714f3bbd9889892b7dc89619939b431ce82fbf4a0d442fa1e6c990d5de1cce", "content": "For MCP Servers, the following annotations are provided:\n\n* `@McpTool` - Implements MCP tools with automatic JSON schema generation\n* `@McpResource` - Provides access to resources via URI templates\n* `@McpPrompt` - Generates prompt messages\n* `@McpComplete` - Provides auto-completion functionality", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Server Annotations", "heading_level": 3, "file_order": 53, "section_index": 2, "content_hash": "e9714f3bbd9889892b7dc89619939b431ce82fbf4a0d442fa1e6c990d5de1cce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:f43c015bb6821068fa7ce8b8e858ea5ef8037de12b3d4b4fca5404c253eaf269", "content": "For MCP Clients, the following annotations are provided:\n\n* `@McpLogging` - Handles logging message notifications\n* `@McpSampling` - Handles sampling requests\n* `@McpElicitation` - Handles elicitation requests for gathering additional information\n* `@McpProgress` - Handles progress notifications during long-running operations\n* `@McpToolListChanged` - Handles tool list change notifications\n* `@McpResourceListChanged` - Handles resource list change notifications\n* `@McpPromptListChanged` - Handles prompt list change notifications", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Client Annotations", "heading_level": 3, "file_order": 53, "section_index": 3, "content_hash": "f43c015bb6821068fa7ce8b8e858ea5ef8037de12b3d4b4fca5404c253eaf269", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:9282615bfd82769745589bf39789b3b8b7372d39cecc774a48dcbba4e84264ee", "content": "* `McpSyncRequestContext` - Special parameter type for synchronous operations that provides a unified interface for accessing MCP request context, including the original request, server exchange (for stateful operations), transport context (for stateless operations), and convenient methods for logging, progress, sampling, and elicitation. This parameter is automatically injected and excluded from JSON schema generation. **Supported in Complete, Prompt, Resource, and Tool methods.**\n* `McpAsyncRequestContext` - Special parameter type for asynchronous operations that provides the same unified interface as `McpSyncRequestContext` but with reactive (Mono-based) return types. This parameter is automatically injected and excluded from JSON schema generation. **Supported in Complete, Prompt, Resource, and Tool methods.**\n* `McpTransportContext` - Special parameter type for stateless operations that provides lightweight access to transport-level context without full server exchange functionality. This parameter is automatically injected and excluded from JSON schema generation\n* `@McpProgressToken` - Marks a method parameter to receive the progress token from the request. This parameter is automatically injected and excluded from the generated JSON schema. **Note:** When using `McpSyncRequestContext` or `McpAsyncRequestContext`, the progress token can be accessed via `ctx.request().progressToken()` instead of using this annotation.\n* `McpMeta` - Special parameter type that provides access to metadata from MCP requests, notifications, and results. This parameter is automatically injected and excluded from parameter count limits and JSON schema generation. **Note:** When using `McpSyncRequestContext` or `McpAsyncRequestContext`, metadata can be obtained via `ctx.requestMeta()` instead.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Special Parameters and Annotations", "heading_level": 3, "file_order": 53, "section_index": 4, "content_hash": "9282615bfd82769745589bf39789b3b8b7372d39cecc774a48dcbba4e84264ee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:a5ec1286d3ca21cf6cbe423982321b0c4b6db414822ee5a4c0b29615885d68b7", "content": "Add the MCP annotations dependency to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mcp-annotations</artifactId>\n</dependency>\n----\n\nThe MCP annotations are automatically included when you use any of the MCP Boot Starters:\n\n* `spring-ai-starter-mcp-client`\n* `spring-ai-starter-mcp-client-webflux`\n* `spring-ai-starter-mcp-server`\n* `spring-ai-starter-mcp-server-webflux`\n* `spring-ai-starter-mcp-server-webmvc`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Dependencies", "heading_level": 3, "file_order": 53, "section_index": 5, "content_hash": "a5ec1286d3ca21cf6cbe423982321b0c4b6db414822ee5a4c0b29615885d68b7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:bcfed60eeeac3293c2c047158b1f4553cdbc752f7b6f5dd1436929b63f615938", "content": "The annotation scanning is enabled by default when using the MCP Boot Starters. You can configure the scanning behavior using the following properties:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Configuration", "heading_level": 3, "file_order": 53, "section_index": 6, "content_hash": "bcfed60eeeac3293c2c047158b1f4553cdbc752f7b6f5dd1436929b63f615938", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:aecdde3b86776804c4168d6e6152595a9cfe92b858484bd3b64f2a58418e698f", "content": "[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n annotation-scanner:\n enabled: true # Enable/disable annotation scanning\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Client Annotation Scanner", "heading_level": 4, "file_order": 53, "section_index": 7, "content_hash": "aecdde3b86776804c4168d6e6152595a9cfe92b858484bd3b64f2a58418e698f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:4c4f2252501478ce40a039dee72727a966afa5cb84dd3bef36f5eaa35332a514", "content": "[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n annotation-scanner:\n enabled: true # Enable/disable annotation scanning\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Server Annotation Scanner", "heading_level": 4, "file_order": 53, "section_index": 8, "content_hash": "4c4f2252501478ce40a039dee72727a966afa5cb84dd3bef36f5eaa35332a514", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:f20764c6a9d2f028137544b5cde30f1f7fdefffb73143f5f7a52264c08cc09e3", "content": "Here's a simple example of using MCP annotations to create a calculator tool:\n\n[source,java]\n----\n@Component\npublic class CalculatorTools {\n\n @McpTool(name = \"add\", description = \"Add two numbers together\")\n public int add(\n @McpToolParam(description = \"First number\", required = true) int a,\n @McpToolParam(description = \"Second number\", required = true) int b) {\n return a + b;\n }\n\n @McpTool(name = \"multiply\", description = \"Multiply two numbers\")\n public double multiply(\n @McpToolParam(description = \"First number\", required = true) double x,\n @McpToolParam(description = \"Second number\", required = true) double y) {\n return x * y;\n }\n}\n----\n\nAnd a simple client handler for logging:\n\n[source,java]\n----\n@Component\npublic class LoggingHandler {\n\n @McpLogging(clients = \"my-server\")\n public void handleLoggingMessage(LoggingMessageNotification notification) {\n System.out.println(\"Received log: \" + notification.level() +\n \" - \" + notification.data());\n }\n}\n----\n\nWith Spring Boot auto-configuration, these annotated beans are automatically detected and registered with the MCP server or client.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Quick Example", "heading_level": 2, "file_order": 53, "section_index": 9, "content_hash": "f20764c6a9d2f028137544b5cde30f1f7fdefffb73143f5f7a52264c08cc09e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:dab73e041c855afcca381cf5cb290a9ed96afef320574c9d11a02b87fb8a0925", "content": "* xref:api/mcp/mcp-annotations-client.adoc[Client Annotations] - Detailed guide for client-side annotations\n* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations] - Detailed guide for server-side annotations\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters] - Guide for special parameter types\n* xref:api/mcp/mcp-annotations-examples.adoc[Examples] - Comprehensive examples and use cases", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Documentation", "heading_level": 2, "file_order": 53, "section_index": 10, "content_hash": "dab73e041c855afcca381cf5cb290a9ed96afef320574c9d11a02b87fb8a0925", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:0f1a2a136d71b0556382ac92297d36b3197f5defeff8ce4166c029ba189a9f5f", "content": "* xref:api/mcp/mcp-overview.adoc[MCP Overview]\n* xref:api/mcp/mcp-client-boot-starter-docs.adoc[MCP Client Boot Starter]\n* xref:api/mcp/mcp-server-boot-starter-docs.adoc[MCP Server Boot Starter]\n* link:https://modelcontextprotocol.github.io/specification/[Model Context Protocol Specification]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc", "title": "MCP Annotations", "heading": "Additional Resources", "heading_level": 2, "file_order": 53, "section_index": 11, "content_hash": "0f1a2a136d71b0556382ac92297d36b3197f5defeff8ce4166c029ba189a9f5f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-overview.adoc"}}
{"id": "sha256:2f3767742e3260319544b96c6cb54359088e2b7641faeb588e03b5aacb85fb9e", "content": "The MCP Server Annotations provide a declarative way to implement MCP server functionality using Java annotations.\nThese annotations simplify the creation of tools, resources, prompts, and completion handlers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "MCP Server Annotations", "heading_level": 1, "file_order": 54, "section_index": 0, "content_hash": "2f3767742e3260319544b96c6cb54359088e2b7641faeb588e03b5aacb85fb9e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:0104c537a8ddb55a1ca06c0f43ab8bfcc81677c5b8b2c832b2f02bdafa2f0dcf", "content": "The `@McpTool` annotation marks a method as an MCP tool implementation with automatic JSON schema generation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "@McpTool", "heading_level": 3, "file_order": 54, "section_index": 1, "content_hash": "0104c537a8ddb55a1ca06c0f43ab8bfcc81677c5b8b2c832b2f02bdafa2f0dcf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:8d129d05523a7399e0a3b374055292de07ba02db5da5eeadb0095f3800c32de7", "content": "[source,java]\n----\n@Component\npublic class CalculatorTools {\n\n @McpTool(name = \"add\", description = \"Add two numbers together\")\n public int add(\n @McpToolParam(description = \"First number\", required = true) int a,\n @McpToolParam(description = \"Second number\", required = true) int b) {\n return a + b;\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 54, "section_index": 2, "content_hash": "8d129d05523a7399e0a3b374055292de07ba02db5da5eeadb0095f3800c32de7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:ec853809f8c35b5252b63455b4691c584f47c760341b3712731e2680d8b3d09c", "content": "[source,java]\n----\n@McpTool(name = \"calculate-area\",\n description = \"Calculate the area of a rectangle\",\n annotations = McpTool.McpAnnotations(\n title = \"Rectangle Area Calculator\",\n readOnlyHint = true,\n destructiveHint = false,\n idempotentHint = true\n ))\npublic AreaResult calculateRectangleArea(\n @McpToolParam(description = \"Width\", required = true) double width,\n @McpToolParam(description = \"Height\", required = true) double height) {\n\n return new AreaResult(width * height, \"square units\");\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Advanced Features", "heading_level": 4, "file_order": 54, "section_index": 3, "content_hash": "ec853809f8c35b5252b63455b4691c584f47c760341b3712731e2680d8b3d09c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:5ef97c22706d146f67221fe8560a8769513850ddf5557294f7023dd6b684d8cc", "content": "Tools can access the request context for advanced operations:\n\n[source,java]\n----\n@McpTool(name = \"process-data\", description = \"Process data with request context\")\npublic String processData(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Data to process\", required = true) String data) {\n\n // Send logging notification\n context.info(\"Processing data: \" + data);\n\n // Send progress notification (using convenient method)\n context.progress(p -> p.progress(0.5).total(1.0).message(\"Processing...\"));\n\n // Ping the client\n context.ping();\n\n return \"Processed: \" + data.toUpperCase();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With Request Context", "heading_level": 4, "file_order": 54, "section_index": 4, "content_hash": "5ef97c22706d146f67221fe8560a8769513850ddf5557294f7023dd6b684d8cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:0d117d2c3e6f5131000c66574b26fd1c21e3e94fdfa0422080dacc69276a031d", "content": "Tools can accept `CallToolRequest` for runtime schema handling:\n\n[source,java]\n----\n@McpTool(name = \"flexible-tool\", description = \"Process dynamic schema\")\npublic CallToolResult processDynamic(CallToolRequest request) {\n Map<String, Object> args = request.arguments();\n\n // Process based on runtime schema\n String result = \"Processed \" + args.size() + \" arguments dynamically\";\n\n return CallToolResult.builder()\n .addTextContent(result)\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Dynamic Schema Support", "heading_level": 4, "file_order": 54, "section_index": 5, "content_hash": "0d117d2c3e6f5131000c66574b26fd1c21e3e94fdfa0422080dacc69276a031d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:fb9a15e18041827c5edfe152c1e929c693f37deca00410ed53f8cce259867dfe", "content": "Tools can receive progress tokens for tracking long-running operations:\n\n[source,java]\n----\n@McpTool(name = \"long-task\", description = \"Long-running task with progress\")\npublic String performLongTask(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Task name\", required = true) String taskName) {\n\n // Access progress token from context\n String progressToken = context.request().progressToken();\n\n if (progressToken != null) {\n context.progress(p -> p.progress(0.0).total(1.0).message(\"Starting task\"));\n\n // Perform work...\n\n context.progress(p -> p.progress(1.0).total(1.0).message(\"Task completed\"));\n }\n\n return \"Task \" + taskName + \" completed\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Progress Tracking", "heading_level": 4, "file_order": 54, "section_index": 6, "content_hash": "fb9a15e18041827c5edfe152c1e929c693f37deca00410ed53f8cce259867dfe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:23cff047ff36323a5950fa6d118d954805d32e3691cc273bceaa690150256f48", "content": "The `@McpResource` annotation provides access to resources via URI templates.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "@McpResource", "heading_level": 3, "file_order": 54, "section_index": 7, "content_hash": "23cff047ff36323a5950fa6d118d954805d32e3691cc273bceaa690150256f48", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:d7bfd2a5e0722cba81890217b4c6268e4f3543c1a3ca9d010257ae954daba5bf", "content": "[source,java]\n----\n@Component\npublic class ResourceProvider {\n\n @McpResource(\n uri = \"config://{key}\",\n name = \"Configuration\",\n description = \"Provides configuration data\")\n public String getConfig(String key) {\n return configData.get(key);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 54, "section_index": 8, "content_hash": "d7bfd2a5e0722cba81890217b4c6268e4f3543c1a3ca9d010257ae954daba5bf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:f63d309674f7389daa134db488d61815b7adae7a08e5421ae496a9c24af6ebfe", "content": "[source,java]\n----\n@McpResource(\n uri = \"user-profile://{username}\",\n name = \"User Profile\",\n description = \"Provides user profile information\")\npublic ReadResourceResult getUserProfile(String username) {\n String profileData = loadUserProfile(username);\n\n return new ReadResourceResult(List.of(\n new TextResourceContents(\n \"user-profile://\" + username,\n \"application/json\",\n profileData)\n ));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With ReadResourceResult", "heading_level": 4, "file_order": 54, "section_index": 9, "content_hash": "f63d309674f7389daa134db488d61815b7adae7a08e5421ae496a9c24af6ebfe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:b6860d03367e28813d841d7893e039b1ca068a4cb73cb052b2813f240ac8486e", "content": "[source,java]\n----\n@McpResource(\n uri = \"data://{id}\",\n name = \"Data Resource\",\n description = \"Resource with request context\")\npublic ReadResourceResult getData(\n McpSyncRequestContext context,\n String id) {\n\n // Send logging notification using convenient method\n context.info(\"Accessing resource: \" + id);\n\n // Ping the client\n context.ping();\n\n String data = fetchData(id);\n\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"data://\" + id, \"text/plain\", data)\n ));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With Request Context", "heading_level": 4, "file_order": 54, "section_index": 10, "content_hash": "b6860d03367e28813d841d7893e039b1ca068a4cb73cb052b2813f240ac8486e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:7580e7dea95348e6e18db3f4eb8562e94b95387454cd1865f0df23dc415f1f56", "content": "The `@McpPrompt` annotation generates prompt messages for AI interactions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "@McpPrompt", "heading_level": 3, "file_order": 54, "section_index": 11, "content_hash": "7580e7dea95348e6e18db3f4eb8562e94b95387454cd1865f0df23dc415f1f56", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:2bd1d43091897fcd5cde4ea63f5b01dc0cf52801cee566c4bd9ef0e44c474a81", "content": "[source,java]\n----\n@Component\npublic class PromptProvider {\n\n @McpPrompt(\n name = \"greeting\",\n description = \"Generate a greeting message\")\n public GetPromptResult greeting(\n @McpArg(name = \"name\", description = \"User's name\", required = true)\n String name) {\n\n String message = \"Hello, \" + name + \"! How can I help you today?\";\n\n return new GetPromptResult(\n \"Greeting\",\n List.of(new PromptMessage(Role.ASSISTANT, new TextContent(message)))\n );\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 54, "section_index": 12, "content_hash": "2bd1d43091897fcd5cde4ea63f5b01dc0cf52801cee566c4bd9ef0e44c474a81", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:e2c4d9ffcd7c60c28c78ec42514b2813c1dc9bfcd69f902e529d661a75ff4c2b", "content": "[source,java]\n----\n@McpPrompt(\n name = \"personalized-message\",\n description = \"Generate a personalized message\")\npublic GetPromptResult personalizedMessage(\n @McpArg(name = \"name\", required = true) String name,\n @McpArg(name = \"age\", required = false) Integer age,\n @McpArg(name = \"interests\", required = false) String interests) {\n\n StringBuilder message = new StringBuilder();\n message.append(\"Hello, \").append(name).append(\"!\\n\\n\");\n\n if (age != null) {\n message.append(\"At \").append(age).append(\" years old, \");\n // Add age-specific content\n }\n\n if (interests != null && !interests.isEmpty()) {\n message.append(\"Your interest in \").append(interests);\n // Add interest-specific content\n }\n\n return new GetPromptResult(\n \"Personalized Message\",\n List.of(new PromptMessage(Role.ASSISTANT, new TextContent(message.toString())))\n );\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With Optional Arguments", "heading_level": 4, "file_order": 54, "section_index": 13, "content_hash": "e2c4d9ffcd7c60c28c78ec42514b2813c1dc9bfcd69f902e529d661a75ff4c2b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:a3f9736a120854138460e2366e190ab9b39f109179b9b4bcd34321def83cb349", "content": "The `@McpComplete` annotation provides auto-completion functionality for prompts.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "@McpComplete", "heading_level": 3, "file_order": 54, "section_index": 14, "content_hash": "a3f9736a120854138460e2366e190ab9b39f109179b9b4bcd34321def83cb349", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:f1bb1ba12149f2001f40d237b8f8a74ec55b3339f68cc60c3eac336649acafd4", "content": "[source,java]\n----\n@Component\npublic class CompletionProvider {\n\n @McpComplete(prompt = \"city-search\")\n public List<String> completeCityName(String prefix) {\n return cities.stream()\n .filter(city -> city.toLowerCase().startsWith(prefix.toLowerCase()))\n .limit(10)\n .toList();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Basic Usage", "heading_level": 4, "file_order": 54, "section_index": 15, "content_hash": "f1bb1ba12149f2001f40d237b8f8a74ec55b3339f68cc60c3eac336649acafd4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:afe5ac64c4da02b5ca2b4b54264d1b5fb16770156ca766d2215185d744d6c006", "content": "[source,java]\n----\n@McpComplete(prompt = \"travel-planner\")\npublic List<String> completeTravelDestination(CompleteRequest.CompleteArgument argument) {\n String prefix = argument.value().toLowerCase();\n String argumentName = argument.name();\n\n // Different completions based on argument name\n if (\"city\".equals(argumentName)) {\n return completeCities(prefix);\n } else if (\"country\".equals(argumentName)) {\n return completeCountries(prefix);\n }\n\n return List.of();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With CompleteRequest.CompleteArgument", "heading_level": 4, "file_order": 54, "section_index": 16, "content_hash": "afe5ac64c4da02b5ca2b4b54264d1b5fb16770156ca766d2215185d744d6c006", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:a3a366139223370b20532cef7aeb10d8b522aa0a728439e06a49c34ddca57678", "content": "[source,java]\n----\n@McpComplete(prompt = \"code-completion\")\npublic CompleteResult completeCode(String prefix) {\n List<String> completions = generateCodeCompletions(prefix);\n\n return new CompleteResult(\n new CompleteResult.CompleteCompletion(\n completions,\n completions.size(), // total\n hasMoreCompletions // hasMore flag\n )\n );\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "With CompleteResult", "heading_level": 4, "file_order": 54, "section_index": 17, "content_hash": "a3a366139223370b20532cef7aeb10d8b522aa0a728439e06a49c34ddca57678", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:afdf7ab73a402352d6c4b095328da3acf892258e92d2201e7d98b536fe4b81a9", "content": "Use `McpSyncRequestContext` or `McpAsyncRequestContext` for a unified interface that works with both stateful and stateless operations:\n\n[source,java]\n----\npublic record UserInfo(String name, String email, int age) {}\n\n@McpTool(name = \"unified-tool\", description = \"Tool with unified request context\")\npublic String unifiedTool(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n\n // Access request and metadata\n String progressToken = context.request().progressToken();\n\n // Logging with convenient methods\n context.info(\"Processing: \" + input);\n\n // Progress notifications (Note client should set a progress token\n // with its request to be able to receive progress updates)\n context.progress(50); // Simple percentage\n\n // Ping client\n context.ping();\n\n // Check capabilities before using\n if (context.elicitEnabled()) {\n // Request user input (only in stateful mode)\n StructuredElicitResult<UserInfo> elicitResult = context.elicit(UserInfo.class);\n if (elicitResult.action() == ElicitResult.Action.ACCEPT) {\n // Use elicited data\n }\n }\n\n if (context.sampleEnabled()) {\n // Request LLM sampling (only in stateful mode)\n CreateMessageResult samplingResult = context.sample(\"Generate response\");\n // Use sampling result\n }\n\n return \"Processed with unified context\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Unified Request Context (Recommended)", "heading_level": 3, "file_order": 54, "section_index": 18, "content_hash": "afdf7ab73a402352d6c4b095328da3acf892258e92d2201e7d98b536fe4b81a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:164127f02bd4dce56d8290ad1a27bafef7244124b4ea30d34048cbbf12e4093a", "content": "For simple operations, you can omit context parameters entirely:\n\n[source,java]\n----\n@McpTool(name = \"simple-add\", description = \"Simple addition\")\npublic int simpleAdd(\n @McpToolParam(description = \"First number\", required = true) int a,\n @McpToolParam(description = \"Second number\", required = true) int b) {\n return a + b;\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Simple Operations (No Context)", "heading_level": 3, "file_order": 54, "section_index": 19, "content_hash": "164127f02bd4dce56d8290ad1a27bafef7244124b4ea30d34048cbbf12e4093a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:5882b311c3af19d0cb396a1c61ae7697140901beb112539724bff7a4898ef292", "content": "For stateless operations where you need minimal transport context:\n\n[source,java]\n----\n@McpTool(name = \"stateless-tool\", description = \"Stateless with transport context\")\npublic String statelessTool(\n McpTransportContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n // Access transport-level context only\n // No bidirectional operations (roots, elicitation, sampling)\n return \"Processed: \" + input;\n}\n----\n\n[IMPORTANT]\n**Stateless servers do not support bidirectional operations:**\n\nTherefore methods using `McpSyncRequestContext` or `McpAsyncRequestContext` in stateless mode are ignored.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Lightweight Stateless (with McpTransportContext)", "heading_level": 3, "file_order": 54, "section_index": 20, "content_hash": "5882b311c3af19d0cb396a1c61ae7697140901beb112539724bff7a4898ef292", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:a88423d9a948fcf2146f752ab1299d746cb41be5af18cfedbb4dac8845a6a2d5", "content": "The MCP annotations framework automatically filters annotated methods based on the server type and method characteristics. This ensures that only appropriate methods are registered for each server configuration.\nA warning is logged for each filtered method to help with debugging.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Method Filtering by Server Type", "heading_level": 2, "file_order": 54, "section_index": 21, "content_hash": "a88423d9a948fcf2146f752ab1299d746cb41be5af18cfedbb4dac8845a6a2d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:f1ab122fcef6f5dc83af7c6493f7ddb528b89805730db8094da7dab50643868f", "content": "Synchronous servers (configured with `spring.ai.mcp.server.type=SYNC`) use synchronous providers that:\n\n* **Accept** methods with non-reactive return types:\n - Primitive types (`int`, `double`, `boolean`)\n - Object types (`String`, `Integer`, custom POJOs)\n - MCP types (`CallToolResult`, `ReadResourceResult`, `GetPromptResult`, `CompleteResult`)\n - Collections (`List<String>`, `Map<String, Object>`)\n\n* **Filter out** methods with reactive return types:\n - `Mono<T>`\n - `Flux<T>`\n - `Publisher<T>`\n\n[source,java]\n----\n@Component\npublic class SyncTools {\n\n @McpTool(name = \"sync-tool\", description = \"Synchronous tool\")\n public String syncTool(String input) {\n // This method WILL be registered on sync servers\n return \"Processed: \" + input;\n }\n\n @McpTool(name = \"async-tool\", description = \"Async tool\")\n public Mono<String> asyncTool(String input) {\n // This method will be FILTERED OUT on sync servers\n // A warning will be logged\n return Mono.just(\"Processed: \" + input);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Synchronous Servers", "heading_level": 4, "file_order": 54, "section_index": 22, "content_hash": "f1ab122fcef6f5dc83af7c6493f7ddb528b89805730db8094da7dab50643868f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:fd27f1f49368f18e1e1a5a90e19006892ff19b7aeb394af19acea0f26f70d966", "content": "Asynchronous servers (configured with `spring.ai.mcp.server.type=ASYNC`) use asynchronous providers that:\n\n* **Accept** methods with reactive return types:\n - `Mono<T>` (for single results)\n - `Flux<T>` (for streaming results)\n - `Publisher<T>` (generic reactive type)\n\n* **Filter out** methods with non-reactive return types:\n - Primitive types\n - Object types\n - Collections\n - MCP result types\n\n[source,java]\n----\n@Component\npublic class AsyncTools {\n\n @McpTool(name = \"async-tool\", description = \"Async tool\")\n public Mono<String> asyncTool(String input) {\n // This method WILL be registered on async servers\n return Mono.just(\"Processed: \" + input);\n }\n\n @McpTool(name = \"sync-tool\", description = \"Sync tool\")\n public String syncTool(String input) {\n // This method will be FILTERED OUT on async servers\n // A warning will be logged\n return \"Processed: \" + input;\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Asynchronous Servers", "heading_level": 4, "file_order": 54, "section_index": 23, "content_hash": "fd27f1f49368f18e1e1a5a90e19006892ff19b7aeb394af19acea0f26f70d966", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:98ce2a0ebf98fbc28a5df2db18721b4e03177aaa9e4afb9de9833d756b63255b", "content": "Stateful servers support bidirectional communication and accept methods with:\n\n* **Bidirectional context parameters**:\n - `McpSyncRequestContext` (for sync operations)\n - `McpAsyncRequestContext` (for async operations)\n - `McpSyncServerExchange` (legacy, for sync operations)\n - `McpAsyncServerExchange` (legacy, for async operations)\n\n* Support for bidirectional operations:\n - `roots()` - Access root directories\n - `elicit()` - Request user input\n - `sample()` - Request LLM sampling\n\n[source,java]\n----\n@Component\npublic class StatefulTools {\n\n @McpTool(name = \"interactive-tool\", description = \"Tool with bidirectional operations\")\n public String interactiveTool(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n\n // This method WILL be registered on stateful servers\n // Can use elicitation, sampling, roots\n if (context.sampleEnabled()) {\n var samplingResult = context.sample(\"Generate response\");\n // Process sampling result...\n }\n\n return \"Processed with context\";\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Stateful Servers", "heading_level": 4, "file_order": 54, "section_index": 24, "content_hash": "98ce2a0ebf98fbc28a5df2db18721b4e03177aaa9e4afb9de9833d756b63255b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:cbae01d566dbf25999a7d6980bd6b09d48685e59b7081f94b29c1dd6172f52b6", "content": "Stateless servers are optimized for simple request-response patterns and:\n\n* **Filter out** methods with bidirectional context parameters:\n - Methods with `McpSyncRequestContext` are skipped\n - Methods with `McpAsyncRequestContext` are skipped\n - Methods with `McpSyncServerExchange` are skipped\n - Methods with `McpAsyncServerExchange` are skipped\n - A warning is logged for each filtered method\n\n* **Accept** methods with:\n - `McpTransportContext` (lightweight stateless context)\n - No context parameter at all\n - Only regular `@McpToolParam` parameters\n\n* Do **not** support bidirectional operations:\n - `roots()` - Not available\n - `elicit()` - Not available\n - `sample()` - Not available\n\n[source,java]\n----\n@Component\npublic class StatelessTools {\n\n @McpTool(name = \"simple-tool\", description = \"Simple stateless tool\")\n public String simpleTool(@McpToolParam(description = \"Input\") String input) {\n // This method WILL be registered on stateless servers\n return \"Processed: \" + input;\n }\n\n @McpTool(name = \"context-tool\", description = \"Tool with transport context\")\n public String contextTool(\n McpTransportContext context,\n @McpToolParam(description = \"Input\") String input) {\n // This method WILL be registered on stateless servers\n return \"Processed: \" + input;\n }\n\n @McpTool(name = \"bidirectional-tool\", description = \"Tool with bidirectional context\")\n public String bidirectionalTool(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Input\") String input) {\n // This method will be FILTERED OUT on stateless servers\n // A warning will be logged\n return \"Processed with sampling\";\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Stateless Servers", "heading_level": 4, "file_order": 54, "section_index": 25, "content_hash": "cbae01d566dbf25999a7d6980bd6b09d48685e59b7081f94b29c1dd6172f52b6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:9afec340256b61fb08b7c0b2aa9b75a59f2308fa3e00cef82339d8110709c658", "content": "[cols=\"1,2,2\"]\n|===\n|Server Type |Accepted Methods |Filtered Methods\n\n|**Sync Stateful**\n|Non-reactive returns + bidirectional context\n|Reactive returns (Mono/Flux)\n\n|**Async Stateful**\n|Reactive returns (Mono/Flux) + bidirectional context\n|Non-reactive returns\n\n|**Sync Stateless**\n|Non-reactive returns + no bidirectional context\n|Reactive returns OR bidirectional context parameters\n\n|**Async Stateless**\n|Reactive returns (Mono/Flux) + no bidirectional context\n|Non-reactive returns OR bidirectional context parameters\n|===\n\n[TIP]\n**Best Practices for Method Filtering:**\n\n1. **Keep methods aligned** with your server type - use sync methods for sync servers, async for async servers\n2. **Separate stateful and stateless** implementations into different classes for clarity\n3. **Check logs** during startup for filtered method warnings\n4. **Use the right context** - `McpSyncRequestContext`/`McpAsyncRequestContext` for stateful, `McpTransportContext` for stateless\n5. **Test both modes** if you support both stateful and stateless deployments", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Filtering Summary", "heading_level": 3, "file_order": 54, "section_index": 26, "content_hash": "9afec340256b61fb08b7c0b2aa9b75a59f2308fa3e00cef82339d8110709c658", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:8fe5dca814b41625e044948cb114a9465523eaf9114b2b2ab52bff213c502ec2", "content": "All server annotations support asynchronous implementations using Reactor:\n\n[source,java]\n----\n@Component\npublic class AsyncTools {\n\n @McpTool(name = \"async-fetch\", description = \"Fetch data asynchronously\")\n public Mono<String> asyncFetch(\n @McpToolParam(description = \"URL\", required = true) String url) {\n\n return Mono.fromCallable(() -> {\n // Simulate async operation\n return fetchFromUrl(url);\n }).subscribeOn(Schedulers.boundedElastic());\n }\n\n @McpResource(uri = \"async-data://{id}\", name = \"Async Data\")\n public Mono<ReadResourceResult> asyncResource(String id) {\n return Mono.fromCallable(() -> {\n String data = loadData(id);\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"async-data://\" + id, \"text/plain\", data)\n ));\n }).delayElements(Duration.ofMillis(100));\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Async Support", "heading_level": 2, "file_order": 54, "section_index": 27, "content_hash": "8fe5dca814b41625e044948cb114a9465523eaf9114b2b2ab52bff213c502ec2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:e34d9303aac059c7ff13763ddaf142836e0a9c09b9a2e5540af8b461aaa0594e", "content": "With Spring Boot auto-configuration, annotated beans are automatically detected and registered:\n\n[source,java]\n----\n@SpringBootApplication\npublic class McpServerApplication {\n public static void main(String[] args) {\n SpringApplication.run(McpServerApplication.class, args);\n }\n}\n\n@Component\npublic class MyMcpTools {\n // Your @McpTool annotated methods\n}\n\n@Component\npublic class MyMcpResources {\n // Your @McpResource annotated methods\n}\n----\n\nThe auto-configuration will:\n\n1. Scan for beans with MCP annotations\n2. Create appropriate specifications\n3. Register them with the MCP server\n4. Handle both sync and async implementations based on configuration", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Spring Boot Integration", "heading_level": 2, "file_order": 54, "section_index": 28, "content_hash": "e34d9303aac059c7ff13763ddaf142836e0a9c09b9a2e5540af8b461aaa0594e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:ecb6f2dc829ec2132de8e9cff7292f7f7a20636f216bf28302faca5d601c39fb", "content": "Configure the server annotation scanner:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n type: SYNC # or ASYNC\n annotation-scanner:\n enabled: true\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Configuration Properties", "heading_level": 2, "file_order": 54, "section_index": 29, "content_hash": "ecb6f2dc829ec2132de8e9cff7292f7f7a20636f216bf28302faca5d601c39fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:003bd6f655b3c6c9c77231dd572f51b262479ae94457d20456f9b2eab0e841bc", "content": "* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Overview]\n* xref:api/mcp/mcp-annotations-client.adoc[Client Annotations]\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters]\n* xref:api/mcp/mcp-server-boot-starter-docs.adoc[MCP Server Boot Starter]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc", "title": "MCP Server Annotations", "heading": "Additional Resources", "heading_level": 2, "file_order": 54, "section_index": 30, "content_hash": "003bd6f655b3c6c9c77231dd572f51b262479ae94457d20456f9b2eab0e841bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-server.adoc"}}
{"id": "sha256:183c4caee7155f5c8a8e649c627bbd03a1138eee330c5df0e069cd0378476fdf", "content": "The MCP Annotations support several special parameter types that provide additional context and functionality to annotated methods.\nThese parameters are automatically injected by the framework and are excluded from JSON schema generation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "MCP Annotations Special Parameters", "heading_level": 1, "file_order": 55, "section_index": 0, "content_hash": "183c4caee7155f5c8a8e649c627bbd03a1138eee330c5df0e069cd0378476fdf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:f0acd5f0851807aa58a717de50c0b427ac1c122f3f01eb9a844328f22f6ae675", "content": "The `McpMeta` class provides access to metadata from MCP requests, notifications, and results.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "McpMeta", "heading_level": 3, "file_order": 55, "section_index": 1, "content_hash": "f0acd5f0851807aa58a717de50c0b427ac1c122f3f01eb9a844328f22f6ae675", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:db3ed201cbc5324f0cd6d25c274614322466df9724a562d5a783a1da5be8c56b", "content": "* Automatically injected when used as a method parameter\n* Excluded from parameter count limits and JSON schema generation\n* Provides convenient access to metadata through the `get(String key)` method\n* If no metadata is present in the request, an empty `McpMeta` object is injected", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Overview", "heading_level": 4, "file_order": 55, "section_index": 2, "content_hash": "db3ed201cbc5324f0cd6d25c274614322466df9724a562d5a783a1da5be8c56b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:2a27622950e76d6e4d0fcbb25fcd4a2d430bd22bb87a3b2fde1eef847a624578", "content": "[source,java]\n----\n@McpTool(name = \"contextual-tool\", description = \"Tool with metadata access\")\npublic String processWithContext(\n @McpToolParam(description = \"Input data\", required = true) String data,\n McpMeta meta) {\n\n // Access metadata from the request\n String userId = (String) meta.get(\"userId\");\n String sessionId = (String) meta.get(\"sessionId\");\n String userRole = (String) meta.get(\"userRole\");\n\n // Use metadata to customize behavior\n if (\"admin\".equals(userRole)) {\n return processAsAdmin(data, userId);\n } else {\n return processAsUser(data, userId);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage in Tools", "heading_level": 4, "file_order": 55, "section_index": 3, "content_hash": "2a27622950e76d6e4d0fcbb25fcd4a2d430bd22bb87a3b2fde1eef847a624578", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:95c427707ac878ea9f5babe1e57bdb97b00fb523e0ef11beb275fdd2e4cd93fd", "content": "[source,java]\n----\n@McpResource(uri = \"secure-data://{id}\", name = \"Secure Data\")\npublic ReadResourceResult getSecureData(String id, McpMeta meta) {\n\n String requestingUser = (String) meta.get(\"requestingUser\");\n String accessLevel = (String) meta.get(\"accessLevel\");\n\n // Check access permissions using metadata\n if (!\"admin\".equals(accessLevel)) {\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"secure-data://\" + id,\n \"text/plain\", \"Access denied\")\n ));\n }\n\n String data = loadSecureData(id);\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"secure-data://\" + id,\n \"text/plain\", data)\n ));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage in Resources", "heading_level": 4, "file_order": 55, "section_index": 4, "content_hash": "95c427707ac878ea9f5babe1e57bdb97b00fb523e0ef11beb275fdd2e4cd93fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:db65ea625da26924402fc257168882ff076dc5749aed1e47a472c7c7e1ee1012", "content": "[source,java]\n----\n@McpPrompt(name = \"localized-prompt\", description = \"Localized prompt generation\")\npublic GetPromptResult localizedPrompt(\n @McpArg(name = \"topic\", required = true) String topic,\n McpMeta meta) {\n\n String language = (String) meta.get(\"language\");\n String region = (String) meta.get(\"region\");\n\n // Generate localized content based on metadata\n String message = generateLocalizedMessage(topic, language, region);\n\n return new GetPromptResult(\"Localized Prompt\",\n List.of(new PromptMessage(Role.ASSISTANT, new TextContent(message)))\n );\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage in Prompts", "heading_level": 4, "file_order": 55, "section_index": 5, "content_hash": "db65ea625da26924402fc257168882ff076dc5749aed1e47a472c7c7e1ee1012", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:f45ebc2596e28a154f52708f245feb3826fad943d43a083e9a38cd7ca5fad80b", "content": "The `@McpProgressToken` annotation marks a parameter to receive progress tokens from MCP requests.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "@McpProgressToken", "heading_level": 3, "file_order": 55, "section_index": 6, "content_hash": "f45ebc2596e28a154f52708f245feb3826fad943d43a083e9a38cd7ca5fad80b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:87bfcf93439ea696dacb2a2f714027516fa13dbb18c74baa768602c7447d5cbf", "content": "* Parameter type should be `String`\n* Automatically receives the progress token value from the request\n* Excluded from the generated JSON schema\n* If no progress token is present, `null` is injected\n* Used for tracking long-running operations", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Overview", "heading_level": 4, "file_order": 55, "section_index": 7, "content_hash": "87bfcf93439ea696dacb2a2f714027516fa13dbb18c74baa768602c7447d5cbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:325e2e3426c4ea790954039555969de4bfc1d633e51e5270cd79a6989f08466f", "content": "[source,java]\n----\n@McpTool(name = \"long-operation\", description = \"Long-running operation with progress\")\npublic String performLongOperation(\n @McpProgressToken String progressToken,\n @McpToolParam(description = \"Operation name\", required = true) String operation,\n @McpToolParam(description = \"Duration in seconds\", required = true) int duration,\n McpSyncServerExchange exchange) {\n\n if (progressToken != null) {\n // Send initial progress\n exchange.progressNotification(new ProgressNotification(\n progressToken, 0.0, 1.0, \"Starting \" + operation));\n\n // Simulate work with progress updates\n for (int i = 1; i <= duration; i++) {\n Thread.sleep(1000);\n double progress = (double) i / duration;\n\n exchange.progressNotification(new ProgressNotification(\n progressToken, progress, 1.0,\n String.format(\"Processing... %d%%\", (int)(progress * 100))));\n }\n }\n\n return \"Operation \" + operation + \" completed\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage in Tools", "heading_level": 4, "file_order": 55, "section_index": 8, "content_hash": "325e2e3426c4ea790954039555969de4bfc1d633e51e5270cd79a6989f08466f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:5630a5136672513c49c7b56f224d33958d846e103f6c3f79f87d7d89cc37b84f", "content": "[source,java]\n----\n@McpResource(uri = \"large-file://{path}\", name = \"Large File Resource\")\npublic ReadResourceResult getLargeFile(\n @McpProgressToken String progressToken,\n String path,\n McpSyncServerExchange exchange) {\n\n File file = new File(path);\n long fileSize = file.length();\n\n if (progressToken != null) {\n // Track file reading progress\n exchange.progressNotification(new ProgressNotification(\n progressToken, 0.0, fileSize, \"Reading file\"));\n }\n\n String content = readFileWithProgress(file, progressToken, exchange);\n\n if (progressToken != null) {\n exchange.progressNotification(new ProgressNotification(\n progressToken, fileSize, fileSize, \"File read complete\"));\n }\n\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"large-file://\" + path, \"text/plain\", content)\n ));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage in Resources", "heading_level": 4, "file_order": 55, "section_index": 9, "content_hash": "5630a5136672513c49c7b56f224d33958d846e103f6c3f79f87d7d89cc37b84f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:f76e4d6c266970fba14e7af31e368745f520224105f2ac2dcabe5e329873c9ff", "content": "Request context objects provide unified access to MCP request information and server-side operations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "McpSyncRequestContext / McpAsyncRequestContext", "heading_level": 3, "file_order": 55, "section_index": 10, "content_hash": "f76e4d6c266970fba14e7af31e368745f520224105f2ac2dcabe5e329873c9ff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:c2420db8c4faf370959b23263f0f454a059c8d337af2f8a38df866501fe5cef4", "content": "* Provides unified interface for both stateful and stateless operations\n* Automatically injected when used as a parameter\n* Excluded from JSON schema generation\n* Enables advanced features like logging, progress notifications, sampling, and elicitation\n* Works with both stateful (server exchange) and stateless (transport context) modes", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Overview", "heading_level": 4, "file_order": 55, "section_index": 11, "content_hash": "c2420db8c4faf370959b23263f0f454a059c8d337af2f8a38df866501fe5cef4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:b2b4d7bdb9808a9e473bda79c7b25e01724da0b51a73672636d4e01c2e9f6202", "content": "[source,java]\n----\npublic record UserInfo(String name, String email, int age) {}\n\n@McpTool(name = \"advanced-tool\", description = \"Tool with full server capabilities\")\npublic String advancedTool(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n\n // Send logging notification\n context.info(\"Processing: \" + input);\n\n // Ping the client\n context.ping();\n\n // Send progress updates\n context.progress(50); // 50% complete\n\n // Check if elicitation is supported before using it\n if (context.elicitEnabled()) {\n // Request additional information from user\n StructuredElicitResult<UserInfo> elicitResult = context.elicit(\n e -> e.message(\"Need additional information\"),\n UserInfo.class\n );\n\n if (elicitResult.action() == ElicitResult.Action.ACCEPT) {\n UserInfo userInfo = elicitResult.structuredContent();\n // Use the user information\n }\n }\n\n // Check if sampling is supported before using it\n if (context.sampleEnabled()) {\n // Request LLM sampling\n CreateMessageResult samplingResult = context.sample(\n s -> s.message(\"Process: \" + input)\n .modelPreferences(pref -> pref.modelHints(\"gpt-4\"))\n );\n }\n\n return \"Processed with advanced features\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "McpSyncRequestContext Features", "heading_level": 4, "file_order": 55, "section_index": 12, "content_hash": "b2b4d7bdb9808a9e473bda79c7b25e01724da0b51a73672636d4e01c2e9f6202", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:981cb15828914e69a2d132eaefc7af405fc59d02fdca9d9f9025f3296875420a", "content": "[source,java]\n----\npublic record UserInfo(String name, String email, int age) {}\n\n@McpTool(name = \"async-advanced-tool\", description = \"Async tool with server capabilities\")\npublic Mono<String> asyncAdvancedTool(\n McpAsyncRequestContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n\n return context.info(\"Async processing: \" + input)\n .then(context.progress(25))\n .then(context.ping())\n .flatMap(v -> {\n // Perform elicitation if supported\n if (context.elicitEnabled()) {\n return context.elicitation(UserInfo.class)\n .map(userInfo -> \"Processing for user: \" + userInfo.name());\n }\n return Mono.just(\"Processing...\");\n })\n .flatMap(msg -> {\n // Perform sampling if supported\n if (context.sampleEnabled()) {\n return context.sampling(\"Process: \" + input)\n .map(result -> \"Completed: \" + result);\n }\n return Mono.just(\"Completed: \" + msg);\n });\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "McpAsyncRequestContext Features", "heading_level": 4, "file_order": 55, "section_index": 13, "content_hash": "981cb15828914e69a2d132eaefc7af405fc59d02fdca9d9f9025f3296875420a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:3254f48a2464aea4676b86e882d174542ba8ebe6f8a89be77ab2a1beb8a7ceb3", "content": "Lightweight context for stateless operations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "McpTransportContext", "heading_level": 3, "file_order": 55, "section_index": 14, "content_hash": "3254f48a2464aea4676b86e882d174542ba8ebe6f8a89be77ab2a1beb8a7ceb3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:6a5995dbe9d73bfe976d3b15cc16ee8a68f04f13cefbe08f90d2073ee4d54936", "content": "* Provides minimal context without full server exchange\n* Used in stateless implementations\n* Automatically injected when used as a parameter\n* Excluded from JSON schema generation", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Overview", "heading_level": 4, "file_order": 55, "section_index": 15, "content_hash": "6a5995dbe9d73bfe976d3b15cc16ee8a68f04f13cefbe08f90d2073ee4d54936", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:509ff99dd76c1abc70f53b1e811dad30847bf56a034bdd296edcd212b0d47f41", "content": "[source,java]\n----\n@McpTool(name = \"stateless-tool\", description = \"Stateless tool with context\")\npublic String statelessTool(\n McpTransportContext context,\n @McpToolParam(description = \"Input\", required = true) String input) {\n\n // Limited context access\n // Useful for transport-level operations\n\n return \"Processed in stateless mode: \" + input;\n}\n\n@McpResource(uri = \"stateless://{id}\", name = \"Stateless Resource\")\npublic ReadResourceResult statelessResource(\n McpTransportContext context,\n String id) {\n\n // Access transport context if needed\n String data = loadData(id);\n\n return new ReadResourceResult(List.of(\n new TextResourceContents(\"stateless://\" + id, \"text/plain\", data)\n ));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage Example", "heading_level": 4, "file_order": 55, "section_index": 16, "content_hash": "509ff99dd76c1abc70f53b1e811dad30847bf56a034bdd296edcd212b0d47f41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:b0aee5fb41de020620e2849594b846f56f2c9becc0aa73ff14d7260553783dae", "content": "Special parameter for tools that need access to the full request with dynamic schema.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "CallToolRequest", "heading_level": 3, "file_order": 55, "section_index": 17, "content_hash": "b0aee5fb41de020620e2849594b846f56f2c9becc0aa73ff14d7260553783dae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:25c12d1be1ed5d7e736c84d594ed43a2c2dca38e44814d8c82c1b6c6ac2c975a", "content": "* Provides access to the complete tool request\n* Enables dynamic schema handling at runtime\n* Automatically injected and excluded from schema generation\n* Useful for flexible tools that adapt to different input schemas", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Overview", "heading_level": 4, "file_order": 55, "section_index": 18, "content_hash": "25c12d1be1ed5d7e736c84d594ed43a2c2dca38e44814d8c82c1b6c6ac2c975a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:f0f39bc2664d9a4e583eab8f5bdbd5c603505bf268a96f0e855db0d3affbf4e2", "content": "[source,java]\n----\n@McpTool(name = \"dynamic-tool\", description = \"Tool with dynamic schema support\")\npublic CallToolResult processDynamicSchema(CallToolRequest request) {\n Map<String, Object> args = request.arguments();\n\n // Process based on whatever schema was provided at runtime\n StringBuilder result = new StringBuilder(\"Processed:\\n\");\n\n for (Map.Entry<String, Object> entry : args.entrySet()) {\n result.append(\" \").append(entry.getKey())\n .append(\": \").append(entry.getValue()).append(\"\\n\");\n }\n\n return CallToolResult.builder()\n .addTextContent(result.toString())\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Usage Examples", "heading_level": 4, "file_order": 55, "section_index": 19, "content_hash": "f0f39bc2664d9a4e583eab8f5bdbd5c603505bf268a96f0e855db0d3affbf4e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:bf926d60b58b7e27111a2889e8fa95409039e0bf49a18c2c4d8fe74f87e58e6b", "content": "[source,java]\n----\n@McpTool(name = \"hybrid-tool\", description = \"Tool with typed and dynamic parameters\")\npublic String processHybrid(\n @McpToolParam(description = \"Operation\", required = true) String operation,\n @McpToolParam(description = \"Priority\", required = false) Integer priority,\n CallToolRequest request) {\n\n // Use typed parameters for known fields\n String result = \"Operation: \" + operation;\n if (priority != null) {\n result += \" (Priority: \" + priority + \")\";\n }\n\n // Access additional dynamic arguments\n Map<String, Object> allArgs = request.arguments();\n\n // Remove known parameters to get only additional ones\n Map<String, Object> additionalArgs = new HashMap<>(allArgs);\n additionalArgs.remove(\"operation\");\n additionalArgs.remove(\"priority\");\n\n if (!additionalArgs.isEmpty()) {\n result += \" with \" + additionalArgs.size() + \" additional parameters\";\n }\n\n return result;\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Mixed Parameters", "heading_level": 4, "file_order": 55, "section_index": 20, "content_hash": "bf926d60b58b7e27111a2889e8fa95409039e0bf49a18c2c4d8fe74f87e58e6b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:c1fd8920a1080403ed15623ecd369005f21f6a948199dcf53e9c7dceda9bb789", "content": "[source,java]\n----\n@McpTool(name = \"flexible-with-progress\", description = \"Flexible tool with progress\")\npublic CallToolResult flexibleWithProgress(\n @McpProgressToken String progressToken,\n CallToolRequest request,\n McpSyncServerExchange exchange) {\n\n Map<String, Object> args = request.arguments();\n\n if (progressToken != null) {\n exchange.progressNotification(new ProgressNotification(\n progressToken, 0.0, 1.0, \"Processing dynamic request\"));\n }\n\n // Process dynamic arguments\n String result = processDynamicArgs(args);\n\n if (progressToken != null) {\n exchange.progressNotification(new ProgressNotification(\n progressToken, 1.0, 1.0, \"Complete\"));\n }\n\n return CallToolResult.builder()\n .addTextContent(result)\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "With Progress Token", "heading_level": 4, "file_order": 55, "section_index": 21, "content_hash": "c1fd8920a1080403ed15623ecd369005f21f6a948199dcf53e9c7dceda9bb789", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:3fd53e26b2c807ec7fd81fa0ca81dbfcc163e10c530c1ea0eb8d3aea80e5f7ad", "content": "The following parameters are automatically injected by the framework:\n\n1. `McpMeta` - Metadata from the request\n2. `@McpProgressToken String` - Progress token if available\n3. `McpSyncServerExchange` / `McpAsyncServerExchange` - Server exchange context\n4. `McpTransportContext` - Transport context for stateless operations\n5. `CallToolRequest` - Full tool request for dynamic schema", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Automatic Injection", "heading_level": 3, "file_order": 55, "section_index": 22, "content_hash": "3fd53e26b2c807ec7fd81fa0ca81dbfcc163e10c530c1ea0eb8d3aea80e5f7ad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:af4f474f5789d4d60152b004bd92f9d40018135134270cf5ac92b70b0aa9df1a", "content": "Special parameters are excluded from JSON schema generation:\n\n* They don't appear in the tool's input schema\n* They don't count towards parameter limits\n* They're not visible to MCP clients", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Schema Generation", "heading_level": 3, "file_order": 55, "section_index": 23, "content_hash": "af4f474f5789d4d60152b004bd92f9d40018135134270cf5ac92b70b0aa9df1a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:fdafac82617d13592467c01e9ff918572b087a1f63f533aeade353cf71f44e3b", "content": "* `McpMeta` - Never null, empty object if no metadata\n* `@McpProgressToken` - Can be null if no token provided\n* Server exchanges - Never null when properly configured\n* `CallToolRequest` - Never null for tool methods", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Null Handling", "heading_level": 3, "file_order": 55, "section_index": 24, "content_hash": "fdafac82617d13592467c01e9ff918572b087a1f63f533aeade353cf71f44e3b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:7321b44245ce7c9368f49deb47f4c2d4553762d0ede3993c430885f8d52f9445", "content": "[source,java]\n----\n@McpTool(name = \"context-aware\", description = \"Context-aware tool\")\npublic String contextAware(\n @McpToolParam(description = \"Data\", required = true) String data,\n McpMeta meta) {\n\n // Always check for null values in metadata\n String userId = (String) meta.get(\"userId\");\n if (userId == null) {\n userId = \"anonymous\";\n }\n\n return processForUser(data, userId);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Use McpMeta for Context", "heading_level": 3, "file_order": 55, "section_index": 25, "content_hash": "7321b44245ce7c9368f49deb47f4c2d4553762d0ede3993c430885f8d52f9445", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:1df174d56f22786af87a4ddfb384d200e766a78f3ee519d43bb47c9da26f1ebc", "content": "[source,java]\n----\n@McpTool(name = \"safe-progress\", description = \"Safe progress handling\")\npublic String safeProgress(\n @McpProgressToken String progressToken,\n @McpToolParam(description = \"Task\", required = true) String task,\n McpSyncServerExchange exchange) {\n\n // Always check if progress token is available\n if (progressToken != null) {\n exchange.progressNotification(new ProgressNotification(\n progressToken, 0.0, 1.0, \"Starting\"));\n }\n\n // Perform work...\n\n if (progressToken != null) {\n exchange.progressNotification(new ProgressNotification(\n progressToken, 1.0, 1.0, \"Complete\"));\n }\n\n return \"Task completed\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Progress Token Null Checks", "heading_level": 3, "file_order": 55, "section_index": 26, "content_hash": "1df174d56f22786af87a4ddfb384d200e766a78f3ee519d43bb47c9da26f1ebc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:9e4aea14ae50ed04ba619469182f91dda28a2dc4911dcf59fd11f50b7bc592b8", "content": "* Use `McpSyncRequestContext` / `McpAsyncRequestContext` for unified access to request context, supporting both stateful and stateless operations with convenient helper methods\n* Use `McpTransportContext` for simple stateless operations when you only need transport-level context\n* Omit context parameters entirely for the simplest cases", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Choose the Right Context", "heading_level": 3, "file_order": 55, "section_index": 27, "content_hash": "9e4aea14ae50ed04ba619469182f91dda28a2dc4911dcf59fd11f50b7bc592b8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:a20b089bca19c688d18b82348fd2d92ace48627ca7242d39777f0c190c1e6d09", "content": "Always check capability support before using client features:\n\n[source,java]\n----\n@McpTool(name = \"capability-aware\", description = \"Tool that checks capabilities\")\npublic String capabilityAware(\n McpSyncRequestContext context,\n @McpToolParam(description = \"Data\", required = true) String data) {\n\n // Check if elicitation is supported before using it\n if (context.elicitEnabled()) {\n // Safe to use elicitation\n var result = context.elicit(UserInfo.class);\n // Process result...\n }\n\n // Check if sampling is supported before using it\n if (context.sampleEnabled()) {\n // Safe to use sampling\n var samplingResult = context.sample(\"Process: \" + data);\n // Process result...\n }\n\n // Note: Stateless servers do not support bidirectional operations\n // (roots, elicitation, sampling) and will return false for these checks\n\n return \"Processed with capability awareness\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Capability Checking", "heading_level": 3, "file_order": 55, "section_index": 28, "content_hash": "a20b089bca19c688d18b82348fd2d92ace48627ca7242d39777f0c190c1e6d09", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:398b752e205a23d8b890d1c7680b6596a359483308b6def996d1e1c2f465201a", "content": "* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Overview]\n* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations]\n* xref:api/mcp/mcp-annotations-client.adoc[Client Annotations]\n* xref:api/mcp/mcp-annotations-examples.adoc[Examples]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc", "title": "MCP Annotations Special Parameters", "heading": "Additional Resources", "heading_level": 2, "file_order": 55, "section_index": 29, "content_hash": "398b752e205a23d8b890d1c7680b6596a359483308b6def996d1e1c2f465201a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-annotations-special-params.adoc"}}
{"id": "sha256:9d45ca7ab2e369c155f5f2d01c0654a29a158925e1bbd79140f407751bae8a70", "content": "The Spring AI MCP (Model Context Protocol) Client Boot Starter provides auto-configuration for MCP client functionality in Spring Boot applications.\nIt supports both synchronous and asynchronous client implementations with various transport options.\n\nThe MCP Client Boot Starter provides:\n\n* Management of multiple client instances\n* Automatic client initialization (if enabled)\n* Support for multiple named transports (STDIO, Http/SSE and Streamable HTTP)\n* Integration with Spring AI's tool execution framework\n* Tool filtering capabilities for selective tool inclusion/exclusion\n* Customizable tool name prefix generation for avoiding naming conflicts\n* Proper lifecycle management with automatic cleanup of resources when the application context is closed\n* Customizable client creation through customizers", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "MCP Client Boot Starter", "heading_level": 1, "file_order": 56, "section_index": 0, "content_hash": "9d45ca7ab2e369c155f5f2d01c0654a29a158925e1bbd79140f407751bae8a70", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:ac3cef775aa4c801906d71e85cb0db73e384dec1a12094828bdc61236bd6beb1", "content": "[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-client</artifactId>\n</dependency>\n----\n\nThe standard starter connects simultaneously to one or more MCP servers over `STDIO` (in-process), `SSE`, `Streamable-HTTP` and `Stateless Streamable-HTTP` transports.\nThe SSE and Streamable-Http transports use the JDK HttpClient-based transport implementation.\nEach connection to an MCP server creates a new MCP client instance.\nYou can choose either `SYNC` or `ASYNC` MCP clients (note: you cannot mix sync and async clients).\nFor production deployment, we recommend using the WebFlux-based SSE & StreamableHttp connection with the `spring-ai-starter-mcp-client-webflux`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Standard MCP Client", "heading_level": 3, "file_order": 56, "section_index": 1, "content_hash": "ac3cef775aa4c801906d71e85cb0db73e384dec1a12094828bdc61236bd6beb1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:17ff38ca95fcaedf83220aceba141bc4cbad3f8818a337fa5747a412e740b975", "content": "The WebFlux starter provides similar functionality to the standard starter but uses a WebFlux-based Streamable-Http, Stateless Streamable-Http and SSE transport implementation.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-client-webflux</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "WebFlux Client", "heading_level": 3, "file_order": 56, "section_index": 2, "content_hash": "17ff38ca95fcaedf83220aceba141bc4cbad3f8818a337fa5747a412e740b975", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:fca3519f65d6aa3da2f12c58b2800554d419a758c3c5d85ebe3852266b600f97", "content": "The common properties are prefixed with `spring.ai.mcp.client`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`enabled`\n|Enable/disable the MCP client\n|`true`\n\n|`name`\n|Name of the MCP client instance\n|`spring-ai-mcp-client`\n\n|`version`\n|Version of the MCP client instance\n|`1.0.0`\n\n|`initialized`\n|Whether to initialize clients on creation\n|`true`\n\n|`request-timeout`\n|Timeout duration for MCP client requests\n|`20s`\n\n|`type`\n|Client type (SYNC or ASYNC). All clients must be either sync or async; mixing is not supported\n|`SYNC`\n\n|`root-change-notification`\n|Enable/disable root change notifications for all clients\n|`true`\n\n|`toolcallback.enabled`\n|Enable/disable the MCP tool callback integration with Spring AI's tool execution framework\n|`true`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Common Properties", "heading_level": 3, "file_order": 56, "section_index": 3, "content_hash": "fca3519f65d6aa3da2f12c58b2800554d419a758c3c5d85ebe3852266b600f97", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:20376c57ebcfa7b49afefeb0572b9132e2217adc09604b705ada4a41a1b03a52", "content": "MCP Client Annotations provide a declarative way to implement MCP client handlers using Java annotations.\nThe client mcp-annotations properties are prefixed with `spring.ai.mcp.client.annotation-scanner`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`enabled`\n|Enable/disable the MCP client annotations auto-scanning\n|`true`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "MCP Annotations Properties", "heading_level": 3, "file_order": 56, "section_index": 4, "content_hash": "20376c57ebcfa7b49afefeb0572b9132e2217adc09604b705ada4a41a1b03a52", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:c80ac2e7f3ee4fc5a437931306b03a9330cd52666bbbf910b1f48d55f0ba10b7", "content": "Properties for Standard I/O transport are prefixed with `spring.ai.mcp.client.stdio`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`servers-configuration`\n|Resource containing the MCP servers configuration in JSON format\n|-\n\n|`connections`\n|Map of named stdio connection configurations\n|-\n\n|`connections.[name].command`\n|The command to execute for the MCP server\n|-\n\n|`connections.[name].args`\n|List of command arguments\n|-\n\n|`connections.[name].env`\n|Map of environment variables for the server process\n|-\n|===\n\nExample configuration:\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n stdio:\n root-change-notification: true\n connections:\n server1:\n command: /path/to/server\n args:\n - --port=8080\n - --mode=production\n env:\n API_KEY: your-api-key\n DEBUG: \"true\"\n----\n\nAlternatively, you can configure stdio connections using an external JSON file using the link:https://modelcontextprotocol.io/quickstart/user[Claude Desktop format]:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n stdio:\n servers-configuration: classpath:mcp-servers.json\n----\n\nThe Claude Desktop format looks like this:\n\n[source,json]\n----\n{\n \"mcpServers\": {\n \"filesystem\": {\n \"command\": \"npx\",\n \"args\": [\n \"-y\",\n \"@modelcontextprotocol/server-filesystem\",\n \"/Users/username/Desktop\",\n \"/Users/username/Downloads\"\n ]\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Stdio Transport Properties", "heading_level": 3, "file_order": 56, "section_index": 5, "content_hash": "c80ac2e7f3ee4fc5a437931306b03a9330cd52666bbbf910b1f48d55f0ba10b7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:30955e644e0b736eef1539d82e26f2f4743d25b3819e75baa3a105b72cf6ca9f", "content": "IMPORTANT: On Windows, commands like `npx`, `npm`, and `node` are implemented as **batch files** (`.cmd`), not native executables. Java's `ProcessBuilder` cannot execute batch files directly and requires the `cmd.exe /c` wrapper.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Windows STDIO Configuration", "heading_level": 3, "file_order": 56, "section_index": 6, "content_hash": "30955e644e0b736eef1539d82e26f2f4743d25b3819e75baa3a105b72cf6ca9f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:3c5c116633e161df959d92096fa31efca98286cd8df3e43a944b3228d3de3358", "content": "When Java's `ProcessBuilder` (used internally by `StdioClientTransport`) attempts to spawn a process on Windows, it can only execute:\n\n* Native executables (`.exe` files)\n* System commands available to `cmd.exe`\n\nWindows batch files like `npx.cmd`, `npm.cmd`, and even `python.cmd` (from the Microsoft Store) require the `cmd.exe` shell to execute them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Why Windows Needs Special Handling", "heading_level": 4, "file_order": 56, "section_index": 7, "content_hash": "3c5c116633e161df959d92096fa31efca98286cd8df3e43a944b3228d3de3358", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:40d568f835cd0a3235ba8d8770798cd1debf793f508fc73bcfd5cc081561645e", "content": "Wrap batch file commands with `cmd.exe /c`:\n\n**Windows Configuration:**\n[source,json]\n----\n{\n \"mcpServers\": {\n \"filesystem\": {\n \"command\": \"cmd.exe\",\n \"args\": [\n \"/c\",\n \"npx\",\n \"-y\",\n \"@modelcontextprotocol/server-filesystem\",\n \"C:\\\\Users\\\\username\\\\Desktop\"\n ]\n }\n }\n}\n----\n\n**Linux/macOS Configuration:**\n[source,json]\n----\n{\n \"mcpServers\": {\n \"filesystem\": {\n \"command\": \"npx\",\n \"args\": [\n \"-y\",\n \"@modelcontextprotocol/server-filesystem\",\n \"/Users/username/Desktop\"\n ]\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Solution: cmd.exe Wrapper", "heading_level": 4, "file_order": 56, "section_index": 8, "content_hash": "40d568f835cd0a3235ba8d8770798cd1debf793f508fc73bcfd5cc081561645e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:424d6403f7fd7964b457366933c32a05b1cc8c509774caeafda266ab67c0c33a", "content": "For applications that need to work across platforms without separate configuration files, use OS detection in your Spring Boot application:\n\n[source,java]\n----\n@Bean(destroyMethod = \"close\")\n@ConditionalOnMissingBean(McpSyncClient.class)\npublic McpSyncClient mcpClient() {\n ServerParameters stdioParams;\n\n if (isWindows()) {\n // Windows: cmd.exe /c npx approach\n var winArgs = new ArrayList<>(Arrays.asList(\n \"/c\", \"npx\", \"-y\", \"@modelcontextprotocol/server-filesystem\", \"target\"));\n stdioParams = ServerParameters.builder(\"cmd.exe\")\n .args(winArgs)\n .build();\n } else {\n // Linux/Mac: direct npx approach\n stdioParams = ServerParameters.builder(\"npx\")\n .args(\"-y\", \"@modelcontextprotocol/server-filesystem\", \"target\")\n .build();\n }\n\n return McpClient.sync(new StdioClientTransport(stdioParams, McpJsonMapper.createDefault()))\n .requestTimeout(Duration.ofSeconds(10))\n .build()\n .initialize();\n}\n\nprivate static boolean isWindows() {\n return System.getProperty(\"os.name\").toLowerCase().contains(\"win\");\n}\n----\n\nNOTE: When using programmatic configuration with `@Bean`, add `@ConditionalOnMissingBean(McpSyncClient.class)` to avoid conflicts with auto-configuration from JSON files.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Cross-Platform Programmatic Configuration", "heading_level": 4, "file_order": 56, "section_index": 9, "content_hash": "424d6403f7fd7964b457366933c32a05b1cc8c509774caeafda266ab67c0c33a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:421e7c525a03a0225c1e77b19b265ccd8caff5b22002844b678b7e1b53397276", "content": "**Relative paths** (recommended for portability):\n[source,json]\n----\n{\n \"command\": \"cmd.exe\",\n \"args\": [\"/c\", \"npx\", \"-y\", \"@modelcontextprotocol/server-filesystem\", \"target\"]\n}\n----\n\nThe MCP server resolves relative paths based on the application's working directory.\n\n**Absolute paths** (Windows requires backslashes or escaped forward slashes):\n[source,json]\n----\n{\n \"command\": \"cmd.exe\",\n \"args\": [\"/c\", \"npx\", \"-y\", \"@modelcontextprotocol/server-filesystem\", \"C:\\\\Users\\\\username\\\\project\\\\target\"]\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Path Considerations", "heading_level": 4, "file_order": 56, "section_index": 10, "content_hash": "421e7c525a03a0225c1e77b19b265ccd8caff5b22002844b678b7e1b53397276", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:ba3136227d230bc3a9efe83e83094a5254295aec8b0345a837617d077199d7ab", "content": "* `npx.cmd`, `npm.cmd` - Node package managers\n* `python.cmd` - Python (Microsoft Store installation)\n* `pip.cmd` - Python package manager\n* `mvn.cmd` - Maven wrapper\n* `gradle.cmd` - Gradle wrapper\n* Custom `.cmd` or `.bat` scripts", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Common Windows Batch Files Requiring cmd.exe", "heading_level": 4, "file_order": 56, "section_index": 11, "content_hash": "ba3136227d230bc3a9efe83e83094a5254295aec8b0345a837617d077199d7ab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:db230597adf42da7cd9e58ef2ed307a2031c796d926d6a1577d735828186304d", "content": "See link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/filesystem[Spring AI Examples - Filesystem] for a complete cross-platform MCP client implementation that automatically detects the OS and configures the client appropriately.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Reference Implementation", "heading_level": 4, "file_order": 56, "section_index": 12, "content_hash": "db230597adf42da7cd9e58ef2ed307a2031c796d926d6a1577d735828186304d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:f79af351035d852be8fc7b0c6409e9cadc177f45efa2ed532e39a580b9c6c604", "content": "Used for connecting to Streamable-HTTP and Stateless Streamable-HTTP MCP servers.\n\nProperties for Streamable-HTTP transport are prefixed with `spring.ai.mcp.client.streamable-http`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description | Default Value\n\n|`connections`\n|Map of named Streamable-HTTP connection configurations\n|-\n\n|`connections.[name].url`\n|Base URL endpoint for Streamable-Http communication with the MCP server\n|-\n\n|`connections.[name].endpoint`\n|the streamable-http endpoint (as url suffix) to use for the connection\n|`/mcp`\n|===\n\nExample configuration:\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n streamable-http:\n connections:\n server1:\n url: http://localhost:8080\n server2:\n url: http://otherserver:8081\n endpoint: /custom-sse\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Streamable-HTTP Transport Properties", "heading_level": 3, "file_order": 56, "section_index": 13, "content_hash": "f79af351035d852be8fc7b0c6409e9cadc177f45efa2ed532e39a580b9c6c604", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:289de80ef16b71d90bfe1a5ed10b640b893c18a4e02af60ead8811b9fd71978b", "content": "Properties for Server-Sent Events (SSE) transport are prefixed with `spring.ai.mcp.client.sse`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description | Default Value\n\n|`connections`\n|Map of named SSE connection configurations\n|-\n\n|`connections.[name].url`\n|Base URL endpoint for SSE communication with the MCP server\n|-\n\n|`connections.[name].sse-endpoint`\n|the sse endpoint (as url suffix) to use for the connection\n|`/sse`\n|===\n\nExample configurations:\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n sse:\n connections:\n # Simple configuration using default /sse endpoint\n server1:\n url: http://localhost:8080\n # Custom SSE endpoint\n server2:\n url: http://otherserver:8081\n sse-endpoint: /custom-sse\n # Complex URL with path and token (like MCP Hub)\n mcp-hub:\n url: http://localhost:3000\n sse-endpoint: /mcp-hub/sse/cf9ec4527e3c4a2cbb149a85ea45ab01\n # SSE endpoint with query parameters\n api-server:\n url: https://api.example.com\n sse-endpoint: /v1/mcp/events?token=abc123&format=json\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "SSE Transport Properties", "heading_level": 3, "file_order": 56, "section_index": 14, "content_hash": "289de80ef16b71d90bfe1a5ed10b640b893c18a4e02af60ead8811b9fd71978b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:bdb17bc111831d8d3bf1882fbdf331f7d67dacf6aae32b84c893b0c6dc8c89b0", "content": "When you have a full SSE URL, split it into base URL and endpoint path:\n\n[cols=\"2,2\"]\n|===\n|Full URL |Configuration\n\n|`\\http://localhost:3000/mcp-hub/sse/token123`\n|`url: http://localhost:3000` +\n`sse-endpoint: /mcp-hub/sse/token123`\n\n|`\\https://api.service.com/v2/events?key=secret`\n|`url: https://api.service.com` +\n`sse-endpoint: /v2/events?key=secret`\n\n|`\\http://localhost:8080/sse`\n|`url: http://localhost:8080` +\n`sse-endpoint: /sse` (or omit for default)\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "URL Splitting Guidelines", "heading_level": 4, "file_order": 56, "section_index": 15, "content_hash": "bdb17bc111831d8d3bf1882fbdf331f7d67dacf6aae32b84c893b0c6dc8c89b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:e0f835e4b34bb584c3b2a86025fa970d91781b706329521d4ed3450ea1f7b7a7", "content": "*404 Not Found Errors:*\n\n* Verify URL splitting: ensure the base `url` contains only the scheme, host, and port\n* Check the `sse-endpoint` starts with `/` and includes the full path and query parameters\n* Test the full URL directly in a browser or curl to confirm it's accessible", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Troubleshooting SSE Connections", "heading_level": 4, "file_order": 56, "section_index": 16, "content_hash": "e0f835e4b34bb584c3b2a86025fa970d91781b706329521d4ed3450ea1f7b7a7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:e10f8df2e0712723a58669fc39843be606cb4fbdd0b57a13e9c2a89fa4796902", "content": "Properties for Streamable Http transport are prefixed with `spring.ai.mcp.client.streamable-http`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description | Default Value\n\n|`connections`\n|Map of named Streamable Http connection configurations\n|-\n\n|`connections.[name].url`\n|Base URL endpoint for Streamable-Http communication with the MCP server\n|-\n\n|`connections.[name].endpoint`\n|the streamable-http endpoint (as url suffix) to use for the connection\n|`/mcp`\n|===\n\nExample configuration:\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n streamable-http:\n connections:\n server1:\n url: http://localhost:8080\n server2:\n url: http://otherserver:8081\n endpoint: /custom-sse\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Streamable Http Transport Properties", "heading_level": 3, "file_order": 56, "section_index": 17, "content_hash": "e10f8df2e0712723a58669fc39843be606cb4fbdd0b57a13e9c2a89fa4796902", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:2f17649cb433b3b0ea381c87f8528e30438ace593422c8e3c663800bc04c5fc3", "content": "The starter supports two types of clients:\n\n* Synchronous - default client type (`spring.ai.mcp.client.type=SYNC`), suitable for traditional request-response patterns with blocking operations\n\n**NOTE:** The SYNC client will register only synchronous MCP annotated methods. Asynchronous methods will be ignored.\n\n* Asynchronous - suitable for reactive applications with non-blocking operations, configured using `spring.ai.mcp.client.type=ASYNC`\n\n**NOTE:** The ASYNC client will register only asynchronous MCP annotated methods. Synchronous methods will be ignored.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Sync/Async Client Types", "heading_level": 3, "file_order": 56, "section_index": 18, "content_hash": "2f17649cb433b3b0ea381c87f8528e30438ace593422c8e3c663800bc04c5fc3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:2d53084ed7cbd64de571e8e950b7ba66c2b8d70bc9448c58117c713fb5590ebe", "content": "The auto-configuration provides extensive client spec customization capabilities through callback interfaces. These customizers allow you to configure various aspects of the MCP client behavior, from request timeouts to event handling and message processing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Client Customization", "heading_level": 3, "file_order": 56, "section_index": 19, "content_hash": "2d53084ed7cbd64de571e8e950b7ba66c2b8d70bc9448c58117c713fb5590ebe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:8903e720ea523a7e3a34abe6254eb82d989e2486161383a9b206e5285bd5b11e", "content": "The following customization options are available:\n\n* *Request Configuration* - Set custom request timeouts\n* link:https://modelcontextprotocol.io/specification/2025-06-18/client/sampling[*Custom Sampling Handlers*] - standardized way for servers to request LLM sampling (`completions` or `generations`) from LLMs via clients. This flow allows clients to maintain control over model access, selection, and permissions while enabling servers to leverage AI capabilities — with no server API keys necessary.\n* link:https://modelcontextprotocol.io/specification/2025-06-18/client/roots[*File system (Roots) Access*] - standardized way for clients to expose filesystem `roots` to servers.\nRoots define the boundaries of where servers can operate within the filesystem, allowing them to understand which directories and files they have access to.\nServers can request the list of roots from supporting clients and receive notifications when that list changes.\n* link:https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation[*Elicitation Handlers*] - standardized way for servers to request additional information from users through the client during interactions.\n* *Event Handlers* - client's handler to be notified when a certain server event occurs:\n - Tools change notifications - when the list of available server tools changes\n - Resources change notifications - when the list of available server resources changes.\n - Prompts change notifications - when the list of available server prompts changes.\n - link:https://modelcontextprotocol.io/specification/2025-06-18/server/utilities/logging[*Logging Handlers*] - standardized way for servers to send structured log messages to clients.\n - link:https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/progress[*Progress Handlers*] - standardized way for servers to send structured progress messages to clients.\n\nClients can control logging verbosity by setting minimum log levels", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Customization Types", "heading_level": 4, "file_order": 56, "section_index": 20, "content_hash": "8903e720ea523a7e3a34abe6254eb82d989e2486161383a9b206e5285bd5b11e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:716ccff2e5efe137b987f6206e72857e0667e72853a4c2cac9d721dae92d92cd", "content": "You can implement either `McpSyncClientCustomizer` for synchronous clients or `McpAsyncClientCustomizer` for asynchronous clients, depending on your application's needs.\n\n[tabs]\n======\nSync::\n+\n[source,java]\n----\n@Component\npublic class CustomMcpSyncClientCustomizer implements McpSyncClientCustomizer {\n @Override\n public void customize(String serverConfigurationName, McpClient.SyncSpec spec) {\n\n // Customize the request timeout configuration\n spec.requestTimeout(Duration.ofSeconds(30));\n\n // Sets the root URIs that this client can access.\n spec.roots(roots);\n\n // Sets a custom sampling handler for processing message creation requests.\n spec.sampling((CreateMessageRequest messageRequest) -> {\n // Handle sampling\n CreateMessageResult result = ...\n return result;\n });\n\n // Sets a custom elicitation handler for processing elicitation requests.\n spec.elicitation((ElicitRequest request) -> {\n // handle elicitation\n return new ElicitResult(ElicitResult.Action.ACCEPT, Map.of(\"message\", request.message()));\n });\n\n // Adds a consumer to be notified when progress notifications are received.\n spec.progressConsumer((ProgressNotification progress) -> {\n // Handle progress notifications\n });\n\n // Adds a consumer to be notified when the available tools change, such as tools\n // being added or removed.\n spec.toolsChangeConsumer((List<McpSchema.Tool> tools) -> {\n // Handle tools change\n });\n\n // Adds a consumer to be notified when the available resources change, such as resources\n // being added or removed.\n spec.resourcesChangeConsumer((List<McpSchema.Resource> resources) -> {\n // Handle resources change\n });\n\n // Adds a consumer to be notified when the available prompts change, such as prompts\n // being added or removed.\n spec.promptsChangeConsumer((List<McpSchema.Prompt> prompts) -> {\n // Handle prompts change\n });\n\n // Adds a consumer to be notified when logging messages are received from the server.\n spec.loggingConsumer((McpSchema.LoggingMessageNotification log) -> {\n // Handle log messages\n });\n }\n}\n----\n\nAsync::\n+\n[source,java]\n----\n@Component\npublic class CustomMcpAsyncClientCustomizer implements McpAsyncClientCustomizer {\n @Override\n public void customize(String serverConfigurationName, McpClient.AsyncSpec spec) {\n // Customize the async client configuration\n spec.requestTimeout(Duration.ofSeconds(30));\n }\n}\n----\n======\nThe `serverConfigurationName` parameter is the name of the server configuration that the customizer is being applied to and the MCP Client is created for.\n\nThe MCP client auto-configuration automatically detects and applies any customizers found in the application context.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Client Customization Example", "heading_level": 4, "file_order": 56, "section_index": 21, "content_hash": "716ccff2e5efe137b987f6206e72857e0667e72853a4c2cac9d721dae92d92cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:0dd38a211f122a45315e28c1d09ac8e6343a3f1346791430da3eb63ac6099394", "content": "The auto-configuration supports multiple transport types:\n\n* Standard I/O (Stdio) (activated by the `spring-ai-starter-mcp-client` and `spring-ai-starter-mcp-client-webflux`)\n* (HttpClient) HTTP/SSE and Streamable-HTTP (activated by the `spring-ai-starter-mcp-client`)\n* (WebFlux) HTTP/SSE and Streamable-HTTP (activated by the `spring-ai-starter-mcp-client-webflux`)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Transport Support", "heading_level": 3, "file_order": 56, "section_index": 22, "content_hash": "0dd38a211f122a45315e28c1d09ac8e6343a3f1346791430da3eb63ac6099394", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:4676172b78d837b81d72d1ef43bb9540898780a16c7f7377fe3a0d80b22742b6", "content": "The MCP Client Boot Starter supports filtering of discovered tools through the `McpToolFilter` interface. This allows you to selectively include or exclude tools based on custom criteria such as the MCP connection information or tool properties.\n\nTo implement tool filtering, create a bean that implements the `McpToolFilter` interface:\n\n[source,java]\n----\n@Component\npublic class CustomMcpToolFilter implements McpToolFilter {\n\n @Override\n public boolean test(McpConnectionInfo connectionInfo, McpSchema.Tool tool) {\n // Filter logic based on connection information and tool properties\n // Return true to include the tool, false to exclude it\n\n // Example: Exclude tools from a specific client\n if (connectionInfo.clientInfo().name().equals(\"restricted-client\")) {\n return false;\n }\n\n // Example: Only include tools with specific names\n if (tool.name().startsWith(\"allowed_\")) {\n return true;\n }\n\n // Example: Filter based on tool description or other properties\n if (tool.description() != null &&\n tool.description().contains(\"experimental\")) {\n return false;\n }\n\n return true; // Include all other tools by default\n }\n}\n----\n\nThe `McpConnectionInfo` record provides access to:\n\n* `clientCapabilities` - The capabilities of the MCP client\n* `clientInfo` - Information about the MCP client (name and version)\n* `initializeResult` - The initialization result from the MCP server\n\nThe filter is automatically detected and applied to both synchronous and asynchronous MCP tool callback providers.\nIf no custom filter is provided, all discovered tools are included by default.\n\nNote: Only one `McpToolFilter` bean should be defined in the application context.\nIf multiple filters are needed, combine them into a single composite filter implementation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Tool Filtering", "heading_level": 3, "file_order": 56, "section_index": 23, "content_hash": "4676172b78d837b81d72d1ef43bb9540898780a16c7f7377fe3a0d80b22742b6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:fb105a398757526e6f9c8b1febac78d42bc5f2a7a40d1a95ccdc755487a780e0", "content": "The MCP Client Boot Starter supports customizable tool name prefix generation through the `McpToolNamePrefixGenerator` interface. This feature helps avoid naming conflicts when integrating tools from multiple MCP servers by adding unique prefixes to tool names.\n\nBy default, if no custom `McpToolNamePrefixGenerator` bean is provided, the starter uses `DefaultMcpToolNamePrefixGenerator` which ensures unique tool names across all MCP client connections. The default generator:\n\n* Tracks all existing connections and tool names to ensure uniqueness\n* Formats tool names by replacing non-alphanumeric characters with underscores (e.g., `my-tool` becomes `my_tool`)\n* When duplicate tool names are detected across different connections, adds a counter prefix (e.g., `alt_1_toolName`, `alt_2_toolName`)\n* Is thread-safe and maintains idempotency - the same combination of (client, server, tool) always gets the same unique name\n* Ensures the final name doesn't exceed 64 characters (truncating from the beginning if necessary)\n\nFor example:\n* First occurrence of tool `search` → `search`\n* Second occurrence of tool `search` from a different connection → `alt_1_search`\n* Tool with special characters `my-special-tool` → `my_special_tool`\n\nYou can customize this behavior by providing your own implementation:\n\n[source,java]\n----\n@Component\npublic class CustomToolNamePrefixGenerator implements McpToolNamePrefixGenerator {\n\n @Override\n public String prefixedToolName(McpConnectionInfo connectionInfo, Tool tool) {\n // Custom logic to generate prefixed tool names\n\n // Example: Use server name and version as prefix\n String serverName = connectionInfo.initializeResult().serverInfo().name();\n String serverVersion = connectionInfo.initializeResult().serverInfo().version();\n return serverName + \"_v\" + serverVersion.replace(\".\", \"_\") + \"_\" + tool.name();\n }\n}\n----\n\nThe `McpConnectionInfo` record provides comprehensive information about the MCP connection:\n\n* `clientCapabilities` - The capabilities of the MCP client\n* `clientInfo` - Information about the MCP client (name, title, and version)\n* `initializeResult` - The initialization result from the MCP server, including server information", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Tool Name Prefix Generation", "heading_level": 3, "file_order": 56, "section_index": 24, "content_hash": "fb105a398757526e6f9c8b1febac78d42bc5f2a7a40d1a95ccdc755487a780e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:4b8b8442b7efcb8b12c222e44b695670575e04250f3e7a7f941d8441f0f46a05", "content": "The framework provides several built-in prefix generators:\n\n* `DefaultMcpToolNamePrefixGenerator` - Ensures unique tool names by tracking duplicates and adding counter prefixes when needed (used by default if no custom bean is provided)\n* `McpToolNamePrefixGenerator.noPrefix()` - Returns tool names without any prefix (may cause conflicts if multiple servers provide tools with the same name)\n\nTo disable prefixing entirely and use raw tool names (not recommended if using multiple MCP servers), register the no-prefix generator as a bean:\n\n[source,java]\n----\n@Configuration\npublic class McpConfiguration {\n\n @Bean\n public McpToolNamePrefixGenerator mcpToolNamePrefixGenerator() {\n return McpToolNamePrefixGenerator.noPrefix();\n }\n}\n----\n\nThe prefix generator is automatically detected and applied to both synchronous and asynchronous MCP tool callback providers through Spring's `ObjectProvider` mechanism.\nIf no custom generator bean is provided, the `DefaultMcpToolNamePrefixGenerator` is used automatically.\n\nWARNING: When using `McpToolNamePrefixGenerator.noPrefix()` with multiple MCP servers, duplicate tool names will cause an `IllegalStateException`. The default `DefaultMcpToolNamePrefixGenerator` prevents this by automatically adding unique prefixes to duplicate tool names.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Built-in Prefix Generators", "heading_level": 4, "file_order": 56, "section_index": 25, "content_hash": "4b8b8442b7efcb8b12c222e44b695670575e04250f3e7a7f941d8441f0f46a05", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:dc2cb1bbc7a38a70e4019548b74b49ca96b54492830c0aca3db2b1a9d1c4f7f2", "content": "The MCP Client Boot Starter supports customizable conversion of Spring AI's xref:api/tools.adoc#_tool_context[ToolContext] to MCP tool-call metadata through the `ToolContextToMcpMetaConverter` interface.\nThis feature allows you to pass additional contextual information (e.g. user id, secrets token) as metadata along with the LLM's generated call arguments.\n\nFor example you can pass the MCP `progressToken` to your link:https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/progress#progress-flow[MCP Progress Flow] in the tool context to track the progress of long-running operations:\n\n[source,java]\n----\nChatModel chatModel = ...\n\nString response = ChatClient.create(chatModel)\n .prompt(\"Tell me more about the customer with ID 42\")\n .toolContext(Map.of(\"progressToken\", \"my-progress-token\"))\n .call()\n .content();\n----\n\nBy default, if no custom converter bean is provided, the starter uses `ToolContextToMcpMetaConverter.defaultConverter()` which:\n\n* Filters out the MCP exchange key (`McpToolUtils.TOOL_CONTEXT_MCP_EXCHANGE_KEY`)\n* Filters out entries with null values\n* Passes through all other context entries as metadata\n\nYou can customize this behavior by providing your own implementation:\n\n[source,java]\n----\n@Component\npublic class CustomToolContextToMcpMetaConverter implements ToolContextToMcpMetaConverter {\n\n @Override\n public Map<String, Object> convert(ToolContext toolContext) {\n if (toolContext == null || toolContext.getContext() == null) {\n return Map.of();\n }\n\n // Custom logic to convert tool context to MCP metadata\n Map<String, Object> metadata = new HashMap<>();\n\n // Example: Add custom prefix to all keys\n for (Map.Entry<String, Object> entry : toolContext.getContext().entrySet()) {\n if (entry.getValue() != null) {\n metadata.put(\"app_\" + entry.getKey(), entry.getValue());\n }\n }\n\n // Example: Add additional metadata\n metadata.put(\"timestamp\", System.currentTimeMillis());\n metadata.put(\"source\", \"spring-ai\");\n\n return metadata;\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Tool Context to MCP Meta Converter", "heading_level": 3, "file_order": 56, "section_index": 26, "content_hash": "dc2cb1bbc7a38a70e4019548b74b49ca96b54492830c0aca3db2b1a9d1c4f7f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:5cde0671f785738bfd71e326b56c8ca329f39570f0addac84b094902cef6529d", "content": "The framework provides built-in converters:\n\n* `ToolContextToMcpMetaConverter.defaultConverter()` - Filters out MCP exchange key and null values (used by default if no custom bean is provided)\n* `ToolContextToMcpMetaConverter.noOp()` - Returns an empty map, effectively disabling context-to-metadata conversion\n\nTo disable context-to-metadata conversion entirely:\n\n[source,java]\n----\n@Configuration\npublic class McpConfiguration {\n\n @Bean\n public ToolContextToMcpMetaConverter toolContextToMcpMetaConverter() {\n return ToolContextToMcpMetaConverter.noOp();\n }\n}\n----\n\nThe converter is automatically detected and applied to both synchronous and asynchronous MCP tool callbacks through Spring's `ObjectProvider` mechanism.\nIf no custom converter bean is provided, the default converter is used automatically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Built-in Converters", "heading_level": 4, "file_order": 56, "section_index": 27, "content_hash": "5cde0671f785738bfd71e326b56c8ca329f39570f0addac84b094902cef6529d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:3ead715325053eb2eb4752871194b866b8e001f2c336af955b65e86fea2d3201", "content": "The MCP ToolCallback auto-configuration is enabled by default, but can be disabled with the `spring.ai.mcp.client.toolcallback.enabled=false` property.\n\nWhen disabled, no `ToolCallbackProvider` bean is created from the available MCP tools.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Disable the MCP ToolCallback Auto-Configuration", "heading_level": 3, "file_order": 56, "section_index": 28, "content_hash": "3ead715325053eb2eb4752871194b866b8e001f2c336af955b65e86fea2d3201", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:e85f205670c833e4a6998069cedc8e9d309da024f3f7875c6b523bb725b301ec", "content": "The MCP Client Boot Starter automatically detects and registers annotated methods for handling various MCP client operations:\n\n* *@McpLogging* - Handles logging message notifications from MCP servers\n* *@McpSampling* - Handles sampling requests from MCP servers for LLM completions\n* *@McpElicitation* - Handles elicitation requests to gather additional information from users\n* *@McpProgress* - Handles progress notifications for long-running operations\n* *@McpToolListChanged* - Handles notifications when the server's tool list changes\n* *@McpResourceListChanged* - Handles notifications when the server's resource list changes\n* *@McpPromptListChanged* - Handles notifications when the server's prompt list changes\n\nExample usage:\n\n[source,java]\n----\n@Component\npublic class McpClientHandlers {\n\n @McpLogging(clients = \"server1\")\n public void handleLoggingMessage(LoggingMessageNotification notification) {\n System.out.println(\"Received log: \" + notification.level() +\n \" - \" + notification.data());\n }\n\n @McpSampling(clients = \"server1\")\n public CreateMessageResult handleSamplingRequest(CreateMessageRequest request) {\n // Process the request and generate a response\n String response = generateLLMResponse(request);\n\n return CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response))\n .model(\"gpt-4\")\n .build();\n }\n\n @McpProgress(clients = \"server1\")\n public void handleProgressNotification(ProgressNotification notification) {\n double percentage = notification.progress() * 100;\n System.out.println(String.format(\"Progress: %.2f%% - %s\",\n percentage, notification.message()));\n }\n\n @McpToolListChanged(clients = \"server1\")\n public void handleToolListChanged(List<McpSchema.Tool> updatedTools) {\n System.out.println(\"Tool list updated: \" + updatedTools.size() + \" tools available\");\n // Update local tool registry\n toolRegistry.updateTools(updatedTools);\n }\n}\n----\n\nThe annotations support both synchronous and asynchronous implementations, and can be configured for specific clients using the `clients` parameter:\n\n[source,java]\n----\n@McpLogging(clients = \"server1\")\npublic void handleServer1Logs(LoggingMessageNotification notification) {\n // Handle logs from specific server\n logToFile(\"server1.log\", notification);\n}\n\n@McpSampling(clients = \"server1\")\npublic Mono<CreateMessageResult> handleAsyncSampling(CreateMessageRequest request) {\n return Mono.fromCallable(() -> {\n String response = generateLLMResponse(request);\n return CreateMessageResult.builder()\n .role(Role.ASSISTANT)\n .content(new TextContent(response))\n .model(\"gpt-4\")\n .build();\n }).subscribeOn(Schedulers.boundedElastic());\n}\n----\n\nFor detailed information about all available annotations and their usage patterns, see the xref:api/mcp/mcp-annotations-client.adoc[MCP Client Annotations] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "MCP Client Annotations", "heading_level": 2, "file_order": 56, "section_index": 29, "content_hash": "e85f205670c833e4a6998069cedc8e9d309da024f3f7875c6b523bb725b301ec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:03c78b5134c2d3c975274a0447ad01a6d5e045a1c6c78a33edbc189941d8ddb9", "content": "Add the appropriate starter dependency to your project and configure the client in `application.properties` or `application.yml`:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n enabled: true\n name: my-mcp-client\n version: 1.0.0\n request-timeout: 30s\n type: SYNC # or ASYNC for reactive applications\n sse:\n connections:\n server1:\n url: http://localhost:8080\n server2:\n url: http://otherserver:8081\n streamable-http:\n connections:\n server3:\n url: http://localhost:8083\n endpoint: /mcp\n stdio:\n root-change-notification: false\n connections:\n server1:\n command: /path/to/server\n args:\n - --port=8080\n - --mode=production\n env:\n API_KEY: your-api-key\n DEBUG: \"true\"\n----\n\nThe MCP client beans will be automatically configured and available for injection:\n\n[source,java]\n----\n@Autowired\nprivate List<McpSyncClient> mcpSyncClients; // For sync client\n\n@Autowired\nprivate List<McpAsyncClient> mcpAsyncClients; // For async client\n----\n\nWhen tool callbacks are enabled (the default behavior), the registered MCP Tools with all MCP clients are provided as a `ToolCallbackProvider` instance:\n\n[source,java]\n----\n@Autowired\nprivate SyncMcpToolCallbackProvider toolCallbackProvider;\nToolCallback[] toolCallbacks = toolCallbackProvider.getToolCallbacks();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Usage Example", "heading_level": 2, "file_order": 56, "section_index": 30, "content_hash": "03c78b5134c2d3c975274a0447ad01a6d5e045a1c6c78a33edbc189941d8ddb9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:77c770368c4a02cb342da7d5425b713c9d5d2fd19e109165cd30e1bb5fad23c4", "content": "- link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/web-search/brave-chatbot[Brave Web Search Chatbot] - A chatbot that uses the Model Context Protocol to interact with a web search server.\n- link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/client-starter/starter-default-client[Default MCP Client Starter] - A simple example of using the default `spring-ai-starter-mcp-client` MCP Client Boot Starter.\n- link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/client-starter/starter-webflux-client[WebFlux MCP Client Starter] - A simple example of using the `spring-ai-starter-mcp-client-webflux` MCP Client Boot Starter.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Example Applications", "heading_level": 2, "file_order": 56, "section_index": 31, "content_hash": "77c770368c4a02cb342da7d5425b713c9d5d2fd19e109165cd30e1bb5fad23c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:ae5a7af98766fe7830c15b7a301ed60f8dccc1202b4917cecc10ba9e9fdf7a8d", "content": "* link:https://docs.spring.io/spring-ai/reference/[Spring AI Documentation]\n* link:https://modelcontextprotocol.github.io/specification/[Model Context Protocol Specification]\n* link:https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.developing-auto-configuration[Spring Boot Auto-configuration]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc", "title": "MCP Client Boot Starter", "heading": "Additional Resources", "heading_level": 2, "file_order": 56, "section_index": 32, "content_hash": "ae5a7af98766fe7830c15b7a301ed60f8dccc1202b4917cecc10ba9e9fdf7a8d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-client-boot-starter-docs.adoc"}}
{"id": "sha256:7caad41b4338c8073e6aaab63368714ef5ba874d56352e543bba6597693592dc", "content": "The MCP utilities provide foundational support for integrating Model Context Protocol with Spring AI applications.\nThese utilities enable seamless communication between Spring AI's tool system and MCP servers, supporting both synchronous and asynchronous operations.\nThey are typically used for programmatic MCP Client and Server configuration and interaction.\nFor a more streamlined configuration, consider using the boot starters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "MCP Utilities", "heading_level": 1, "file_order": 57, "section_index": 0, "content_hash": "7caad41b4338c8073e6aaab63368714ef5ba874d56352e543bba6597693592dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:06906730cc0d277f5f97ca40bb97c81ec4545865cd2096d93c857137cc93496f", "content": "Adapts MCP tools to Spring AI's tool interface with both synchronous and asynchronous execution support.\n\n[tabs]\n======\nSync::\n+\n[source,java]\n----\nMcpSyncClient mcpClient = // obtain MCP client\nTool mcpTool = // obtain MCP tool definition\nToolCallback callback = new SyncMcpToolCallback(mcpClient, mcpTool);\n\nToolDefinition definition = callback.getToolDefinition();\nString result = callback.call(\"{\\\"param\\\": \\\"value\\\"}\");\n----\n\nAsync::\n+\n[source,java]\n----\nMcpAsyncClient mcpClient = // obtain MCP client\nTool mcpTool = // obtain MCP tool definition\nToolCallback callback = new AsyncMcpToolCallback(mcpClient, mcpTool);\n\nToolDefinition definition = callback.getToolDefinition();\nString result = callback.call(\"{\\\"param\\\": \\\"value\\\"}\");\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "Tool Callback Adapter", "heading_level": 3, "file_order": 57, "section_index": 1, "content_hash": "06906730cc0d277f5f97ca40bb97c81ec4545865cd2096d93c857137cc93496f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:e35e7851cafcc081f63352665f2984a30430feee7da2bf70363318a31bd020db", "content": "Discovers and provides MCP tools from MCP clients.\n\n[tabs]\n======\nSync::\n+\n[source,java]\n----\nMcpSyncClient mcpClient = // obtain MCP client\nToolCallbackProvider provider = new SyncMcpToolCallbackProvider(mcpClient);\n\nToolCallback[] tools = provider.getToolCallbacks();\n----\n+\nFor multiple clients:\n+\n[source,java]\n----\nList<McpSyncClient> clients = // obtain list of clients\nList<ToolCallback> callbacks = SyncMcpToolCallbackProvider.syncToolCallbacks(clients);\n----\n+\nFor dynamic selection of a subset of clients\n+\n[source,java]\n----\n@Autowired\nprivate List<McpSyncClient> mcpSyncClients;\n\npublic ToolCallbackProvider buildProvider(Set<String> allowedServerNames) {\n // Filter by server.name().\n List<McpSyncClient> selected = mcpSyncClients.stream()\n .filter(c -> allowedServerNames.contains(c.getServerInfo().name()))\n .toList();\n\n return new SyncMcpToolCallbackProvider(selected);\n}\n\n----\nAsync::\n+\n[source,java]\n----\nMcpAsyncClient mcpClient = // obtain MCP client\nToolCallbackProvider provider = new AsyncMcpToolCallbackProvider(mcpClient);\n\nToolCallback[] tools = provider.getToolCallbacks();\n----\n+\nFor multiple clients:\n+\n[source,java]\n----\nList<McpAsyncClient> clients = // obtain list of clients\nFlux<ToolCallback> callbacks = AsyncMcpToolCallbackProvider.asyncToolCallbacks(clients);\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "Tool Callback Providers", "heading_level": 3, "file_order": 57, "section_index": 2, "content_hash": "e35e7851cafcc081f63352665f2984a30430feee7da2bf70363318a31bd020db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:8b217f167c2f2f4c7bda4f4601dd905b6a416710754e03d8fe5211c1a5fd2284", "content": "Converting Spring AI tool callbacks to MCP tool specifications:\n\n[tabs]\n======\nSync::\n+\n[source,java]\n----\nList<ToolCallback> toolCallbacks = // obtain tool callbacks\nList<SyncToolSpecifications> syncToolSpecs = McpToolUtils.toSyncToolSpecifications(toolCallbacks);\n----\n+\nthen you can use the `McpServer.SyncSpecification` to register the tool specifications:\n+\n[source,java]\n----\nMcpServer.SyncSpecification syncSpec = ...\nsyncSpec.tools(syncToolSpecs);\n----\n\nAsync::\n+\n[source,java]\n----\nList<ToolCallback> toolCallbacks = // obtain tool callbacks\nList<AsyncToolSpecification> asyncToolSpecifications = McpToolUtils.toAsyncToolSpecifications(toolCallbacks);\n----\n+\nthen you can use the `McpServer.AsyncSpecification` to register the tool specifications:\n+\n[source,java]\n----\nMcpServer.AsyncSpecification asyncSpec = ...\nasyncSpec.tools(asyncToolSpecifications);\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "ToolCallbacks to ToolSpecifications", "heading_level": 3, "file_order": 57, "section_index": 3, "content_hash": "8b217f167c2f2f4c7bda4f4601dd905b6a416710754e03d8fe5211c1a5fd2284", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:44ae110aad0778056f2de8b1f571ee6c141128ce1a28f826f179ac4230afe3e8", "content": "Getting tool callbacks from MCP clients\n\n[tabs]\n======\nSync::\n+\n[source,java]\n----\nList<McpSyncClient> syncClients = // obtain sync clients\nList<ToolCallback> syncCallbacks = McpToolUtils.getToolCallbacksFromSyncClients(syncClients);\n----\n\nAsync::\n+\n[source,java]\n----\nList<McpAsyncClient> asyncClients = // obtain async clients\nList<ToolCallback> asyncCallbacks = McpToolUtils.getToolCallbacksFromAsyncClients(asyncClients);\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "MCP Clients to ToolCallbacks", "heading_level": 3, "file_order": 57, "section_index": 4, "content_hash": "44ae110aad0778056f2de8b1f571ee6c141128ce1a28f826f179ac4230afe3e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:6d524dc34b58c244b01ceba49adaa81be240705b5481677c8bd3fdd78e6737ec", "content": "The `McpHints` class provides GraalVM native image hints for MCP schema classes.\nThis class automatically registers all necessary reflection hints for MCP schema classes when building native images.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc", "title": "MCP Utilities", "heading": "Native Image Support", "heading_level": 2, "file_order": 57, "section_index": 5, "content_hash": "6d524dc34b58c244b01ceba49adaa81be240705b5481677c8bd3fdd78e6737ec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-helpers.adoc"}}
{"id": "sha256:394f4ce3f783a54ce14771e433cf989249514060f52f18551e010c5fbef5f985", "content": "TIP: **New to MCP?** Start with our xref:guides/getting-started-mcp.adoc[Getting Started with MCP] guide for a quick introduction and hands-on examples.\n\nThe link:https://modelcontextprotocol.org/docs/concepts/architecture[Model Context Protocol] (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.\nThink of it as a bridge between your AI models and the real world - allowing them to access databases, APIs, file systems, and other external services through a consistent interface.\nIt supports multiple transport mechanisms to provide flexibility across different environments.\n\nThe link:https://modelcontextprotocol.io/sdk/java/mcp-overview[MCP Java SDK] provides a Java implementation of the Model Context Protocol, enabling standardized interaction with AI models and tools through both synchronous and asynchronous communication patterns.\n\nSpring AI embraces MCP with comprehensive support through dedicated Boot Starters and MCP Java Annotations, making it easier than ever to build sophisticated AI-powered applications that can seamlessly connect to external systems.\nThis means Spring developers can participate in both sides of the MCP ecosystem - building AI applications that consume MCP servers and creating MCP servers that expose Spring-based services to the wider AI community.\nBootstrap your AI applications with MCP support using link:https://start.spring.io[Spring Initializer].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Model Context Protocol (MCP)", "heading_level": 1, "file_order": 58, "section_index": 0, "content_hash": "394f4ce3f783a54ce14771e433cf989249514060f52f18551e010c5fbef5f985", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:aebdb731aba38020c5e84ea5f69c56d0f73d1190e955792d3513d1cd810db9a0", "content": "TIP: This section provides an overview for the link:https://modelcontextprotocol.io/sdk/java/mcp-overview[MCP Java SDK architecture].\nFor the Spring AI MCP integration, refer to the xref:#_spring_ai_mcp_integration[Spring AI MCP Boot Starters] documentation.\n\nThe Java MCP implementation follows a three-layer architecture that separates concerns for maintainability and flexibility:\n\n.MCP Stack Architecture\nimage::mcp/mcp-stack.svg[MCP Stack Architecture, align=center]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "MCP Java SDK Architecture", "heading_level": 2, "file_order": 58, "section_index": 1, "content_hash": "aebdb731aba38020c5e84ea5f69c56d0f73d1190e955792d3513d1cd810db9a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:ba44b40e8cac47a1f8fbc73044db7faf82a47aacdee33b4948082e29bdc99e60", "content": "The top layer handles the main application logic and protocol operations:\n\n* *McpClient* - Manages client-side operations and server connections\n* *McpServer* - Handles server-side protocol operations and client requests\n* Both components utilize the session layer below for communication management", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Client/Server Layer (Top)", "heading_level": 3, "file_order": 58, "section_index": 2, "content_hash": "ba44b40e8cac47a1f8fbc73044db7faf82a47aacdee33b4948082e29bdc99e60", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:a360803a88a0167bfdb4d1782fab6682fbed9f79991dbfa937a8e0275f51cbdb", "content": "The middle layer manages communication patterns and maintains connection state:\n\n* *McpSession* - Core session management interface\n* *McpClientSession* - Client-specific session implementation\n* *McpServerSession* - Server-specific session implementation", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Session Layer (Middle)", "heading_level": 3, "file_order": 58, "section_index": 3, "content_hash": "a360803a88a0167bfdb4d1782fab6682fbed9f79991dbfa937a8e0275f51cbdb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:86a4e7bdc9beccb88ade8f9591f425e8727c416a651e247a1835780e0f494827", "content": "The bottom layer handles the actual message transport and serialization:\n\n* *McpTransport* - Manages JSON-RPC message serialization and deserialization\n* Supports multiple transport implementations (STDIO, HTTP/SSE, Streamable-HTTP, etc.)\n* Provides the foundation for all higher-level communication\n\n|===\n| link:https://modelcontextprotocol.io/sdk/java/mcp-client[MCP Client] |\n\na| The MCP Client is a key component in the Model Context Protocol (MCP) architecture, responsible for establishing and managing connections with MCP servers. It implements the client-side of the protocol, handling:\n\n* Protocol version negotiation to ensure compatibility with servers\n* Capability negotiation to determine available features\n* Message transport and JSON-RPC communication\n* Tool discovery and execution\n* Resource access and management\n* Prompt system interactions\n* Optional features:\n** Roots management\n** Sampling support\n* Synchronous and asynchronous operations\n* Transport options:\n** Stdio-based transport for process-based communication\n** Java HttpClient-based SSE client transport\n** WebFlux SSE client transport for reactive HTTP streaming\n\n^a| image::mcp/java-mcp-client-architecture.jpg[Java MCP Client Architecture, width=500]\n|===\n\n|===\n| link:https://modelcontextprotocol.io/sdk/java/mcp-server[MCP Server] |\n\na| The MCP Server is a foundational component in the Model Context Protocol (MCP) architecture that provides tools, resources, and capabilities to clients. It implements the server-side of the protocol, responsible for:\n\n* Server-side protocol operations implementation\n** Tool exposure and discovery\n** Resource management with URI-based access\n** Prompt template provision and handling\n** Capability negotiation with clients\n** Structured logging and notifications\n* Concurrent client connection management\n* Synchronous and Asynchronous API support\n* Transport implementations:\n** Stdio, Streamable-HTTP, Stateless Streamable-HTTP, SSE\n\n^a| image::mcp/java-mcp-server-architecture.jpg[Java MCP Server Architecture, width=600]\n|===\n\nFor detailed implementation guidance, using the low-level MCP Client/Server APIs, refer to the link:https://modelcontextprotocol.io/sdk/java/mcp-overview[MCP Java SDK documentation].\nFor simplified setup using Spring Boot, use the MCP Boot Starters described below.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Transport Layer (Bottom)", "heading_level": 3, "file_order": 58, "section_index": 4, "content_hash": "86a4e7bdc9beccb88ade8f9591f425e8727c416a651e247a1835780e0f494827", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:a0b0c8e306d9158dde3f34cf078573c4e61154604cb0094c0726596461fac5cd", "content": "Spring AI provides MCP integration through the following Spring Boot starters:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Spring AI MCP Integration", "heading_level": 2, "file_order": 58, "section_index": 5, "content_hash": "a0b0c8e306d9158dde3f34cf078573c4e61154604cb0094c0726596461fac5cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:1ab5183c8bdb5ed9d39bc17c719c55a1f797f6a740479b5bc0f5a7d0a58949c6", "content": "* `spring-ai-starter-mcp-client` - Core starter providing `STDIO`, Servlet-based `Streamable-HTTP`, `Stateless Streamable-HTTP` and `SSE` support\n* `spring-ai-starter-mcp-client-webflux` - WebFlux-based `Streamable-HTTP`, `Stateless Streamable-HTTP` and `SSE` transport implementation", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "link:mcp-client-boot-starter-docs.html[Client Starters]", "heading_level": 3, "file_order": 58, "section_index": 6, "content_hash": "1ab5183c8bdb5ed9d39bc17c719c55a1f797f6a740479b5bc0f5a7d0a58949c6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:982629287582ce15dd6ae9fbe17524fbf61c7537b72c0e5e9724077bd0b930b8", "content": "[options=\"header\"]\n|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc[Standard Input/Output (STDIO)] | `spring-ai-starter-mcp-server` | `spring.ai.mcp.server.stdio=true`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "STDIO", "heading_level": 4, "file_order": 58, "section_index": 7, "content_hash": "982629287582ce15dd6ae9fbe17524fbf61c7537b72c0e5e9724077bd0b930b8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:d7b3c07331e59efb93d73a78541f9fbef5d8561444db532e6165fe7e31ad61db", "content": "|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc#_sse_webmvc_serve[SSE WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=SSE` or empty\n| xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc#_streamable_http_webmvc_server[Streamable-HTTP WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STREAMABLE`\n| xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc#_stateless_webmvc_server[Stateless Streamable-HTTP WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STATELESS`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "WebMVC", "heading_level": 4, "file_order": 58, "section_index": 8, "content_hash": "d7b3c07331e59efb93d73a78541f9fbef5d8561444db532e6165fe7e31ad61db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:473e375c29ae3ec25ac2f08a40c4e0c7c62a8f1a53e27a3437c47e8c0ea334f9", "content": "|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc#_sse_webflux_serve[SSE WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=SSE` or empty\n| xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc#_streamable_http_webflux_server[Streamable-HTTP WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STREAMABLE`\n| xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc#_stateless_webflux_server[Stateless Streamable-HTTP WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STATELESS`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "WebMVC (Reactive)", "heading_level": 4, "file_order": 58, "section_index": 9, "content_hash": "473e375c29ae3ec25ac2f08a40c4e0c7c62a8f1a53e27a3437c47e8c0ea334f9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:f3ebbd4658ed0a888670901cbe28511e2c94c5c3ebb3bda7fe06f67c443b5996", "content": "In addition to the programmatic MCP client & server configuration, Spring AI provides annotation-based method handling for MCP servers and clients through the xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations] module.\nThis approach simplifies the creation and registration of MCP operations using a clean, declarative programming model with Java annotations.\n\nThe MCP Annotations module enables developers to:\n\n* Create MCP tools, resources, and prompts using simple annotations\n* Handle client-side notifications and requests declaratively\n* Reduce boilerplate code and improve maintainability\n* Automatically generate JSON schemas for tool parameters\n* Access special parameters and context information\n\nKey features include:\n\n* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations]: `@McpTool`, `@McpResource`, `@McpPrompt`, `@McpComplete`\n* xref:api/mcp/mcp-annotations-client.adoc[Client Annotations]: `@McpLogging`, `@McpSampling`, `@McpElicitation`, `@McpProgress`\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters]: `McpSyncServerExchange`, `McpAsyncServerExchange`, `McpTransportContext`, `McpMeta`\n* *Automatic Discovery*: Annotation scanning with configurable package inclusion/exclusion\n* *Spring Boot Integration*: Seamless integration with MCP Boot Starters", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "xref:api/mcp/mcp-annotations-overview.adoc[Spring AI MCP Annotations]", "heading_level": 2, "file_order": 58, "section_index": 10, "content_hash": "f3ebbd4658ed0a888670901cbe28511e2c94c5c3ebb3bda7fe06f67c443b5996", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:38b83e06358228e1716bef55fdedddb65db7014378edae8d12395938c1e0d55d", "content": "* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Documentation]\n* link:mcp-client-boot-starter-docs.html[MCP Client Boot Starters Documentation]\n* link:mcp-server-boot-starter-docs.html[MCP Server Boot Starters Documentation]\n* link:mcp-helpers.html[MCP Utilities Documentation]\n* link:https://modelcontextprotocol.github.io/specification/[Model Context Protocol Specification]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc", "title": "Model Context Protocol (MCP)", "heading": "Additional Resources", "heading_level": 2, "file_order": 58, "section_index": 11, "content_hash": "38b83e06358228e1716bef55fdedddb65db7014378edae8d12395938c1e0d55d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-overview.adoc"}}
{"id": "sha256:82905004bdc3e5dc03870dd29074fd4df262a72c917133dff0745df8c241eec7", "content": "NOTE: This is still work in progress. The documentation and APIs may change in future releases.\n\nThe Spring AI MCP Security module provides comprehensive OAuth 2.0 and API key-based security support for Model Context Protocol implementations in Spring AI. This community-driven project enables developers to secure both MCP servers and clients with industry-standard authentication and authorization mechanisms.\n\nNOTE: This module is part of the link:https://github.com/spring-ai-community/mcp-security[spring-ai-community/mcp-security] project and currently works with Spring AI's 1.1.x branch only.\nThis is a community-driven project and is not officially endorsed yet by Spring AI or the MCP project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "MCP Security", "heading_level": 1, "file_order": 59, "section_index": 0, "content_hash": "82905004bdc3e5dc03870dd29074fd4df262a72c917133dff0745df8c241eec7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:7a8a20028fe55e4ce628ca5f1a70fb678c03ba393b1b7fe997d26384ac0c3dbd", "content": "The MCP Security module provides three main components:\n\n* *MCP Server Security* - OAuth 2.0 resource server and API key authentication for Spring AI MCP servers\n* *MCP Client Security* - OAuth 2.0 client support for Spring AI MCP clients\n* *MCP Authorization Server* - Enhanced Spring Authorization Server with MCP-specific features\n\nThe project enables developers to:\n\n* Secure MCP servers with OAuth 2.0 authentication and API key-based access\n* Configure MCP clients with OAuth 2.0 authorization flows\n* Set up authorization servers specifically designed for MCP workflows\n* Implement fine-grained access control for MCP tools and resources", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Overview", "heading_level": 2, "file_order": 59, "section_index": 1, "content_hash": "7a8a20028fe55e4ce628ca5f1a70fb678c03ba393b1b7fe997d26384ac0c3dbd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:86ede4b3b3e0bce2e3bac68f98f9b1607cf3c48d53bb819353082ddea97d9bc9", "content": "The MCP Server Security module provides OAuth 2.0 resource server capabilities for xref:api/mcp/mcp-server-boot-starter-docs.adoc[Spring AI's MCP servers].\nIt also provides basic support for API-key based authentication.\n\nIMPORTANT: This module is compatible with Spring WebMVC-based servers only.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "MCP Server Security", "heading_level": 2, "file_order": 59, "section_index": 2, "content_hash": "86ede4b3b3e0bce2e3bac68f98f9b1607cf3c48d53bb819353082ddea97d9bc9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:35735adc21cbdd03429d22b62c2d0a91d5500ec87ec8c23472a5a2f866121738", "content": "Add the following dependencies to your project:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependencies>\n <dependency>\n <groupId>org.springaicommunity</groupId>\n <artifactId>mcp-server-security</artifactId>\n </dependency>\n <dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-security</artifactId>\n </dependency>\n\n <!-- OPTIONAL: For OAuth2 support -->\n <dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>\n </dependency>\n</dependencies>\n----\n\nGradle::\n+\n[source,groovy]\n----\nimplementation 'org.springaicommunity:mcp-server-security'\nimplementation 'org.springframework.boot:spring-boot-starter-security'\n\nimplementation 'org.springframework.boot:spring-boot-starter-oauth2-resource-server'\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Dependencies", "heading_level": 3, "file_order": 59, "section_index": 3, "content_hash": "35735adc21cbdd03429d22b62c2d0a91d5500ec87ec8c23472a5a2f866121738", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:c5f52b546f922b499a24c6aef89a1d9be0e9d285fe9de0fc480f63cdb028749c", "content": "First, enable the MCP server in your `application.properties`:\n\n[source,properties]\n----\nspring.ai.mcp.server.name=my-cool-mcp-server\n# Supported protocols: STREAMABLE, STATELESS\nspring.ai.mcp.server.protocol=STREAMABLE\n----\n\nThen, configure security using Spring Security's standard APIs with the provided MCP configurer:\n\n[source,java]\n----\n@Configuration\n@EnableWebSecurity\nclass McpServerConfiguration {\n\n @Value(\"${spring.security.oauth2.resourceserver.jwt.issuer-uri}\")\n private String issuerUrl;\n\n @Bean\n SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n return http\n // Enforce authentication with token on EVERY request\n .authorizeHttpRequests(auth -> auth.anyRequest().authenticated())\n // Configure OAuth2 on the MCP server\n .with(\n McpServerOAuth2Configurer.mcpServerOAuth2(),\n (mcpAuthorization) -> {\n // REQUIRED: the issuerURI\n mcpAuthorization.authorizationServer(issuerUrl);\n // OPTIONAL: enforce the `aud` claim in the JWT token.\n // Not all authorization servers support resource indicators,\n // so it may be absent. Defaults to `false`.\n // See RFC 8707 Resource Indicators for OAuth 2.0\n // https://www.rfc-editor.org/rfc/rfc8707.html\n mcpAuthorization.validateAudienceClaim(true);\n }\n )\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Basic OAuth 2.0 Setup", "heading_level": 4, "file_order": 59, "section_index": 4, "content_hash": "c5f52b546f922b499a24c6aef89a1d9be0e9d285fe9de0fc480f63cdb028749c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:b41f0fbf7e25bc9d3c4355cb9fbd6a89c55d712734f0f05f68d7fa4591ed2c56", "content": "You can configure the server to secure only tool calls while leaving other MCP operations (like `initialize` and `tools/list`) public:\n\n[source,java]\n----\n@Configuration\n@EnableWebSecurity\n@EnableMethodSecurity // Enable annotation-driven security\nclass McpServerConfiguration {\n\n @Value(\"${spring.security.oauth2.resourceserver.jwt.issuer-uri}\")\n private String issuerUrl;\n\n @Bean\n SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n return http\n // Open every request on the server\n .authorizeHttpRequests(auth -> {\n auth.requestMatcher(\"/mcp\").permitAll();\n auth.anyRequest().authenticated();\n })\n // Configure OAuth2 on the MCP server\n .with(\n McpResourceServerConfigurer.mcpServerOAuth2(),\n (mcpAuthorization) -> {\n // REQUIRED: the issuerURI\n mcpAuthorization.authorizationServer(issuerUrl);\n }\n )\n .build();\n }\n}\n----\n\nThen, secure your tool calls using the `@PreAuthorize` annotation with link:https://docs.spring.io/spring-security/reference/servlet/authorization/method-security.html[method security]:\n\n[source,java]\n----\n@Service\npublic class MyToolsService {\n\n @PreAuthorize(\"isAuthenticated()\")\n @McpTool(name = \"greeter\", description = \"A tool that greets you, in the selected language\")\n public String greet(\n @ToolParam(description = \"The language for the greeting (example: english, french, ...)\") String language\n ) {\n if (!StringUtils.hasText(language)) {\n language = \"\";\n }\n return switch (language.toLowerCase()) {\n case \"english\" -> \"Hello you!\";\n case \"french\" -> \"Salut toi!\";\n default -> \"I don't understand language \\\"%s\\\". So I'm just going to say Hello!\".formatted(language);\n };\n }\n}\n----\n\nYou can also access the current authentication directly from the tool method using `SecurityContextHolder`:\n\n[source,java]\n----\n@McpTool(name = \"greeter\", description = \"A tool that greets the user by name, in the selected language\")\n@PreAuthorize(\"isAuthenticated()\")\npublic String greet(\n @ToolParam(description = \"The language for the greeting (example: english, french, ...)\") String language\n) {\n if (!StringUtils.hasText(language)) {\n language = \"\";\n }\n var authentication = SecurityContextHolder.getContext().getAuthentication();\n var name = authentication.getName();\n return switch (language.toLowerCase()) {\n case \"english\" -> \"Hello, %s!\".formatted(name);\n case \"french\" -> \"Salut %s!\".formatted(name);\n default -> (\"I don't understand language \\\"%s\\\". \" +\n \"So I'm just going to say Hello %s!\").formatted(language, name);\n };\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Securing Tool Calls Only", "heading_level": 4, "file_order": 59, "section_index": 5, "content_hash": "b41f0fbf7e25bc9d3c4355cb9fbd6a89c55d712734f0f05f68d7fa4591ed2c56", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:83ba621f9be173236e3329dd8a2288ac3cef579751a158234b9eefe489296217", "content": "The MCP Server Security module also supports API key-based authentication. You need to provide your own implementation of `ApiKeyEntityRepository` for storing `ApiKeyEntity` objects.\n\nA sample implementation is available with `InMemoryApiKeyEntityRepository` along with a default `ApiKeyEntityImpl`:\n\nWARNING: The `InMemoryApiKeyEntityRepository` uses bcrypt for storing API keys, which is computationally expensive. It is not suited for high-traffic production use. For production, implement your own `ApiKeyEntityRepository`.\n\n[source,java]\n----\n@Configuration\n@EnableWebSecurity\nclass McpServerConfiguration {\n\n @Bean\n SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n return http.authorizeHttpRequests(authz -> authz.anyRequest().authenticated())\n .with(\n mcpServerApiKey(),\n (apiKey) -> {\n // REQUIRED: the repo for API keys\n apiKey.apiKeyRepository(apiKeyRepository());\n\n // OPTIONAL: name of the header containing the API key.\n // Here for example, api keys will be sent with \"CUSTOM-API-KEY: <value>\"\n // Replaces .authenticationConverter(...) (see below)\n //\n // apiKey.headerName(\"CUSTOM-API-KEY\");\n\n // OPTIONAL: custom converter for transforming an http request\n // into an authentication object. Useful when the header is\n // \"Authorization: Bearer <value>\".\n // Replaces .headerName(...) (see above)\n //\n // apiKey.authenticationConverter(request -> {\n // var key = extractKey(request);\n // return ApiKeyAuthenticationToken.unauthenticated(key);\n // });\n }\n )\n .build();\n }\n\n /**\n * Provide a repository of {@link ApiKeyEntity}.\n */\n private ApiKeyEntityRepository<ApiKeyEntityImpl> apiKeyRepository() {\n var apiKey = ApiKeyEntityImpl.builder()\n .name(\"test api key\")\n .id(\"api01\")\n .secret(\"mycustomapikey\")\n .build();\n\n return new InMemoryApiKeyEntityRepository<>(List.of(apiKey));\n }\n}\n----\n\nWith this configuration, you can call your MCP server with a header `X-API-key: api01.mycustomapikey`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "API Key Authentication", "heading_level": 3, "file_order": 59, "section_index": 6, "content_hash": "83ba621f9be173236e3329dd8a2288ac3cef579751a158234b9eefe489296217", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:898a86cfe1689b4543abf066c90ac40c996472cdc2f8afa6a153661a678d5b60", "content": "[IMPORTANT]\n====\n\n* The deprecated SSE transport is not supported. Use xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc[Streamable HTTP] or xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc[stateless transport].\n* WebFlux-based servers are not supported.\n* Opaque tokens are not supported. Use JWT.\n\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Known Limitations", "heading_level": 3, "file_order": 59, "section_index": 7, "content_hash": "898a86cfe1689b4543abf066c90ac40c996472cdc2f8afa6a153661a678d5b60", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:0257f9c80fb3b845b1c7cd672ccae9bbf4df7c20266a4eb281f28ad59cb18407", "content": "The MCP Client Security module provides OAuth 2.0 support for xref:api/mcp/mcp-client-boot-starter-docs.adoc[Spring AI's MCP clients], supporting both HttpClient-based clients (from `spring-ai-starter-mcp-client`) and WebClient-based clients (from `spring-ai-starter-mcp-client-webflux`).\n\nIMPORTANT: This module supports `McpSyncClient` only.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "MCP Client Security", "heading_level": 2, "file_order": 59, "section_index": 8, "content_hash": "0257f9c80fb3b845b1c7cd672ccae9bbf4df7c20266a4eb281f28ad59cb18407", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:3639ab3dfb8a5c5c948ba1c55cd5b54c072955fafc6b45fdf7b96f5d4375fe92", "content": "[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springaicommunity</groupId>\n <artifactId>mcp-client-security</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\nimplementation 'org.springaicommunity:mcp-client-security'\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Dependencies", "heading_level": 3, "file_order": 59, "section_index": 9, "content_hash": "3639ab3dfb8a5c5c948ba1c55cd5b54c072955fafc6b45fdf7b96f5d4375fe92", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:98c3cdd6e6960314161aabef731625e8803bccbabd0fbbf6ebe5b9c1595fc166", "content": "Three OAuth 2.0 flows are available for obtaining tokens:\n\n* *Authorization Code Flow* - For user-level permissions when every MCP request is made within the context of a user request\n* *Client Credentials Flow* - For machine-to-machine use cases where no human is in the loop\n* *Hybrid Flow* - Combines both flows for scenarios where some operations (like `initialize` or `tools/list`) happen without a user present, but tool calls require user-level permissions\n\nTIP: Use authorization code flow when you have user-level permissions and all MCP requests occur within user context. Use client credentials for machine-to-machine communication. Use hybrid flow when using Spring Boot properties for MCP client configuration, as tool discovery happens at startup without a user present.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Authorization Flows", "heading_level": 3, "file_order": 59, "section_index": 10, "content_hash": "98c3cdd6e6960314161aabef731625e8803bccbabd0fbbf6ebe5b9c1595fc166", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:a9aeeee5dda69f8d77e7177d9ca102535720628e531df180097e38f6e04da5ef", "content": "For all flows, activate Spring Security's OAuth2 client support in your `application.properties`:\n\n[source,properties]\n----\n# Ensure MCP clients are sync\nspring.ai.mcp.client.type=SYNC\n\n# For authorization_code or hybrid flow\nspring.security.oauth2.client.registration.authserver.client-id=<THE CLIENT ID>\nspring.security.oauth2.client.registration.authserver.client-secret=<THE CLIENT SECRET>\nspring.security.oauth2.client.registration.authserver.authorization-grant-type=authorization_code\nspring.security.oauth2.client.registration.authserver.provider=authserver\n\n# For client_credentials or hybrid flow\nspring.security.oauth2.client.registration.authserver-client-credentials.client-id=<THE CLIENT ID>\nspring.security.oauth2.client.registration.authserver-client-credentials.client-secret=<THE CLIENT SECRET>\nspring.security.oauth2.client.registration.authserver-client-credentials.authorization-grant-type=client_credentials\nspring.security.oauth2.client.registration.authserver-client-credentials.provider=authserver\n\n# Authorization server configuration\nspring.security.oauth2.client.provider.authserver.issuer-uri=<THE ISSUER URI OF YOUR AUTH SERVER>\n----\n\nThen, create a configuration class activating OAuth2 client capabilities:\n\n[source,java]\n----\n@Configuration\n@EnableWebSecurity\nclass SecurityConfiguration {\n\n @Bean\n SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n return http\n // in this example, the client app has no security on its endpoints\n .authorizeHttpRequests(auth -> auth.anyRequest().permitAll())\n // turn on OAuth2 support\n .oauth2Client(Customizer.withDefaults())\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Common Setup", "heading_level": 3, "file_order": 59, "section_index": 11, "content_hash": "a9aeeee5dda69f8d77e7177d9ca102535720628e531df180097e38f6e04da5ef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:282f01ed73d555fc9986c58714464b8dd1b3277c1296ba9658573a289b780f76", "content": "When using `spring-ai-starter-mcp-client`, configure a `McpSyncHttpClientRequestCustomizer` bean:\n\n[source,java]\n----\n@Configuration\nclass McpConfiguration {\n\n @Bean\n McpSyncClientCustomizer syncClientCustomizer() {\n return (name, syncSpec) ->\n syncSpec.transportContextProvider(\n new AuthenticationMcpTransportContextProvider()\n );\n }\n\n @Bean\n McpSyncHttpClientRequestCustomizer requestCustomizer(\n OAuth2AuthorizedClientManager clientManager\n ) {\n // The clientRegistration name, \"authserver\",\n // must match the name in application.properties\n return new OAuth2AuthorizationCodeSyncHttpRequestCustomizer(\n clientManager,\n \"authserver\"\n );\n }\n}\n----\n\nAvailable customizers:\n\n* `OAuth2AuthorizationCodeSyncHttpRequestCustomizer` - For authorization code flow\n* `OAuth2ClientCredentialsSyncHttpRequestCustomizer` - For client credentials flow\n* `OAuth2HybridSyncHttpRequestCustomizer` - For hybrid flow", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "HttpClient-Based Clients", "heading_level": 3, "file_order": 59, "section_index": 12, "content_hash": "282f01ed73d555fc9986c58714464b8dd1b3277c1296ba9658573a289b780f76", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:285423abbb4cb0fe1237d1046d088ebe8145e7501e17997477429f50b07f659a", "content": "When using `spring-ai-starter-mcp-client-webflux`, configure a `WebClient.Builder` with an MCP `ExchangeFilterFunction`:\n\n[source,java]\n----\n@Configuration\nclass McpConfiguration {\n\n @Bean\n McpSyncClientCustomizer syncClientCustomizer() {\n return (name, syncSpec) ->\n syncSpec.transportContextProvider(\n new AuthenticationMcpTransportContextProvider()\n );\n }\n\n @Bean\n WebClient.Builder mcpWebClientBuilder(OAuth2AuthorizedClientManager clientManager) {\n // The clientRegistration name, \"authserver\", must match the name in application.properties\n return WebClient.builder().filter(\n new McpOAuth2AuthorizationCodeExchangeFilterFunction(\n clientManager,\n \"authserver\"\n )\n );\n }\n}\n----\n\nAvailable filter functions:\n\n* `McpOAuth2AuthorizationCodeExchangeFilterFunction` - For authorization code flow\n* `McpOAuth2ClientCredentialsExchangeFilterFunction` - For client credentials flow\n* `McpOAuth2HybridExchangeFilterFunction` - For hybrid flow", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "WebClient-Based Clients", "heading_level": 3, "file_order": 59, "section_index": 13, "content_hash": "285423abbb4cb0fe1237d1046d088ebe8145e7501e17997477429f50b07f659a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:2d8bbd6b4e6e436aeeed2d150ebf9d8d2e4ad3cd816d89413f2160a12ce39751", "content": "Spring AI's autoconfiguration initializes MCP clients at startup, which can cause issues with user-based authentication. To avoid this:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Working Around Spring AI Autoconfiguration", "heading_level": 3, "file_order": 59, "section_index": 14, "content_hash": "2d8bbd6b4e6e436aeeed2d150ebf9d8d2e4ad3cd816d89413f2160a12ce39751", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:168b475f8227996de76810a2611ba2ff3f312420598caaf68594ec2c63b18feb", "content": "Disable Spring AI's `@Tool` autoconfiguration by publishing an empty `ToolCallbackResolver` bean:\n\n[source,java]\n----\n@Configuration\npublic class McpConfiguration {\n\n @Bean\n ToolCallbackResolver resolver() {\n return new StaticToolCallbackResolver(List.of());\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Option 1: Disable @Tool Auto-configuration", "heading_level": 4, "file_order": 59, "section_index": 15, "content_hash": "168b475f8227996de76810a2611ba2ff3f312420598caaf68594ec2c63b18feb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:d72cd00ca807a02c648d1ecaf78270ca8744fe77bf8dedc660414f2081701de7", "content": "Configure MCP clients programmatically instead of using Spring Boot properties. For HttpClient-based clients:\n\n[source,java]\n----\n@Bean\nMcpSyncClient client(\n ObjectMapper objectMapper,\n McpSyncHttpClientRequestCustomizer requestCustomizer,\n McpClientCommonProperties commonProps\n) {\n var transport = HttpClientStreamableHttpTransport.builder(mcpServerUrl)\n .clientBuilder(HttpClient.newBuilder())\n .jsonMapper(new JacksonMcpJsonMapper(objectMapper))\n .httpRequestCustomizer(requestCustomizer)\n .build();\n\n var clientInfo = new McpSchema.Implementation(\"client-name\", commonProps.getVersion());\n\n return McpClient.sync(transport)\n .clientInfo(clientInfo)\n .requestTimeout(commonProps.getRequestTimeout())\n .transportContextProvider(new AuthenticationMcpTransportContextProvider())\n .build();\n}\n----\n\nFor WebClient-based clients:\n\n[source,java]\n----\n@Bean\nMcpSyncClient client(\n WebClient.Builder mcpWebClientBuilder,\n ObjectMapper objectMapper,\n McpClientCommonProperties commonProperties\n) {\n var builder = mcpWebClientBuilder.baseUrl(mcpServerUrl);\n var transport = WebClientStreamableHttpTransport.builder(builder)\n .jsonMapper(new JacksonMcpJsonMapper(objectMapper))\n .build();\n\n var clientInfo = new McpSchema.Implementation(\"clientName\", commonProperties.getVersion());\n\n return McpClient.sync(transport)\n .clientInfo(clientInfo)\n .requestTimeout(commonProperties.getRequestTimeout())\n .transportContextProvider(new AuthenticationMcpTransportContextProvider())\n .build();\n}\n----\n\nThen add the client to your chat client:\n\n[source,java]\n----\nvar chatResponse = chatClient.prompt(\"Prompt the LLM to do the thing\")\n .toolCallbacks(new SyncMcpToolCallbackProvider(mcpClient1, mcpClient2, mcpClient3))\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Option 2: Programmatic Client Configuration", "heading_level": 4, "file_order": 59, "section_index": 16, "content_hash": "d72cd00ca807a02c648d1ecaf78270ca8744fe77bf8dedc660414f2081701de7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:87ebeab56e8e2dff3acf019aa0ad99e63f231a57cc295ddd6e9616bd35cd300d", "content": "[IMPORTANT]\n====\n\n* Spring WebFlux servers are not supported.\n* Spring AI autoconfiguration initializes MCP clients at app start, requiring workarounds for user-based authentication.\n* Unlike the server module, the client implementation supports the SSE transport with both `HttpClient` and `WebClient`.\n\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Known Limitations", "heading_level": 3, "file_order": 59, "section_index": 17, "content_hash": "87ebeab56e8e2dff3acf019aa0ad99e63f231a57cc295ddd6e9616bd35cd300d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:711fdd1b86ed7b99a893e647bdfb08e3b8f5a776f9dea0bf8a93d99d6beb70be", "content": "The MCP Authorization Server module enhances link:https://docs.spring.io/spring-security/reference/7.0/servlet/oauth2/authorization-server/index.html[Spring Security's OAuth 2.0 Authorization Server] with features relevant to the link:https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization[MCP authorization spec], such as Dynamic Client Registration and Resource Indicators.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "MCP Authorization Server", "heading_level": 2, "file_order": 59, "section_index": 18, "content_hash": "711fdd1b86ed7b99a893e647bdfb08e3b8f5a776f9dea0bf8a93d99d6beb70be", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:c289b2c2aacc127aaeed237376e32f874d9a1faf2ecfa97433b6cf77fbdfcb29", "content": "[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springaicommunity</groupId>\n <artifactId>mcp-authorization-server</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\nimplementation 'org.springaicommunity:mcp-authorization-server'\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Dependencies", "heading_level": 3, "file_order": 59, "section_index": 19, "content_hash": "c289b2c2aacc127aaeed237376e32f874d9a1faf2ecfa97433b6cf77fbdfcb29", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:9afceb782794f76ec790c72df47241687692cebb2132c1f7a66585dd70a4125c", "content": "Configure the authorization server in your `application.yml`:\n\n[source,yaml]\n----\nspring:\n application:\n name: sample-authorization-server\n security:\n oauth2:\n authorizationserver:\n client:\n default-client:\n token:\n access-token-time-to-live: 1h\n registration:\n client-id: \"default-client\"\n client-secret: \"{noop}default-secret\"\n client-authentication-methods:\n - \"client_secret_basic\"\n - \"none\"\n authorization-grant-types:\n - \"authorization_code\"\n - \"client_credentials\"\n redirect-uris:\n - \"http://127.0.0.1:8080/authorize/oauth2/code/authserver\"\n - \"http://localhost:8080/authorize/oauth2/code/authserver\"\n # mcp-inspector\n - \"http://localhost:6274/oauth/callback\"\n # claude code\n - \"https://claude.ai/api/mcp/auth_callback\"\n user:\n # A single user, named \"user\"\n name: user\n password: password\n\nserver:\n servlet:\n session:\n cookie:\n # Override the default cookie name (JSESSIONID).\n # This allows running multiple Spring apps on localhost, and they'll each have their own cookie.\n # Otherwise, since the cookies do not take the port into account, they are confused.\n name: MCP_AUTHORIZATION_SERVER_SESSIONID\n----\n\nThen activate the authorization server capabilities with a security filter chain:\n\n[source,java]\n----\n@Bean\nSecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n return http\n // all requests must be authenticated\n .authorizeHttpRequests(auth -> auth.anyRequest().authenticated())\n // enable authorization server customizations\n .with(McpAuthorizationServerConfigurer.mcpAuthorizationServer(), withDefaults())\n // enable form-based login, for user \"user\"/\"password\"\n .formLogin(withDefaults())\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Configuration", "heading_level": 3, "file_order": 59, "section_index": 20, "content_hash": "9afceb782794f76ec790c72df47241687692cebb2132c1f7a66585dd70a4125c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:7db1ccadcabdcfea8bceb7b2a93872e3335bed61cae592e4c2b2efb77ccde1b5", "content": "[IMPORTANT]\n====\n\n* Spring WebFlux servers are not supported.\n* Every client supports ALL `resource` identifiers.\n\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Known Limitations", "heading_level": 3, "file_order": 59, "section_index": 21, "content_hash": "7db1ccadcabdcfea8bceb7b2a93872e3335bed61cae592e4c2b2efb77ccde1b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:fda97ec7b09468d221e12bbbb0ae0c1cdb60546427b20044a261dd6afb9cd810", "content": "The link:https://github.com/spring-ai-community/mcp-security/tree/main/samples[samples directory] contains working examples for all modules in this project, including integration tests.\n\nWith `mcp-server-security` and a supporting `mcp-authorization-server`, you can integrate with:\n\n* Cursor\n* Claude Desktop\n* link:https://modelcontextprotocol.io/docs/tools/inspector[MCP Inspector]\n\nNOTE: When using the link:https://modelcontextprotocol.io/docs/tools/inspector[MCP Inspector], you may need to disable CSRF and CORS protection.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Samples and Integrations", "heading_level": 2, "file_order": 59, "section_index": 22, "content_hash": "fda97ec7b09468d221e12bbbb0ae0c1cdb60546427b20044a261dd6afb9cd810", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:fc91659d236e53e9b8f091fe535e5bbf55cfc3ae9fccf2449a8ccef5c140a5a4", "content": "* link:https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization#communication-security[MCP Authorization Specification]\n* link:https://github.com/spring-ai-community/mcp-security[MCP Security GitHub Repository]\n* link:https://github.com/spring-ai-community/mcp-security/tree/main/samples[Sample Applications]\n* link:https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization[MCP Authorization Specification]\n* link:https://docs.spring.io/spring-security/reference/servlet/oauth2/resource-server/index.html[Spring Security OAuth 2.0 Resource Server]\n* link:https://docs.spring.io/spring-security/reference/servlet/oauth2/client/index.html[Spring Security OAuth 2.0 Client]\n* link:https://docs.spring.io/spring-security/reference/7.0/servlet/oauth2/authorization-server/index.html[Spring Authorization Server]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-security.adoc", "title": "MCP Security", "heading": "Additional Resources", "heading_level": 2, "file_order": 59, "section_index": 23, "content_hash": "fc91659d236e53e9b8f091fe535e5bbf55cfc3ae9fccf2449a8ccef5c140a5a4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-security.adoc"}}
{"id": "sha256:d4e5d60dd02e27e5f4e0988e9926e3b3e0c2b09911c2c3bb05aa0b0f3a4f2fde", "content": "link:https://modelcontextprotocol.io/docs/learn/server-concepts[Model Context Protocol (MCP) Servers] are programs that expose specific capabilities to AI applications through standardized protocol interfaces.\nEach server provides focused functionality for a particular domain.\n\nThe Spring AI MCP Server Boot Starters provide auto-configuration for setting up link:https://modelcontextprotocol.io/docs/learn/server-concepts[MCP Servers] in Spring Boot applications.\nThey enable seamless integration of MCP server capabilities with Spring Boot's auto-configuration system.\n\nThe MCP Server Boot Starters offer:\n\n* Automatic configuration of MCP server components, including tools, resources, and prompts\n* Support for different MCP protocol versions, including STDIO, SSE, Streamable-HTTP, and stateless servers\n* Support for both synchronous and asynchronous operation modes\n* Multiple transport layer options\n* Flexible tool, resource, and prompt specification\n* Change notification capabilities\n* xref:api/mcp/mcp-annotations-server.adoc[Annotation-based server development] with automatic bean scanning and registration", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "MCP Server Boot Starter", "heading_level": 1, "file_order": 60, "section_index": 0, "content_hash": "d4e5d60dd02e27e5f4e0988e9926e3b3e0c2b09911c2c3bb05aa0b0f3a4f2fde", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:71f9941c4c4bd51301e36f3cff65ba66703992ad687341b2ea72fa0e4a9fd137", "content": "MCP Servers support multiple protocol and transport mechanisms.\nUse the dedicated starter and the correct `spring.ai.mcp.server.protocol` property to configure your server:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "MCP Server Boot Starters", "heading_level": 2, "file_order": 60, "section_index": 1, "content_hash": "71f9941c4c4bd51301e36f3cff65ba66703992ad687341b2ea72fa0e4a9fd137", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:b12d726a415d65675a09795f96b31aa5ea12d6c444c9dfee69d973beab5f28c9", "content": "[options=\"header\"]\n|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc[Standard Input/Output (STDIO)] | `spring-ai-starter-mcp-server` | `spring.ai.mcp.server.stdio=true`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "STDIO", "heading_level": 3, "file_order": 60, "section_index": 2, "content_hash": "b12d726a415d65675a09795f96b31aa5ea12d6c444c9dfee69d973beab5f28c9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:96e7105de95faf2d8918793f5512f3f4cb5d96ea43246667ef968b13e6b446e3", "content": "|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc#_sse_webmvc_serve[SSE WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=SSE` or empty\n| xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc#_streamable_http_webmvc_server[Streamable-HTTP WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STREAMABLE`\n| xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc#_stateless_webmvc_server[Stateless WebMVC] | `spring-ai-starter-mcp-server-webmvc` | `spring.ai.mcp.server.protocol=STATELESS`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "WebMVC", "heading_level": 3, "file_order": 60, "section_index": 3, "content_hash": "96e7105de95faf2d8918793f5512f3f4cb5d96ea43246667ef968b13e6b446e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:0a710530bc1e5bcab77bd8f660230b3be140a014bf1fcbabfb9311f174ca93d3", "content": "|===\n|Server Type | Dependency | Property\n| xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc#_sse_webflux_serve[SSE WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=SSE` or empty\n| xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc#_streamable_http_webflux_server[Streamable-HTTP WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STREAMABLE`\n| xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc#_stateless_webflux_server[Stateless WebFlux] | `spring-ai-starter-mcp-server-webflux` | `spring.ai.mcp.server.protocol=STATELESS`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "WebMVC (Reactive)", "heading_level": 3, "file_order": 60, "section_index": 4, "content_hash": "0a710530bc1e5bcab77bd8f660230b3be140a014bf1fcbabfb9311f174ca93d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:26830534c96834428136e52080d43e0ec8a4e1ae988bc698f858660dae417a49", "content": "Depending on the server and transport types, MCP Servers can support various capabilities, such as:\n\n* **Tools** - Allows servers to expose tools that can be invoked by language models\n* **Resources** - Provides a standardized way for servers to expose resources to clients\n* **Prompts** - Provides a standardized way for servers to expose prompt templates to clients\n* **Utility/Completions** - Provides a standardized way for servers to offer argument autocompletion suggestions for prompts and resource URIs\n* **Utility/Logging** - Provides a standardized way for servers to send structured log messages to clients\n* **Utility/Progress** - Optional progress tracking for long-running operations through notification messages\n* **Utility/Ping** - Optional health check mechanism for the server to report its status\n\nAll capabilities are enabled by default. Disabling a capability will prevent the server from registering and exposing the corresponding features to clients.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Server Capabilities", "heading_level": 2, "file_order": 60, "section_index": 5, "content_hash": "26830534c96834428136e52080d43e0ec8a4e1ae988bc698f858660dae417a49", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:0e5ccb45e914f772545a615f0d4087bb60116221e839f9db604c493b9cd62c6a", "content": "MCP provides several protocol types including:\n\n* xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc[**STDIO**] - In process (e.g. server runs inside the host application) protocol. Communication is over standard in and standard out. To enable the `STDIO` set `spring.ai.mcp.server.stdio=true`.\n* xref:api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc#_sse_webmvc_server[**SSE**] - Server-sent events protocol for real-time updates. The server operates as an independent process that can handle multiple client connections.\n* xref:api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc[**Streamable-HTTP**] - The link:https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#streamable-http[Streamable HTTP transport] allows MCP servers to operate as independent processes that can handle multiple client connections using HTTP POST and GET requests, with optional Server-Sent Events (SSE) streaming for multiple server messages. It replaces the SSE transport. To enable the `STREAMABLE` protocol, set `spring.ai.mcp.server.protocol=STREAMABLE`.\n* xref:api/mcp/mcp-stateless-server-boot-starter-docs.adoc[**Stateless**] - Stateless MCP servers are designed for simplified deployments where session state is not maintained between requests.\nThey are ideal for microservices architectures and cloud-native deployments. To enable the `STATELESS` protocol, set `spring.ai.mcp.server.protocol=STATELESS`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Server Protocols", "heading_level": 2, "file_order": 60, "section_index": 6, "content_hash": "0e5ccb45e914f772545a615f0d4087bb60116221e839f9db604c493b9cd62c6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:2f555503df29460b99ef1643ad91db9da6438b7290de1e745e54044493508a2c", "content": "The MCP Server API supports imperative (i.e. synchronous) and reactive (e.g. asynchronous) programming models.\n\n* **Synchronous Server** - The default server type implemented using `McpSyncServer`.\nIt is designed for straightforward request-response patterns in your applications.\nTo enable this server type, set `spring.ai.mcp.server.type=SYNC` in your configuration.\nWhen activated, it automatically handles the configuration of synchronous tool specifications.\n\n**NOTE:** The SYNC server will register only synchronous MCP annotated methods. Asynchronous methods will be ignored.\n\n* **Asynchronous Server** - The asynchronous server implementation uses `McpAsyncServer` and is optimized for non-blocking operations.\nTo enable this server type, configure your application with `spring.ai.mcp.server.type=ASYNC`.\nThis server type automatically sets up asynchronous tool specifications with built-in Project Reactor support.\n\n**NOTE:** The ASYNC server will register only asynchronous MCP annotated methods. Synchronous methods will be ignored.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Sync/Async Server API Options", "heading_level": 2, "file_order": 60, "section_index": 7, "content_hash": "2f555503df29460b99ef1643ad91db9da6438b7290de1e745e54044493508a2c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:cdf01df507b94514ee1b3d42392133e1c800a6ba55144d0b3601c9da479d6963", "content": "The MCP Server Boot Starters provide comprehensive support for annotation-based server development, allowing you to create MCP servers using declarative Java annotations instead of manual configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "MCP Server Annotations", "heading_level": 2, "file_order": 60, "section_index": 8, "content_hash": "cdf01df507b94514ee1b3d42392133e1c800a6ba55144d0b3601c9da479d6963", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:55371c6ea2888f24bf1977af75c29ddf90eb78174e2a0e0a400ee96db2874c71", "content": "* **xref:api/mcp/mcp-annotations-server.adoc#_mcptool[@McpTool]** - Mark methods as MCP tools with automatic JSON schema generation\n* **xref:api/mcp/mcp-annotations-server.adoc#_mcpresource[@McpResource]** - Provide access to resources via URI templates\n* **xref:api/mcp/mcp-annotations-server.adoc#_mcpprompt[@McpPrompt]** - Generate prompt messages for AI interactions\n* **xref:api/mcp/mcp-annotations-server.adoc#_mcpcomplete[@McpComplete]** - Provide auto-completion functionality for prompts", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Key Annotations", "heading_level": 3, "file_order": 60, "section_index": 9, "content_hash": "55371c6ea2888f24bf1977af75c29ddf90eb78174e2a0e0a400ee96db2874c71", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:a666ac2883d4e9a378a9df119a700b61a26e3c0c775dd47aa1067e9e917a19e0", "content": "The annotation system supports xref:api/mcp/mcp-annotations-special-params.adoc[special parameter types] that provide additional context:\n\n* **`McpMeta`** - Access metadata from MCP requests\n* **`@McpProgressToken`** - Receive progress tokens for long-running operations\n* **`McpSyncServerExchange`/`McpAsyncServerExchange`** - Full server context for advanced operations\n* **`McpTransportContext`** - Lightweight context for stateless operations\n* **`CallToolRequest`** - Dynamic schema support for flexible tools", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Special Parameters", "heading_level": 3, "file_order": 60, "section_index": 10, "content_hash": "a666ac2883d4e9a378a9df119a700b61a26e3c0c775dd47aa1067e9e917a19e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:788d15bf96758da9fd34274644e084bd0ffdcf4a27944dd106bc3cf9e588a790", "content": "[source,java]\n----\n@Component\npublic class CalculatorTools {\n\n @McpTool(name = \"add\", description = \"Add two numbers together\")\n public int add(\n @McpToolParam(description = \"First number\", required = true) int a,\n @McpToolParam(description = \"Second number\", required = true) int b) {\n return a + b;\n }\n\n @McpResource(uri = \"config://{key}\", name = \"Configuration\")\n public String getConfig(String key) {\n return configData.get(key);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Simple Example", "heading_level": 3, "file_order": 60, "section_index": 11, "content_hash": "788d15bf96758da9fd34274644e084bd0ffdcf4a27944dd106bc3cf9e588a790", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:c08f9952d7520810bc8f011b4ace36bcf1e8c02f189180947c3f6bf2c1c695ce", "content": "By default, the `McpTransportContext` is empty (`McpTransportContext.EMPTY`).\nThis is by design, to keep the MCP server transport-agnostic.\n\nIf you need transport-specific metadata (for example, HTTP headers, remote host, etc) in your tools,\nconfigure a `TransportContextExtractor` on your transport provider.\n\n[source,java]\n----\n@Bean\npublic WebMvcStreamableServerTransportProvider transport(ObjectMapper objectMapper) {\n return WebMvcStreamableServerTransportProvider.builder()\n .contextExtractor(serverRequest -> {\n String authorization = serverRequest.headers().firstHeader(\"Authorization\");\n return McpTransportContext.create(Map.of(\"authorization\", authorization));\n })\n .build();\n}\n----\n\nOnce configured, access the context via `McpSyncRequestContext` (or `McpAsyncRequestContext`) in your tool.\n\n[source,java]\n----\n@McpTool\npublic String accessProtectedResource(McpSyncRequestContext requestContext) {\n McpTransportContext context = requestContext.transportContext();\n String authorization = (String) context.get(\"authorization\");\n\n return \"Successfully accessed protected resource.\";\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Adding data to McpTransportContext", "heading_level": 3, "file_order": 60, "section_index": 12, "content_hash": "c08f9952d7520810bc8f011b4ace36bcf1e8c02f189180947c3f6bf2c1c695ce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:66665c15fd4d285d312580c56705bf45dda33a920355660c2f61288ac20f742e", "content": "With Spring Boot auto-configuration, annotated beans are automatically detected and registered:\n\n[source,java]\n----\n@SpringBootApplication\npublic class McpServerApplication {\n public static void main(String[] args) {\n SpringApplication.run(McpServerApplication.class, args);\n }\n}\n----\n\nThe auto-configuration will:\n\n1. Scan for beans with MCP annotations\n2. Create appropriate specifications\n3. Register them with the MCP server\n4. Handle both sync and async implementations based on configuration", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Auto-Configuration", "heading_level": 3, "file_order": 60, "section_index": 13, "content_hash": "66665c15fd4d285d312580c56705bf45dda33a920355660c2f61288ac20f742e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:fef8a5ff54a9a8d1bc314308788b12868d01b53691c0947ecb030f2466168c6a", "content": "Configure the server annotation scanner:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n type: SYNC # or ASYNC\n annotation-scanner:\n enabled: true\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Configuration Properties", "heading_level": 3, "file_order": 60, "section_index": 14, "content_hash": "fef8a5ff54a9a8d1bc314308788b12868d01b53691c0947ecb030f2466168c6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:edada292d798cb077dba296f082f71a1af67638c549ac416cc85f3348bfe28be", "content": "* xref:api/mcp/mcp-annotations-server.adoc[Server Annotations Reference] - Complete guide to server annotations\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters] - Advanced parameter injection\n* xref:api/mcp/mcp-annotations-examples.adoc[Examples] - Comprehensive examples and use cases", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Additional Resources", "heading_level": 3, "file_order": 60, "section_index": 15, "content_hash": "edada292d798cb077dba296f082f71a1af67638c549ac416cc85f3348bfe28be", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:5a19189f8ae35cbdf96c0607a7f611cb3230b989cb0ac811f98ba2ded43f4073", "content": "* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-webflux-server[Weather Server (SSE WebFlux)] - Spring AI MCP Server Boot Starter with WebFlux transport\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-stdio-server[Weather Server (STDIO)] - Spring AI MCP Server Boot Starter with STDIO transport\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/manual-webflux-server[Weather Server Manual Configuration] - Spring AI MCP Server Boot Starter that doesn't use auto-configuration but uses the Java SDK to configure the server manually\n* Streamable-HTTP WebFlux/WebMVC Example - TODO\n* Stateless WebFlux/WebMVC Example - TODO", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Example Applications", "heading_level": 2, "file_order": 60, "section_index": 16, "content_hash": "5a19189f8ae35cbdf96c0607a7f611cb3230b989cb0ac811f98ba2ded43f4073", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:99f32b2d2f78f5741ea6306a1011d0354c75f553cb1361818545dbae09ef43aa", "content": "* xref:api/mcp/mcp-annotations-server.adoc[MCP Server Annotations] - Declarative server development with annotations\n* xref:api/mcp/mcp-annotations-special-params.adoc[Special Parameters] - Advanced parameter injection and context access\n* xref:api/mcp/mcp-annotations-examples.adoc[MCP Annotations Examples] - Comprehensive examples and use cases\n* link:https://docs.spring.io/spring-ai/reference/[Spring AI Documentation]\n* link:https://modelcontextprotocol.io/specification[Model Context Protocol Specification]\n* link:https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.developing-auto-configuration[Spring Boot Auto-configuration]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc", "title": "MCP Server Boot Starter", "heading": "Additional Resources", "heading_level": 2, "file_order": 60, "section_index": 17, "content_hash": "99f32b2d2f78f5741ea6306a1011d0354c75f553cb1361818545dbae09ef43aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-server-boot-starter-docs.adoc"}}
{"id": "sha256:ecbf2f785112e6a644256a256faee498b70ca990b8f25570b4cd0a27d92fef35", "content": "Stateless Streamable-HTTP MCP servers are designed for simplified deployments where session state is not maintained between requests.\nThese servers are ideal for microservices architectures and cloud-native deployments.\n\nTIP: Set the `spring.ai.mcp.server.protocol=STATELESS` property\n\nTIP: Use the xref:api/mcp/mcp-client-boot-starter-docs#_streamable_http_transport_properties[Streamable-HTTP clients] to connect to the stateless servers.\n\nNOTE: The stateless servers don't support message requests to the MCP client (e.g., elicitation, sampling, ping).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Stateless Streamable-HTTP MCP Servers", "heading_level": 2, "file_order": 61, "section_index": 0, "content_hash": "ecbf2f785112e6a644256a256faee498b70ca990b8f25570b4cd0a27d92fef35", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:c0c9dca08eb79a1ef633d55a3bc0d7e0fc14869ea38e289065bcf2adfc12a0d7", "content": "Use the `spring-ai-starter-mcp-server-webmvc` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webmvc</artifactId>\n</dependency>\n----\n\nand set the `spring.ai.mcp.server.protocol` property to `STATELESS`.\n\n----\nspring.ai.mcp.server.protocol=STATELESS\n----\n\n- Stateless operation with Spring MVC transport\n- No session state management\n- Simplified deployment model\n- Optimized for cloud-native environments", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Stateless WebMVC Server", "heading_level": 3, "file_order": 61, "section_index": 1, "content_hash": "c0c9dca08eb79a1ef633d55a3bc0d7e0fc14869ea38e289065bcf2adfc12a0d7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:98bba3f40c57cdc180c7f8df9f5f5e505ffd71960f3ea0758480a103eef3f6f4", "content": "Use the `spring-ai-starter-mcp-server-webflux` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webflux</artifactId>\n</dependency>\n----\n\nand set the `spring.ai.mcp.server.protocol` property to `STATELESS`.\n\n- Reactive stateless operation with WebFlux transport\n- No session state management\n- Non-blocking request processing\n- Optimized for high-throughput scenarios", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Stateless WebFlux Server", "heading_level": 3, "file_order": 61, "section_index": 2, "content_hash": "98bba3f40c57cdc180c7f8df9f5f5e505ffd71960f3ea0758480a103eef3f6f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:d4baf8c3e7cc9c50a24c766414d03cf9a46a9fa6474d759587e9545c14fa33e1", "content": "All Common properties are prefixed with `spring.ai.mcp.server`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`enabled` |Enable/disable the stateless MCP server |`true`\n|`protocol` |MCP server protocol | Must be set to `STATELESS` to enable the stateless server\n|`tool-callback-converter` |Enable/disable the conversion of Spring AI ToolCallbacks into MCP Tool specs |`true`\n|`name` |Server name for identification |`mcp-server`\n|`version` |Server version |`1.0.0`\n|`instructions` |Optional instructions for client interaction |`null`\n|`type` |Server type (SYNC/ASYNC) |`SYNC`\n|`capabilities.resource` |Enable/disable resource capabilities |`true`\n|`capabilities.tool` |Enable/disable tool capabilities |`true`\n|`capabilities.prompt` |Enable/disable prompt capabilities |`true`\n|`capabilities.completion` |Enable/disable completion capabilities |`true`\n|`tool-response-mime-type` |Response MIME type per tool name |`-`\n|`request-timeout` |Request timeout duration |`20 seconds`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Common Properties", "heading_level": 3, "file_order": 61, "section_index": 3, "content_hash": "d4baf8c3e7cc9c50a24c766414d03cf9a46a9fa6474d759587e9545c14fa33e1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:fbce80fc13fe98979043c35cbad931612a890775d18d0bafdde1a81e27ea10b3", "content": "MCP Server Annotations provide a declarative way to implement MCP server handlers using Java annotations.\n\nThe server mcp-annotations properties are prefixed with `spring.ai.mcp.server.annotation-scanner`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`enabled`\n|Enable/disable the MCP server annotations auto-scanning\n|`true`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "MCP Annotations Properties", "heading_level": 3, "file_order": 61, "section_index": 4, "content_hash": "fbce80fc13fe98979043c35cbad931612a890775d18d0bafdde1a81e27ea10b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:bac6564a769a16c047d7faa79e12ba8c7875a5822e414044f2a0eba0720b4427", "content": "All connection properties are prefixed with `spring.ai.mcp.server.stateless`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`mcp-endpoint` |Custom MCP endpoint path |`/mcp`\n|`disallow-delete` |Disallow delete operations |`false`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Stateless Connection Properties", "heading_level": 3, "file_order": 61, "section_index": 5, "content_hash": "bac6564a769a16c047d7faa79e12ba8c7875a5822e414044f2a0eba0720b4427", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:5ad0f45fa4c077b98b629c2c60420b46e74393458a92cfc93da1b9d35a056eb4", "content": "The MCP Server Boot Starter allows servers to expose tools, resources, and prompts to clients.\nIt automatically converts custom capability handlers registered as Spring beans to sync/async specifications based on the server type:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Features and Capabilities", "heading_level": 2, "file_order": 61, "section_index": 6, "content_hash": "5ad0f45fa4c077b98b629c2c60420b46e74393458a92cfc93da1b9d35a056eb4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:ae8f6b39b431b9c7d26a0f0c69d66392c74e8cae1f7121f425ecaa7c7b054d6c", "content": "Allows servers to expose tools that can be invoked by language models. The MCP Server Boot Starter provides:\n\n* Change notification support\n* xref:api/tools.adoc[Spring AI Tools] are automatically converted to sync/async specifications based on the server type\n* Automatic tool specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic ToolCallbackProvider myTools(...) {\n List<ToolCallback> tools = ...\n return ToolCallbackProvider.from(tools);\n}\n----\n\nor using the low-level API:\n\n[source,java]\n----\n@Bean\npublic List<McpStatelessServerFeatures.SyncToolSpecification> myTools(...) {\n List<McpStatelessServerFeatures.SyncToolSpecification> tools = ...\n return tools;\n}\n----\n\nThe auto-configuration will automatically detect and register all tool callbacks from:\n\n- Individual `ToolCallback` beans\n- Lists of `ToolCallback` beans\n- `ToolCallbackProvider` beans\n\nTools are de-duplicated by name, with the first occurrence of each tool name being used.\n\nTIP: You can disable the automatic detection and registration of all tool callbacks by setting the `tool-callback-converter` to `false`.\n\nNOTE: Tool Context Support is not applicable for stateless servers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/tools[Tools]", "heading_level": 3, "file_order": 61, "section_index": 7, "content_hash": "ae8f6b39b431b9c7d26a0f0c69d66392c74e8cae1f7121f425ecaa7c7b054d6c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:97f073c7c682308dabc258013951f1cb532f7c8dd3fe323805d6fe24ca803183", "content": "Provides a standardized way for servers to expose resources to clients.\n\n* Static and dynamic resource specifications\n* Optional change notifications\n* Support for resource templates\n* Automatic conversion between sync/async resource specifications\n* Automatic resource specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpStatelessServerFeatures.SyncResourceSpecification> myResources(...) {\n var systemInfoResource = new McpSchema.Resource(...);\n var resourceSpecification = new McpStatelessServerFeatures.SyncResourceSpecification(systemInfoResource, (context, request) -> {\n try {\n var systemInfo = Map.of(...);\n String jsonContent = new ObjectMapper().writeValueAsString(systemInfo);\n return new McpSchema.ReadResourceResult(\n List.of(new McpSchema.TextResourceContents(request.uri(), \"application/json\", jsonContent)));\n }\n catch (Exception e) {\n throw new RuntimeException(\"Failed to generate system info\", e);\n }\n });\n\n return List.of(resourceSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/resources/[Resources]", "heading_level": 3, "file_order": 61, "section_index": 8, "content_hash": "97f073c7c682308dabc258013951f1cb532f7c8dd3fe323805d6fe24ca803183", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:873f493a5abc4155b957cd9d72173e808e4b693302a745c338a881964f2c3623", "content": "Provides a standardized way for servers to expose prompt templates to clients.\n\n* Change notification support\n* Template versioning\n* Automatic conversion between sync/async prompt specifications\n* Automatic prompt specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpStatelessServerFeatures.SyncPromptSpecification> myPrompts() {\n var prompt = new McpSchema.Prompt(\"greeting\", \"A friendly greeting prompt\",\n List.of(new McpSchema.PromptArgument(\"name\", \"The name to greet\", true)));\n\n var promptSpecification = new McpStatelessServerFeatures.SyncPromptSpecification(prompt, (context, getPromptRequest) -> {\n String nameArgument = (String) getPromptRequest.arguments().get(\"name\");\n if (nameArgument == null) { nameArgument = \"friend\"; }\n var userMessage = new PromptMessage(Role.USER, new TextContent(\"Hello \" + nameArgument + \"! How can I assist you today?\"));\n return new GetPromptResult(\"A personalized greeting message\", List.of(userMessage));\n });\n\n return List.of(promptSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/prompts/[Prompts]", "heading_level": 3, "file_order": 61, "section_index": 9, "content_hash": "873f493a5abc4155b957cd9d72173e808e4b693302a745c338a881964f2c3623", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:013214c892dbed73faeaf62a2288e23f50d36f69810584b502c471e72ba9f400", "content": "Provides a standardized way for servers to expose completion capabilities to clients.\n\n* Support for both sync and async completion specifications\n* Automatic registration through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpStatelessServerFeatures.SyncCompletionSpecification> myCompletions() {\n var completion = new McpStatelessServerFeatures.SyncCompletionSpecification(\n new McpSchema.PromptReference(\n \"ref/prompt\", \"code-completion\", \"Provides code completion suggestions\"),\n (exchange, request) -> {\n // Implementation that returns completion suggestions\n return new McpSchema.CompleteResult(List.of(\"python\", \"pytorch\", \"pyside\"), 10, true);\n }\n );\n\n return List.of(completion);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/utilities/completion/[Completion]", "heading_level": 3, "file_order": 61, "section_index": 10, "content_hash": "013214c892dbed73faeaf62a2288e23f50d36f69810584b502c471e72ba9f400", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:a19163b40b5fb25b1d24ba3738d2c612edce1a53a56523fa10c995d149e37917", "content": "[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n protocol: STATELESS\n name: stateless-mcp-server\n version: 1.0.0\n type: ASYNC\n instructions: \"This stateless server is optimized for cloud deployments\"\n streamable-http:\n mcp-endpoint: /api/mcp\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Stateless Server Configuration", "heading_level": 3, "file_order": 61, "section_index": 11, "content_hash": "a19163b40b5fb25b1d24ba3738d2c612edce1a53a56523fa10c995d149e37917", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:ecb5aeacb71fbae3cd893618e25680650ba2487c111710ec08cea3c2518b2552", "content": "[source,java]\n----\n@Service\npublic class WeatherService {\n\n @Tool(description = \"Get weather information by city name\")\n public String getWeather(String cityName) {\n // Implementation\n }\n}\n\n@SpringBootApplication\npublic class McpServerApplication {\n\n private static final Logger logger = LoggerFactory.getLogger(McpServerApplication.class);\n\n public static void main(String[] args) {\n SpringApplication.run(McpServerApplication.class, args);\n }\n\n\t@Bean\n\tpublic ToolCallbackProvider weatherTools(WeatherService weatherService) {\n return MethodToolCallbackProvider.builder().toolObjects(weatherService).build();\n\t}\n}\n----\n\nThe auto-configuration will automatically register the tool callbacks as MCP tools.\nYou can have multiple beans producing ToolCallbacks, and the auto-configuration will merge them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc", "title": "mcp-stateless-server-boot-starter-docs", "heading": "Creating a Spring Boot Application with MCP Server", "heading_level": 3, "file_order": 61, "section_index": 12, "content_hash": "ecb5aeacb71fbae3cd893618e25680650ba2487c111710ec08cea3c2518b2552", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stateless-server-boot-starter-docs.adoc"}}
{"id": "sha256:37430394a1bbf751389732570a61d11d5139428cbf337b4ffa278b2cb2627666", "content": "The STDIO and SSE MCP Servers support multiple transport mechanisms, each with its dedicated starter.\n\nTIP: Use the xref:api/mcp/mcp-client-boot-starter-docs#_stdio_transport_properties[STDIO clients] or xref:api/mcp/mcp-client-boot-starter-docs#_sse_transport_properties[SSE clients] to connect to the STDIO and SSE servers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "STDIO and SSE MCP Servers", "heading_level": 2, "file_order": 62, "section_index": 0, "content_hash": "37430394a1bbf751389732570a61d11d5139428cbf337b4ffa278b2cb2627666", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:fa8b5d6690b4c453059ae5391dd05cedfcdbf5f05114278c8c6c304d653a6fab", "content": "Full MCP Server feature support with `STDIO` server transport.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server</artifactId>\n</dependency>\n----\n\n* Suitable for command-line and desktop tools\n* No additional web dependencies required\n* Configuration of basic server components\n* Handling of tool, resource, and prompt specifications\n* Management of server capabilities and change notifications\n* Support for both sync and async server implementations", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "STDIO MCP Server", "heading_level": 3, "file_order": 62, "section_index": 1, "content_hash": "fa8b5d6690b4c453059ae5391dd05cedfcdbf5f05114278c8c6c304d653a6fab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:99d84e83b154b97870de6887034e3f9c0c1fce296a7709617345fcd5d7f3b57f", "content": "Full MCP Server feature support with `SSE` (Server-Sent Events) server transport based on Spring MVC and an optional `STDIO` transport.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webmvc</artifactId>\n</dependency>\n----\n\n* HTTP-based transport using Spring MVC (`WebMvcSseServerTransportProvider`)\n* Automatically configured SSE endpoints\n* Optional `STDIO` transport (enabled by setting `spring.ai.mcp.server.stdio=true`)\n* Includes `spring-boot-starter-web` and `mcp-spring-webmvc` dependencies", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "SSE WebMVC Server", "heading_level": 3, "file_order": 62, "section_index": 2, "content_hash": "99d84e83b154b97870de6887034e3f9c0c1fce296a7709617345fcd5d7f3b57f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:9aaaee10027c59b865f985c13885265e58b28110bead4ee2355c3f1d165dacb8", "content": "Full MCP Server feature support with `SSE` (Server-Sent Events) server transport based on Spring WebFlux and an optional `STDIO` transport.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webflux</artifactId>\n</dependency>\n----\n\nThe starter activates the `McpWebFluxServerAutoConfiguration` and `McpServerAutoConfiguration` auto-configurations to provide:\n\n* Reactive transport using Spring WebFlux (`WebFluxSseServerTransportProvider`)\n* Automatically configured reactive SSE endpoints\n* Optional `STDIO` transport (enabled by setting `spring.ai.mcp.server.stdio=true`)\n* Includes `spring-boot-starter-webflux` and `mcp-spring-webflux` dependencies\n\n[NOTE]\n====\nDue to Spring Boot's default behavior, when both `org.springframework.web.servlet.DispatcherServlet` and `org.springframework.web.reactive.DispatcherHandler` are present on the classpath, Spring Boot will prioritize `DispatcherServlet`. As a result, if your project uses `spring-boot-starter-web`, it is recommended to use `spring-ai-starter-mcp-server-webmvc` instead of `spring-ai-starter-mcp-server-webflux`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "SSE WebFlux Server", "heading_level": 3, "file_order": 62, "section_index": 3, "content_hash": "9aaaee10027c59b865f985c13885265e58b28110bead4ee2355c3f1d165dacb8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:9f4ab55cec5d31a66d36e533213e503534599afc47f25cc07066e81f49585e28", "content": "All Common properties are prefixed with `spring.ai.mcp.server`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`enabled` |Enable/disable the MCP server |`true`\n|`tool-callback-converter` |Enable/disable the conversion of Spring AI ToolCallbacks into MCP Tool specs |`true`\n|`stdio` |Enable/disable STDIO transport |`false`\n|`name` |Server name for identification |`mcp-server`\n|`version` |Server version |`1.0.0`\n|`instructions` |Optional instructions to provide guidance to the client on how to interact with this server |`null`\n|`type` |Server type (SYNC/ASYNC) |`SYNC`\n|`capabilities.resource` |Enable/disable resource capabilities |`true`\n|`capabilities.tool` |Enable/disable tool capabilities |`true`\n|`capabilities.prompt` |Enable/disable prompt capabilities |`true`\n|`capabilities.completion` |Enable/disable completion capabilities |`true`\n|`resource-change-notification` |Enable resource change notifications |`true`\n|`prompt-change-notification` |Enable prompt change notifications |`true`\n|`tool-change-notification` |Enable tool change notifications |`true`\n|`tool-response-mime-type` |Optional response MIME type per tool name. For example, `spring.ai.mcp.server.tool-response-mime-type.generateImage=image/png` will associate the `image/png` MIME type with the `generateImage()` tool name |`-`\n|`request-timeout` |Duration to wait for server responses before timing out requests. Applies to all requests made through the client, including tool calls, resource access, and prompt operations |`20 seconds`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Common Properties", "heading_level": 3, "file_order": 62, "section_index": 4, "content_hash": "9f4ab55cec5d31a66d36e533213e503534599afc47f25cc07066e81f49585e28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:dd33ffa1900de470ac78ef0a7730de9b9080e2472582557046c106b2a3553339", "content": "MCP Server Annotations provide a declarative way to implement MCP server handlers using Java annotations.\n\nThe server mcp-annotations properties are prefixed with `spring.ai.mcp.server.annotation-scanner`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`enabled`\n|Enable/disable the MCP server annotations auto-scanning\n|`true`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "MCP Annotations Properties", "heading_level": 3, "file_order": 62, "section_index": 5, "content_hash": "dd33ffa1900de470ac78ef0a7730de9b9080e2472582557046c106b2a3553339", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:cbe059f824d5d449c40beae1770664175a6185e0d1a015979b38fd8c97dc120b", "content": "All SSE properties are prefixed with `spring.ai.mcp.server`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`sse-message-endpoint` |Custom SSE message endpoint path for web transport to be used by the client to send messages |`/mcp/message`\n|`sse-endpoint` |Custom SSE endpoint path for web transport |`/sse`\n|`base-url` |Optional URL prefix. For example, `base-url=/api/v1` means that the client should access the SSE endpoint at `/api/v1` + `sse-endpoint` and the message endpoint is `/api/v1` + `sse-message-endpoint` |`-`\n|`keep-alive-interval` |Connection keep-alive interval |`null` (disabled)\n|===\n\nNOTE: For backward compatibility reasons, the SSE properties do not have additional suffix (like `.sse`).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "SSE Properties", "heading_level": 3, "file_order": 62, "section_index": 6, "content_hash": "cbe059f824d5d449c40beae1770664175a6185e0d1a015979b38fd8c97dc120b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:27fcc56f0fd886f13cb17b7131c6e31940cfb44535aa79da31939223e1bac014", "content": "The MCP Server Boot Starter allows servers to expose tools, resources, and prompts to clients.\nIt automatically converts custom capability handlers registered as Spring beans to sync/async specifications based on the server type:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Features and Capabilities", "heading_level": 2, "file_order": 62, "section_index": 7, "content_hash": "27fcc56f0fd886f13cb17b7131c6e31940cfb44535aa79da31939223e1bac014", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:6474f941398e92ccb7422412f8619ac579591df6cc11fefe8ff1fb3f46c0a6aa", "content": "Allows servers to expose tools that can be invoked by language models. The MCP Server Boot Starter provides:\n\n* Change notification support\n* xref:api/tools.adoc[Spring AI Tools] are automatically converted to sync/async specifications based on the server type\n* Automatic tool specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic ToolCallbackProvider myTools(...) {\n List<ToolCallback> tools = ...\n return ToolCallbackProvider.from(tools);\n}\n----\n\nor using the low-level API:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncToolSpecification> myTools(...) {\n List<McpServerFeatures.SyncToolSpecification> tools = ...\n return tools;\n}\n----\n\nThe auto-configuration will automatically detect and register all tool callbacks from:\n\n- Individual `ToolCallback` beans\n- Lists of `ToolCallback` beans\n- `ToolCallbackProvider` beans\n\nTools are de-duplicated by name, with the first occurrence of each tool name being used.\n\nTIP: You can disable the automatic detection and registration of all tool callbacks by setting the `tool-callback-converter` to `false`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://spec.modelcontextprotocol.io/specification/2024-11-05/server/tools/[Tools]", "heading_level": 3, "file_order": 62, "section_index": 8, "content_hash": "6474f941398e92ccb7422412f8619ac579591df6cc11fefe8ff1fb3f46c0a6aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:76e4aa6f8d1f272e87880614ab8cc3d8aa1756b4af26218efeff03fbeeb56dbd", "content": "The xref:api/tools.adoc#_tool_context[ToolContext] is supported, allowing contextual information to be passed to tool calls. It contains an `McpSyncServerExchange` instance under the `exchange` key, accessible via `McpToolUtils.getMcpExchange(toolContext)`. See this https://github.com/spring-projects/spring-ai-examples/blob/3fab8483b8deddc241b1e16b8b049616604b7767/model-context-protocol/sampling/mcp-weather-webmvc-server/src/main/java/org/springframework/ai/mcp/sample/server/WeatherService.java#L59-L126[example] demonstrating `exchange.loggingNotification(...)` and `exchange.createMessage(...)`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Tool Context Support", "heading_level": 4, "file_order": 62, "section_index": 9, "content_hash": "76e4aa6f8d1f272e87880614ab8cc3d8aa1756b4af26218efeff03fbeeb56dbd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:8966b30e27984ce4cb0b28077c384ae91b171611cdf91ce5984c7e470630b892", "content": "Provides a standardized way for servers to expose resources to clients.\n\n* Static and dynamic resource specifications\n* Optional change notifications\n* Support for resource templates\n* Automatic conversion between sync/async resource specifications\n* Automatic resource specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncResourceSpecification> myResources(...) {\n var systemInfoResource = new McpSchema.Resource(...);\n var resourceSpecification = new McpServerFeatures.SyncResourceSpecification(systemInfoResource, (exchange, request) -> {\n try {\n var systemInfo = Map.of(...);\n String jsonContent = new ObjectMapper().writeValueAsString(systemInfo);\n return new McpSchema.ReadResourceResult(\n List.of(new McpSchema.TextResourceContents(request.uri(), \"application/json\", jsonContent)));\n }\n catch (Exception e) {\n throw new RuntimeException(\"Failed to generate system info\", e);\n }\n });\n\n return List.of(resourceSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://spec.modelcontextprotocol.io/specification/2024-11-05/server/resources/[Resources]", "heading_level": 3, "file_order": 62, "section_index": 10, "content_hash": "8966b30e27984ce4cb0b28077c384ae91b171611cdf91ce5984c7e470630b892", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:eb45de681bb8bb3ed1dd049c19d30a7e70c94e6d464af223d1f67153781f941f", "content": "Provides a standardized way for servers to expose prompt templates to clients.\n\n* Change notification support\n* Template versioning\n* Automatic conversion between sync/async prompt specifications\n* Automatic prompt specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncPromptSpecification> myPrompts() {\n var prompt = new McpSchema.Prompt(\"greeting\", \"A friendly greeting prompt\",\n List.of(new McpSchema.PromptArgument(\"name\", \"The name to greet\", true)));\n\n var promptSpecification = new McpServerFeatures.SyncPromptSpecification(prompt, (exchange, getPromptRequest) -> {\n String nameArgument = (String) getPromptRequest.arguments().get(\"name\");\n if (nameArgument == null) { nameArgument = \"friend\"; }\n var userMessage = new PromptMessage(Role.USER, new TextContent(\"Hello \" + nameArgument + \"! How can I assist you today?\"));\n return new GetPromptResult(\"A personalized greeting message\", List.of(userMessage));\n });\n\n return List.of(promptSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://spec.modelcontextprotocol.io/specification/2024-11-05/server/prompts/[Prompts]", "heading_level": 3, "file_order": 62, "section_index": 11, "content_hash": "eb45de681bb8bb3ed1dd049c19d30a7e70c94e6d464af223d1f67153781f941f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:305f542d4ad32079f9dbfb7e1ab340b30f616b84acfeafbc8a0729e9e49ef8b3", "content": "Provides a standardized way for servers to expose completion capabilities to clients.\n\n* Support for both sync and async completion specifications\n* Automatic registration through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncCompletionSpecification> myCompletions() {\n var completion = new McpServerFeatures.SyncCompletionSpecification(\n new McpSchema.PromptReference(\n \"ref/prompt\", \"code-completion\", \"Provides code completion suggestions\"),\n (exchange, request) -> {\n // Implementation that returns completion suggestions\n return new McpSchema.CompleteResult(List.of(\"python\", \"pytorch\", \"pyside\"), 10, true);\n }\n );\n\n return List.of(completion);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://spec.modelcontextprotocol.io/specification/2024-11-05/server/completions/[Completions]", "heading_level": 3, "file_order": 62, "section_index": 12, "content_hash": "305f542d4ad32079f9dbfb7e1ab340b30f616b84acfeafbc8a0729e9e49ef8b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:b784ff35a0d83c52f42d38f4a5dcf98352e6a6f66db339e6c81511bc15fc1204", "content": "Provides a standardized way for servers to send structured log messages to clients.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send logging messages:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.loggingNotification(LoggingMessageNotification.builder()\n .level(LoggingLevel.INFO)\n .logger(\"test-logger\")\n .data(\"This is a test log message\")\n .build());\n}\n----\n\nOn the MCP client you can register xref::api/mcp/mcp-client-boot-starter-docs#_customization_types[logging consumers] to handle these messages:\n\n[source,java]\n----\nmcpClientSpec.loggingConsumer((McpSchema.LoggingMessageNotification log) -> {\n // Handle log messages\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/utilities/logging/[Logging]", "heading_level": 3, "file_order": 62, "section_index": 13, "content_hash": "b784ff35a0d83c52f42d38f4a5dcf98352e6a6f66db339e6c81511bc15fc1204", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:20b3212e25beac1b44e6997f194e9b8217ee81c82963dd2d867d10cf2931ce82", "content": "Provides a standardized way for servers to send progress updates to clients.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send progress notifications:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.progressNotification(ProgressNotification.builder()\n .progressToken(\"test-progress-token\")\n .progress(0.25)\n .total(1.0)\n .message(\"tool call in progress\")\n .build());\n}\n----\n\nThe Mcp Client can receive progress notifications and update its UI accordingly.\nFor this it needs to register a progress consumer.\n\n[source,java]\n----\nmcpClientSpec.progressConsumer((McpSchema.ProgressNotification progress) -> {\n // Handle progress notifications\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/basic/utilities/progress[Progress]", "heading_level": 3, "file_order": 62, "section_index": 14, "content_hash": "20b3212e25beac1b44e6997f194e9b8217ee81c82963dd2d867d10cf2931ce82", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:d1428cc45a8a58d2d98f0fb95b543425372aa73e6505df9306dd73e0ed2ffaab", "content": "When roots change, clients that support `listChanged` send a root change notification.\n\n* Support for monitoring root changes\n* Automatic conversion to async consumers for reactive applications\n* Optional registration through Spring beans\n\n[source,java]\n----\n@Bean\npublic BiConsumer<McpSyncServerExchange, List<McpSchema.Root>> rootsChangeHandler() {\n return (exchange, roots) -> {\n logger.info(\"Registering root resources: {}\", roots);\n };\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://spec.modelcontextprotocol.io/specification/2024-11-05/client/roots/#root-list-changes[Root List Changes]", "heading_level": 3, "file_order": 62, "section_index": 15, "content_hash": "d1428cc45a8a58d2d98f0fb95b543425372aa73e6505df9306dd73e0ed2ffaab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:64657ce56cdfb3240b2a1b5502079e8d45a3cde8599c85a96cbe2ae053383c3c", "content": "Ping mechanism for the server to verify that its clients are still alive.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send ping messages:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.ping();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/basic/utilities/ping/[Ping]", "heading_level": 3, "file_order": 62, "section_index": 16, "content_hash": "64657ce56cdfb3240b2a1b5502079e8d45a3cde8599c85a96cbe2ae053383c3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:bb551615e034d5537be185555ea08a5417d9a60fa3c8184a12d9b4be55325a49", "content": "Server can optionally, periodically issue pings to connected clients to verify connection health.\n\nBy default, keep-alive is disabled.\nTo enable keep-alive, set the `keep-alive-interval` property in your configuration:\n\n```yaml\nspring:\n ai:\n mcp:\n server:\n keep-alive-interval: 30s\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Keep Alive", "heading_level": 3, "file_order": 62, "section_index": 17, "content_hash": "bb551615e034d5537be185555ea08a5417d9a60fa3c8184a12d9b4be55325a49", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:0934f1e9e5713b937b37bf9a8d0f99e5237a75d9a9c28e09ac92af8ee9189b56", "content": "[source,yaml]\n----\n# Using spring-ai-starter-mcp-server\nspring:\n ai:\n mcp:\n server:\n name: stdio-mcp-server\n version: 1.0.0\n type: SYNC\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Standard STDIO Server Configuration", "heading_level": 3, "file_order": 62, "section_index": 18, "content_hash": "0934f1e9e5713b937b37bf9a8d0f99e5237a75d9a9c28e09ac92af8ee9189b56", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:fca0f34a3a4c11af92574d051995f28ee1a4d41996fb2704daf88220fa0c9a08", "content": "[source,yaml]\n----\n# Using spring-ai-starter-mcp-server-webmvc\nspring:\n ai:\n mcp:\n server:\n name: webmvc-mcp-server\n version: 1.0.0\n type: SYNC\n instructions: \"This server provides weather information tools and resources\"\n capabilities:\n tool: true\n resource: true\n prompt: true\n completion: true\n # sse properties\n sse-message-endpoint: /mcp/messages\n keep-alive-interval: 30s\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "WebMVC Server Configuration", "heading_level": 3, "file_order": 62, "section_index": 19, "content_hash": "fca0f34a3a4c11af92574d051995f28ee1a4d41996fb2704daf88220fa0c9a08", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:ee5fc204c45496ab86061c8db62b4431c090f1bd664b4dda4f94c9a662c1e4b5", "content": "[source,yaml]\n----\n# Using spring-ai-starter-mcp-server-webflux\nspring:\n ai:\n mcp:\n server:\n name: webflux-mcp-server\n version: 1.0.0\n type: ASYNC # Recommended for reactive applications\n instructions: \"This reactive server provides weather information tools and resources\"\n capabilities:\n tool: true\n resource: true\n prompt: true\n completion: true\n # sse properties\n sse-message-endpoint: /mcp/messages\n keep-alive-interval: 30s\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "WebFlux Server Configuration", "heading_level": 3, "file_order": 62, "section_index": 20, "content_hash": "ee5fc204c45496ab86061c8db62b4431c090f1bd664b4dda4f94c9a662c1e4b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:86ccd705fc6bb1cd96cadc6b93c6c6ef67b58e2d929d0c6201c1bd5d2220b23f", "content": "[source,java]\n----\n@Service\npublic class WeatherService {\n\n @Tool(description = \"Get weather information by city name\")\n public String getWeather(String cityName) {\n // Implementation\n }\n}\n\n@SpringBootApplication\npublic class McpServerApplication {\n\n private static final Logger logger = LoggerFactory.getLogger(McpServerApplication.class);\n\n public static void main(String[] args) {\n SpringApplication.run(McpServerApplication.class, args);\n }\n\n\t@Bean\n\tpublic ToolCallbackProvider weatherTools(WeatherService weatherService) {\n return MethodToolCallbackProvider.builder().toolObjects(weatherService).build();\n\t}\n}\n----\n\nThe auto-configuration will automatically register the tool callbacks as MCP tools.\nYou can have multiple beans producing ToolCallbacks, and the auto-configuration will merge them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Creating a Spring Boot Application with MCP Server", "heading_level": 3, "file_order": 62, "section_index": 21, "content_hash": "86ccd705fc6bb1cd96cadc6b93c6c6ef67b58e2d929d0c6201c1bd5d2220b23f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:e0516fbd20fe3c8650371a6f74f6384a96d97ebb2fc3ee9823c017ddbbf2c912", "content": "* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-webflux-server[Weather Server (WebFlux)] - Spring AI MCP Server Boot Starter with WebFlux transport\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-stdio-server[Weather Server (STDIO)] - Spring AI MCP Server Boot Starter with STDIO transport\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/manual-webflux-server[Weather Server Manual Configuration] - Spring AI MCP Server Boot Starter that doesn't use auto-configuration but uses the Java SDK to configure the server manually", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc", "title": "mcp-stdio-sse-server-boot-starter-docs", "heading": "Example Applications", "heading_level": 2, "file_order": 62, "section_index": 22, "content_hash": "e0516fbd20fe3c8650371a6f74f6384a96d97ebb2fc3ee9823c017ddbbf2c912", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-stdio-sse-server-boot-starter-docs.adoc"}}
{"id": "sha256:000740fc879bf1fa1e93faf144c5264961f1b10974b750a3a80382c0e03b224f", "content": "The link:https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#streamable-http[Streamable HTTP transport] allows MCP servers to operate as independent processes that can handle multiple client connections using HTTP POST and GET requests, with optional Server-Sent Events (SSE) streaming for multiple server messages. It replaces the SSE transport.\n\nThese servers, introduced with spec version link:https://modelcontextprotocol.io/specification/2025-03-26[2025-03-26], are ideal for applications that need to notify clients about dynamic changes to tools, resources, or prompts.\n\nTIP: Set the `spring.ai.mcp.server.protocol=STREAMABLE` property\n\nTIP: Use the xref:api/mcp/mcp-client-boot-starter-docs#_streamable_http_transport_properties[Streamable-HTTP clients] to connect to the Streamable-HTTP servers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Streamable-HTTP MCP Servers", "heading_level": 2, "file_order": 63, "section_index": 0, "content_hash": "000740fc879bf1fa1e93faf144c5264961f1b10974b750a3a80382c0e03b224f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:6f9bd6dbed7a1cca7f95f5511a70233ae4b2883f91a5da5eccac0dc8d36497ec", "content": "Use the `spring-ai-starter-mcp-server-webmvc` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webmvc</artifactId>\n</dependency>\n----\n\nand set the `spring.ai.mcp.server.protocol` property to `STREAMABLE`.\n\n* Full MCP server capabilities with Spring MVC Streamable transport\n* Support for tools, resources, prompts, completion, logging, progression, ping, root-changes capabilities\n* Persistent connection management", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Streamable-HTTP WebMVC Server", "heading_level": 3, "file_order": 63, "section_index": 1, "content_hash": "6f9bd6dbed7a1cca7f95f5511a70233ae4b2883f91a5da5eccac0dc8d36497ec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:8e96323ddcb06bfce7a72bd15495e5ff93e67da25f7faa8bfee9d93835c88dab", "content": "Use the `spring-ai-starter-mcp-server-webflux` dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webflux</artifactId>\n</dependency>\n----\n\nand set the `spring.ai.mcp.server.protocol` property to `STREAMABLE`.\n\n* Reactive MCP server with WebFlux Streamable transport\n* Support for tools, resources, prompts, completion, logging, progression, ping, root-changes capabilities\n* Non-blocking, persistent connection management", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Streamable-HTTP WebFlux Server", "heading_level": 3, "file_order": 63, "section_index": 2, "content_hash": "8e96323ddcb06bfce7a72bd15495e5ff93e67da25f7faa8bfee9d93835c88dab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:96d4c6eeb3b007d1d5a53c086a4f7d75690c1b29de1cea271da1eea87f261300", "content": "All common properties are prefixed with `spring.ai.mcp.server`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`enabled` |Enable/disable the streamable MCP server |`true`\n|`protocol` |MCP server protocol | Must be set to `STREAMABLE` to enable the streamable server\n|`tool-callback-converter` |Enable/disable the conversion of Spring AI ToolCallbacks into MCP Tool specs |`true`\n|`name` |Server name for identification |`mcp-server`\n|`version` |Server version |`1.0.0`\n|`instructions` |Optional instructions for client interaction |`null`\n|`type` |Server type (SYNC/ASYNC) |`SYNC`\n|`capabilities.resource` |Enable/disable resource capabilities |`true`\n|`capabilities.tool` |Enable/disable tool capabilities |`true`\n|`capabilities.prompt` |Enable/disable prompt capabilities |`true`\n|`capabilities.completion` |Enable/disable completion capabilities |`true`\n|`resource-change-notification` |Enable resource change notifications |`true`\n|`prompt-change-notification` |Enable prompt change notifications |`true`\n|`tool-change-notification` |Enable tool change notifications |`true`\n|`tool-response-mime-type` |Response MIME type per tool name |`-`\n|`request-timeout` |Request timeout duration |`20 seconds`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Common Properties", "heading_level": 3, "file_order": 63, "section_index": 3, "content_hash": "96d4c6eeb3b007d1d5a53c086a4f7d75690c1b29de1cea271da1eea87f261300", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:26b009bf2cbba03818c91a177463a64d7b3a98da9f2a0e5bc372309ad6eb7759", "content": "MCP Server Annotations provide a declarative way to implement MCP server handlers using Java annotations.\n\nThe server mcp-annotations properties are prefixed with `spring.ai.mcp.server.annotation-scanner`:\n\n[cols=\"3,4,3\"]\n|===\n|Property |Description |Default Value\n\n|`enabled`\n|Enable/disable the MCP server annotations auto-scanning\n|`true`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "MCP Annotations Properties", "heading_level": 3, "file_order": 63, "section_index": 4, "content_hash": "26b009bf2cbba03818c91a177463a64d7b3a98da9f2a0e5bc372309ad6eb7759", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:1817e099b445d7f2ebab25eea6a5d928d7323c70c2bda1fce70de5ce993bf78b", "content": "All streamable-HTTP properties are prefixed with `spring.ai.mcp.server.streamable-http`:\n\n[options=\"header\"]\n|===\n|Property |Description |Default\n|`mcp-endpoint` |Custom MCP endpoint path |`/mcp`\n|`keep-alive-interval` |Connection keep-alive interval |`null` (disabled)\n|`disallow-delete` |Disallow delete operations |`false`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Streamable-HTTP Properties", "heading_level": 3, "file_order": 63, "section_index": 5, "content_hash": "1817e099b445d7f2ebab25eea6a5d928d7323c70c2bda1fce70de5ce993bf78b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:41e396c74ecc3f21069cddb30a3679f2c819197b25019588041820dedb5a3466", "content": "The MCP Server supports four main capability types that can be individually enabled or disabled:\n\n- **Tools** - Enable/disable tool capabilities with `spring.ai.mcp.server.capabilities.tool=true|false`\n- **Resources** - Enable/disable resource capabilities with `spring.ai.mcp.server.capabilities.resource=true|false`\n- **Prompts** - Enable/disable prompt capabilities with `spring.ai.mcp.server.capabilities.prompt=true|false`\n- **Completions** - Enable/disable completion capabilities with `spring.ai.mcp.server.capabilities.completion=true|false`\n\nAll capabilities are enabled by default. Disabling a capability will prevent the server from registering and exposing the corresponding features to clients.\n\nThe MCP Server Boot Starter allows servers to expose tools, resources, and prompts to clients.\nIt automatically converts custom capability handlers registered as Spring beans to sync/async specifications based on the server type:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Features and Capabilities", "heading_level": 2, "file_order": 63, "section_index": 6, "content_hash": "41e396c74ecc3f21069cddb30a3679f2c819197b25019588041820dedb5a3466", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:2f43cae55ece30221802e43460b09f3777bfc9aaedd6fd59071ac3e8b6773a72", "content": "Allows servers to expose tools that can be invoked by language models. The MCP Server Boot Starter provides:\n\n* Change notification support\n* xref:api/tools.adoc[Spring AI Tools] are automatically converted to sync/async specifications based on the server type\n* Automatic tool specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic ToolCallbackProvider myTools(...) {\n List<ToolCallback> tools = ...\n return ToolCallbackProvider.from(tools);\n}\n----\n\nor using the low-level API:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncToolSpecification> myTools(...) {\n List<McpServerFeatures.SyncToolSpecification> tools = ...\n return tools;\n}\n----\n\nThe auto-configuration will automatically detect and register all tool callbacks from:\n\n- Individual `ToolCallback` beans\n- Lists of `ToolCallback` beans\n- `ToolCallbackProvider` beans\n\nTools are de-duplicated by name, with the first occurrence of each tool name being used.\n\nTIP: You can disable the automatic detection and registration of all tool callbacks by setting the `tool-callback-converter` to `false`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/tools[Tools]", "heading_level": 3, "file_order": 63, "section_index": 7, "content_hash": "2f43cae55ece30221802e43460b09f3777bfc9aaedd6fd59071ac3e8b6773a72", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:9a41362796d0f3074619a41d80761f859e4fc65e7c14c8eee20540f4c6f72f11", "content": "The xref:api/tools.adoc#_tool_context[ToolContext] is supported, allowing contextual information to be passed to tool calls. It contains an `McpSyncServerExchange` instance under the `exchange` key, accessible via `McpToolUtils.getMcpExchange(toolContext)`. See this https://github.com/spring-projects/spring-ai-examples/blob/3fab8483b8deddc241b1e16b8b049616604b7767/model-context-protocol/sampling/mcp-weather-webmvc-server/src/main/java/org/springframework/ai/mcp/sample/server/WeatherService.java#L59-L126[example] demonstrating `exchange.loggingNotification(...)` and `exchange.createMessage(...)`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Tool Context Support", "heading_level": 4, "file_order": 63, "section_index": 8, "content_hash": "9a41362796d0f3074619a41d80761f859e4fc65e7c14c8eee20540f4c6f72f11", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:8b2dd1faacce12636561c598fc74c0de5630f7bee2872020152c36040e0a2219", "content": "Provides a standardized way for servers to expose resources to clients.\n\n* Static and dynamic resource specifications\n* Optional change notifications\n* Support for resource templates\n* Automatic conversion between sync/async resource specifications\n* Automatic resource specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncResourceSpecification> myResources(...) {\n var systemInfoResource = new McpSchema.Resource(...);\n var resourceSpecification = new McpServerFeatures.SyncResourceSpecification(systemInfoResource, (exchange, request) -> {\n try {\n var systemInfo = Map.of(...);\n String jsonContent = new ObjectMapper().writeValueAsString(systemInfo);\n return new McpSchema.ReadResourceResult(\n List.of(new McpSchema.TextResourceContents(request.uri(), \"application/json\", jsonContent)));\n }\n catch (Exception e) {\n throw new RuntimeException(\"Failed to generate system info\", e);\n }\n });\n\n return List.of(resourceSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/resources/[Resources]", "heading_level": 3, "file_order": 63, "section_index": 9, "content_hash": "8b2dd1faacce12636561c598fc74c0de5630f7bee2872020152c36040e0a2219", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:b890d8dfbe73c7cc1a4e2b01ff7e302e5324809670398ff523ba10a36a6c8097", "content": "Provides a standardized way for servers to expose prompt templates to clients.\n\n* Change notification support\n* Template versioning\n* Automatic conversion between sync/async prompt specifications\n* Automatic prompt specification through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncPromptSpecification> myPrompts() {\n var prompt = new McpSchema.Prompt(\"greeting\", \"A friendly greeting prompt\",\n List.of(new McpSchema.PromptArgument(\"name\", \"The name to greet\", true)));\n\n var promptSpecification = new McpServerFeatures.SyncPromptSpecification(prompt, (exchange, getPromptRequest) -> {\n String nameArgument = (String) getPromptRequest.arguments().get(\"name\");\n if (nameArgument == null) { nameArgument = \"friend\"; }\n var userMessage = new PromptMessage(Role.USER, new TextContent(\"Hello \" + nameArgument + \"! How can I assist you today?\"));\n return new GetPromptResult(\"A personalized greeting message\", List.of(userMessage));\n });\n\n return List.of(promptSpecification);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/prompts/[Prompts]", "heading_level": 3, "file_order": 63, "section_index": 10, "content_hash": "b890d8dfbe73c7cc1a4e2b01ff7e302e5324809670398ff523ba10a36a6c8097", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:2ec5ae0fe754b77364c4374c982a9a20625d4f1f260344f47cbba747c13bc9ea", "content": "Provides a standardized way for servers to expose completion capabilities to clients.\n\n* Support for both sync and async completion specifications\n* Automatic registration through Spring beans:\n\n[source,java]\n----\n@Bean\npublic List<McpServerFeatures.SyncCompletionSpecification> myCompletions() {\n var completion = new McpServerFeatures.SyncCompletionSpecification(\n new McpSchema.PromptReference(\n \"ref/prompt\", \"code-completion\", \"Provides code completion suggestions\"),\n (exchange, request) -> {\n // Implementation that returns completion suggestions\n return new McpSchema.CompleteResult(List.of(\"python\", \"pytorch\", \"pyside\"), 10, true);\n }\n );\n\n return List.of(completion);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/utilities/completion/[Completions]", "heading_level": 3, "file_order": 63, "section_index": 11, "content_hash": "2ec5ae0fe754b77364c4374c982a9a20625d4f1f260344f47cbba747c13bc9ea", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:09d1711b82d49bedb3678220a516a2567329256e0090fa78315eddbde6ae55aa", "content": "Provides a standardized way for servers to send structured log messages to clients.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send logging messages:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.loggingNotification(LoggingMessageNotification.builder()\n .level(LoggingLevel.INFO)\n .logger(\"test-logger\")\n .data(\"This is a test log message\")\n .build());\n}\n----\n\nOn the MCP client you can register xref::api/mcp/mcp-client-boot-starter-docs#_customization_types[logging consumers] to handle these messages:\n\n[source,java]\n----\nmcpClientSpec.loggingConsumer((McpSchema.LoggingMessageNotification log) -> {\n // Handle log messages\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/server/utilities/logging/[Logging]", "heading_level": 3, "file_order": 63, "section_index": 12, "content_hash": "09d1711b82d49bedb3678220a516a2567329256e0090fa78315eddbde6ae55aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:2462d853adde42d802a78de74183fe9ccaba0fa50fca7e89a9e127f162cffde7", "content": "Provides a standardized way for servers to send progress updates to clients.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send progress notifications:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.progressNotification(ProgressNotification.builder()\n .progressToken(\"test-progress-token\")\n .progress(0.25)\n .total(1.0)\n .message(\"tool call in progress\")\n .build());\n}\n----\n\nThe Mcp Client can receive progress notifications and update its UI accordingly.\nFor this it needs to register a progress consumer.\n\n[source,java]\n----\nmcpClientSpec.progressConsumer((McpSchema.ProgressNotification progress) -> {\n // Handle progress notifications\n});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/basic/utilities/progress[Progress]", "heading_level": 3, "file_order": 63, "section_index": 13, "content_hash": "2462d853adde42d802a78de74183fe9ccaba0fa50fca7e89a9e127f162cffde7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:c39a6518a542d9a4ebd40ae4743436550616e094a50405ee06474bf48e159ce7", "content": "When roots change, clients that support `listChanged` send a root change notification.\n\n* Support for monitoring root changes\n* Automatic conversion to async consumers for reactive applications\n* Optional registration through Spring beans\n\n[source,java]\n----\n@Bean\npublic BiConsumer<McpSyncServerExchange, List<McpSchema.Root>> rootsChangeHandler() {\n return (exchange, roots) -> {\n logger.info(\"Registering root resources: {}\", roots);\n };\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/client/roots#root-list-changes[Root List Changes]", "heading_level": 3, "file_order": 63, "section_index": 14, "content_hash": "c39a6518a542d9a4ebd40ae4743436550616e094a50405ee06474bf48e159ce7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:e8a1523a0752fbcfc91ae390b166cca88f0eb98c876cf7fc35da652cfd625840", "content": "Ping mechanism for the server to verify that its clients are still alive.\nFrom within the tool, resource, prompt or completion call handler use the provided `McpSyncServerExchange`/`McpAsyncServerExchange` `exchange` object to send ping messages:\n\n[source,java]\n----\n(exchange, request) -> {\n exchange.ping();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "link:https://modelcontextprotocol.io/specification/2025-03-26/basic/utilities/ping/[Ping]", "heading_level": 3, "file_order": 63, "section_index": 15, "content_hash": "e8a1523a0752fbcfc91ae390b166cca88f0eb98c876cf7fc35da652cfd625840", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:5331111e3366d245a31ec13c5138eb5b93691daebae3b5fb20fb37cbc34c834b", "content": "Server can optionally, periodically issue pings to connected clients to verify connection health.\n\nBy default, keep-alive is disabled.\nTo enable keep-alive, set the `keep-alive-interval` property in your configuration:\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n server:\n streamable-http:\n keep-alive-interval: 30s\n----\n\nNOTE: Currently, for streamable-http servers, the keep-alive mechanism is available only for the link:https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#listening-for-messages-from-the-server[Listening for Messages from the Server (SSE)] connection.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Keep Alive", "heading_level": 3, "file_order": 63, "section_index": 16, "content_hash": "5331111e3366d245a31ec13c5138eb5b93691daebae3b5fb20fb37cbc34c834b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:bb07535a04333894601308f9dffc11ecd99152940dd1a388bb5225bac73d2283", "content": "[source,yaml]\n----\n# Using spring-ai-starter-mcp-server-streamable-webmvc\nspring:\n ai:\n mcp:\n server:\n protocol: STREAMABLE\n name: streamable-mcp-server\n version: 1.0.0\n type: SYNC\n instructions: \"This streamable server provides real-time notifications\"\n resource-change-notification: true\n tool-change-notification: true\n prompt-change-notification: true\n streamable-http:\n mcp-endpoint: /api/mcp\n keep-alive-interval: 30s\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Streamable HTTP Server Configuration", "heading_level": 3, "file_order": 63, "section_index": 17, "content_hash": "bb07535a04333894601308f9dffc11ecd99152940dd1a388bb5225bac73d2283", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:cd92f4dcc2e972987bc85a431e92b00a2930edf07f7dc906effa5613f4db5458", "content": "[source,java]\n----\n@Service\npublic class WeatherService {\n\n @Tool(description = \"Get weather information by city name\")\n public String getWeather(String cityName) {\n // Implementation\n }\n}\n\n@SpringBootApplication\npublic class McpServerApplication {\n\n private static final Logger logger = LoggerFactory.getLogger(McpServerApplication.class);\n\n public static void main(String[] args) {\n SpringApplication.run(McpServerApplication.class, args);\n }\n\n\t@Bean\n\tpublic ToolCallbackProvider weatherTools(WeatherService weatherService) {\n return MethodToolCallbackProvider.builder().toolObjects(weatherService).build();\n\t}\n}\n----\n\nThe auto-configuration will automatically register the tool callbacks as MCP tools.\nYou can have multiple beans producing ToolCallbacks, and the auto-configuration will merge them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc", "title": "mcp-streamable-http-server-boot-starter-docs", "heading": "Creating a Spring Boot Application with MCP Server", "heading_level": 3, "file_order": 63, "section_index": 18, "content_hash": "cd92f4dcc2e972987bc85a431e92b00a2930edf07f7dc906effa5613f4db5458", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/mcp/mcp-streamable-http-server-boot-starter-docs.adoc"}}
{"id": "sha256:a270f16ee02b18b26b0af029a6ccacb0e4311db2eaa447c3328f489c3c15e811", "content": "Spring AI supports the new moderation service introduced by Mistral AI and powered by the Mistral Moderation model.\nIt enables the detection of harmful text content along several policy dimensions.\nFollow this https://docs.mistral.ai/capabilities/guardrailing/[link] for more information on the Mistral AI moderation model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Introduction", "heading_level": 2, "file_order": 64, "section_index": 0, "content_hash": "a270f16ee02b18b26b0af029a6ccacb0e4311db2eaa447c3328f489c3c15e811", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:7d3422ef933ce584c3e00704247e8baae7abfcdca2c1389ce8611e7d3e20f51e", "content": ". Create an Mistral AI account and obtain an API key. You can sign up at https://auth.mistral.ai/ui/registration[Mistral AI registration page] and generate an API key on the https://console.mistral.ai/api-keys/[API Keys page].\n. Add the `spring-ai-mistral-ai` dependency to your project's build file. For more information, refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Prerequisites", "heading_level": 2, "file_order": 64, "section_index": 1, "content_hash": "7d3422ef933ce584c3e00704247e8baae7abfcdca2c1389ce8611e7d3e20f51e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:6fa48f7e8d5ad0ba8916e6ad6352202acc09403014dc607112439c0e44841e42", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Mistral AI Moderation Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 64, "section_index": 2, "content_hash": "6fa48f7e8d5ad0ba8916e6ad6352202acc09403014dc607112439c0e44841e42", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:ea66e8bff9e2c310f56861a4605b931ae8daf1c797b0d72476446e9a6fadd44c", "content": "The prefix spring.ai.mistralai is used as the property prefix that lets you connect to Mistral AI.\n[cols=\"3,3,1\"]\n|====\n| Property | Description | Default\n| spring.ai.mistralai.base-url | The URL to connect to | https://api.mistral.ai\n| spring.ai.mistralai.api-key | The API Key | -\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Connection Properties", "heading_level": 3, "file_order": 64, "section_index": 3, "content_hash": "ea66e8bff9e2c310f56861a4605b931ae8daf1c797b0d72476446e9a6fadd44c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:c9e5c94e8fcd21fe1e7011c7543c3cb5996ba9436f45037736bafbd6097fbd5e", "content": "[NOTE]\n====\nEnabling and disabling of the moderation auto-configurations are now configured via top level properties with the prefix `spring.ai.model.moderation`.\n\nTo enable, spring.ai.model.moderation=mistral (It is enabled by default)\n\nTo disable, spring.ai.model.moderation=none (or any value which doesn't match mistral)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix spring.ai.mistralai.moderation is used as the property prefix for configuring the Mistral AI moderation model.\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.model.moderation | Enable Moderation model | mistral\n| spring.ai.mistralai.moderation.base-url | The URL to connect to | https://api.mistral.ai\n| spring.ai.mistralai.moderation.api-key | The API Key | -\n| spring.ai.mistralai.moderation.options.model | ID of the model to use for moderation. | mistral-moderation-latest\n|====\n\nNOTE: You can override the common `spring.ai.mistralai.base-url`, `spring.ai.mistralai.api-key`, properties.\nThe `spring.ai.mistralai.moderation.base-url`, `spring.ai.mistralai.moderation.api-key`, properties, if set, take precedence over the common properties.\nThis is useful if you want to use different Mistral AI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.mistralai.moderation.options` can be overridden at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Configuration Properties", "heading_level": 3, "file_order": 64, "section_index": 4, "content_hash": "c9e5c94e8fcd21fe1e7011c7543c3cb5996ba9436f45037736bafbd6097fbd5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:42c559dddbe7daaacbb934fd1552b1c360a7b493ae01b507f443ef30fddbc12c", "content": "The MistralAiModerationOptions class provides the options to use when making a moderation request.\nOn start-up, the options specified by spring.ai.mistralai.moderation are used, but you can override these at runtime.\n\nFor example:\n\n[source,java]\n----\nMistralAiModerationOptions moderationOptions = MistralAiModerationOptions.builder()\n .model(\"mistral-moderation-latest\")\n .build();\n\nModerationPrompt moderationPrompt = new ModerationPrompt(\"Text to be moderated\", this.moderationOptions);\nModerationResponse response = mistralAiModerationModel.call(this.moderationPrompt);\n\nModeration moderation = moderationResponse.getResult().getOutput();\n\nSystem.out.println(\"Moderation ID: \" + moderation.getId());\nSystem.out.println(\"Model used: \" + moderation.getModel());\n\nfor (ModerationResult result : moderation.getResults()) {\n System.out.println(\"\\nModeration Result:\");\n System.out.println(\"Flagged: \" + result.isFlagged());\n\n // Access categories\n Categories categories = this.result.getCategories();\n System.out.println(\"\\nCategories:\");\n System.out.println(\"Law: \" + categories.isLaw());\n System.out.println(\"Financial: \" + categories.isFinancial());\n System.out.println(\"PII: \" + categories.isPii());\n System.out.println(\"Sexual: \" + categories.isSexual());\n System.out.println(\"Hate: \" + categories.isHate());\n System.out.println(\"Harassment: \" + categories.isHarassment());\n System.out.println(\"Self-Harm: \" + categories.isSelfHarm());\n System.out.println(\"Sexual/Minors: \" + categories.isSexualMinors());\n System.out.println(\"Hate/Threatening: \" + categories.isHateThreatening());\n System.out.println(\"Violence/Graphic: \" + categories.isViolenceGraphic());\n System.out.println(\"Self-Harm/Intent: \" + categories.isSelfHarmIntent());\n System.out.println(\"Self-Harm/Instructions: \" + categories.isSelfHarmInstructions());\n System.out.println(\"Harassment/Threatening: \" + categories.isHarassmentThreatening());\n System.out.println(\"Violence: \" + categories.isViolence());\n\n // Access category scores\n CategoryScores scores = this.result.getCategoryScores();\n System.out.println(\"\\nCategory Scores:\");\n System.out.println(\"Law: \" + scores.getLaw());\n System.out.println(\"Financial: \" + scores.getFinancial());\n System.out.println(\"PII: \" + scores.getPii());\n System.out.println(\"Sexual: \" + scores.getSexual());\n System.out.println(\"Hate: \" + scores.getHate());\n System.out.println(\"Harassment: \" + scores.getHarassment());\n System.out.println(\"Self-Harm: \" + scores.getSelfHarm());\n System.out.println(\"Sexual/Minors: \" + scores.getSexualMinors());\n System.out.println(\"Hate/Threatening: \" + scores.getHateThreatening());\n System.out.println(\"Violence/Graphic: \" + scores.getViolenceGraphic());\n System.out.println(\"Self-Harm/Intent: \" + scores.getSelfHarmIntent());\n System.out.println(\"Self-Harm/Instructions: \" + scores.getSelfHarmInstructions());\n System.out.println(\"Harassment/Threatening: \" + scores.getHarassmentThreatening());\n System.out.println(\"Violence: \" + scores.getViolence());\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Runtime Options", "heading_level": 2, "file_order": 64, "section_index": 5, "content_hash": "42c559dddbe7daaacbb934fd1552b1c360a7b493ae01b507f443ef30fddbc12c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:426e0f2f4d55edfc11686b7f526c8a9e1764bc0ef705334ab99a95b0570c5bec", "content": "Add the `spring-ai-mistral-ai` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mistral-ai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-mistral-ai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an MistralAiModerationModel:\n\n[source,java]\n----\nMistralAiModerationApi mistralAiModerationApi = new MistralAiModerationApi(System.getenv(\"MISTRAL_AI_API_KEY\"));\n\nMistralAiModerationModel mistralAiModerationModel = new MistralAiModerationModel(this.mistralAiModerationApi);\n\nMistralAiModerationOptions moderationOptions = MistralAiModerationOptions.builder()\n .model(\"mistral-moderation-latest\")\n .build();\n\nModerationPrompt moderationPrompt = new ModerationPrompt(\"Text to be moderated\", this.moderationOptions);\nModerationResponse response = this.mistralAiModerationModel.call(this.moderationPrompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Manual Configuration", "heading_level": 2, "file_order": 64, "section_index": 6, "content_hash": "426e0f2f4d55edfc11686b7f526c8a9e1764bc0ef705334ab99a95b0570c5bec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:1dac1fba10aa871ce6c3446680b04ad4b917dceae5cfee7ae01b4d4e02b9133a", "content": "The `MistralAiModerationModelIT` test provides some general examples of how to use the library. You can refer to this test for more detailed usage examples.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc", "title": "Moderation", "heading": "Example Code", "heading_level": 2, "file_order": 64, "section_index": 7, "content_hash": "1dac1fba10aa871ce6c3446680b04ad4b917dceae5cfee7ae01b4d4e02b9133a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/mistral-ai-moderation.adoc"}}
{"id": "sha256:233c478f584c6b21b901069dabce5f9709d684a36590478211709967a4f167fa", "content": "Spring AI supports OpenAI's Moderation model, which allows you to detect potentially harmful or sensitive content in text.\nFollow this https://platform.openai.com/docs/guides/moderation[guide] to for more information on OpenAI's moderation model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Introduction", "heading_level": 2, "file_order": 65, "section_index": 0, "content_hash": "233c478f584c6b21b901069dabce5f9709d684a36590478211709967a4f167fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:5c4ea37c4001eda4de4f2d5b10f0391edac64a2f4dba383762c90eccd365e1a8", "content": ". Create an OpenAI account and obtain an API key. You can sign up at the https://platform.openai.com/signup[OpenAI signup page] and generate an API key on the https://platform.openai.com/account/api-keys[API Keys page].\n. Add the `spring-ai-openai` dependency to your project's build file. For more information, refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Prerequisites", "heading_level": 2, "file_order": 65, "section_index": 1, "content_hash": "5c4ea37c4001eda4de4f2d5b10f0391edac64a2f4dba383762c90eccd365e1a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:78ea11fdc01215beebd8b7ebfc0b87778a73fcd5c59b6efe0a2e8ed39280a657", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenAI Moderation Model.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Auto-configuration", "heading_level": 2, "file_order": 65, "section_index": 2, "content_hash": "78ea11fdc01215beebd8b7ebfc0b87778a73fcd5c59b6efe0a2e8ed39280a657", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:f3e96caf7e59efe2ff089c8aba8f6f63d5fe9bbd4a43b2cb18516addd66631f0", "content": "The prefix spring.ai.openai is used as the property prefix that lets you connect to OpenAI.\n[cols=\"3,5,1\"]\n|====\n| Property | Description | Default\n| spring.ai.openai.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.api-key | The API Key | -\n| spring.ai.openai.organization-id | Optionally you can specify which organization is used for an API request. | -\n| spring.ai.openai.project-id | Optionally, you can specify which project is used for an API request. | -\n|====\n\nTIP: For users that belong to multiple organizations (or are accessing their projects through their legacy user API key), optionally, you can specify which organization and project is used for an API request.\nUsage from these API requests will count as usage for the specified organization and project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Connection Properties", "heading_level": 3, "file_order": 65, "section_index": 3, "content_hash": "f3e96caf7e59efe2ff089c8aba8f6f63d5fe9bbd4a43b2cb18516addd66631f0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:b5b4dc2ef99fa3b9aed167337c934cff3d99f48cc40391e12814e76b29123eec", "content": "[NOTE]\n====\nEnabling and disabling of the embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.moderation`.\n\nTo enable, spring.ai.model.moderation=openai (It is enabled by default)\n\nTo disable, spring.ai.model.moderation=none (or any value which doesn't match openai)\n\nThis change is done to allow configuration of multiple models.\n====\n\nThe prefix spring.ai.openai.moderation is used as the property prefix for configuring the OpenAI moderation model.\n[cols=\"3,5,2\"]\n|====\n| Property | Description | Default\n| spring.ai.model.moderation | Enable Moderation model | openai\n| spring.ai.openai.moderation.base-url | The URL to connect to | https://api.openai.com\n| spring.ai.openai.moderation.api-key | The API Key | -\n| spring.ai.openai.moderation.organization-id | Optionally you can specify which organization is used for an API request. | -\n| spring.ai.openai.moderation.project-id | Optionally, you can specify which project is used for an API request. | -\n| spring.ai.openai.moderation.moderation-path | The API endpoint path for moderation requests. Useful for OpenAI-compatible APIs with different endpoint structures. | /v1/moderations\n| spring.ai.openai.moderation.options.model | ID of the model to use for moderation. | omni-moderation-latest\n|====\n\nNOTE: You can override the common `spring.ai.openai.base-url`, `spring.ai.openai.api-key`, `spring.ai.openai.organization-id` and `spring.ai.openai.project-id` properties.\nThe `spring.ai.openai.moderation.base-url`, `spring.ai.openai.moderation.api-key`, `spring.ai.openai.moderation.organization-id` and `spring.ai.openai.moderation.project-id` properties, if set, take precedence over the common properties.\nThis is useful if you want to use different OpenAI accounts for different models and different model endpoints.\n\nTIP: All properties prefixed with `spring.ai.openai.moderation.options` can be overridden at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Configuration Properties", "heading_level": 3, "file_order": 65, "section_index": 4, "content_hash": "b5b4dc2ef99fa3b9aed167337c934cff3d99f48cc40391e12814e76b29123eec", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:8ea06828e558b1399f3331e274729ec62cf68f6f6ca30a9cf7a2a6986dce4c4c", "content": "For OpenAI-compatible APIs (such as LocalAI, custom proxies, or other OpenAI-compatible services) that use different endpoint paths, you can configure the moderation path:\n\n[source,properties]\n----\nspring.ai.openai.moderation.moderation-path=/custom/path/to/moderations\n----\n\nThis is particularly useful when:\n\n* Using API gateways or proxies that modify standard OpenAI paths\n* Working with OpenAI-compatible services that implement different URL structures\n* Testing against mock endpoints with custom paths\n* Deploying in environments with path-based routing requirements", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Custom API Paths", "heading_level": 3, "file_order": 65, "section_index": 5, "content_hash": "8ea06828e558b1399f3331e274729ec62cf68f6f6ca30a9cf7a2a6986dce4c4c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:8b9fb0b338f6981db55f71fd47b619f1919ac2fca8b7595d061e8e3e6d8ea199", "content": "The OpenAiModerationOptions class provides the options to use when making a moderation request.\nOn start-up, the options specified by spring.ai.openai.moderation are used, but you can override these at runtime.\n\nFor example:\n\n[source,java]\n----\nOpenAiModerationOptions moderationOptions = OpenAiModerationOptions.builder()\n .model(\"omni-moderation-latest\")\n .build();\n\nModerationPrompt moderationPrompt = new ModerationPrompt(\"Text to be moderated\", this.moderationOptions);\nModerationResponse response = openAiModerationModel.call(this.moderationPrompt);\n\nModeration moderation = moderationResponse.getResult().getOutput();\n\nSystem.out.println(\"Moderation ID: \" + moderation.getId());\nSystem.out.println(\"Model used: \" + moderation.getModel());\n\nfor (ModerationResult result : moderation.getResults()) {\n System.out.println(\"\\nModeration Result:\");\n System.out.println(\"Flagged: \" + result.isFlagged());\n\n // Access categories\n Categories categories = this.result.getCategories();\n System.out.println(\"\\nCategories:\");\n System.out.println(\"Sexual: \" + categories.isSexual());\n System.out.println(\"Hate: \" + categories.isHate());\n System.out.println(\"Harassment: \" + categories.isHarassment());\n System.out.println(\"Self-Harm: \" + categories.isSelfHarm());\n System.out.println(\"Sexual/Minors: \" + categories.isSexualMinors());\n System.out.println(\"Hate/Threatening: \" + categories.isHateThreatening());\n System.out.println(\"Violence/Graphic: \" + categories.isViolenceGraphic());\n System.out.println(\"Self-Harm/Intent: \" + categories.isSelfHarmIntent());\n System.out.println(\"Self-Harm/Instructions: \" + categories.isSelfHarmInstructions());\n System.out.println(\"Harassment/Threatening: \" + categories.isHarassmentThreatening());\n System.out.println(\"Violence: \" + categories.isViolence());\n\n // Access category scores\n CategoryScores scores = this.result.getCategoryScores();\n System.out.println(\"\\nCategory Scores:\");\n System.out.println(\"Sexual: \" + scores.getSexual());\n System.out.println(\"Hate: \" + scores.getHate());\n System.out.println(\"Harassment: \" + scores.getHarassment());\n System.out.println(\"Self-Harm: \" + scores.getSelfHarm());\n System.out.println(\"Sexual/Minors: \" + scores.getSexualMinors());\n System.out.println(\"Hate/Threatening: \" + scores.getHateThreatening());\n System.out.println(\"Violence/Graphic: \" + scores.getViolenceGraphic());\n System.out.println(\"Self-Harm/Intent: \" + scores.getSelfHarmIntent());\n System.out.println(\"Self-Harm/Instructions: \" + scores.getSelfHarmInstructions());\n System.out.println(\"Harassment/Threatening: \" + scores.getHarassmentThreatening());\n System.out.println(\"Violence: \" + scores.getViolence());\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Runtime Options", "heading_level": 2, "file_order": 65, "section_index": 6, "content_hash": "8b9fb0b338f6981db55f71fd47b619f1919ac2fca8b7595d061e8e3e6d8ea199", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:a5527fddfb567444d6ed3eeec9a1f8391cbeb8509aca43aa4e1ccd43c8bfda63", "content": "Add the `spring-ai-openai` dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nNext, create an OpenAiModerationModel:\n\n[source,java]\n----\nOpenAiModerationApi openAiModerationApi = new OpenAiModerationApi(System.getenv(\"OPENAI_API_KEY\"));\n\nOpenAiModerationModel openAiModerationModel = new OpenAiModerationModel(this.openAiModerationApi);\n\nOpenAiModerationOptions moderationOptions = OpenAiModerationOptions.builder()\n .model(\"omni-moderation-latest\")\n .build();\n\nModerationPrompt moderationPrompt = new ModerationPrompt(\"Text to be moderated\", this.moderationOptions);\nModerationResponse response = this.openAiModerationModel.call(this.moderationPrompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Manual Configuration", "heading_level": 2, "file_order": 65, "section_index": 7, "content_hash": "a5527fddfb567444d6ed3eeec9a1f8391cbeb8509aca43aa4e1ccd43c8bfda63", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:ce242fe286fed9bfce75f592e633b88b6e69ad405c0787fef96bbc2a79cf517a", "content": "The `OpenAiModerationModelIT` test provides some general examples of how to use the library. You can refer to this test for more detailed usage examples.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc", "title": "Moderation", "heading": "Example Code", "heading_level": 2, "file_order": 65, "section_index": 8, "content_hash": "ce242fe286fed9bfce75f592e633b88b6e69ad405c0787fef96bbc2a79cf517a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/moderation/openai-moderation.adoc"}}
{"id": "sha256:b1fb36d47add35aa6c2badcf0b2c69e1a4ad6356955e0937b2b467ce54045c48", "content": "This section walks you through setting up `CassandraVectorStore` to store document embeddings and perform similarity searches.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Apache Cassandra Vector Store", "heading_level": 1, "file_order": 66, "section_index": 0, "content_hash": "b1fb36d47add35aa6c2badcf0b2c69e1a4ad6356955e0937b2b467ce54045c48", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:3884b402c60b939df69aab430bcfdc09ab2ca2e0adc4c32d00533d8e9f3987eb", "content": "link:https://cassandra.apache.org[Apache Cassandra®] is a true open source distributed database renowned for linear scalability, proven fault-tolerance and low latency, making it the perfect platform for mission-critical transactional data.\n\nIts Vector Similarity Search (VSS) is based on the JVector library that ensures best-in-class performance and relevancy.\n\nA vector search in Apache Cassandra is done as simply as:\n[source,sql]\n----\nSELECT content FROM table ORDER BY content_vector ANN OF query_embedding;\n----\n\nMore docs on this can be read https://cassandra.apache.org/doc/latest/cassandra/getting-started/vector-search-quickstart.html[here].\n\nThis Spring AI Vector Store is designed to work for both brand-new RAG applications and be able to be retrofitted on top of existing data and tables.\n\nThe store can also be used for non-RAG use-cases in an existing database, e.g. semantic searches, geo-proximity searches, etc.\n\nThe store will automatically create, or enhance, the schema as needed according to its configuration. If you don't want the schema modifications, configure the store with `initializeSchema`.\n\nWhen using spring-boot-autoconfigure `initializeSchema` defaults to `false`, per Spring Boot standards, and you must opt-in to schema creation/modifications by setting `...initialize-schema=true` in the `application.properties` file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "What is Apache Cassandra?", "heading_level": 2, "file_order": 66, "section_index": 1, "content_hash": "3884b402c60b939df69aab430bcfdc09ab2ca2e0adc4c32d00533d8e9f3987eb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:df35ad661eb998d5591e6940a6158ddbc6b82869f19dd1233b31549cbe2a1772", "content": "link:https://github.com/jbellis/jvector[JVector] is a pure Java embedded vector search engine.\n\nIt stands out from other HNSW Vector Similarity Search implementations by being:\n\n* Algorithmic-fast. JVector uses state of the art graph algorithms inspired by DiskANN and related research that offer high recall and low latency.\n* Implementation-fast. JVector uses the Panama SIMD API to accelerate index build and queries.\n* Memory efficient. JVector compresses vectors using product quantization so they can stay in memory during searches.\n* Disk-aware. JVector's disk layout is designed to do the minimum necessary iops at query time.\n* Concurrent. Index builds scale linearly to at least 32 threads. Double the threads, half the build time.\n* Incremental. Query your index as you build it. No delay between adding a vector and being able to find it in search results.\n* Easy to embed. API designed for easy embedding, by people using it in production.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "What is JVector?", "heading_level": 2, "file_order": 66, "section_index": 2, "content_hash": "df35ad661eb998d5591e6940a6158ddbc6b82869f19dd1233b31549cbe2a1772", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:51018aa9ed4ef5eb51417e6546ec30bd6c4e306009fc8cdc7d039b0c61494f75", "content": "1. A `EmbeddingModel` instance to compute the document embeddings. This is usually configured as a Spring Bean. Several options are available:\n\n- `Transformers Embedding` - computes the embedding in your local environment. The default is via ONNX and the all-MiniLM-L6-v2 Sentence Transformers. This just works.\n- If you want to use OpenAI's Embeddings - uses the OpenAI embedding endpoint. You need to create an account at link:https://platform.openai.com/signup[OpenAI Signup] and generate the api-key token at link:https://platform.openai.com/account/api-keys[API Keys].\n- There are many more choices, see `Embeddings API` docs.\n\n2. An Apache Cassandra instance, from version 5.0-beta1\na. link:https://cassandra.apache.org/_/quickstart.html[DIY Quick Start]\nb. For a managed offering https://astra.datastax.com/[Astra DB] offers a healthy free tier offering.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Prerequisites", "heading_level": 2, "file_order": 66, "section_index": 3, "content_hash": "51018aa9ed4ef5eb51417e6546ec30bd6c4e306009fc8cdc7d039b0c61494f75", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:8b8618a980c2ffce114af4754b2efdda1664fe514b928f4a735853e756d3b1b5", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nTIP: For dependency management, we recommend using the Spring AI BOM as explained in the xref:getting-started.adoc#dependency-management[Dependency Management] section.\n\nAdd these dependencies to your project:\n\n* For just the Cassandra Vector Store:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-cassandra-store</artifactId>\n</dependency>\n----\n\n* Or, for everything you need in a RAG application (using the default ONNX Embedding Model):\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-cassandra</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Dependencies", "heading_level": 2, "file_order": 66, "section_index": 4, "content_hash": "8b8618a980c2ffce114af4754b2efdda1664fe514b928f4a735853e756d3b1b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:2b050b7720ab190faa21e7c83088a034e49943168153838682b846ee9df7bc89", "content": "You can use the following properties in your Spring Boot configuration to customize the Apache Cassandra vector store.\n\n[cols=\"2,1\",stripes=even]\n|===\n|Property|Default Value\n\n|`spring.ai.vectorstore.cassandra.keyspace`|springframework\n|`spring.ai.vectorstore.cassandra.table`|ai_vector_store\n|`spring.ai.vectorstore.cassandra.initialize-schema`|false\n|`spring.ai.vectorstore.cassandra.index-name`|\n|`spring.ai.vectorstore.cassandra.content-column-name`|content\n|`spring.ai.vectorstore.cassandra.embedding-column-name`|embedding\n|`spring.ai.vectorstore.cassandra.fixed-thread-pool-executor-size`|16\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Configuration Properties", "heading_level": 2, "file_order": 66, "section_index": 5, "content_hash": "2b050b7720ab190faa21e7c83088a034e49943168153838682b846ee9df7bc89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:c1ba32fee132996d1888fceb940c8728f3da4f2d0d272af4cda77005db9fc986", "content": "Create a CassandraVectorStore instance as a Spring Bean:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(CqlSession session, EmbeddingModel embeddingModel) {\n return CassandraVectorStore.builder(embeddingModel)\n .session(session)\n .keyspace(\"my_keyspace\")\n .table(\"my_vectors\")\n .build();\n}\n----\n\nOnce you have the vector store instance, you can add documents and perform searches:\n\n[source,java]\n----\nvectorStore.add(List.of(\n new Document(\"1\", \"content1\", Map.of(\"key1\", \"value1\")),\n new Document(\"2\", \"content2\", Map.of(\"key2\", \"value2\"))\n));\n\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.query(\"search text\")\n .withTopK(5)\n .withSimilarityThreshold(0.7f)\n .withFilterExpression(\"metadata.key1 == 'value1'\")\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Basic Usage", "heading_level": 3, "file_order": 66, "section_index": 6, "content_hash": "c1ba32fee132996d1888fceb940c8728f3da4f2d0d272af4cda77005db9fc986", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:9813687ec08e1edb3d000e72d07c1dc4799333224c4f99f25a937b273cec95fe", "content": "For more complex use cases, you can configure additional settings in your Spring Bean:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(CqlSession session, EmbeddingModel embeddingModel) {\n return CassandraVectorStore.builder(embeddingModel)\n .session(session)\n .keyspace(\"my_keyspace\")\n .table(\"my_vectors\")\n // Configure primary keys\n .partitionKeys(List.of(\n new SchemaColumn(\"id\", DataTypes.TEXT),\n new SchemaColumn(\"category\", DataTypes.TEXT)\n ))\n .clusteringKeys(List.of(\n new SchemaColumn(\"timestamp\", DataTypes.TIMESTAMP)\n ))\n // Add metadata columns with optional indexing\n .addMetadataColumns(\n new SchemaColumn(\"category\", DataTypes.TEXT, SchemaColumnTags.INDEXED),\n new SchemaColumn(\"score\", DataTypes.DOUBLE)\n )\n // Customize column names\n .contentColumnName(\"text\")\n .embeddingColumnName(\"vector\")\n // Performance tuning\n .fixedThreadPoolExecutorSize(32)\n // Schema management\n .initializeSchema(true)\n // Custom batching strategy\n .batchingStrategy(new TokenCountBatchingStrategy())\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Advanced Configuration", "heading_level": 3, "file_order": 66, "section_index": 7, "content_hash": "9813687ec08e1edb3d000e72d07c1dc4799333224c4f99f25a937b273cec95fe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:5e293336ba675b684e9d2aae719e4431ea1c0e2c540ba85838fe981e0dd0ab06", "content": "There are two ways to configure the connection to Cassandra:\n\n* Using an injected CqlSession (recommended):\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(CqlSession session, EmbeddingModel embeddingModel) {\n return CassandraVectorStore.builder(embeddingModel)\n .session(session)\n .keyspace(\"my_keyspace\")\n .table(\"my_vectors\")\n .build();\n}\n----\n\n* Using connection details directly in the builder:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(EmbeddingModel embeddingModel) {\n return CassandraVectorStore.builder(embeddingModel)\n .contactPoint(new InetSocketAddress(\"localhost\", 9042))\n .localDatacenter(\"datacenter1\")\n .keyspace(\"my_keyspace\")\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Connection Configuration", "heading_level": 3, "file_order": 66, "section_index": 8, "content_hash": "5e293336ba675b684e9d2aae719e4431ea1c0e2c540ba85838fe981e0dd0ab06", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:698107815d13d8c61d5e78c7d1daa08ac4de107b82a76caf932f496bf3eff423", "content": "You can leverage the generic, portable metadata filters with the CassandraVectorStore. For metadata columns to be searchable they must be either primary keys or SAI indexed. To make non-primary-key columns indexed, configure the metadata column with the `SchemaColumnTags.INDEXED`.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder().query(\"The World\")\n .topK(5)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the expression DSL:\n\n[source,java]\n----\nFilter.Expression f = new FilterExpressionBuilder()\n .and(\n f.in(\"country\", \"UK\", \"NL\"),\n f.gte(\"year\", 2020)\n ).build();\n\nvectorStore.similaritySearch(\n SearchRequest.builder().query(\"The World\")\n .topK(5)\n .filterExpression(f).build());\n----\n\nThe portable filter expressions get automatically converted into link:https://cassandra.apache.org/doc/latest/cassandra/developing/cql/index.html[CQL queries].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Metadata Filtering", "heading_level": 3, "file_order": 66, "section_index": 9, "content_hash": "698107815d13d8c61d5e78c7d1daa08ac4de107b82a76caf932f496bf3eff423", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:536195f71a257a4ffe994dfb4e708359264be4305b976752c39ee4754806e631", "content": "The following example demonstrates how to use the store on an existing schema. Here we use the schema from the https://github.com/datastax-labs/colbert-wikipedia-data project which comes with the full wikipedia dataset ready vectorized for you.\n\nFirst, create the schema in the Cassandra database:\n\n[source,bash]\n----\nwget https://s.apache.org/colbert-wikipedia-schema-cql -O colbert-wikipedia-schema.cql\ncqlsh -f colbert-wikipedia-schema.cql\n----\n\nThen configure the store using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(CqlSession session, EmbeddingModel embeddingModel) {\n List<SchemaColumn> partitionColumns = List.of(\n new SchemaColumn(\"wiki\", DataTypes.TEXT),\n new SchemaColumn(\"language\", DataTypes.TEXT),\n new SchemaColumn(\"title\", DataTypes.TEXT)\n );\n\n List<SchemaColumn> clusteringColumns = List.of(\n new SchemaColumn(\"chunk_no\", DataTypes.INT),\n new SchemaColumn(\"bert_embedding_no\", DataTypes.INT)\n );\n\n List<SchemaColumn> extraColumns = List.of(\n new SchemaColumn(\"revision\", DataTypes.INT),\n new SchemaColumn(\"id\", DataTypes.INT)\n );\n\n return CassandraVectorStore.builder()\n .session(session)\n .embeddingModel(embeddingModel)\n .keyspace(\"wikidata\")\n .table(\"articles\")\n .partitionKeys(partitionColumns)\n .clusteringKeys(clusteringColumns)\n .contentColumnName(\"body\")\n .embeddingColumnName(\"all_minilm_l6_v2_embedding\")\n .indexName(\"all_minilm_l6_v2_ann\")\n .initializeSchema(false)\n .addMetadataColumns(extraColumns)\n .primaryKeyTranslator((List<Object> primaryKeys) -> {\n if (primaryKeys.isEmpty()) {\n return \"test§¶0\";\n }\n return String.format(\"%s§¶%s\", primaryKeys.get(2), primaryKeys.get(3));\n })\n .documentIdTranslator((id) -> {\n String[] parts = id.split(\"§¶\");\n String title = parts[0];\n int chunk_no = parts.length > 1 ? Integer.parseInt(parts[1]) : 0;\n return List.of(\"simplewiki\", \"en\", title, chunk_no, 0);\n })\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n // default is ONNX all-MiniLM-L6-v2 which is what we want\n return new TransformersEmbeddingModel();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Advanced Example: Vector Store on top of Wikipedia Dataset", "heading_level": 2, "file_order": 66, "section_index": 10, "content_hash": "536195f71a257a4ffe994dfb4e708359264be4305b976752c39ee4754806e631", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:2e511afa739536936e65c016f2a821488064016ba456d1d26475b294ad47c33b", "content": "To load the full wikipedia dataset:\n\n1. Download `simplewiki-sstable.tar` from https://s.apache.org/simplewiki-sstable-tar (this will take a while, the file is tens of GBs)\n\n2. Load the data:\n[source,bash]\n----\ntar -xf simplewiki-sstable.tar -C ${CASSANDRA_DATA}/data/wikidata/articles-*/\nnodetool import wikidata articles ${CASSANDRA_DATA}/data/wikidata/articles-*/\n----\n\n[NOTE]\n====\n* If you have existing data in this table, check the tarball's files don't clobber existing sstables when doing the `tar`.\n* An alternative to `nodetool import` is to just restart Cassandra.\n* If there are any failures in the indexes they will be rebuilt automatically.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Loading the Complete Wikipedia Dataset", "heading_level": 3, "file_order": 66, "section_index": 11, "content_hash": "2e511afa739536936e65c016f2a821488064016ba456d1d26475b294ad47c33b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:7dcf4c68a0e082563dc76865640d328f966761ddcf5ead1708fd065b11c556b4", "content": "The Cassandra Vector Store implementation provides access to the underlying native Cassandra client (`CqlSession`) through the `getNativeClient()` method:\n\n[source,java]\n----\nCassandraVectorStore vectorStore = context.getBean(CassandraVectorStore.class);\nOptional<CqlSession> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n CqlSession session = nativeClient.get();\n // Use the native client for Cassandra-specific operations\n}\n----\n\nThe native client gives you access to Cassandra-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc", "title": "Apache Cassandra Vector Store", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 66, "section_index": 12, "content_hash": "7dcf4c68a0e082563dc76865640d328f966761ddcf5ead1708fd065b11c556b4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/apache-cassandra.adoc"}}
{"id": "sha256:54434f0889e73c8fea3f38729d7611c5d6fa41b3d8aafe512c2e3dcfc75e1080", "content": "This section walks you through setting up `CosmosDBVectorStore` to store document embeddings and perform similarity searches.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Azure Cosmos DB", "heading_level": 1, "file_order": 67, "section_index": 0, "content_hash": "54434f0889e73c8fea3f38729d7611c5d6fa41b3d8aafe512c2e3dcfc75e1080", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:ee0c4fb321a665497353a6d32970be01c30a819d0ae1bc6804be5ca4e3f488f1", "content": "link:https://azure.microsoft.com/en-us/services/cosmos-db/[Azure Cosmos DB] is Microsoft's globally distributed cloud-native database service designed for mission-critical applications.\nIt offers high availability, low latency, and the ability to scale horizontally to meet modern application demands.\nIt was built from the ground up with global distribution, fine-grained multi-tenancy, and horizontal scalability at its core.\nIt is a foundational service in Azure, used by most of Microsoft’s mission critical applications at global scale, including Teams, Skype, Xbox Live, Office 365, Bing, Azure Active Directory, Azure Portal, Microsoft Store, and many others.\nIt is also used by thousands of external customers including OpenAI for ChatGPT and other mission-critical AI applications that require elastic scale, turnkey global distribution, and low latency and high availability across the planet.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "What is Azure Cosmos DB?", "heading_level": 2, "file_order": 67, "section_index": 1, "content_hash": "ee0c4fb321a665497353a6d32970be01c30a819d0ae1bc6804be5ca4e3f488f1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:db707aa83c25f72e58c2a314225de72db2adf63b6777868280e5e1657521c6e7", "content": "DiskANN (Disk-based Approximate Nearest Neighbor Search) is an innovative technology used in Azure Cosmos DB to enhance the performance of vector searches.\nIt enables efficient and scalable similarity searches across high-dimensional data by indexing embeddings stored in Cosmos DB.\n\nDiskANN provides the following benefits:\n\n* **Efficiency**: By utilizing disk-based structures, DiskANN significantly reduces the time required to find nearest neighbors compared to traditional methods.\n* **Scalability**: It can handle large datasets that exceed memory capacity, making it suitable for various applications, including machine learning and AI-driven solutions.\n* **Low Latency**: DiskANN minimizes latency during search operations, ensuring that applications can retrieve results quickly even with substantial data volumes.\n\nIn the context of Spring AI for Azure Cosmos DB, vector searches will create and leverage DiskANN indexes to ensure optimal performance for similarity queries.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "What is DiskANN?", "heading_level": 2, "file_order": 67, "section_index": 2, "content_hash": "db707aa83c25f72e58c2a314225de72db2adf63b6777868280e5e1657521c6e7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:261e0af412f0b304ecb465afdd802f8c63316938f7cf42364842b19c107f7e83", "content": "The following code demonstrates how to set up the `CosmosDBVectorStore` with auto-configuration:\n\n```java\npackage com.example.demo;\n\nimport io.micrometer.observation.ObservationRegistry;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.vectorstore.SearchRequest;\nimport org.springframework.ai.vectorstore.VectorStore;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Lazy;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\n@SpringBootApplication\n@EnableAutoConfiguration\npublic class DemoApplication implements CommandLineRunner {\n\n private static final Logger log = LoggerFactory.getLogger(DemoApplication.class);\n\n @Lazy\n @Autowired\n private VectorStore vectorStore;\n\n public static void main(String[] args) {\n SpringApplication.run(DemoApplication.class, args);\n }\n\n @Override\n public void run(String... args) throws Exception {\n Document document1 = new Document(UUID.randomUUID().toString(), \"Sample content1\", Map.of(\"key1\", \"value1\"));\n Document document2 = new Document(UUID.randomUUID().toString(), \"Sample content2\", Map.of(\"key2\", \"value2\"));\n this.vectorStore.add(List.of(document1, document2));\n List<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Sample content\").topK(1).build());\n\n log.info(\"Search results: {}\", results);\n\n // Remove the documents from the vector store\n this.vectorStore.delete(List.of(document1.getId(), document2.getId()));\n }\n\n @Bean\n public ObservationRegistry observationRegistry() {\n return ObservationRegistry.create();\n }\n}\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Setting up Azure Cosmos DB Vector Store with Auto Configuration", "heading_level": 2, "file_order": 67, "section_index": 3, "content_hash": "261e0af412f0b304ecb465afdd802f8c63316938f7cf42364842b19c107f7e83", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:79cdd03fce065d13482f12b1f6e459f5e79840171e14d3a48c2d976f00e959ba", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the following dependency to your Maven project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-azure-cosmos-db</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Auto Configuration", "heading_level": 2, "file_order": 67, "section_index": 4, "content_hash": "79cdd03fce065d13482f12b1f6e459f5e79840171e14d3a48c2d976f00e959ba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:08731630504e6855af06d9b37026f0654a498bd3a4eec3b625c8a62b13accb4d", "content": "The following configuration properties are available for the Cosmos DB vector store:\n\n[stripes=even]\n|===\n| Property | Description\n\n| spring.ai.vectorstore.cosmosdb.databaseName | The name of the Cosmos DB database to use.\n| spring.ai.vectorstore.cosmosdb.containerName | The name of the Cosmos DB container to use.\n| spring.ai.vectorstore.cosmosdb.partitionKeyPath | The path for the partition key.\n| spring.ai.vectorstore.cosmosdb.metadataFields | Comma-separated list of metadata fields.\n| spring.ai.vectorstore.cosmosdb.vectorStoreThroughput | The throughput for the vector store.\n| spring.ai.vectorstore.cosmosdb.vectorDimensions | The number of dimensions for the vectors.\n| spring.ai.vectorstore.cosmosdb.endpoint | The endpoint for the Cosmos DB.\n| spring.ai.vectorstore.cosmosdb.key | The key for the Cosmos DB (if key is not present, [DefaultAzureCredential](https://learn.microsoft.com/azure/developer/java/sdk/authentication/credential-chains#defaultazurecredential-overview) will be used).\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Configuration Properties", "heading_level": 2, "file_order": 67, "section_index": 5, "content_hash": "08731630504e6855af06d9b37026f0654a498bd3a4eec3b625c8a62b13accb4d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:bf55b8dc1ce2b4d2c0f7c78e4d31e77e992b56100313ce3cd1efb447cea4a8b7", "content": "You can perform more complex searches using filters in the Cosmos DB vector store.\nBelow is a sample demonstrating how to use filters in your search queries.\n\n[source,java]\n----\nMap<String, Object> metadata1 = new HashMap<>();\nmetadata1.put(\"country\", \"UK\");\nmetadata1.put(\"year\", 2021);\nmetadata1.put(\"city\", \"London\");\n\nMap<String, Object> metadata2 = new HashMap<>();\nmetadata2.put(\"country\", \"NL\");\nmetadata2.put(\"year\", 2022);\nmetadata2.put(\"city\", \"Amsterdam\");\n\nDocument document1 = new Document(\"1\", \"A document about the UK\", this.metadata1);\nDocument document2 = new Document(\"2\", \"A document about the Netherlands\", this.metadata2);\n\nvectorStore.add(List.of(document1, document2));\n\nFilterExpressionBuilder builder = new FilterExpressionBuilder();\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"The World\")\n .topK(10)\n .filterExpression((this.builder.in(\"country\", \"UK\", \"NL\")).build()).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Complex Searches with Filters", "heading_level": 2, "file_order": 67, "section_index": 6, "content_hash": "bf55b8dc1ce2b4d2c0f7c78e4d31e77e992b56100313ce3cd1efb447cea4a8b7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:5defb99c376af38cd09683b91d9a529613dc61d0f0ebd477aa77e175d4c39c2c", "content": "The following code demonstrates how to set up the `CosmosDBVectorStore` without relying on auto-configuration. [DefaultAzureCredential](https://learn.microsoft.com/azure/developer/java/sdk/authentication/credential-chains#defaultazurecredential-overview) is recommended for authentication to Azure Cosmos DB.\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(ObservationRegistry observationRegistry) {\n // Create the Cosmos DB client\n CosmosAsyncClient cosmosClient = new CosmosClientBuilder()\n .endpoint(System.getenv(\"COSMOSDB_AI_ENDPOINT\"))\n .credential(new DefaultAzureCredentialBuilder().build())\n .userAgentSuffix(\"SpringAI-CDBNoSQL-VectorStore\")\n .gatewayMode()\n .buildAsyncClient();\n\n // Create and configure the vector store\n return CosmosDBVectorStore.builder(cosmosClient, embeddingModel)\n .databaseName(\"test-database\")\n .containerName(\"test-container\")\n // Configure metadata fields for filtering\n .metadataFields(List.of(\"country\", \"year\", \"city\"))\n // Set the partition key path (optional)\n .partitionKeyPath(\"/id\")\n // Configure performance settings\n .vectorStoreThroughput(1000)\n .vectorDimensions(1536) // Match your embedding model's dimensions\n // Add custom batching strategy (optional)\n .batchingStrategy(new TokenCountBatchingStrategy())\n // Add observation registry for metrics\n .observationRegistry(observationRegistry)\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new TransformersEmbeddingModel();\n}\n----\n\nThis configuration shows all the available builder options:\n\n* `databaseName`: The name of your Cosmos DB database\n* `containerName`: The name of your container within the database\n* `partitionKeyPath`: The path for the partition key (e.g., \"/id\")\n* `metadataFields`: List of metadata fields that will be used for filtering\n* `vectorStoreThroughput`: The throughput (RU/s) for the vector store container\n* `vectorDimensions`: The number of dimensions for your vectors (should match your embedding model)\n* `batchingStrategy`: Strategy for batching document operations (optional)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Setting up Azure Cosmos DB Vector Store without Auto Configuration", "heading_level": 2, "file_order": 67, "section_index": 7, "content_hash": "5defb99c376af38cd09683b91d9a529613dc61d0f0ebd477aa77e175d4c39c2c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:82d61ae393d4c613a225aad7e87304f89c426446b6d5d5eb120d622dc3d8f66a", "content": "Add the following dependency in your Maven project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-azure-cosmos-db-store</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Manual Dependency Setup", "heading_level": 2, "file_order": 67, "section_index": 8, "content_hash": "82d61ae393d4c613a225aad7e87304f89c426446b6d5d5eb120d622dc3d8f66a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:44d780a5ba5ffa671562af7b29e5ce15d83cce08bc0cb03031143178b15e5e7f", "content": "The Azure Cosmos DB Vector Store implementation provides access to the underlying native Azure Cosmos DB client (`CosmosClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nCosmosDBVectorStore vectorStore = context.getBean(CosmosDBVectorStore.class);\nOptional<CosmosClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n CosmosClient client = nativeClient.get();\n // Use the native client for Azure Cosmos DB-specific operations\n}\n----\n\nThe native client gives you access to Azure Cosmos DB-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc", "title": "Azure Cosmos DB", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 67, "section_index": 9, "content_hash": "44d780a5ba5ffa671562af7b29e5ce15d83cce08bc0cb03031143178b15e5e7f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure-cosmos-db.adoc"}}
{"id": "sha256:ec727c961368b67d4525761aa94ead886de7ddc96c5925b504437bfdff8aa079", "content": "This section will walk you through setting up the `AzureVectorStore` to store document embeddings and perform similarity searches using the Azure AI Search Service.\n\nlink:https://azure.microsoft.com/en-us/products/ai-services/ai-search/[Azure AI Search] is a versatile cloud-hosted cloud information retrieval system that is part of Microsoft's larger AI platform. Among other features, it allows users to query information using vector-based storage and retrieval.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Azure AI Service", "heading_level": 1, "file_order": 68, "section_index": 0, "content_hash": "ec727c961368b67d4525761aa94ead886de7ddc96c5925b504437bfdff8aa079", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:8970e2c1538a6e2997b3bfc22e3c35e33df01f04dc3f42c588a16206e273230f", "content": "1. Azure Subscription: You will need an link:https://azure.microsoft.com/en-us/free/[Azure subscription] to use any Azure service.\n2. Azure AI Search Service: Create an link:https://portal.azure.com/#create/Microsoft.Search[AI Search service]. Once the service is created, obtain the admin apiKey from the `Keys` section under `Settings` and retrieve the endpoint from the `Url` field under the `Overview` section.\n3. (Optional) Azure OpenAI Service: Create an Azure link:https://portal.azure.com/#create/Microsoft.AIServicesOpenAI[OpenAI service]. **NOTE:** You may have to fill out a separate form to gain access to Azure Open AI services. Once the service is created, obtain the endpoint and apiKey from the `Keys and Endpoint` section under `Resource Management`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Prerequisites", "heading_level": 2, "file_order": 68, "section_index": 1, "content_hash": "8970e2c1538a6e2997b3bfc22e3c35e33df01f04dc3f42c588a16206e273230f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:2eceebbaa3575682041ea2eab89795cb1d7997fe8050e8483c04401947948f42", "content": "On startup, the `AzureVectorStore` can attempt to create a new index within your AI Search service instance if you've opted in by setting the relevant `initialize-schema` `boolean` property to `true` in the constructor or, if using Spring Boot, setting `...initialize-schema=true` in your `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nAlternatively, you can create the index manually.\n\nTo set up an AzureVectorStore, you will need the settings retrieved from the prerequisites above along with your index name:\n\n* Azure AI Search Endpoint\n* Azure AI Search Key\n* (optional) Azure OpenAI API Endpoint\n* (optional) Azure OpenAI API Key\n\nYou can provide these values as OS environment variables.\n\n[source,bash]\n----\nexport AZURE_AI_SEARCH_API_KEY=<My AI Search API Key>\nexport AZURE_AI_SEARCH_ENDPOINT=<My AI Search Index>\nexport OPENAI_API_KEY=<My Azure AI API Key> (Optional)\n----\n\n[NOTE]\n====\nYou can replace Azure Open AI implementation with any valid OpenAI implementation that supports the Embeddings interface. For example, you could use Spring AI's Open AI or `TransformersEmbedding` implementations for embeddings instead of the Azure implementation.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Configuration", "heading_level": 2, "file_order": 68, "section_index": 2, "content_hash": "2eceebbaa3575682041ea2eab89795cb1d7997fe8050e8483c04401947948f42", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:4914f6bea528fa2453b97aa8a137a78233c169fd0f778416d155c6bb6bb7267c", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd these dependencies to your project:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Dependencies", "heading_level": 2, "file_order": 68, "section_index": 3, "content_hash": "4914f6bea528fa2453b97aa8a137a78233c169fd0f778416d155c6bb6bb7267c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:7bd36175430d9184f5b96fbe2d8eb9482b6162cff27ea1836985fee30ac49add", "content": "[tabs]\n======\nOpenAI Embedding::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nAzure AI Embedding::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-azure-openai</artifactId>\n</dependency>\n----\n\nLocal Sentence Transformers Embedding::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-transformers</artifactId>\n</dependency>\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "1. Select an Embeddings interface implementation. You can choose between:", "heading_level": 3, "file_order": 68, "section_index": 4, "content_hash": "7bd36175430d9184f5b96fbe2d8eb9482b6162cff27ea1836985fee30ac49add", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:17e9c58e682f3df24ae30126d7831fbc7b07ff5520a18862136be8348fb8222c", "content": "[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-azure-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "2. Azure (AI Search) Vector Store", "heading_level": 3, "file_order": 68, "section_index": 5, "content_hash": "17e9c58e682f3df24ae30126d7831fbc7b07ff5520a18862136be8348fb8222c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:0a604a4344b2cc2baa4e0753f649bab830152d8a01847975e6e2c0b629baf021", "content": "You can use the following properties in your Spring Boot configuration to customize the Azure vector store.\n\n[stripes=even]\n|===\n|Property|Default value\n\n|`spring.ai.vectorstore.azure.url`|\n|`spring.ai.vectorstore.azure.api-key`|\n|`spring.ai.vectorstore.azure.useKeylessAuth`|false\n|`spring.ai.vectorstore.azure.initialize-schema`|false\n|`spring.ai.vectorstore.azure.index-name`|spring_ai_azure_vector_store\n|`spring.ai.vectorstore.azure.default-top-k`|4\n|`spring.ai.vectorstore.azure.default-similarity-threshold`|0.0\n|`spring.ai.vectorstore.azure.content-field-name`|content\n|`spring.ai.vectorstore.azure.embedding-field-name`|embedding\n|`spring.ai.vectorstore.azure.metadata-field-name`|metadata\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Configuration Properties", "heading_level": 2, "file_order": 68, "section_index": 6, "content_hash": "0a604a4344b2cc2baa4e0753f649bab830152d8a01847975e6e2c0b629baf021", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:ecf15b78d7bc0a32040071668a71f53f7ae9f92911bb11a4341edf40c21b6dbf", "content": "To configure an Azure `SearchIndexClient` in your application, you can use the following code:\n\n[source,java]\n----\n@Bean\npublic SearchIndexClient searchIndexClient() {\n return new SearchIndexClientBuilder().endpoint(System.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"))\n .credential(new AzureKeyCredential(System.getenv(\"AZURE_AI_SEARCH_API_KEY\")))\n .buildClient();\n}\n----\n\nTo create a vector store, you can use the following code by injecting the `SearchIndexClient` bean created in the above sample along with an `EmbeddingModel` provided by the Spring AI library that implements the desired Embeddings interface.\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(SearchIndexClient searchIndexClient, EmbeddingModel embeddingModel) {\n\n return AzureVectorStore.builder(searchIndexClient, embeddingModel)\n .initializeSchema(true)\n // Define the metadata fields to be used\n // in the similarity search filters.\n .filterMetadataFields(List.of(MetadataField.text(\"country\"), MetadataField.int64(\"year\"),\n MetadataField.date(\"activationDate\")))\n .defaultTopK(5)\n .defaultSimilarityThreshold(0.7)\n .indexName(\"spring-ai-document-index\")\n .build();\n}\n----\n\n[NOTE]\n====\nYou must list explicitly all metadata field names and types for any metadata key used in the filter expression. The list above registers filterable metadata fields: `country` of type `TEXT`, `year` of type `INT64`, and `active` of type `BOOLEAN`.\n\nIf the filterable metadata fields are expanded with new entries, you have to (re)upload/update the documents with this metadata.\n====\n\nIn your main code, create some documents:\n\n[source,java]\n----\nList<Document> documents = List.of(\n\tnew Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"country\", \"BG\", \"year\", 2020)),\n\tnew Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n\tnew Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"country\", \"NL\", \"year\", 2023)));\n----\n\nAdd the documents to your vector store:\n\n[source,java]\n----\nvectorStore.add(documents);\n----\n\nAnd finally, retrieve documents similar to a query:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"Spring\")\n .topK(5).build());\n----\n\nIf all goes well, you should retrieve the document containing the text \"Spring AI rocks!!\".", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Sample Code", "heading_level": 2, "file_order": 68, "section_index": 7, "content_hash": "ecf15b78d7bc0a32040071668a71f53f7ae9f92911bb11a4341edf40c21b6dbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:287744f0e914f4e521354a7a690dbd2205d05e1bdead4403ed4675c7e2f6bfe1", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with AzureVectorStore as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the expression DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"country\", \"UK\", \"NL\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nThe portable filter expressions get automatically converted into the proprietary Azure Search link:https://learn.microsoft.com/en-us/azure/search/search-query-odata-filter[OData filters]. For example, the following portable filter expression:\n\n[source,sql]\n----\ncountry in ['UK', 'NL'] && year >= 2020\n----\n\nis converted into the following Azure OData link:https://learn.microsoft.com/en-us/azure/search/search-query-odata-filter[filter expression]:\n\n[source,graphql]\n----\n$filter search.in(meta_country, 'UK,NL', ',') and meta_year ge 2020\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Metadata filtering", "heading_level": 3, "file_order": 68, "section_index": 8, "content_hash": "287744f0e914f4e521354a7a690dbd2205d05e1bdead4403ed4675c7e2f6bfe1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:760f84fabe1d92769cba9fa1c9c68ae305fae059a8d6a4daa6b274f31713c213", "content": "By default, the Azure Vector Store uses the following field names in the Azure AI Search index:\n\n* `content` - for document text\n* `embedding` - for vector embeddings\n* `metadata` - for document metadata\n\nHowever, when working with existing Azure AI Search indexes that use different field names, you can configure custom field names to match your index schema. This allows you to integrate Spring AI with pre-existing indexes without needing to modify them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Custom Field Names", "heading_level": 2, "file_order": 68, "section_index": 9, "content_hash": "760f84fabe1d92769cba9fa1c9c68ae305fae059a8d6a4daa6b274f31713c213", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:e51c935d536434837d7744b72dabc7b51510a0e331d1f5cf00bca9b38589d4e2", "content": "Custom field names are particularly useful when:\n\n* **Integrating with existing indexes**: Your organization already has Azure AI Search indexes with established field naming conventions (e.g., `chunk_text`, `vector`, `meta_data`).\n* **Following naming standards**: Your team follows specific naming conventions that differ from the defaults.\n* **Migrating from other systems**: You're migrating from another vector database or search system and want to maintain consistent field names.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Use Cases", "heading_level": 3, "file_order": 68, "section_index": 10, "content_hash": "e51c935d536434837d7744b72dabc7b51510a0e331d1f5cf00bca9b38589d4e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:1b7a1a0dc8ed1e357fa8c75721be2a80c965d3cf5a2a57311f102eb9714f731f", "content": "You can configure custom field names using Spring Boot application properties:\n\n[source,properties]\n----\nspring.ai.vectorstore.azure.url=${AZURE_AI_SEARCH_ENDPOINT}\nspring.ai.vectorstore.azure.api-key=${AZURE_AI_SEARCH_API_KEY}\nspring.ai.vectorstore.azure.index-name=my-existing-index\nspring.ai.vectorstore.azure.initialize-schema=false\n\n# Custom field names to match existing index schema\nspring.ai.vectorstore.azure.content-field-name=chunk_text\nspring.ai.vectorstore.azure.embedding-field-name=vector\nspring.ai.vectorstore.azure.metadata-field-name=meta_data\n----\n\nIMPORTANT: When using an existing index with custom field names, set `initialize-schema=false` to prevent Spring AI from trying to create a new index with the default schema.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Configuration via Properties", "heading_level": 3, "file_order": 68, "section_index": 11, "content_hash": "1b7a1a0dc8ed1e357fa8c75721be2a80c965d3cf5a2a57311f102eb9714f731f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:dd90ea6c21c5592a1237934c39d87a2e3fc66e83fd4a53ab6fe21448e7817898", "content": "Alternatively, you can configure custom field names programmatically using the builder API:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(SearchIndexClient searchIndexClient, EmbeddingModel embeddingModel) {\n\n\treturn AzureVectorStore.builder(searchIndexClient, embeddingModel)\n .indexName(\"my-existing-index\")\n .initializeSchema(false) // Don't create schema - use existing index\n // Configure custom field names to match existing index\n .contentFieldName(\"chunk_text\")\n .embeddingFieldName(\"vector\")\n .metadataFieldName(\"meta_data\")\n .filterMetadataFields(List.of(\n MetadataField.text(\"category\"),\n MetadataField.text(\"source\")))\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Configuration via Builder API", "heading_level": 3, "file_order": 68, "section_index": 12, "content_hash": "dd90ea6c21c5592a1237934c39d87a2e3fc66e83fd4a53ab6fe21448e7817898", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:2d3e3ea3a857bb57f3422b3b65e9757090e0af95a1843e121d569c91788208e2", "content": "Here's a complete example showing how to use Spring AI with an existing Azure AI Search index that has custom field names:\n\n[source,java]\n----\n@Configuration\npublic class VectorStoreConfig {\n\n\t@Bean\n\tpublic SearchIndexClient searchIndexClient() {\n return new SearchIndexClientBuilder()\n .endpoint(System.getenv(\"AZURE_AI_SEARCH_ENDPOINT\"))\n .credential(new AzureKeyCredential(System.getenv(\"AZURE_AI_SEARCH_API_KEY\")))\n .buildClient();\n\t}\n\n\t@Bean\n\tpublic VectorStore vectorStore(SearchIndexClient searchIndexClient,\n EmbeddingModel embeddingModel) {\n\n return AzureVectorStore.builder(searchIndexClient, embeddingModel)\n .indexName(\"production-documents-index\")\n .initializeSchema(false) // Use existing index\n // Map to existing index field names\n .contentFieldName(\"document_text\")\n .embeddingFieldName(\"text_vector\")\n .metadataFieldName(\"document_metadata\")\n // Define filterable metadata fields from existing schema\n .filterMetadataFields(List.of(\n MetadataField.text(\"department\"),\n MetadataField.int64(\"year\"),\n MetadataField.date(\"created_date\")))\n .defaultTopK(10)\n .defaultSimilarityThreshold(0.75)\n .build();\n\t}\n}\n----\n\nYou can then use the vector store as normal:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n\tSearchRequest.builder()\n .query(\"artificial intelligence\")\n .topK(5)\n .filterExpression(\"department == 'Engineering' && year >= 2023\")\n .build());\n\nresults.forEach(doc -> System.out.println(doc.getText()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Complete Example: Working with Existing Index", "heading_level": 3, "file_order": 68, "section_index": 13, "content_hash": "2d3e3ea3a857bb57f3422b3b65e9757090e0af95a1843e121d569c91788208e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:71a2422dafe01247c0221a6aff9ad51c2da573f4de92ee6f1e3ccb207867251b", "content": "You can also create a new index with custom field names by setting `initializeSchema=true`:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(SearchIndexClient searchIndexClient,\n EmbeddingModel embeddingModel) {\n\n\treturn AzureVectorStore.builder(searchIndexClient, embeddingModel)\n .indexName(\"new-custom-index\")\n .initializeSchema(true) // Create new index with custom field names\n .contentFieldName(\"text_content\")\n .embeddingFieldName(\"content_vector\")\n .metadataFieldName(\"doc_metadata\")\n .filterMetadataFields(List.of(\n MetadataField.text(\"category\"),\n MetadataField.text(\"author\")))\n .build();\n}\n----\n\nThis will create a new Azure AI Search index with your custom field names, allowing you to establish your own naming conventions from the start.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Creating New Index with Custom Field Names", "heading_level": 3, "file_order": 68, "section_index": 14, "content_hash": "71a2422dafe01247c0221a6aff9ad51c2da573f4de92ee6f1e3ccb207867251b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:bed2adb3f6cff78b15874198b2ca883d6341ed7fd1e8a1d16adc0d895a384c7d", "content": "The Azure Vector Store implementation provides access to the underlying native Azure Search client (`SearchClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nAzureVectorStore vectorStore = context.getBean(AzureVectorStore.class);\nOptional<SearchClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n SearchClient client = nativeClient.get();\n // Use the native client for Azure Search-specific operations\n}\n----\n\nThe native client gives you access to Azure Search-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/azure.adoc", "title": "Azure AI Service", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 68, "section_index": 15, "content_hash": "bed2adb3f6cff78b15874198b2ca883d6341ed7fd1e8a1d16adc0d895a384c7d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/azure.adoc"}}
{"id": "sha256:aab9f28814b4f82bb9f5888ba2a763d14858110d741d5dda147ae4715895c784", "content": "This section walks you through setting up the Amazon Bedrock Knowledge Base `VectorStore` to perform similarity searches against a pre-configured Knowledge Base.\n\nlink:https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html[Amazon Bedrock Knowledge Bases] is a fully managed RAG (Retrieval-Augmented Generation) capability that allows you to connect foundation models to your data sources. Unlike other vector stores, Bedrock Knowledge Base handles document ingestion, chunking, and embedding internally.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Amazon Bedrock Knowledge Base", "heading_level": 1, "file_order": 69, "section_index": 0, "content_hash": "aab9f28814b4f82bb9f5888ba2a763d14858110d741d5dda147ae4715895c784", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:1a60d801007c43d18aa6f9a9b1f590131f36aad9a674ba251841e98b608e5610", "content": "1. AWS Account with Bedrock access enabled\n2. A configured Bedrock Knowledge Base with at least one data source synced\n3. AWS credentials configured (via environment variables, AWS config file, or IAM role)\n\n[NOTE]\n====\nThis vector store is read-only. Documents are managed through the Knowledge Base's data source sync process, not through the `add()` or `delete()` methods.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Prerequisites", "heading_level": 2, "file_order": 69, "section_index": 1, "content_hash": "1a60d801007c43d18aa6f9a9b1f590131f36aad9a674ba251841e98b608e5610", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:d7abe257d072fb37b9f8864344d5aa893cce17cc23f042d0af3e2026e948bffc", "content": "Spring AI provides Spring Boot auto-configuration for the Bedrock Knowledge Base Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-bedrock-knowledgebase</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-bedrock-knowledgebase'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\n[NOTE]\n====\nUnlike other vector stores, Bedrock Knowledge Base does not require an `EmbeddingModel` bean. The Knowledge Base handles embeddings internally during data source synchronization.\n====\n\nTo connect to your Knowledge Base, provide the Knowledge Base ID via Spring Boot's `application.properties`:\n\n[source,properties]\n----\nspring.ai.vectorstore.bedrock-knowledge-base.knowledge-base-id=YOUR_KNOWLEDGE_BASE_ID\nspring.ai.vectorstore.bedrock-knowledge-base.region=us-east-1\n----\n\nOr via environment variables:\n\n[source,bash]\n----\nexport SPRING_AI_VECTORSTORE_BEDROCK_KNOWLEDGE_BASE_KNOWLEDGE_BASE_ID=YOUR_KNOWLEDGE_BASE_ID\n----\n\nNow you can auto-wire the Vector Store in your application:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"What is the return policy?\")\n .topK(5)\n .build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Auto-configuration", "heading_level": 2, "file_order": 69, "section_index": 2, "content_hash": "d7abe257d072fb37b9f8864344d5aa893cce17cc23f042d0af3e2026e948bffc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:fef39e736a8d595b4266228477c11daf939fa22011d57db56806a1125dfbc9e5", "content": "You can use the following properties in your Spring Boot configuration to customize the Bedrock Knowledge Base vector store.\n\n[stripes=even]\n|===\n|Property | Description | Default value\n\n|`spring.ai.vectorstore.bedrock-knowledge-base.knowledge-base-id` | The ID of the Bedrock Knowledge Base to query | -\n|`spring.ai.vectorstore.bedrock-knowledge-base.region` | AWS region for the Bedrock service | SDK default\n|`spring.ai.vectorstore.bedrock-knowledge-base.top-k` | Number of results to return | 5\n|`spring.ai.vectorstore.bedrock-knowledge-base.similarity-threshold` | Minimum similarity score (0.0 to 1.0) | 0.0\n|`spring.ai.vectorstore.bedrock-knowledge-base.search-type` | Search type: SEMANTIC or HYBRID | null (KB default)\n|`spring.ai.vectorstore.bedrock-knowledge-base.reranking-model-arn` | ARN of Bedrock reranking model | null (disabled)\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Configuration Properties", "heading_level": 3, "file_order": 69, "section_index": 3, "content_hash": "fef39e736a8d595b4266228477c11daf939fa22011d57db56806a1125dfbc9e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:fa79c8dba4dbdcc629292fe3bbab72fb2bb33beab66b438369af1a8a568a4768", "content": "Bedrock Knowledge Base supports two search types:\n\n* `SEMANTIC` - Vector similarity search only (default)\n* `HYBRID` - Combines semantic search with keyword search\n\n[NOTE]\n====\nHYBRID search is only available with OpenSearch-based vector stores. S3 Vectors, Aurora PostgreSQL, and other vector store types only support SEMANTIC search.\n====\n\n[source,properties]\n----\nspring.ai.vectorstore.bedrock-knowledge-base.search-type=HYBRID\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Search Types", "heading_level": 2, "file_order": 69, "section_index": 4, "content_hash": "fa79c8dba4dbdcc629292fe3bbab72fb2bb33beab66b438369af1a8a568a4768", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:a5b9e749a3728d549563836c596bbc9b0b022a4c71cfb1f0abfc2323e4fdc575", "content": "You can improve search relevance by enabling a Bedrock reranking model:\n\n[source,properties]\n----\nspring.ai.vectorstore.bedrock-knowledge-base.reranking-model-arn=arn:aws:bedrock:us-west-2::foundation-model/amazon.rerank-v1:0\n----\n\nAvailable reranking models:\n\n* Amazon Rerank 1.0 - Available in us-west-2, ap-northeast-1, ca-central-1, eu-central-1\n* Cohere Rerank 3.5 - Requires AWS Marketplace subscription", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Reranking", "heading_level": 2, "file_order": 69, "section_index": 5, "content_hash": "a5b9e749a3728d549563836c596bbc9b0b022a4c71cfb1f0abfc2323e4fdc575", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:b733186e4907f64f9083f216d69b409f72b0a3ddda407e60a15074e9193b3ba0", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the Bedrock Knowledge Base store.\n\nFor example, you can use the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"travel policy\")\n .topK(5)\n .similarityThreshold(0.5)\n .filterExpression(\"department == 'HR' && year >= 2024\")\n .build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"travel policy\")\n .topK(5)\n .filterExpression(b.and(\n b.eq(\"department\", \"HR\"),\n b.gte(\"year\", 2024)).build())\n .build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 69, "section_index": 6, "content_hash": "b733186e4907f64f9083f216d69b409f72b0a3ddda407e60a15074e9193b3ba0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:3c8efd0166c7be5e6894e98503467262c067d11def423b216cccaaf0a435612d", "content": "[stripes=even]\n|===\n| Spring AI | Bedrock | Description\n\n| EQ | equals | Equal to\n| NE | notEquals | Not equal to\n| GT | greaterThan | Greater than\n| GTE | greaterThanOrEquals | Greater than or equal\n| LT | lessThan | Less than\n| LTE | lessThanOrEquals | Less than or equal\n| IN | in | Value in list\n| NIN | notIn | Value not in list\n| AND | andAll | Logical AND\n| OR | orAll | Logical OR\n| NOT | (negation) | Logical NOT\n\n|===\n\n[NOTE]\n====\nMetadata filtering requires documents in your Knowledge Base to have metadata attributes. For S3 data sources, create `.metadata.json` files alongside your documents.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Supported Filter Operators", "heading_level": 3, "file_order": 69, "section_index": 7, "content_hash": "3c8efd0166c7be5e6894e98503467262c067d11def423b216cccaaf0a435612d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:878a18c2fa0ed427e8467618930df11d0c1c656da002564f918b2daeeb7ef8d6", "content": "If you prefer to configure the vector store manually, you can do so by creating the beans directly.\n\nAdd this dependency to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-bedrock-knowledgebase-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Manual Configuration", "heading_level": 2, "file_order": 69, "section_index": 8, "content_hash": "878a18c2fa0ed427e8467618930df11d0c1c656da002564f918b2daeeb7ef8d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:d81ddcdce08969a0d6948f233bbb3fd7f506b36f2424be8e75562bd93f9dbca4", "content": "[source,java]\n----\n@Bean\npublic BedrockAgentRuntimeClient bedrockAgentRuntimeClient() {\n return BedrockAgentRuntimeClient.builder()\n .region(Region.US_EAST_1)\n .build();\n}\n\n@Bean\npublic VectorStore vectorStore(BedrockAgentRuntimeClient client) {\n return BedrockKnowledgeBaseVectorStore.builder(client, \"YOUR_KNOWLEDGE_BASE_ID\")\n .topK(10)\n .similarityThreshold(0.5)\n .searchType(SearchType.SEMANTIC)\n .build();\n}\n----\n\nThen use the vector store:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"What are the company holidays?\")\n .topK(3)\n .build());\n\nfor (Document doc : results) {\n System.out.println(\"Content: \" + doc.getText());\n System.out.println(\"Score: \" + doc.getScore());\n System.out.println(\"Source: \" + doc.getMetadata().get(\"source\"));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Sample Code", "heading_level": 3, "file_order": 69, "section_index": 9, "content_hash": "d81ddcdce08969a0d6948f233bbb3fd7f506b36f2424be8e75562bd93f9dbca4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:5cd7c0fba51e1332fe3bc508c71ecbdf981068974610cf014cf515e733e4046b", "content": "The Bedrock Knowledge Base Vector Store provides access to the underlying native client through the `getNativeClient()` method:\n\n[source,java]\n----\nBedrockKnowledgeBaseVectorStore vectorStore = context.getBean(BedrockKnowledgeBaseVectorStore.class);\nOptional<BedrockAgentRuntimeClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n BedrockAgentRuntimeClient client = nativeClient.get();\n // Use the native client for Bedrock-specific operations\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 69, "section_index": 10, "content_hash": "5cd7c0fba51e1332fe3bc508c71ecbdf981068974610cf014cf515e733e4046b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:633707f2a82f59330f0f0d4b384cc18ca409734d70ae44b40366eccac28dcc8b", "content": "* **Read-only**: The `add()` and `delete()` methods throw `UnsupportedOperationException`. Documents are managed through the Knowledge Base's data source sync process.\n* **HYBRID search**: Only available with OpenSearch-based vector stores.\n* **Reranking availability**: Model availability varies by AWS region.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Limitations", "heading_level": 2, "file_order": 69, "section_index": 11, "content_hash": "633707f2a82f59330f0f0d4b384cc18ca409734d70ae44b40366eccac28dcc8b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:e45f180f749eca86232007bac6ec44fe298a4549f85837af02d45c8e51cd2a13", "content": "Bedrock Knowledge Base supports multiple data source types. The source location is included in document metadata:\n\n[stripes=even]\n|===\n| Data Source | Metadata Field | Example\n\n| S3 | `source` | `s3://bucket/path/document.pdf`\n| Confluence | `source` | `https://confluence.example.com/page/123`\n| SharePoint | `source` | `https://sharepoint.example.com/doc/456`\n| Salesforce | `source` | `https://salesforce.example.com/record/789`\n| Web Crawler | `source` | `https://example.com/page`\n| Custom | `source` | Custom document ID\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc", "title": "Amazon Bedrock Knowledge Base", "heading": "Supported Data Sources", "heading_level": 2, "file_order": 69, "section_index": 12, "content_hash": "e45f180f749eca86232007bac6ec44fe298a4549f85837af02d45c8e51cd2a13", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/bedrock-knowledge-base.adoc"}}
{"id": "sha256:ccdb2e0f9eac3803f18ede67b8b14ae179e07cc02f161992796e8dca78ca6da5", "content": "This section will walk you through setting up the Chroma VectorStore to store document embeddings and perform similarity searches.\n\nlink:https://docs.trychroma.com/[Chroma] is the open-source embedding database. It gives you the tools to store document embeddings, content, and metadata and to search through those embeddings, including metadata filtering.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Chroma", "heading_level": 1, "file_order": 70, "section_index": 0, "content_hash": "ccdb2e0f9eac3803f18ede67b8b14ae179e07cc02f161992796e8dca78ca6da5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:dfd5c8280f77af5ef509894f1d5a1aded4ecb0cc584fc85045b59ac78cafe8a0", "content": "1. Access to ChromaDB. Compatible with link:https://trychroma.com/signup[Chroma Cloud], or <<run Chroma Locally, setup local ChromaDB>> in the appendix shows how to set up a DB locally with a Docker container.\n - For Chroma Cloud: You'll need your API key, tenant name, and database name from your Chroma Cloud dashboard.\n - For local ChromaDB: No additional configuration required beyond starting the container.\n\n2. `EmbeddingModel` instance to compute the document embeddings. Several options are available:\n- If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `ChromaVectorStore`.\n\nOn startup, the `ChromaVectorStore` creates the required collection if one is not provisioned already.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Prerequisites", "heading_level": 2, "file_order": 70, "section_index": 1, "content_hash": "dfd5c8280f77af5ef509894f1d5a1aded4ecb0cc584fc85045b59ac78cafe8a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:05e074a83b263a5b215b159b3354a579b97c78886f7935ee1bb7b9190206b40e", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Chroma Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-chroma</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-chroma'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nHere is an example of the needed bean:\n\n[source,java]\n----\n@Bean\npublic EmbeddingModel embeddingModel() {\n // Can be any other EmbeddingModel implementation.\n return new OpenAiEmbeddingModel(OpenAiApi.builder().apiKey(System.getenv(\"OPENAI_API_KEY\")).build());\n}\n----\n\nTo connect to Chroma you need to provide access details for your instance.\nA simple configuration can either be provided via Spring Boot's _application.properties_,\n\n[source,properties]\n----\n# Chroma Vector Store connection properties\nspring.ai.vectorstore.chroma.client.host=<your Chroma instance host> // for Chroma Cloud: api.trychroma.com\nspring.ai.vectorstore.chroma.client.port=<your Chroma instance port> // for Chroma Cloud: 443\nspring.ai.vectorstore.chroma.client.key-token=<your access token (if configure)> // for Chroma Cloud: use the API key\nspring.ai.vectorstore.chroma.client.username=<your username (if configure)>\nspring.ai.vectorstore.chroma.client.password=<your password (if configure)>\n\n# Chroma Vector Store tenant and database properties (required for Chroma Cloud)\nspring.ai.vectorstore.chroma.tenant-name=<your tenant name> // default: SpringAiTenant\nspring.ai.vectorstore.chroma.database-name=<your database name> // default: SpringAiDatabase\n\n# Chroma Vector Store collection properties\nspring.ai.vectorstore.chroma.initialize-schema=<true or false>\nspring.ai.vectorstore.chroma.collection-name=<your collection name>\n\n# Chroma Vector Store configuration properties\n\n# OpenAI API key if the OpenAI auto-configuration is used.\nspring.ai.openai.api.key=<OpenAI Api-key>\n----\n\nPlease have a look at the list of xref:#_configuration_properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nNow you can auto-wire the Chroma Vector Store in your application and use it\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Auto-configuration", "heading_level": 2, "file_order": 70, "section_index": 2, "content_hash": "05e074a83b263a5b215b159b3354a579b97c78886f7935ee1bb7b9190206b40e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:fc99ff27f9c8b7b5faa6ef879a19490ef58db109d1c0867784a853c34e072463", "content": "You can use the following properties in your Spring Boot configuration to customize the vector store.\n\n[stripes=even]\n|===\n|Property| Description | Default value\n\n|`spring.ai.vectorstore.chroma.client.host`| Server connection host | http://localhost[http://localhost]\n|`spring.ai.vectorstore.chroma.client.port`| Server connection port | `8000`\n|`spring.ai.vectorstore.chroma.client.key-token`| Access token (if configured) | -\n|`spring.ai.vectorstore.chroma.client.username`| Access username (if configured) | -\n|`spring.ai.vectorstore.chroma.client.password`| Access password (if configured) | -\n|`spring.ai.vectorstore.chroma.tenant-name`| Tenant (required for Chroma Cloud) | `SpringAiTenant`\n|`spring.ai.vectorstore.chroma.database-name`| Database name (required for Chroma Cloud) | `SpringAiDatabase`\n|`spring.ai.vectorstore.chroma.collection-name`| Collection name | `SpringAiCollection`\n|`spring.ai.vectorstore.chroma.initialize-schema`| Whether to initialize the required schema (creates tenant/database/collection if they don't exist) | `false`\n|===\n\n[NOTE]\n====\nFor ChromaDB secured with link:https://docs.trychroma.com/usage-guide#static-api-token-authentication[Static API Token Authentication] use the `ChromaApi#withKeyToken(<Your Token Credentials>)` method to set your credentials. Check the `ChromaWhereIT` for an example.\n\nFor ChromaDB secured with link:https://docs.trychroma.com/usage-guide#basic-authentication[Basic Authentication] use the `ChromaApi#withBasicAuth(<your user>, <your password>)` method to set your credentials. Check the `BasicAuthChromaWhereIT` for an example.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Configuration properties", "heading_level": 3, "file_order": 70, "section_index": 3, "content_hash": "fc99ff27f9c8b7b5faa6ef879a19490ef58db109d1c0867784a853c34e072463", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:dcdebf756d8fa9f8545fd306905d2b9a32afb5fbdb844723d5d6c5d4bff8f273", "content": "For Chroma Cloud, you need to provide the tenant and database names from your Chroma Cloud instance. Here's an example configuration:\n\n[source,properties]\n----\n# Chroma Cloud connection\nspring.ai.vectorstore.chroma.client.host=api.trychroma.com\nspring.ai.vectorstore.chroma.client.port=443\nspring.ai.vectorstore.chroma.client.key-token=<your-chroma-cloud-api-key>\n\n# Chroma Cloud tenant and database (required)\nspring.ai.vectorstore.chroma.tenant-name=<your-tenant-id>\nspring.ai.vectorstore.chroma.database-name=<your-database-name>\n\n# Collection configuration\nspring.ai.vectorstore.chroma.collection-name=my-collection\nspring.ai.vectorstore.chroma.initialize-schema=true\n----\n\n[NOTE]\n====\nFor Chroma Cloud:\n- The host should be `api.trychroma.com`\n- The port should be `443` (HTTPS)\n- You must provide your API key via `key-token`\n- The tenant and database names must match your Chroma Cloud configuration\n- Set `initialize-schema=true` to automatically create the collection if it doesn't exist (it won't recreate existing tenant/database)\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Chroma Cloud Configuration", "heading_level": 3, "file_order": 70, "section_index": 4, "content_hash": "dcdebf756d8fa9f8545fd306905d2b9a32afb5fbdb844723d5d6c5d4bff8f273", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:667b397cfa48afd6d9140651b7d031ca0a27e0c8ba297e400b7fc7c36d40c085", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with ChromaVector store as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary Chroma `where` link:https://docs.trychroma.com/usage-guide#using-where-filters[filter expressions].\n\nFor example, this portable filter expression:\n\n```sql\nauthor in ['john', 'jill'] && article_type == 'blog'\n```\n\nis converted into the proprietary Chroma format\n\n```json\n{\"$and\":[\n\t{\"author\": {\"$in\": [\"john\", \"jill\"]}},\n\t{\"article_type\":{\"$eq\":\"blog\"}}]\n}\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Metadata filtering", "heading_level": 2, "file_order": 70, "section_index": 5, "content_hash": "667b397cfa48afd6d9140651b7d031ca0a27e0c8ba297e400b7fc7c36d40c085", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:a437ff940c21f32811dd2123a066a9e22270129f1e71e7e6e50a4fdcfee1a802", "content": "If you prefer to configure the Chroma Vector Store manually, you can do so by creating a `ChromaVectorStore` bean in your Spring Boot application.\n\nAdd these dependencies to your project:\n* Chroma VectorStore.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-chroma-store</artifactId>\n</dependency>\n----\n\n* OpenAI: Required for calculating embeddings. You can use any other embedding model implementation.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Manual Configuration", "heading_level": 2, "file_order": 70, "section_index": 6, "content_hash": "a437ff940c21f32811dd2123a066a9e22270129f1e71e7e6e50a4fdcfee1a802", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:ddd857ac60bf746c31699a7093f4372469212b4dead39071b32e458f995d347e", "content": "Create a `RestClient.Builder` instance with proper ChromaDB authorization configurations and Use it to create a `ChromaApi` instance:\n\n[source,java]\n----\n@Bean\npublic RestClient.Builder builder() {\n return RestClient.builder().requestFactory(new SimpleClientHttpRequestFactory());\n}\n\n@Bean\npublic ChromaApi chromaApi(RestClient.Builder restClientBuilder) {\n String chromaUrl = \"http://localhost:8000\";\n ChromaApi chromaApi = new ChromaApi(chromaUrl, restClientBuilder);\n return chromaApi;\n}\n----\n\nIntegrate with OpenAI's embeddings by adding the Spring Boot OpenAI starter to your project. This provides you with an implementation of the Embeddings client:\n\n[source,java]\n----\n@Bean\npublic VectorStore chromaVectorStore(EmbeddingModel embeddingModel, ChromaApi chromaApi) {\n return ChromaVectorStore.builder(chromaApi, embeddingModel)\n .tenantName(\"your-tenant-name\") // default: SpringAiTenant\n .databaseName(\"your-database-name\") // default: SpringAiDatabase\n .collectionName(\"TestCollection\")\n .initializeSchema(true)\n .build();\n}\n----\n\nIn your main code, create some documents:\n\n[source,java]\n----\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n----\n\nAdd the documents to your vector store:\n\n[source,java]\n----\nvectorStore.add(documents);\n----\n\nAnd finally, retrieve documents similar to a query:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\"Spring\");\n----\n\nIf all goes well, you should retrieve the document containing the text \"Spring AI rocks!!\".", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Sample Code", "heading_level": 3, "file_order": 70, "section_index": 7, "content_hash": "ddd857ac60bf746c31699a7093f4372469212b4dead39071b32e458f995d347e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:909e72d05f97e6dab78a535e6ca4f38d48a9151e34e026650fd2118689125eb2", "content": "```shell\ndocker run -it --rm --name chroma -p 8000:8000 ghcr.io/chroma-core/chroma:1.0.0\n```\n\nStarts a chroma store at <http://localhost:8000/api/v1>", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/chroma.adoc", "title": "Chroma", "heading": "Run Chroma Locally", "heading_level": 3, "file_order": 70, "section_index": 8, "content_hash": "909e72d05f97e6dab78a535e6ca4f38d48a9151e34e026650fd2118689125eb2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/chroma.adoc"}}
{"id": "sha256:5a18f20d28b541f551100bdce873011df0799c15ef0600343fd5b4109cb59b4f", "content": "The Coherence Vector Store implementation provides access to the underlying native Coherence client (`Session`) through the `getNativeClient()` method:\n\n[source,java]\n----\nCoherenceVectorStore vectorStore = context.getBean(CoherenceVectorStore.class);\nOptional<Session> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n Session session = nativeClient.get();\n // Use the native client for Coherence-specific operations\n}\n----\n\nThe native client gives you access to Coherence-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/coherence.adoc", "title": "coherence", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 71, "section_index": 0, "content_hash": "5a18f20d28b541f551100bdce873011df0799c15ef0600343fd5b4109cb59b4f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/coherence.adoc"}}
{"id": "sha256:9dfe7d738195145af435cb60f3911c066a6d9e4ecedb7ba85948e2a8877b8c0a", "content": "This section will walk you through setting up the `CouchbaseSearchVectorStore` to store document embeddings and perform similarity searches using Couchbase.\n\nlink:https://docs.couchbase.com/server/current/vector-search/vector-search.html[Couchbase] is a distributed, JSON document database, with all the desired capabilities of a relational DBMS. Among other features, it allows users to query information using vector-based storage and retrieval.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Couchbase", "heading_level": 1, "file_order": 72, "section_index": 0, "content_hash": "9dfe7d738195145af435cb60f3911c066a6d9e4ecedb7ba85948e2a8877b8c0a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:66bfa3e81b2d6928a3d1f9ef9978fd8c0bc5483cbac0f3c4844e2f4a9e6960f7", "content": "A running Couchbase instance. The following options are available:\nCouchbase\n* link:https://hub.docker.com/_/couchbase/[Docker]\n* link:https://cloud.couchbase.com/[Capella - Couchbase as a Service]\n* link:https://www.couchbase.com/downloads/?family=couchbase-server[Install Couchbase locally]\n* link:https://www.couchbase.com/downloads/?family=open-source-kubernetes[Couchbase Kubernetes Operator]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Prerequisites", "heading_level": 2, "file_order": 72, "section_index": 1, "content_hash": "66bfa3e81b2d6928a3d1f9ef9978fd8c0bc5483cbac0f3c4844e2f4a9e6960f7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:f44852d8179d2626c7a352776240aa08681e7664a1d1dc89ee79500005f3d3c5", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Couchbase Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-couchbase</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-couchbase-store-spring-boot-starter'\n}\n----\nNOTE: Couchbase Vector search is only available in starting version 7.6 and Java SDK version 3.6.0\"\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Milestone and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the configured bucket, scope, collection and search index for you, with default options, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor.\n\nNOTE: This is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nPlease have a look at the list of <<couchbasevector-properties,configuration parameters>> for the vector store to learn about the default values and configuration options.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `CouchbaseSearchVectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.query(\"Spring\").withTopK(5));\n----\n\n[[couchbasevector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Auto-configuration", "heading_level": 2, "file_order": 72, "section_index": 2, "content_hash": "f44852d8179d2626c7a352776240aa08681e7664a1d1dc89ee79500005f3d3c5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:7bf2b5274e42e295f6e4176b2ba5c77ed89ad54c7bf3dc582e3deeb26dc4b7d9", "content": "To connect to Couchbase and use the `CouchbaseSearchVectorStore`, you need to provide access details for your instance.\nConfiguration can be provided via Spring Boot's `application.properties`:\n\n[source,properties]\n----\nspring.ai.openai.api-key=<key>\nspring.couchbase.connection-string=<conn_string>\nspring.couchbase.username=<username>\nspring.couchbase.password=<password>\n----\n\nIf you prefer to use environment variables for sensitive information like passwords or API keys, you have multiple options:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Configuration Properties", "heading_level": 3, "file_order": 72, "section_index": 3, "content_hash": "7bf2b5274e42e295f6e4176b2ba5c77ed89ad54c7bf3dc582e3deeb26dc4b7d9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:fbe5062b8d49d40b0cc25b7ee8c999b9cc6ba01086e7f9c7e44a0a1ae9602ae3", "content": "You can use custom environment variable names and reference them in your application configuration using SpEL:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n openai:\n api-key: ${OPENAI_API_KEY}\n couchbase:\n connection-string: ${COUCHBASE_CONN_STRING}\n username: ${COUCHBASE_USER}\n password: ${COUCHBASE_PASSWORD}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport OPENAI_API_KEY=<api-key>\nexport COUCHBASE_CONN_STRING=<couchbase connection string like couchbase://localhost>\nexport COUCHBASE_USER=<couchbase username>\nexport COUCHBASE_PASSWORD=<couchbase password>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Option 1: Using Spring Expression Language (SpEL)", "heading_level": 4, "file_order": 72, "section_index": 4, "content_hash": "fbe5062b8d49d40b0cc25b7ee8c999b9cc6ba01086e7f9c7e44a0a1ae9602ae3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:fcf55bf4e650b747a22bb716c242abc0d09f275db89746f3cae49b7ae7d20f7a", "content": "Alternatively, you can access environment variables in your Java code:\n\n[source,java]\n----\nString apiKey = System.getenv(\"OPENAI_API_KEY\");\n----\n\nThis approach gives you flexibility in naming your environment variables while keeping sensitive information out of your application configuration files.\n\nNOTE: If you choose to create a shell script for ease in future work, be sure to run it prior to starting your application by \"sourcing\" the file, i.e. `source <your_script_name>.sh`.\n\nSpring Boot's auto-configuration feature for the Couchbase Cluster will create a bean instance that will be used by the `CouchbaseSearchVectorStore`.\n\nThe Spring Boot properties starting with `spring.couchbase.*` are used to configure the Couchbase cluster instance:\n\n|===\n|Property | Description | Default Value\n\n| `spring.couchbase.connection-string` | A couchbase connection string | `couchbase://localhost`\n| `spring.couchbase.password` | Password for authentication with Couchbase. | -\n| `spring.couchbase.username` | Username for authentication with Couchbase.| -\n| `spring.couchbase.env.io.minEndpoints` | Minimum number of sockets per node.| 1\n| `spring.couchbase.env.io.maxEndpoints` | Maximum number of sockets per node.| 12\n| `spring.couchbase.env.io.idleHttpConnectionTimeout` | Length of time an HTTP connection may remain idle before it is closed and removed from the pool.| 1s\n| `spring.couchbase.env.ssl.enabled` | Whether to enable SSL support. Enabled automatically if a \"bundle\" is provided unless specified otherwise.| -\n| `spring.couchbase.env.ssl.bundle` | SSL bundle name.| -\n| `spring.couchbase.env.timeouts.connect` | Bucket connect timeout.| 10s\n| `spring.couchbase.env.timeouts.disconnect` | Bucket disconnect timeout.| 10s\n| `spring.couchbase.env.timeouts.key-value` | Timeout for operations on a specific key-value.| 2500ms\n| `spring.couchbase.env.timeouts.key-value` | Timeout for operations on a specific key-value with a durability level.| 10s\n| `spring.couchbase.env.timeouts.key-value-durable` | Timeout for operations on a specific key-value with a durability level.| 10s\n| `spring.couchbase.env.timeouts.query` | SQL++ query operations timeout.| 75s\n| `spring.couchbase.env.timeouts.view` | Regular and geospatial view operations timeout.| 75s\n| `spring.couchbase.env.timeouts.search` | Timeout for the search service.| 75s\n| `spring.couchbase.env.timeouts.analytics` | Timeout for the analytics service.| 75s\n| `spring.couchbase.env.timeouts.management` | Timeout for the management operations.| 75s\n|===\n\nProperties starting with the `spring.ai.vectorstore.couchbase.*` prefix are used to configure `CouchbaseSearchVectorStore`.\n\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.couchbase.index-name` | The name of the index to store the vectors. | spring-ai-document-index\n|`spring.ai.vectorstore.couchbase.bucket-name` | The name of the Couchbase Bucket, parent of the scope. | default\n|`spring.ai.vectorstore.couchbase.scope-name` |The name of the Couchbase scope, parent of the collection. Search queries will be executed in the scope context.| _default_\n|`spring.ai.vectorstore.couchbase.collection-name` | The name of the Couchbase collection to store the Documents. | _default_\n|`spring.ai.vectorstore.couchbase.dimensions` | The number of dimensions in the vector. | 1536\n|`spring.ai.vectorstore.couchbase.similarity` | The similarity function to use. | `dot_product`\n|`spring.ai.vectorstore.couchbase.optimization` | The similarity function to use. | `recall`\n|`spring.ai.vectorstore.couchbase.initialize-schema`| whether to initialize the required schema | `false`\n|===\n\nThe following similarity functions are available:\n\n* l2_norm\n* dot_product\n\nThe following index optimizations are available:\n\n* recall\n* latency\n\nMore details about each in the https://docs.couchbase.com/server/current/search/child-field-options-reference.html[Couchbase Documentation] on vector searches.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Option 2: Accessing Environment Variables Programmatically", "heading_level": 4, "file_order": 72, "section_index": 5, "content_hash": "fcf55bf4e650b747a22bb716c242abc0d09f275db89746f3cae49b7ae7d20f7a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:b3c4ab4c1f353d9c78971097ab415f5cac12d7802bef209dc3b0ea8df1d5823a", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the Couchbase store.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.defaults()\n .query(\"The World\")\n .topK(TOP_K)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\"));\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.defaults()\n .query(\"The World\")\n .topK(TOP_K)\n .filterExpression(b.and(\n b.in(\"author\",\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()));\n----\n\nNOTE: These filter expressions are converted into the equivalent Couchbase SQL++ filters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 72, "section_index": 6, "content_hash": "b3c4ab4c1f353d9c78971097ab415f5cac12d7802bef209dc3b0ea8df1d5823a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:f94306e3316c207626221fc780bc6a7bb61c2a2a53a5382274fcddd95d677743", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the Couchbase vector store. For this you need to add the `spring-ai-couchbase-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-couchbase-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-couchbase-store'\n}\n----\n\nCreate a Couchbase `Cluster` bean.\nRead the link:https://docs.couchbase.com/java-sdk/current/hello-world/start-using-sdk.html[Couchbase Documentation] for more in-depth information about the configuration of a custom Cluster instance.\n\n[source,java]\n----\n@Bean\npublic Cluster cluster() {\n return Cluster.connect(\"couchbase://localhost\", \"username\", \"password\");\n}\n\n----\n\nand then create the `CouchbaseSearchVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore couchbaseSearchVectorStore(Cluster cluster,\n EmbeddingModel embeddingModel,\n Boolean initializeSchema) {\n return CouchbaseSearchVectorStore\n .builder(cluster, embeddingModel)\n .bucketName(\"test\")\n .scopeName(\"test\")\n .collectionName(\"test\")\n .initializeSchema(initializeSchema)\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(OpenAiApi.builder().apiKey(this.openaiKey).build());\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Manual Configuration", "heading_level": 2, "file_order": 72, "section_index": 7, "content_hash": "f94306e3316c207626221fc780bc6a7bb61c2a2a53a5382274fcddd95d677743", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:daf46aa3a0877532c32fbe971973df06763a711b7216b960d23b4c4d81b7325f", "content": "NOTE: It is mandatory to have the following Couchbase services activated: Data, Query, Index, Search. While Data and Search could be enough, Query and Index are necessary to support the complete metadata filtering mechanism.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc", "title": "Couchbase", "heading": "Limitations", "heading_level": 2, "file_order": 72, "section_index": 8, "content_hash": "daf46aa3a0877532c32fbe971973df06763a711b7216b960d23b4c4d81b7325f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/couchbase.adoc"}}
{"id": "sha256:a66e706b5f7226bc9be92cb3781ea8c2bf1536839aede9bbbcb2c5b1945cd021", "content": "This section walks you through setting up the Elasticsearch `VectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://www.elastic.co/elasticsearch[Elasticsearch] is an open source search and analytics engine based on the Apache Lucene library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Elasticsearch", "heading_level": 1, "file_order": 73, "section_index": 0, "content_hash": "a66e706b5f7226bc9be92cb3781ea8c2bf1536839aede9bbbcb2c5b1945cd021", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:a5cac71f62937ee7f48ab70d50dcfcb1a562284c9de2f19aba37255f5e44156b", "content": "A running Elasticsearch instance. The following options are available:\n\n* link:https://hub.docker.com/_/elasticsearch/[Docker]\n* link:https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html#elasticsearch-install-packages[Self-Managed Elasticsearch]\n* link:https://www.elastic.co/cloud/elasticsearch-service/signup?page=docs&placement=docs-body[Elastic Cloud]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Prerequisites", "heading_level": 2, "file_order": 73, "section_index": 1, "content_hash": "a5cac71f62937ee7f48ab70d50dcfcb1a562284c9de2f19aba37255f5e44156b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:2391736e3acd74d972a91ebb63ced1961a56aaff20a2f87bf07749758998318e", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Elasticsearch Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` or Gradle `build.gradle` build files:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-elasticsearch</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-elasticsearch'\n}\n----\n======\n\n[NOTE]\n--\nFor spring-boot versions pre 3.3.0 it's necessary to explicitly add the elasticsearch-java dependency with version > 8.13.3, otherwise the older version used will be incompatible with the queries performed:\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>co.elastic.clients</groupId>\n <artifactId>elasticsearch-java</artifactId>\n <version>8.13.3</version>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'co.elastic.clients:elasticsearch-java:8.13.3'\n}\n----\n======\n--\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\nAlternatively you can opt-out the initialization and create the index manually using the Elasticsearch client, which can be useful if the index needs advanced mapping or additional configuration.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nPlease have a look at the list of <<elasticsearchvector-properties,configuration parameters>> for the vector store to learn about the default values and configuration options.\nThese properties can be also set by configuring the `ElasticsearchVectorStoreOptions` bean.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `ElasticsearchVectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[elasticsearchvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Auto-configuration", "heading_level": 2, "file_order": 73, "section_index": 2, "content_hash": "2391736e3acd74d972a91ebb63ced1961a56aaff20a2f87bf07749758998318e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:05b9328a2d2805d2a9249ff23dcf14a43bbe339f31d4ece805d82810f068e8c5", "content": "To connect to Elasticsearch and use the `ElasticsearchVectorStore`, you need to provide access details for your instance.\nA simple configuration can either be provided via Spring Boot's `application.yml`,\n\n[source,yaml]\n----\nspring:\n elasticsearch:\n uris: <elasticsearch instance URIs>\n username: <elasticsearch username>\n password: <elasticsearch password>\n ai:\n vectorstore:\n elasticsearch:\n initialize-schema: true\n index-name: custom-index\n dimensions: 1536\n similarity: cosine\n----\n\nThe Spring Boot properties starting with `spring.elasticsearch.*` are used to configure the Elasticsearch client:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n| `spring.elasticsearch.connection-timeout` | Connection timeout used when communicating with Elasticsearch. | `1s`\n| `spring.elasticsearch.password` | Password for authentication with Elasticsearch. | -\n| `spring.elasticsearch.username` | Username for authentication with Elasticsearch.| -\n| `spring.elasticsearch.uris` | Comma-separated list of the Elasticsearch instances to use. | `+http://localhost:9200+`\n| `spring.elasticsearch.path-prefix` | Prefix added to the path of every request sent to Elasticsearch. | -\n| `spring.elasticsearch.restclient.sniffer.delay-after-failure` | Delay of a sniff execution scheduled after a failure.| `1m`\n| `spring.elasticsearch.restclient.sniffer.interval` | Interval between consecutive ordinary sniff executions. | `5m`\n| `spring.elasticsearch.restclient.ssl.bundle` | SSL bundle name. | -\n| `spring.elasticsearch.socket-keep-alive` | Whether to enable socket keep alive between client and Elasticsearch. | `false`\n| `spring.elasticsearch.socket-timeout` | Socket timeout used when communicating with Elasticsearch. | `30s`\n|===\n\nProperties starting with `spring.ai.vectorstore.elasticsearch.*` are used to configure the `ElasticsearchVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.elasticsearch.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.elasticsearch.index-name` | The name of the index to store the vectors | `spring-ai-document-index`\n|`spring.ai.vectorstore.elasticsearch.dimensions` | The number of dimensions in the vector | `1536`\n|`spring.ai.vectorstore.elasticsearch.similarity` | The similarity function to use | `cosine`\n|`spring.ai.vectorstore.elasticsearch.embedding-field-name` | The name of the vector field to search against | `embedding`\n|===\n\nThe following similarity functions are available:\n\n* `cosine` - Default, suitable for most use cases. Measures cosine similarity between vectors.\n* `l2_norm` - Euclidean distance between vectors. Lower values indicate higher similarity.\n* `dot_product` - Best performance for normalized vectors (e.g., OpenAI embeddings).\n\nMore details about each in the https://www.elastic.co/guide/en/elasticsearch/reference/master/dense-vector.html#dense-vector-params[Elasticsearch Documentation] on dense vectors.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Configuration Properties", "heading_level": 3, "file_order": 73, "section_index": 3, "content_hash": "05b9328a2d2805d2a9249ff23dcf14a43bbe339f31d4ece805d82810f068e8c5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:4a072ae198532989c857ab1be85f64a6e79a39b3529ef3f95cf50335d186e83c", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Elasticsearch as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && 'article_type' == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary Elasticsearch link:https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html[Query string query].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\nauthor in ['john', 'jill'] && 'article_type' == 'blog'\n----\n\nis converted into the proprietary Elasticsearch filter format:\n\n[source,text]\n----\n(metadata.author:john OR jill) AND metadata.article_type:blog\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 73, "section_index": 4, "content_hash": "4a072ae198532989c857ab1be85f64a6e79a39b3529ef3f95cf50335d186e83c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:9f2b9fe4bd0869646e409a5427203abac3d5077f4a25571658219df3e77225d3", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the Elasticsearch vector store. For this you need to add the `spring-ai-elasticsearch-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-elasticsearch-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-elasticsearch-store'\n}\n----\n\nCreate an Elasticsearch `RestClient` bean.\nRead the link:https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/java-rest-low-usage-initialization.html[Elasticsearch Documentation] for more in-depth information about the configuration of a custom RestClient.\n\n[source,java]\n----\n@Bean\npublic RestClient restClient() {\n return RestClient.builder(new HttpHost(\"<host>\", 9200, \"http\"))\n .setDefaultHeaders(new Header[]{\n new BasicHeader(\"Authorization\", \"Basic <encoded username and password>\")\n })\n .build();\n}\n----\n\nThen create the `ElasticsearchVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(RestClient restClient, EmbeddingModel embeddingModel) {\n ElasticsearchVectorStoreOptions options = new ElasticsearchVectorStoreOptions();\n options.setIndexName(\"custom-index\"); // Optional: defaults to \"spring-ai-document-index\"\n options.setSimilarity(COSINE); // Optional: defaults to COSINE\n options.setDimensions(1536); // Optional: defaults to model dimensions or 1536\n\n return ElasticsearchVectorStore.builder(restClient, embeddingModel)\n .options(options) // Optional: use custom options\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Manual Configuration", "heading_level": 2, "file_order": 73, "section_index": 5, "content_hash": "9f2b9fe4bd0869646e409a5427203abac3d5077f4a25571658219df3e77225d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:359312d00596c87063bee829897c9b6d8040b4b8408f80f7682d6d4f429d86b8", "content": "The Elasticsearch Vector Store implementation provides access to the underlying native Elasticsearch client (`ElasticsearchClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nElasticsearchVectorStore vectorStore = context.getBean(ElasticsearchVectorStore.class);\nOptional<ElasticsearchClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n ElasticsearchClient client = nativeClient.get();\n // Use the native client for Elasticsearch-specific operations\n}\n----\n\nThe native client gives you access to Elasticsearch-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc", "title": "Elasticsearch", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 73, "section_index": 6, "content_hash": "359312d00596c87063bee829897c9b6d8040b4b8408f80f7682d6d4f429d86b8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/elasticsearch.adoc"}}
{"id": "sha256:cb9aedbba438630a1933c4edc7ec89d487b6a50f5c0040bc67370fb53afbc288", "content": "This section walks you through setting up the `GemFireVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://tanzu.vmware.com/gemfire[GemFire] is a distributed, in-memory, key-value store performing read and write operations at blazingly fast speeds. It offers highly available parallel message queues, continuous availability, and an event-driven architecture you can scale dynamically without downtime. As your data size requirements increase to support high-performance, real-time apps, GemFire can easily scale linearly.\n\nlink:https://docs.vmware.com/en/VMware-GemFire-VectorDB/1.0/gemfire-vectordb/overview.html[GemFire VectorDB] extends GemFire's capabilities, serving as a versatile vector database that efficiently stores, retrieves, and performs vector similarity searches.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "GemFire Vector Store", "heading_level": 1, "file_order": 74, "section_index": 0, "content_hash": "cb9aedbba438630a1933c4edc7ec89d487b6a50f5c0040bc67370fb53afbc288", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:ed768455b965a4255562f1829992a2cf0ecfb3a04f5f4c752edc1994dfcacb19", "content": "1. A GemFire cluster with the GemFire VectorDB extension enabled\n- link:https://docs.vmware.com/en/VMware-GemFire-VectorDB/1.0/gemfire-vectordb/install.html[Install GemFire VectorDB extension]\n\n2. An `EmbeddingModel` bean to compute the document embeddings. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\nAn option that runs locally on your machine is xref:api/embeddings/onnx.adoc[ONNX] and the all-MiniLM-L6-v2 Sentence Transformers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Prerequisites", "heading_level": 2, "file_order": 74, "section_index": 1, "content_hash": "ed768455b965a4255562f1829992a2cf0ecfb3a04f5f4c752edc1994dfcacb19", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:f12c9d6cb0d6711a47e18becf7b836eaf2bbc257dd6b3574059f2a587a314c44", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the GemFire VectorStore Spring Boot starter to you project's Maven build file `pom.xml`:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-gemfire</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` file\n\n[source, xml]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-gemfire'\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Auto-configuration", "heading_level": 2, "file_order": 74, "section_index": 2, "content_hash": "f12c9d6cb0d6711a47e18becf7b836eaf2bbc257dd6b3574059f2a587a314c44", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:e793587907600ff8985027f786f91e923875fee6d4ce22a48ffb409271afa27c", "content": "You can use the following properties in your Spring Boot configuration to further configure the `GemFireVectorStore`.\n\n[stripes=even]\n|===\n|Property|Default value\n\n|`spring.ai.vectorstore.gemfire.host`|localhost\n|`spring.ai.vectorstore.gemfire.port`|8080\n|`spring.ai.vectorstore.gemfire.initialize-schema`| `false`\n|`spring.ai.vectorstore.gemfire.index-name`|spring-ai-gemfire-store\n|`spring.ai.vectorstore.gemfire.beam-width`|100\n|`spring.ai.vectorstore.gemfire.max-connections`|16\n|`spring.ai.vectorstore.gemfire.vector-similarity-function`|COSINE\n|`spring.ai.vectorstore.gemfire.fields`|[]\n|`spring.ai.vectorstore.gemfire.buckets`|0\n|`spring.ai.vectorstore.gemfire.username`|null\n|`spring.ai.vectorstore.gemfire.password`|null\n|`spring.ai.vectorstore.gemfire.token`|null\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Configuration properties", "heading_level": 3, "file_order": 74, "section_index": 3, "content_hash": "e793587907600ff8985027f786f91e923875fee6d4ce22a48ffb409271afa27c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:2a1cfdfee1fdf2f2f762f983ee39ec670d59df57bc563303f2e73bec07510b14", "content": "To use just the `GemFireVectorStore`, without Spring Boot's Auto-configuration add the following dependency to your project’s Maven `pom.xml`:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-gemfire-store</artifactId>\n</dependency>\n----\n\nFor Gradle users, add the following to your `build.gradle` file under the dependencies block to use just the `GemFireVectorStore`:\n\n[souce, xml]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-gemfire-store'\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Manual Configuration", "heading_level": 2, "file_order": 74, "section_index": 4, "content_hash": "2a1cfdfee1fdf2f2f762f983ee39ec670d59df57bc563303f2e73bec07510b14", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:94d7791e20a18028b8b7d9c38f03460107c95d2b359744da210d8de923e8df8a", "content": "Here is a sample that creates an instance of the `GemfireVectorStore` instead of using AutoConfiguration\n\n[source,java]\n----\n@Bean\npublic GemFireVectorStore vectorStore(EmbeddingModel embeddingModel) {\n return GemFireVectorStore.builder(embeddingModel)\n .host(\"localhost\")\n .port(7071)\n .username(\"my-user-name\")\n .password(\"my-password\")\n .indexName(\"my-vector-index\")\n .fields(new String[] {\"country\", \"year\", \"activationDate\"}) // Optional: fields for metadata filtering\n .initializeSchema(true)\n .build();\n}\n----\n\n[NOTE]\n====\nThe default configuration connects to a GemFire cluster at `localhost:8080`\n====\n\n- In your application, create a few documents:\n\n[source,java]\n----\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"country\", \"UK\", \"year\", 2020)),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\", Map.of()),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"country\", \"NL\", \"year\", 2023)));\n----\n\n- Add the documents to the vector store:\n\n[source,java]\n----\nvectorStore.add(documents);\n----\n\n- And to retrieve documents using similarity search:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\nYou should retrieve the document containing the text \"Spring AI rocks!!\".\n\nYou can also limit the number of results using a similarity threshold:\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder().query(\"Spring\").topK(5)\n .similarityThreshold(0.5d).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Usage", "heading_level": 2, "file_order": 74, "section_index": 5, "content_hash": "94d7791e20a18028b8b7d9c38f03460107c95d2b359744da210d8de923e8df8a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:72e4a6c313c350e23c41147d8faa42452348c77d0004d9d4763c7f7d04507f2c", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with GemFire VectorStore as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(5)\n .similarityThreshold(0.7)\n .filterExpression(\"country == 'BG' && year >= 2020\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(5)\n .similarityThreshold(0.7)\n .filterExpression(b.and(\n b.eq(\"country\", \"BG\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary GemFire VectorDB query format.\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\ncountry == 'BG' && year >= 2020\n----\n\nis converted into the proprietary GemFire VectorDB filter format:\n\n----\ncountry:BG AND year:[2020 TO *]\n----\n\nThe GemFire VectorStore supports a wide range of filter operations:\n\n* **Equality**: `country == 'BG'` → `country:BG`\n* **Inequality**: `city != 'Sofia'` → `city: NOT Sofia`\n* **Greater Than**: `year > 2020` → `year:{2020 TO *]`\n* **Greater Than or Equal**: `year >= 2020` → `year:[2020 TO *]`\n* **Less Than**: `year < 2025` → `year:[* TO 2025}`\n* **Less Than or Equal**: `year <= 2025` → `year:[* TO 2025]`\n* **IN**: `country in ['BG', 'NL']` → `country:(BG OR NL)`\n* **NOT IN**: `country nin ['BG', 'NL']` → `NOT country:(BG OR NL)`\n* **AND/OR**: Logical operators for combining conditions\n* **Grouping**: Use parentheses for complex expressions\n* **Date Filtering**: Date values in ISO 8601 format (e.g., `2024-01-07T14:29:12Z`)\n\n[IMPORTANT]\n====\nTo use metadata filtering with GemFire VectorStore, you must specify the metadata fields that can be filtered when creating the vector store. This is done using the `fields` parameter in the builder:\n\n[source,java]\n----\nGemFireVectorStore.builder(embeddingModel)\n .fields(new String[] {\"country\", \"year\", \"activationDate\"})\n .build();\n----\n\nOr via configuration properties:\n\n[source,properties]\n----\nspring.ai.vectorstore.gemfire.fields=country,year,activationDate\n----\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc", "title": "GemFire Vector Store", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 74, "section_index": 6, "content_hash": "72e4a6c313c350e23c41147d8faa42452348c77d0004d9d4763c7f7d04507f2c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/gemfire.adoc"}}
{"id": "sha256:06cdb7562cadbe58c61c081764a99e3586ad065bf10fc25fc266d8ed4ae9c51e", "content": "* You need a SAP HANA Cloud vector engine account - Refer xref:api/vectordbs/hanadb-provision-a-trial-account.adoc[SAP HANA Cloud vector engine - provision a trial account] guide to create a trial account.\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the vector store.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hana.adoc", "title": "SAP HANA Cloud", "heading": "Prerequisites", "heading_level": 2, "file_order": 75, "section_index": 0, "content_hash": "06cdb7562cadbe58c61c081764a99e3586ad065bf10fc25fc266d8ed4ae9c51e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hana.adoc"}}
{"id": "sha256:c3812ae736deee02ef47db2b08ca9c4696a4e194d295b3fd77e2fdc689632a59", "content": "Spring AI does not provide a dedicated module for SAP Hana vector store.\nUsers are expected to provide their own configuration in the applications using the standard vector store module for SAP Hana vector store in Spring AI - `spring-ai-hanadb-store`.\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#hanacloudvectorstore-properties[HanaCloudVectorStore Properties] for the vector store to learn about the default values and configuration options.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\n[[hanacloudvectorstore-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hana.adoc", "title": "SAP HANA Cloud", "heading": "Auto-configuration", "heading_level": 2, "file_order": 75, "section_index": 1, "content_hash": "c3812ae736deee02ef47db2b08ca9c4696a4e194d295b3fd77e2fdc689632a59", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hana.adoc"}}
{"id": "sha256:b32a2d5d0f233815ea6ad1528476fb1cdb297212dd7bd75296f6c1503c11f5cc", "content": "You can use the following properties in your Spring Boot configuration to customize the SAP Hana vector store.\nIt uses `spring.datasource.*` properties to configure the Hana datasource and the `spring.ai.vectorstore.hanadb.*` properties to configure the Hana vector store.\n\n|===\n|Property| Description | Default value\n\n|`spring.datasource.driver-class-name` | Driver class name | com.sap.db.jdbc.Driver\n|`spring.datasource.url` | Hana Datasource URL | -\n|`spring.datasource.username` | Hana datasource username | -\n|`spring.datasource.password` | Hana datasource password | -\n|`spring.ai.vectorstore.hanadb.top-k`| TODO | -\n|`spring.ai.vectorstore.hanadb.table-name`| TODO | -\n|`spring.ai.vectorstore.hanadb.initialize-schema`| whether to initialize the required schema | `false`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hana.adoc", "title": "SAP HANA Cloud", "heading": "HanaCloudVectorStore Properties", "heading_level": 2, "file_order": 75, "section_index": 2, "content_hash": "b32a2d5d0f233815ea6ad1528476fb1cdb297212dd7bd75296f6c1503c11f5cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hana.adoc"}}
{"id": "sha256:c6450f5c24817b120973a04a1e87f18bac897d55aff90bc4301c71ee3fda757a", "content": "Shows how to setup a project that uses SAP Hana Cloud as the vector DB and leverage OpenAI to implement RAG pattern\n\n* Create a table `CRICKET_WORLD_CUP` in SAP Hana DB:\n[sql]\n----\nCREATE TABLE CRICKET_WORLD_CUP (\n _ID VARCHAR2(255) PRIMARY KEY,\n CONTENT CLOB,\n EMBEDDING REAL_VECTOR(1536)\n)\n----\n\n* Add the following dependencies in your `pom.xml`\n\nYou may set the property `spring-ai-version` as `<spring-ai-version>1.0.0-SNAPSHOT</spring-ai-version>`:\n[source,xml]\n----\n\n<dependencyManagement>\n <dependencies>\n <dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-bom</artifactId>\n <version>${spring-ai-version}</version>\n <type>pom</type>\n <scope>import</scope>\n </dependency>\n </dependencies>\n</dependencyManagement>\n\n<dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-web</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-pdf-document-reader</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-hana</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.projectlombok</groupId>\n <artifactId>lombok</artifactId>\n <version>1.18.30</version>\n <scope>provided</scope>\n</dependency>\n----\n\n* Add the following properties in `application.properties` file:\n\n[yml]\n----\nspring.ai.openai.api-key=${OPENAI_API_KEY}\nspring.ai.openai.embedding.options.model=text-embedding-ada-002\n\nspring.datasource.driver-class-name=com.sap.db.jdbc.Driver\nspring.datasource.url=${HANA_DATASOURCE_URL}\nspring.datasource.username=${HANA_DATASOURCE_USERNAME}\nspring.datasource.password=${HANA_DATASOURCE_PASSWORD}\n\nspring.ai.vectorstore.hanadb.tableName=CRICKET_WORLD_CUP\nspring.ai.vectorstore.hanadb.topK=3\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hana.adoc", "title": "SAP HANA Cloud", "heading": "Build a Sample RAG application", "heading_level": 2, "file_order": 75, "section_index": 3, "content_hash": "c6450f5c24817b120973a04a1e87f18bac897d55aff90bc4301c71ee3fda757a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hana.adoc"}}
{"id": "sha256:37e3f3dad1f5d523d24bc5cfc3ff1994ad6cc438f9d44f2d5eb7f3d548e81503", "content": "[source,java]\n----\npackage com.interviewpedia.spring.ai.hana;\n\nimport jakarta.persistence.Column;\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.Table;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\nimport lombok.extern.jackson.Jacksonized;\nimport org.springframework.ai.vectorstore.hanadb.HanaVectorEntity;\n\n@Entity\n@Table(name = \"CRICKET_WORLD_CUP\")\n@Data\n@Jacksonized\n@NoArgsConstructor\npublic class CricketWorldCup extends HanaVectorEntity {\n @Column(name = \"content\")\n private String content;\n}\n\n----\n\n* Create a `Repository` named `CricketWorldCupRepository` that implements `HanaVectorRepository` interface:\n\n[source,java]\n----\npackage com.interviewpedia.spring.ai.hana;\n\nimport jakarta.persistence.EntityManager;\nimport jakarta.persistence.PersistenceContext;\nimport jakarta.transaction.Transactional;\nimport org.springframework.ai.vectorstore.hanadb.HanaVectorRepository;\nimport org.springframework.stereotype.Repository;\n\nimport java.util.List;\n\n@Repository\npublic class CricketWorldCupRepository implements HanaVectorRepository<CricketWorldCup> {\n @PersistenceContext\n private EntityManager entityManager;\n\n @Override\n @Transactional\n public void save(String tableName, String id, String embedding, String content) {\n String sql = String.format(\"\"\"\n INSERT INTO %s (_ID, EMBEDDING, CONTENT)\n VALUES(:_id, TO_REAL_VECTOR(:embedding), :content)\n \"\"\", tableName);\n\n this.entityManager.createNativeQuery(sql)\n .setParameter(\"_id\", id)\n .setParameter(\"embedding\", embedding)\n .setParameter(\"content\", content)\n .executeUpdate();\n }\n\n @Override\n @Transactional\n public int deleteEmbeddingsById(String tableName, List<String> idList) {\n String sql = String.format(\"\"\"\n DELETE FROM %s WHERE _ID IN (:ids)\n \"\"\", tableName);\n\n return this.entityManager.createNativeQuery(sql)\n .setParameter(\"ids\", idList)\n .executeUpdate();\n }\n\n @Override\n @Transactional\n public int deleteAllEmbeddings(String tableName) {\n String sql = String.format(\"\"\"\n DELETE FROM %s\n \"\"\", tableName);\n\n return this.entityManager.createNativeQuery(sql).executeUpdate();\n }\n\n @Override\n public List<CricketWorldCup> cosineSimilaritySearch(String tableName, int topK, String queryEmbedding) {\n String sql = String.format(\"\"\"\n SELECT TOP :topK * FROM %s\n ORDER BY COSINE_SIMILARITY(EMBEDDING, TO_REAL_VECTOR(:queryEmbedding)) DESC\n \"\"\", tableName);\n\n return this.entityManager.createNativeQuery(sql, CricketWorldCup.class)\n .setParameter(\"topK\", topK)\n .setParameter(\"queryEmbedding\", queryEmbedding)\n .getResultList();\n }\n}\n----\n\n* Now, create a REST Controller class `CricketWorldCupHanaController`, and autowire `ChatModel` and `VectorStore` as dependencies\nIn this controller class, create the following REST endpoints:\n\n - `/ai/hana-vector-store/cricket-world-cup/purge-embeddings` - to purge all the embeddings from the Vector Store\n - `/ai/hana-vector-store/cricket-world-cup/upload` - to upload the Cricket_World_Cup.pdf so that its data gets stored in SAP Hana Cloud Vector DB as embeddings\n - `/ai/hana-vector-store/cricket-world-cup` - to implement `RAG` using link:https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/vectors-vector-embeddings-and-metrics[Cosine_Similarity in SAP Hana DB]\n\n[source,java]\n----\npackage com.interviewpedia.spring.ai.hana;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.chat.messages.UserMessage;\nimport org.springframework.ai.chat.prompt.Prompt;\nimport org.springframework.ai.chat.prompt.SystemPromptTemplate;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.reader.pdf.PagePdfDocumentReader;\nimport org.springframework.ai.transformer.splitter.TokenTextSplitter;\nimport org.springframework.ai.vectorstore.hanadb.HanaCloudVectorStore;\nimport org.springframework.ai.vectorstore.VectorStore;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.core.io.Resource;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.multipart.MultipartFile;\n\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.function.Function;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\n@RestController\n@Slf4j\npublic class CricketWorldCupHanaController {\n private final VectorStore hanaCloudVectorStore;\n private final ChatModel chatModel;\n\n @Autowired\n public CricketWorldCupHanaController(ChatModel chatModel, VectorStore hanaCloudVectorStore) {\n this.chatModel = chatModel;\n this.hanaCloudVectorStore = hanaCloudVectorStore;\n }\n\n @PostMapping(\"/ai/hana-vector-store/cricket-world-cup/purge-embeddings\")\n public ResponseEntity<String> purgeEmbeddings() {\n int deleteCount = ((HanaCloudVectorStore) this.hanaCloudVectorStore).purgeEmbeddings();\n log.info(\"{} embeddings purged from CRICKET_WORLD_CUP table in Hana DB\", deleteCount);\n return ResponseEntity.ok().body(String.format(\"%d embeddings purged from CRICKET_WORLD_CUP table in Hana DB\", deleteCount));\n }\n\n @PostMapping(\"/ai/hana-vector-store/cricket-world-cup/upload\")\n public ResponseEntity<String> handleFileUpload(@RequestParam(\"pdf\") MultipartFile file) throws IOException {\n Resource pdf = file.getResource();\n Supplier<List<Document>> reader = new PagePdfDocumentReader(pdf);\n Function<List<Document>, List<Document>> splitter = new TokenTextSplitter();\n List<Document> documents = splitter.apply(reader.get());\n log.info(\"{} documents created from pdf file: {}\", documents.size(), pdf.getFilename());\n this.hanaCloudVectorStore.accept(documents);\n return ResponseEntity.ok().body(String.format(\"%d documents created from pdf file: %s\",\n documents.size(), pdf.getFilename()));\n }\n\n @GetMapping(\"/ai/hana-vector-store/cricket-world-cup\")\n public Map<String, String> hanaVectorStoreSearch(@RequestParam(value = \"message\") String message) {\n var documents = this.hanaCloudVectorStore.similaritySearch(message);\n var inlined = documents.stream().map(Document::getText).collect(Collectors.joining(System.lineSeparator()));\n var similarDocsMessage = new SystemPromptTemplate(\"Based on the following: {documents}\")\n .createMessage(Map.of(\"documents\", inlined));\n\n var userMessage = new UserMessage(message);\n Prompt prompt = new Prompt(List.of(similarDocsMessage, userMessage));\n String generation = this.chatModel.call(prompt).getResult().getOutput().getText();\n log.info(\"Generation: {}\", generation);\n return Map.of(\"generation\", generation);\n }\n}\n----\n\nSince HanaDB vector store support does not provide the autoconfiguration module, you also need to provide the vector store bean in your application, as shown below, as an example.\n\n[source,java]\n----\n@Bean\npublic VectorStore hanaCloudVectorStore(CricketWorldCupRepository cricketWorldCupRepository,\n EmbeddingModel embeddingModel) {\n\n return HanaCloudVectorStore.builder(cricketWorldCupRepository, embeddingModel)\n .tableName(\"CRICKET_WORLD_CUP\")\n .topK(1)\n .build();\n}\n----\n\n* Use a `contextual` pdf file from wikipedia\n\nGo to link:https://en.wikipedia.org/wiki/Cricket_World_Cup[wikipedia] and link:https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Cricket_World_Cup&action=show-download-screen[download] `Cricket World Cup` page as a PDF file.\n\nimage::hanadb/wikipedia.png[width=800]\n\nUpload this PDF file using the file-upload REST endpoint that we created in the previous step.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hana.adoc", "title": "SAP HANA Cloud", "heading": "Create an `Entity` class named `CricketWorldCup` that extends from `HanaVectorEntity`:", "heading_level": 3, "file_order": 75, "section_index": 4, "content_hash": "37e3f3dad1f5d523d24bc5cfc3ff1994ad6cc438f9d44f2d5eb7f3d548e81503", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hana.adoc"}}
{"id": "sha256:d8942a76717330ca171104fdea3716c0657857c3a74ea583b7cfa67a7384227c", "content": "Below are the steps to provision SAP Hana Database using a trial account\n\nLet's start with creating a link:https://temp-mail.org/en/[temporary email] for registration purposes\n\nimage::hanadb/0.png[width=800]\n\nTIP: Don't close the above window, otherwise a new email id would get generated.\n\nGo to link:https://sap.com/[sap.com] and navigate to `products` -> `Trials and Demos`\n\nimage::hanadb/1.png[width=800]\n\nClick `Advanced Trials`\n\nimage::hanadb/2.png[width=800]\n\nClick `SAP BTP Trial`\n\nimage::hanadb/3.png[width=800]\n\nClick `Start your free 90-day trial`\n\nimage::hanadb/4.png[width=800]\n\nPaste the `temporary email id` that we created in the first step, and click `Next`\n\nimage::hanadb/5.png[width=800]\n\nWe fill in our details and click `Submit`\n\nimage::hanadb/6.png[width=800]\n\nIt's time to check the inbox of our temporary email account\n\nimage::hanadb/7.png[width=800]\n\nNotice that there is an email received in our temporary email account\n\nimage::hanadb/8.png[width=800]\n\nOpen the email and `click to activate` the trial account\n\nimage::hanadb/9.png[width=800]\n\nIt will prompt to create a `password`. Provide a password and click `Submit`\n\nimage::hanadb/10.png[width=800]\n\nThe trial account is now created. Click to `start the trial`\n\nimage::hanadb/11.png[width=800]\n\nProvide your phone number and click `Continue`\n\nimage::hanadb/13.png[width=800]\n\nWe receive an OTP on the phone number. Provide the `code` and click `continue`\n\nimage::hanadb/14.png[width=800]\n\nSelect the `region` as `US East (VA) - AWS`\n\nimage::hanadb/15.png[width=800]\n\nClick `Continue`\n\nimage::hanadb/16.png[width=800]\n\nThe `SAP BTP trial` account is ready. Click `Go to your Trial account`\n\nimage::hanadb/17.png[width=800]\n\nClick the `Trial` sub-account\n\nimage::hanadb/18.png[width=800]\n\nOpen `Instances and Subscriptions`\n\nimage::hanadb/19.png[width=800]\n\nIt's time to create a subscription. Click the `Create` button\n\nimage::hanadb/20.1.png[width=800]\n\nWhile creating a subscription, Select `service` as `SAP Hana Cloud` and `Plan` as `tools` and click `Create`\n\nimage::hanadb/20.2.png[width=800]\n\nNotice that `SAP Hana Cloud` subscription is now created. Click `Users` on the left panel\n\nimage::hanadb/21.png[width=800]\n\nSelect the username (temporary email that we supplied earlier) and click `Assign Role Collection`\n\nimage::hanadb/22.png[width=800]\n\nSearch `hana` and select all the 3 role collections that gets displayed. Click `Assign Role Collection`\n\nimage::hanadb/23.png[width=800]\n\nOur `user` now has all the 3 role collections. Click `Instances and Subscriptions`\n\nimage::hanadb/24.png[width=800]\n\nNow, click `SAP Hana Cloud` application under subscriptions\n\nimage::hanadb/25.png[width=800]\n\nThere are no instances yet. Let's click `Create Instance`\n\nimage::hanadb/26.png[width=800]\n\nSelect Type as `SAP HANA Cloud, SAP HANA Database`. Click `Next Step`\n\nimage::hanadb/27.png[width=800]\n\nProvide `Instance Name`, `Description`, `password` for DBADMIN administrator.\nSelect the latest version `2024.2 (QRC 1/2024)`. Click `Next Step`\n\nimage::hanadb/28.png[width=800]\n\nKeep everything as default. Click `Next Step`\n\nimage::hanadb/29.png[width=800]\n\nClick `Next Step`\n\nimage::hanadb/30.png[width=800]\n\nSelect `Allow all IP addresses` and click `Next Step`\n\nimage::hanadb/31.png[width=800]\n\nClick `Review and Create`\n\nimage::hanadb/32.png[width=800]\n\nClick `Create Instance`\n\nimage::hanadb/33.png[width=800]\n\nNotice that the provisioning of `SAP Hana Database` instance has started. It takes some time to provision - please be patient.\n\nimage::hanadb/34.1.png[width=800]\n\nOnce the instance is provisioned (status is displayed as `Running`) we can get the datasource url (`SQL Endpoint`) by clicking the instance and selecting `Connections`\n\nimage::hanadb/34.2.png[width=800]\n\nWe navigate to `SAP Hana Database Explorer` by click the `...`\n\nimage::hanadb/35.png[width=800]\n\nProvide the administrator credentials and click `OK`\n\nimage::hanadb/36.png[width=800]\n\nOpen SQL console and create the table `CRICKET_WORLD_CUP` using the following DDL statement:\n[sql]\n----\nCREATE TABLE CRICKET_WORLD_CUP (\n _ID VARCHAR2(255) PRIMARY KEY,\n CONTENT CLOB,\n EMBEDDING REAL_VECTOR(1536)\n)\n----\n\nimage::hanadb/37.png[width=800]\n\nNavigate to `hana_dev_db -> Catalog -> Tables` to find our table `CRICKET_WORLD_CUP`\n\nimage::hanadb/38.png[width=800]\n\nRight-click on the table and click `Open Data`\n\nimage::hanadb/39.png[width=800]\n\nNotice that the table data is now displayed. There are now rows as we didn't create any embeddings yet.\n\nimage::hanadb/40.png[width=800]\n\nNext steps: xref:api/vectordbs/hana.adoc[SAP Hana Vector Engine]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/hanadb-provision-a-trial-account.adoc", "title": "hanadb-provision-a-trial-account", "heading": "Provision SAP HANA Cloud trial account", "heading_level": 2, "file_order": 76, "section_index": 0, "content_hash": "d8942a76717330ca171104fdea3716c0657857c3a74ea583b7cfa67a7384227c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/hanadb-provision-a-trial-account.adoc"}}
{"id": "sha256:ab35ffcd8734b0b63347e9f012c67b2670994129f9e3babbd50ac05c2b201fb6", "content": "This section walks you through setting up `MariaDBVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://mariadb.org/projects/mariadb-vector/[MariaDB Vector] is part of MariaDB 11.7 and enables storing and searching over machine learning-generated embeddings.\nIt provides efficient vector similarity search capabilities using vector indexes, supporting both cosine similarity and Euclidean distance metrics.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "MariaDB Vector Store", "heading_level": 1, "file_order": 77, "section_index": 0, "content_hash": "ab35ffcd8734b0b63347e9f012c67b2670994129f9e3babbd50ac05c2b201fb6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:1ab6af3fee7a477cd9c902cbee7e0473707eb948215a0cdc6627d51866c0680c", "content": "* A running MariaDB (11.7+) instance. The following options are available:\n** link:https://hub.docker.com/_/mariadb[Docker] image\n** link:https://mariadb.org/download/[MariaDB Server]\n** link:https://mariadb.com/products/skysql/[MariaDB SkySQL]\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `MariaDBVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Prerequisites", "heading_level": 2, "file_order": 77, "section_index": 1, "content_hash": "1ab6af3fee7a477cd9c902cbee7e0473707eb948215a0cdc6627d51866c0680c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:97d5d88831267b7f8419e729cb01670e8ad582567212e97874e14c55ff6b83a3", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the MariaDB Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-mariadb</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-mariadb'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nThe vector store implementation can initialize the required schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: This is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nAdditionally, you will need a configured `EmbeddingModel` bean.\nRefer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nFor example, to use the xref:api/embeddings/openai-embeddings.adoc[OpenAI EmbeddingModel], add the following dependency:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nNow you can auto-wire the `MariaDBVectorStore` in your application:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[mariadbvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Auto-Configuration", "heading_level": 2, "file_order": 77, "section_index": 2, "content_hash": "97d5d88831267b7f8419e729cb01670e8ad582567212e97874e14c55ff6b83a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:e4ac4dd28e7071fbc2d499b4b8bfb1c12a818f72d7f5e8bf0b3943645a24b083", "content": "To connect to MariaDB and use the `MariaDBVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n datasource:\n url: jdbc:mariadb://localhost/db\n username: myUser\n password: myPassword\n ai:\n vectorstore:\n mariadb:\n initialize-schema: true\n distance-type: COSINE\n dimensions: 1536\n----\n\nTIP: If you run MariaDB Vector as a Spring Boot dev service via link:https://docs.spring.io/spring-boot/reference/features/dev-services.html#features.dev-services.docker-compose[Docker Compose]\nor link:https://docs.spring.io/spring-boot/reference/features/dev-services.html#features.dev-services.testcontainers[Testcontainers],\nyou don't need to configure URL, username and password since they are autoconfigured by Spring Boot.\n\nProperties starting with `spring.ai.vectorstore.mariadb.*` are used to configure the `MariaDBVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.mariadb.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.mariadb.distance-type`| Search distance type. Use `COSINE` (default) or `EUCLIDEAN`. If vectors are normalized to length 1, you can use `EUCLIDEAN` for best performance.| `COSINE`\n|`spring.ai.vectorstore.mariadb.dimensions`| Embeddings dimension. If not specified explicitly, will retrieve dimensions from the provided `EmbeddingModel`. | `1536`\n|`spring.ai.vectorstore.mariadb.remove-existing-vector-store-table` | Deletes the existing vector store table on startup. | `false`\n|`spring.ai.vectorstore.mariadb.schema-name` | Vector store schema name | `null`\n|`spring.ai.vectorstore.mariadb.table-name` | Vector store table name | `vector_store`\n|`spring.ai.vectorstore.mariadb.schema-validation` | Enables schema and table name validation to ensure they are valid and existing objects. | `false`\n|===\n\nTIP: If you configure a custom schema and/or table name, consider enabling schema validation by setting `spring.ai.vectorstore.mariadb.schema-validation=true`.\nThis ensures the correctness of the names and reduces the risk of SQL injection attacks.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Configuration Properties", "heading_level": 3, "file_order": 77, "section_index": 3, "content_hash": "e4ac4dd28e7071fbc2d499b4b8bfb1c12a818f72d7f5e8bf0b3943645a24b083", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:832068fce03f9423ecec5287a5a5f857abca21a8022183249d143689759c0abb", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the MariaDB vector store.\nFor this you need to add the following dependencies to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.mariadb.jdbc</groupId>\n <artifactId>mariadb-java-client</artifactId>\n <scope>runtime</scope>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mariadb-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nThen create the `MariaDBVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(JdbcTemplate jdbcTemplate, EmbeddingModel embeddingModel) {\n return MariaDBVectorStore.builder(jdbcTemplate, embeddingModel)\n .dimensions(1536) // Optional: defaults to 1536\n .distanceType(MariaDBDistanceType.COSINE) // Optional: defaults to COSINE\n .schemaName(\"mydb\") // Optional: defaults to null\n .vectorTableName(\"custom_vectors\") // Optional: defaults to \"vector_store\"\n .contentFieldName(\"text\") // Optional: defaults to \"content\"\n .embeddingFieldName(\"embedding\") // Optional: defaults to \"embedding\"\n .idFieldName(\"doc_id\") // Optional: defaults to \"id\"\n .metadataFieldName(\"meta\") // Optional: defaults to \"metadata\"\n .initializeSchema(true) // Optional: defaults to false\n .schemaValidation(true) // Optional: defaults to false\n .removeExistingVectorStoreTable(false) // Optional: defaults to false\n .maxDocumentBatchSize(10000) // Optional: defaults to 10000\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Manual Configuration", "heading_level": 2, "file_order": 77, "section_index": 4, "content_hash": "832068fce03f9423ecec5287a5a5f857abca21a8022183249d143689759c0abb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:fbe8a64c0b5013477385d32904e81c44b3b26d4d6e895c3380cd5a166409254b", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with MariaDB Vector store.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These filter expressions are automatically converted into the equivalent MariaDB JSON path expressions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 77, "section_index": 5, "content_hash": "fbe8a64c0b5013477385d32904e81c44b3b26d4d6e895c3380cd5a166409254b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:418f266c418b3e803cde2205dbc7404b446dfc8a17ea5486a409d978da97c537", "content": "The MariaDB Vector Store automatically calculates similarity scores for documents returned from similarity searches.\nThese scores provide a normalized measure of how closely each document matches your search query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Similarity Scores", "heading_level": 2, "file_order": 77, "section_index": 6, "content_hash": "418f266c418b3e803cde2205dbc7404b446dfc8a17ea5486a409d978da97c537", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:beff3f190e04efaf6bbf00033a132196a75fc39731b4051549c056289d256f5e", "content": "Similarity scores are calculated using the formula `score = 1.0 - distance`, where:\n\n* Score: A value between `0.0` and `1.0`, where `1.0` indicates perfect similarity and `0.0` indicates no similarity\n* Distance: The raw distance value calculated using the configured distance type (`COSINE` or `EUCLIDEAN`)\n\nThis means that documents with smaller distances (more similar) will have higher scores, making the results more intuitive to interpret.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Score Calculation", "heading_level": 3, "file_order": 77, "section_index": 7, "content_hash": "beff3f190e04efaf6bbf00033a132196a75fc39731b4051549c056289d256f5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:b91281bbb18fc19545e1b1ffe43a67c8096a1443c66c05e15fc97a3d0998c68b", "content": "You can access the similarity score for each document through the `getScore()` method:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"Spring AI\")\n .topK(5)\n .build());\n\nfor (Document doc : results) {\n double score = doc.getScore(); // Value between 0.0 and 1.0\n System.out.println(\"Document: \" + doc.getText());\n System.out.println(\"Similarity Score: \" + score);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Accessing Scores", "heading_level": 3, "file_order": 77, "section_index": 8, "content_hash": "b91281bbb18fc19545e1b1ffe43a67c8096a1443c66c05e15fc97a3d0998c68b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:563739c1fb1a3b65bf4b071246fca1e17799086bb6bf937207f032587bda70e5", "content": "Search results are automatically ordered by similarity score in descending order (highest score first).\nThis ensures that the most relevant documents appear at the top of your results.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Search Results Ordering", "heading_level": 3, "file_order": 77, "section_index": 9, "content_hash": "563739c1fb1a3b65bf4b071246fca1e17799086bb6bf937207f032587bda70e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:32f70e91d45d02772266d0950482204e555722ab54cf08a8164943da36fe347f", "content": "In addition to the similarity score, the raw distance value is still available in the document metadata:\n\n[source,java]\n----\nfor (Document doc : results) {\n double score = doc.getScore();\n float distance = (Float) doc.getMetadata().get(\"distance\");\n\n System.out.println(\"Score: \" + score + \", Distance: \" + distance);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Distance Metadata", "heading_level": 3, "file_order": 77, "section_index": 10, "content_hash": "32f70e91d45d02772266d0950482204e555722ab54cf08a8164943da36fe347f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:d3656e8b281f2e7a239051034328584a87643501e0f05f0e159803b406669fce", "content": "When using similarity thresholds in your search requests, specify the threshold as a score value (`0.0` to `1.0`) rather than a distance:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"Spring AI\")\n .topK(10)\n .similarityThreshold(0.8) // Only return documents with score >= 0.8\n .build());\n----\n\nThis makes threshold values consistent and intuitive - higher values mean more restrictive searches that only return highly similar documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Similarity Threshold", "heading_level": 3, "file_order": 77, "section_index": 11, "content_hash": "d3656e8b281f2e7a239051034328584a87643501e0f05f0e159803b406669fce", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:a967c526b043f4a7ab76de979bb01c627946b2fa993137e45fc885a21a673903", "content": "The MariaDB Vector Store implementation provides access to the underlying native JDBC client (`JdbcTemplate`) through the `getNativeClient()` method:\n\n[source,java]\n----\nMariaDBVectorStore vectorStore = context.getBean(MariaDBVectorStore.class);\nOptional<JdbcTemplate> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n JdbcTemplate jdbc = nativeClient.get();\n // Use the native client for MariaDB-specific operations\n}\n----\n\nThe native client gives you access to MariaDB-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc", "title": "MariaDB Vector Store", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 77, "section_index": 12, "content_hash": "a967c526b043f4a7ab76de979bb01c627946b2fa993137e45fc885a21a673903", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mariadb.adoc"}}
{"id": "sha256:f78c1f430bb19d17803716967e56f01d53c435ff33dd79ecce7cdd4290b91940", "content": "link:https://milvus.io/[Milvus] is an open-source vector database that has garnered significant attention in the fields of data science and machine learning. One of its standout features lies in its robust support for vector indexing and querying. Milvus employs state-of-the-art, cutting-edge algorithms to accelerate the search process, making it exceptionally efficient at retrieving similar vectors, even when handling extensive datasets.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Milvus", "heading_level": 1, "file_order": 78, "section_index": 0, "content_hash": "f78c1f430bb19d17803716967e56f01d53c435ff33dd79ecce7cdd4290b91940", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:b6fc8b135646641c7b3d3fafe81aec60287c4c81460f0819bfc18205ca4548e1", "content": "* A running Milvus instance. The following options are available:\n** link:https://milvus.io/docs/install_standalone-docker.md[Milvus Standalone]: Docker, Operator, Helm,DEB/RPM, Docker Compose.\n** link:https://milvus.io/docs/install_cluster-milvusoperator.md[Milvus Cluster]: Operator, Helm.\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `MilvusVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Prerequisites", "heading_level": 2, "file_order": 78, "section_index": 1, "content_hash": "b6fc8b135646641c7b3d3fafe81aec60287c4c81460f0819bfc18205ca4548e1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:a7bf5c1f3de9f5db70ffae6b13c3f9855eb3f57130053545e1aeb8500a102508", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nThen add the Milvus VectorStore boot starter dependency to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-vector-store-milvus</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-milvus'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nThe Vector Store, also requires an `EmbeddingModel` instance to calculate embeddings for the documents.\nYou can pick one of the available xref:api/embeddings.adoc#available-implementations[EmbeddingModel Implementations].\n\nTo connect to and configure the `MilvusVectorStore`, you need to provide access details for your instance.\nA simple configuration can either be provided via Spring Boot's `application.yml`\n\n[yml]\n----\nspring:\n\tai:\n vectorstore:\n milvus:\n client:\n host: \"localhost\"\n port: 19530\n username: \"root\"\n password: \"milvus\"\n databaseName: \"default\"\n collectionName: \"vector_store\"\n embeddingDimension: 1536\n indexType: IVF_FLAT\n metricType: COSINE\n----\n\nTIP: Check the list of xref:#milvus-properties[configuration parameters] to learn about the default values and configuration options.\n\nNow you can Auto-wire the Milvus Vector Store in your application and use it\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Dependencies", "heading_level": 2, "file_order": 78, "section_index": 2, "content_hash": "a7bf5c1f3de9f5db70ffae6b13c3f9855eb3f57130053545e1aeb8500a102508", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:e0209c49ef95f332b90fc438117e6397531f98e793f1a29f6a9d018695a32f49", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the `MilvusVectorStore`.\nTo add the following dependencies to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-milvus-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTo configure MilvusVectorStore in your application, you can use the following setup:\n\n[source,java]\n----\n\t@Bean\n\tpublic VectorStore vectorStore(MilvusServiceClient milvusClient, EmbeddingModel embeddingModel) {\n return MilvusVectorStore.builder(milvusClient, embeddingModel)\n .collectionName(\"test_vector_store\")\n .databaseName(\"default\")\n .indexType(IndexType.IVF_FLAT)\n .metricType(MetricType.COSINE)\n .batchingStrategy(new TokenCountBatchingStrategy())\n .initializeSchema(true)\n .build();\n\t}\n\n\t@Bean\n\tpublic MilvusServiceClient milvusClient() {\n return new MilvusServiceClient(ConnectParam.newBuilder()\n .withAuthorization(\"minioadmin\", \"minioadmin\")\n .withUri(milvusContainer.getEndpoint())\n .build());\n\t}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Manual Configuration", "heading_level": 3, "file_order": 78, "section_index": 3, "content_hash": "e0209c49ef95f332b90fc438117e6397531f98e793f1a29f6a9d018695a32f49", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:ce16d6223ebb70f827322b61eef21a81983a282eae6c6e9ace7da8aba5d63e5e", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the Milvus store.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\",\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These filter expressions are converted into the equivalent Milvus filters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Metadata filtering", "heading_level": 2, "file_order": 78, "section_index": 4, "content_hash": "ce16d6223ebb70f827322b61eef21a81983a282eae6c6e9ace7da8aba5d63e5e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:96017d436ecbf6683168ff467501650a5f8addec67502ea8cde68f76f7131ae8", "content": "MilvusSearchRequest extends SearchRequest, allowing you to use Milvus-specific search parameters such as native expressions and search parameter JSON.\n\n[source,java]\n----\nMilvusSearchRequest request = MilvusSearchRequest.milvusBuilder()\n .query(\"sample query\")\n .topK(5)\n .similarityThreshold(0.7)\n .nativeExpression(\"metadata[\\\"age\\\"] > 30\") // Overrides filterExpression if both are set\n .filterExpression(\"age <= 30\") // Ignored if nativeExpression is set\n .searchParamsJson(\"{\\\"nprobe\\\":128}\")\n .build();\nList results = vectorStore.similaritySearch(request);\n----\nThis allows greater flexibility when using Milvus-specific search features.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Using MilvusSearchRequest", "heading_level": 2, "file_order": 78, "section_index": 5, "content_hash": "96017d436ecbf6683168ff467501650a5f8addec67502ea8cde68f76f7131ae8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:82703e2cad112f33b629af436c1fab118f000e45604a11e4c75258e97f4d5c55", "content": "These two parameters enhance Milvus search precision and ensure optimal query performance:\n\n*nativeExpression*: Enables additional filtering capabilities using Milvus' native filtering expressions.\nhttps://milvus.io/docs/boolean.md[Milvus Filtering]\n\nExample:\n[source,java]\n----\nMilvusSearchRequest request = MilvusSearchRequest.milvusBuilder()\n .query(\"sample query\")\n .topK(5)\n .nativeExpression(\"metadata['category'] == 'science'\")\n .build();\n----\n\n*searchParamsJson*: Essential for tuning search behavior when using IVF_FLAT, Milvus' default index.\nhttps://milvus.io/docs/index.md?tab=floating[Milvus Vector Index]\n\nBy default, `IVF_FLAT` requires `nprobe` to be set for accurate results. If not specified, `nprobe` defaults to `1`, which can lead to poor recall or even zero search results.\n\nExample:\n[source,java]\n----\nMilvusSearchRequest request = MilvusSearchRequest.milvusBuilder()\n .query(\"sample query\")\n .topK(5)\n .searchParamsJson(\"{\\\"nprobe\\\":128}\")\n .build();\n----\n\nUsing `nativeExpression` ensures advanced filtering, while `searchParamsJson` prevents ineffective searches caused by a low default `nprobe` value.\n\n[[milvus-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Importance of `nativeExpression` and `searchParamsJson` in `MilvusSearchRequest`", "heading_level": 2, "file_order": 78, "section_index": 6, "content_hash": "82703e2cad112f33b629af436c1fab118f000e45604a11e4c75258e97f4d5c55", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:30016ca97a1492e7318c8a7c23741cdd267362a0e5a161cecbb647889854371a", "content": "You can use the following properties in your Spring Boot configuration to customize the Milvus vector store.\n\n[cols=\"4,5,1\",stripes=even]\n|===\n|Property| Description | Default value\n\n|spring.ai.vectorstore.milvus.database-name | The name of the Milvus database to use. | default\n|spring.ai.vectorstore.milvus.collection-name | Milvus collection name to store the vectors | vector_store\n|spring.ai.vectorstore.milvus.initialize-schema | whether to initialize Milvus' backend | false\n|spring.ai.vectorstore.milvus.embedding-dimension | The dimension of the vectors to be stored in the Milvus collection. | 1536\n|spring.ai.vectorstore.milvus.index-type | The type of the index to be created for the Milvus collection. | IVF_FLAT\n|spring.ai.vectorstore.milvus.metric-type | The metric type to be used for the Milvus collection. | COSINE\n|spring.ai.vectorstore.milvus.index-parameters | The index parameters to be used for the Milvus collection. | {\"nlist\":1024}\n|spring.ai.vectorstore.milvus.id-field-name | The ID field name for the collection | doc_id\n|spring.ai.vectorstore.milvus.auto-id | Boolean flag to indicate if the auto-id is used for the ID field | false\n|spring.ai.vectorstore.milvus.content-field-name | The content field name for the collection | content\n|spring.ai.vectorstore.milvus.metadata-field-name | The metadata field name for the collection | metadata\n|spring.ai.vectorstore.milvus.embedding-field-name | The embedding field name for the collection | embedding\n|spring.ai.vectorstore.milvus.client.host | The name or address of the host. | localhost\n|spring.ai.vectorstore.milvus.client.port | The connection port. | 19530\n|spring.ai.vectorstore.milvus.client.uri | The uri of Milvus instance | -\n|spring.ai.vectorstore.milvus.client.token\t| Token serving as the key for identification and authentication purposes. | -\n|spring.ai.vectorstore.milvus.client.connect-timeout-ms | Connection timeout value of client channel. The timeout value must be greater than zero . | 10000\n|spring.ai.vectorstore.milvus.client.keep-alive-time-ms | Keep-alive time value of client channel. The keep-alive value must be greater than zero. | 55000\n|spring.ai.vectorstore.milvus.client.keep-alive-timeout-ms | The keep-alive timeout value of client channel. The timeout value must be greater than zero. | 20000\n|spring.ai.vectorstore.milvus.client.rpc-deadline-ms | Deadline for how long you are willing to wait for a reply from the server. With a deadline setting, the client will wait when encounter fast RPC fail caused by network fluctuations. The deadline value must be larger than or equal to zero. | 0\n|spring.ai.vectorstore.milvus.client.client-key-path | The client.key path for tls two-way authentication, only takes effect when \"secure\" is true | -\n|spring.ai.vectorstore.milvus.client.client-pem-path | The client.pem path for tls two-way authentication, only takes effect when \"secure\" is true | -\n|spring.ai.vectorstore.milvus.client.ca-pem-path | The ca.pem path for tls two-way authentication, only takes effect when \"secure\" is true | -\n|spring.ai.vectorstore.milvus.client.server-pem-path | server.pem path for tls one-way authentication, only takes effect when \"secure\" is true. | -\n|spring.ai.vectorstore.milvus.client.server-name | Sets the target name override for SSL host name checking, only takes effect when \"secure\" is True. Note: this value is passed to grpc.ssl_target_name_override | -\n|spring.ai.vectorstore.milvus.client.secure | Secure the authorization for this connection, set to True to enable TLS. | false\n|spring.ai.vectorstore.milvus.client.idle-timeout-ms | Idle timeout value of client channel. The timeout value must be larger than zero. | 24h\n|spring.ai.vectorstore.milvus.client.username | The username and password for this connection. | root\n|spring.ai.vectorstore.milvus.client.password | The password for this connection. | milvus\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Milvus VectorStore properties", "heading_level": 2, "file_order": 78, "section_index": 7, "content_hash": "30016ca97a1492e7318c8a7c23741cdd267362a0e5a161cecbb647889854371a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:bd178e02d5ed9704075cf404b9270893aa409d540015ebe63d2828b0d5f0cd03", "content": "From within the `src/test/resources/` folder run:\n\n[source,bash]\n----\ndocker-compose up\n----\n\nTo clean the environment:\n\n[source,bash]\n----\ndocker-compose down; rm -Rf ./volumes\n----\n\nThen connect to the vector store on link:http://localhost:19530[http://localhost:19530] or for management link:http://localhost:9001[http://localhost:9001] (user: `minioadmin`, pass: `minioadmin`)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Starting Milvus Store", "heading_level": 2, "file_order": 78, "section_index": 8, "content_hash": "bd178e02d5ed9704075cf404b9270893aa409d540015ebe63d2828b0d5f0cd03", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:9d30f1390d8e4c41aed20af83c0fa519e63d09c0d0b89f158d22bc4e1c16dfdb", "content": "If Docker complains about resources, then execute:\n\n[source,bash]\n----\ndocker system prune --all --force --volumes\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Troubleshooting", "heading_level": 2, "file_order": 78, "section_index": 9, "content_hash": "9d30f1390d8e4c41aed20af83c0fa519e63d09c0d0b89f158d22bc4e1c16dfdb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:2e9bf3ae159651af629895b3cbff9d9bc9cade524156e1b37354bfc560aaf9f2", "content": "The Milvus Vector Store implementation provides access to the underlying native Milvus client (`MilvusServiceClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nMilvusVectorStore vectorStore = context.getBean(MilvusVectorStore.class);\nOptional<MilvusServiceClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n MilvusServiceClient client = nativeClient.get();\n // Use the native client for Milvus-specific operations\n}\n----\n\nThe native client gives you access to Milvus-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/milvus.adoc", "title": "Milvus", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 78, "section_index": 10, "content_hash": "2e9bf3ae159651af629895b3cbff9d9bc9cade524156e1b37354bfc560aaf9f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/milvus.adoc"}}
{"id": "sha256:37872e938e819947a48f352677363e660245ad0aa086c3a84422087336ce0414", "content": "This section walks you through setting up MongoDB Atlas as a vector store to use with Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "MongoDB Atlas", "heading_level": 1, "file_order": 79, "section_index": 0, "content_hash": "37872e938e819947a48f352677363e660245ad0aa086c3a84422087336ce0414", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:fa4652f7d061c5201c70e97c2397d8947604a883f9f2a347626f99d169e04f8a", "content": "https://www.mongodb.com/products/platform/atlas-database[MongoDB Atlas] is the fully-managed cloud database from MongoDB available in AWS, Azure, and GCP.\nAtlas supports native Vector Search and full text search on your MongoDB document data.\n\nhttps://www.mongodb.com/products/platform/atlas-vector-search[MongoDB Atlas Vector Search] allows you to store your embeddings in MongoDB documents, create vector search indexes, and perform KNN searches with an approximate nearest neighbor algorithm (Hierarchical Navigable Small Worlds).\nYou can use the `$vectorSearch` aggregation operator in a MongoDB aggregation stage to perform a search on your vector embeddings.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "What is MongoDB Atlas?", "heading_level": 2, "file_order": 79, "section_index": 1, "content_hash": "fa4652f7d061c5201c70e97c2397d8947604a883f9f2a347626f99d169e04f8a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:48154b26b2883225796d86cacf9ce48651f3d4ef1caac8074c1e59fa14fe9d70", "content": "* An Atlas cluster running MongoDB version 6.0.11, 7.0.2, or later. To get started with MongoDB Atlas, you can follow the instructions https://www.mongodb.com/docs/atlas/getting-started/[here]. Ensure that your IP address is included in your Atlas project's https://www.mongodb.com/docs/atlas/security/ip-access-list/#std-label-access-list[access list].\n* A running MongoDB Atlas instance with Vector Search enabled\n* Collection with vector search index configured\n* Collection schema with id (string), content (string), metadata (document), and embedding (vector) fields\n* Proper access permissions for index and collection operations", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Prerequisites", "heading_level": 2, "file_order": 79, "section_index": 2, "content_hash": "48154b26b2883225796d86cacf9ce48651f3d4ef1caac8074c1e59fa14fe9d70", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:98547c3e6476ecb72257d836562049852f26be1dee0c097b08f8aea3854d6f38", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the MongoDB Atlas Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-mongodb-atlas</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-mongodb-atlas'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by setting `spring.ai.vectorstore.mongodb.initialize-schema=true` in the `application.properties` file.\nAlternatively you can opt-out the initialization and create the index manually using the MongoDB Atlas UI, Atlas Administration API, or Atlas CLI, which can be useful if the index needs advanced mapping or additional configuration.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nPlease have a look at the list of <<mongodbvector-properties,configuration parameters>> for the vector store to learn about the default values and configuration options.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `MongoDBAtlasVectorStore` as a vector store in your application:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[mongodbvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Auto-configuration", "heading_level": 2, "file_order": 79, "section_index": 3, "content_hash": "98547c3e6476ecb72257d836562049852f26be1dee0c097b08f8aea3854d6f38", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:a8d4a632dc359e01267c1fab04b177111007910a803875a8399b9a535a120425", "content": "To connect to MongoDB Atlas and use the `MongoDBAtlasVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n data:\n mongodb:\n uri: <mongodb atlas connection string>\n database: <database name>\n ai:\n vectorstore:\n mongodb:\n initialize-schema: true\n collection-name: custom_vector_store\n index-name: custom_vector_index\n path-name: custom_embedding\n metadata-fields-to-filter: author,year\n----\n\nProperties starting with `spring.ai.vectorstore.mongodb.*` are used to configure the `MongoDBAtlasVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.mongodb.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.mongodb.collection-name` | The name of the collection to store the vectors | `vector_store`\n|`spring.ai.vectorstore.mongodb.index-name` | The name of the vector search index | `vector_index`\n|`spring.ai.vectorstore.mongodb.path-name` | The path where vectors are stored | `embedding`\n|`spring.ai.vectorstore.mongodb.metadata-fields-to-filter` | Comma-separated list of metadata fields that can be used for filtering | empty list\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Configuration Properties", "heading_level": 3, "file_order": 79, "section_index": 4, "content_hash": "a8d4a632dc359e01267c1fab04b177111007910a803875a8399b9a535a120425", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:91fd03385b0c2ba1d160f27d038aa0b2f7fcc44d651db6dee70e743df03241ca", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the MongoDB Atlas vector store. For this you need to add the `spring-ai-mongodb-atlas-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-mongodb-atlas-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-mongodb-atlas-store'\n}\n----\n\nCreate a `MongoTemplate` bean:\n\n[source,java]\n----\n@Bean\npublic MongoTemplate mongoTemplate() {\n return new MongoTemplate(MongoClients.create(\"<mongodb atlas connection string>\"), \"<database name>\");\n}\n----\n\nThen create the `MongoDBAtlasVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(MongoTemplate mongoTemplate, EmbeddingModel embeddingModel) {\n return MongoDBAtlasVectorStore.builder(mongoTemplate, embeddingModel)\n .collectionName(\"custom_vector_store\") // Optional: defaults to \"vector_store\"\n .vectorIndexName(\"custom_vector_index\") // Optional: defaults to \"vector_index\"\n .pathName(\"custom_embedding\") // Optional: defaults to \"embedding\"\n .numCandidates(500) // Optional: defaults to 200\n .metadataFieldsToFilter(List.of(\"author\", \"year\")) // Optional: defaults to empty list\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Manual Configuration", "heading_level": 2, "file_order": 79, "section_index": 5, "content_hash": "91fd03385b0c2ba1d160f27d038aa0b2f7fcc44d651db6dee70e743df03241ca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:3faac68fc67384dc6db213ecc9514d2e3547edb74362333e43c1e0b5443914d1", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with MongoDB Atlas as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(5)\n .similarityThreshold(0.7)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(5)\n .similarityThreshold(0.7)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary MongoDB Atlas filter expressions.\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\nauthor in ['john', 'jill'] && article_type == 'blog'\n----\n\nis converted into the proprietary MongoDB Atlas filter format:\n\n[source,json]\n----\n{\n \"$and\": [\n {\n \"$or\": [\n { \"metadata.author\": \"john\" },\n { \"metadata.author\": \"jill\" }\n ]\n },\n {\n \"metadata.article_type\": \"blog\"\n }\n ]\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 79, "section_index": 6, "content_hash": "3faac68fc67384dc6db213ecc9514d2e3547edb74362333e43c1e0b5443914d1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:66f8be1f9980095f0cf9ca111eaed3f8394d1844fb2a89636c653346165d36e9", "content": "To get started with Spring AI and MongoDB:\n\n* See the https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/spring-ai/#std-label-spring-ai[Getting Started guide for Spring AI Integration].\n* For a comprehensive code example demonstrating Retrieval Augmented Generation (RAG) with Spring AI and MongoDB, refer to this https://www.mongodb.com/developer/languages/java/retrieval-augmented-generation-spring-ai/[detailed tutorial].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Tutorials and Code Examples", "heading_level": 2, "file_order": 79, "section_index": 7, "content_hash": "66f8be1f9980095f0cf9ca111eaed3f8394d1844fb2a89636c653346165d36e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:ef5fe1153c2cb488ae69b62a6f29f4a0e413a506be7879bead88ea956b01da91", "content": "The MongoDB Atlas Vector Store implementation provides access to the underlying native MongoDB client (`MongoClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nMongoDBAtlasVectorStore vectorStore = context.getBean(MongoDBAtlasVectorStore.class);\nOptional<MongoClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n MongoClient client = nativeClient.get();\n // Use the native client for MongoDB-specific operations\n}\n----\n\nThe native client gives you access to MongoDB-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc", "title": "MongoDB Atlas", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 79, "section_index": 8, "content_hash": "ef5fe1153c2cb488ae69b62a6f29f4a0e413a506be7879bead88ea956b01da91", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/mongodb.adoc"}}
{"id": "sha256:d8465a3e628b71900388aabfe34a9f002436ddab249f64b35b411394622f6bbf", "content": "This section walks you through setting up `Neo4jVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://neo4j.com[Neo4j] is an open-source NoSQL graph database.\nIt is a fully transactional database (ACID) that stores data structured as graphs consisting of nodes, connected by relationships.\nInspired by the structure of the real world, it allows for high query performance on complex data while remaining intuitive and simple for the developer.\n\nThe link:https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/[Neo4j's Vector Search] allows users to query vector embeddings from large datasets.\nAn embedding is a numerical representation of a data object, such as text, image, audio, or document.\nEmbeddings can be stored on _Node_ properties and can be queried with the `db.index.vector.queryNodes()` function.\nThose indexes are powered by Lucene using a Hierarchical Navigable Small World Graph (HNSW) to perform a k approximate nearest neighbors (k-ANN) query over the vector fields.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Neo4j", "heading_level": 1, "file_order": 80, "section_index": 0, "content_hash": "d8465a3e628b71900388aabfe34a9f002436ddab249f64b35b411394622f6bbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:f19bf844d8bb52dc951f67009f0802d2e29d91eb62acba7c574d2389b66762d6", "content": "* A running Neo4j (5.15+) instance. The following options are available:\n** link:https://hub.docker.com/_/neo4j[Docker] image\n** link:https://neo4j.com/download/[Neo4j Desktop]\n** link:https://neo4j.com/cloud/aura-free/[Neo4j Aura]\n** link:https://neo4j.com/deployment-center/[Neo4j Server] instance\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `Neo4jVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Prerequisites", "heading_level": 2, "file_order": 80, "section_index": 1, "content_hash": "f19bf844d8bb52dc951f67009f0802d2e29d91eb62acba7c574d2389b66762d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:c05c36defe13810d60732e4a80f0b0711612c99a8a993c1ff61444237fe79019", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Neo4j Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-neo4j</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-neo4j'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#neo4jvector-properties[Configuration Properties] for the vector store to learn about the default values and configuration options.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `Neo4jVectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[neo4jvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Auto-configuration", "heading_level": 2, "file_order": 80, "section_index": 2, "content_hash": "c05c36defe13810d60732e4a80f0b0711612c99a8a993c1ff61444237fe79019", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:34d02c012d70197406180e153b3534d5b7970cf8145223aff75276d142301c48", "content": "To connect to Neo4j and use the `Neo4jVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n neo4j:\n uri: <neo4j instance URI>\n authentication:\n username: <neo4j username>\n password: <neo4j password>\n ai:\n vectorstore:\n neo4j:\n initialize-schema: true\n database-name: neo4j\n index-name: custom-index\n embedding-dimension: 1536\n distance-type: cosine\n----\n\nThe Spring Boot properties starting with `spring.neo4j.*` are used to configure the Neo4j client:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n| `spring.neo4j.uri` | URI for connecting to the Neo4j instance | `neo4j://localhost:7687`\n| `spring.neo4j.authentication.username` | Username for authentication with Neo4j | `neo4j`\n| `spring.neo4j.authentication.password` | Password for authentication with Neo4j | -\n|===\n\nProperties starting with `spring.ai.vectorstore.neo4j.*` are used to configure the `Neo4jVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.neo4j.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.neo4j.database-name` | The name of the Neo4j database to use | `neo4j`\n|`spring.ai.vectorstore.neo4j.index-name` | The name of the index to store the vectors | `spring-ai-document-index`\n|`spring.ai.vectorstore.neo4j.embedding-dimension` | The number of dimensions in the vector | `1536`\n|`spring.ai.vectorstore.neo4j.distance-type` | The distance function to use | `cosine`\n|`spring.ai.vectorstore.neo4j.label` | The label used for document nodes | `Document`\n|`spring.ai.vectorstore.neo4j.embedding-property` | The property name used to store embeddings | `embedding`\n|===\n\nThe following distance functions are available:\n\n* `cosine` - Default, suitable for most use cases. Measures cosine similarity between vectors.\n* `euclidean` - Euclidean distance between vectors. Lower values indicate higher similarity.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Configuration Properties", "heading_level": 3, "file_order": 80, "section_index": 3, "content_hash": "34d02c012d70197406180e153b3534d5b7970cf8145223aff75276d142301c48", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:4b79e0a500792ecdcced2fa3fdde41b53617dfb20e0df1cf43a71d0b4db7ffd2", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the Neo4j vector store. For this you need to add the `spring-ai-neo4j-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-neo4j-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-neo4j-store'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nCreate a Neo4j `Driver` bean.\nRead the link:https://neo4j.com/docs/java-manual/current/client-applications/[Neo4j Documentation] for more in-depth information about the configuration of a custom driver.\n\n[source,java]\n----\n@Bean\npublic Driver driver() {\n return GraphDatabase.driver(\"neo4j://<host>:<bolt-port>\",\n AuthTokens.basic(\"<username>\", \"<password>\"));\n}\n----\n\nThen create the `Neo4jVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(Driver driver, EmbeddingModel embeddingModel) {\n return Neo4jVectorStore.builder(driver, embeddingModel)\n .databaseName(\"neo4j\") // Optional: defaults to \"neo4j\"\n .distanceType(Neo4jDistanceType.COSINE) // Optional: defaults to COSINE\n .embeddingDimension(1536) // Optional: defaults to 1536\n .label(\"Document\") // Optional: defaults to \"Document\"\n .embeddingProperty(\"embedding\") // Optional: defaults to \"embedding\"\n .indexName(\"custom-index\") // Optional: defaults to \"spring-ai-document-index\"\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Manual Configuration", "heading_level": 2, "file_order": 80, "section_index": 4, "content_hash": "4b79e0a500792ecdcced2fa3fdde41b53617dfb20e0df1cf43a71d0b4db7ffd2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:8f382229ddad3b6572c11c09ab63b525ec6a43d9a4b7bb06b3286981655bd2ef", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Neo4j store as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && 'article_type' == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary Neo4j `WHERE` link:https://neo4j.com/developer/cypher/filtering-query-results/[filter expressions].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\nauthor in ['john', 'jill'] && 'article_type' == 'blog'\n----\n\nis converted into the proprietary Neo4j filter format:\n\n[source,text]\n----\nnode.`metadata.author` IN [\"john\",\"jill\"] AND node.`metadata.'article_type'` = \"blog\"\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 80, "section_index": 5, "content_hash": "8f382229ddad3b6572c11c09ab63b525ec6a43d9a4b7bb06b3286981655bd2ef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:e09cf7b342c2b21d9eb6623e2eb061c21284d142e55eed7140021f8d2b12bd87", "content": "The Neo4j Vector Store implementation provides access to the underlying native Neo4j client (`Driver`) through the `getNativeClient()` method:\n\n[source,java]\n----\nNeo4jVectorStore vectorStore = context.getBean(Neo4jVectorStore.class);\nOptional<Driver> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n Driver driver = nativeClient.get();\n // Use the native client for Neo4j-specific operations\n}\n----\n\nThe native client gives you access to Neo4j-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc", "title": "Neo4j", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 80, "section_index": 6, "content_hash": "e09cf7b342c2b21d9eb6623e2eb061c21284d142e55eed7140021f8d2b12bd87", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/neo4j.adoc"}}
{"id": "sha256:0c47b563e51a928101ef31b9ee2c77555f83de3e1a68703a3dd9520806e0c6cf", "content": "This section walks you through setting up `OpenSearchVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://opensearch.org[OpenSearch] is an open-source search and analytics engine originally forked from Elasticsearch, distributed under the Apache License 2.0. It enhances AI application development by simplifying the integration and management of AI-generated assets. OpenSearch supports vector, lexical, and hybrid search capabilities, leveraging advanced vector database functionalities to facilitate low-latency queries and similarity searches as detailed on the link:https://opensearch.org/platform/search/vector-database.html[vector database page].\n\nThe link:https://opensearch.org/docs/latest/search-plugins/knn/index/[OpenSearch k-NN] functionality allows users to query vector embeddings from large datasets. An embedding is a numerical representation of a data object, such as text, image, audio, or document. Embeddings can be stored in the index and queried using various similarity functions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "OpenSearch", "heading_level": 1, "file_order": 81, "section_index": 0, "content_hash": "0c47b563e51a928101ef31b9ee2c77555f83de3e1a68703a3dd9520806e0c6cf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:b40661ad88b70e3f49e22ca6e1a23da31ccbe3088770e552f5a78829110d3eb7", "content": "* A running OpenSearch instance. The following options are available:\n** link:https://opensearch.org/docs/latest/opensearch/install/index/[Self-Managed OpenSearch]\n** link:https://docs.aws.amazon.com/opensearch-service/[Amazon OpenSearch Service]\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `OpenSearchVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Prerequisites", "heading_level": 2, "file_order": 81, "section_index": 1, "content_hash": "b40661ad88b70e3f49e22ca6e1a23da31ccbe3088770e552f5a78829110d3eb7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:5e11a8ee4a61dc490b317cd1f286b5149d9fbc9526c9448133f2b798f131a44e", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the OpenSearch Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-opensearch</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-opensearch'\n}\n----\n\nTIP: For both self-hosted and Amazon OpenSearch Service, use the same dependency.\nRefer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#_configuration_properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `OpenSearchVectorStore` as a vector store in your application:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Auto-configuration", "heading_level": 2, "file_order": 81, "section_index": 2, "content_hash": "5e11a8ee4a61dc490b317cd1f286b5149d9fbc9526c9448133f2b798f131a44e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:a4cadcf5eac2ee34ef0f0f68e16c56eae128b5aa26c990da89a7a1e8848e29bd", "content": "To connect to OpenSearch and use the `OpenSearchVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n ai:\n vectorstore:\n opensearch:\n uris: <opensearch instance URIs>\n username: <opensearch username>\n password: <opensearch password>\n index-name: spring-ai-document-index\n initialize-schema: true\n similarity-function: cosinesimil\n read-timeout: <time to wait for response>\n connect-timeout: <time to wait until connection established>\n path-prefix: <custom path prefix>\n ssl-bundle: <name of SSL bundle>\n aws: # Only for Amazon OpenSearch Service\n host: <aws opensearch host>\n service-name: <aws service name>\n access-key: <aws access key>\n secret-key: <aws secret key>\n region: <aws region>\n----\n\nProperties starting with `spring.ai.vectorstore.opensearch.*` are used to configure the `OpenSearchVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.opensearch.uris`| URIs of the OpenSearch cluster endpoints | -\n|`spring.ai.vectorstore.opensearch.username`| Username for accessing the OpenSearch cluster | -\n|`spring.ai.vectorstore.opensearch.password`| Password for the specified username | -\n|`spring.ai.vectorstore.opensearch.index-name`| Name of the index to store vectors | `spring-ai-document-index`\n|`spring.ai.vectorstore.opensearch.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.opensearch.similarity-function`| The similarity function to use (cosinesimil, l1, l2, linf, innerproduct) | `cosinesimil`\n|`spring.ai.vectorstore.opensearch.use-approximate-knn`| Whether to use approximate k-NN for faster searches. If true, uses HNSW-based approximate search. If false, uses exact brute-force k-NN. See link:https://opensearch.org/docs/latest/search-plugins/knn/approximate-knn/[Approximate k-NN] and link:https://opensearch.org/docs/latest/search-plugins/knn/knn-score-script/[Exact k-NN] | `false`\n|`spring.ai.vectorstore.opensearch.dimensions`| Number of dimensions for vector embeddings. Used when creating index mapping for approximate k-NN. If not set, uses the embedding model's dimensions. | `1536`\n|`spring.ai.vectorstore.opensearch.mapping-json`| Custom JSON mapping for the index. Overrides default mapping generation. | -\n|`spring.ai.vectorstore.opensearch.read-timeout`| Time to wait for response from the opposite endpoint. 0 - infinity. | -\n|`spring.ai.vectorstore.opensearch.connect-timeout`| Time to wait until connection established. 0 - infinity. | -\n|`spring.ai.vectorstore.opensearch.path-prefix`| Path prefix for OpenSearch API endpoints. Useful when OpenSearch is behind a reverse proxy with a non-root path. | -\n|`spring.ai.vectorstore.opensearch.ssl-bundle`| Name of the SSL Bundle to use in case of SSL connection | -\n|`spring.ai.vectorstore.opensearch.aws.host`| Hostname of the OpenSearch instance | -\n|`spring.ai.vectorstore.opensearch.aws.service-name`| AWS service name | -\n|`spring.ai.vectorstore.opensearch.aws.access-key`| AWS access key | -\n|`spring.ai.vectorstore.opensearch.aws.secret-key`| AWS secret key | -\n|`spring.ai.vectorstore.opensearch.aws.region`| AWS region | -\n|===\n\n[NOTE]\n====\nYou can control whether the AWS-specific OpenSearch auto-configuration is enabled using the `spring.ai.vectorstore.opensearch.aws.enabled` property.\n\n- If this property is set to `false`, the non-AWS OpenSearch configuration is activated, even if AWS SDK classes are present on the classpath. This allows you to use self-managed or third-party OpenSearch clusters in environments where AWS SDKs are present for other services.\n- If AWS SDK classes are not present, the non-AWS configuration is always used.\n- If AWS SDK classes are present and the property is not set or set to `true`, the AWS-specific configuration is used by default.\n\nThis fallback logic ensures that users have explicit control over the type of OpenSearch integration, preventing accidental activation of AWS-specific logic when not desired.\n====\n\n[NOTE]\n====\nThe `path-prefix` property allows you to specify a custom path prefix when OpenSearch is running behind a reverse proxy that uses a non-root path.\nFor example, if your OpenSearch instance is accessible at `https://example.com/opensearch/` instead of `https://example.com/`, you would set `path-prefix: /opensearch`.\n====\n\nThe following similarity functions are available:\n\n* `cosinesimil` - Default, suitable for most use cases. Measures cosine similarity between vectors.\n* `l1` - Manhattan distance between vectors.\n* `l2` - Euclidean distance between vectors.\n* `linf` - Chebyshev distance between vectors.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Configuration Properties", "heading_level": 3, "file_order": 81, "section_index": 3, "content_hash": "a4cadcf5eac2ee34ef0f0f68e16c56eae128b5aa26c990da89a7a1e8848e29bd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:fc671ef99e58b7a7ff7d364a14dfb6a47ff9e0d91d17ef3a194a1347359a28d1", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the OpenSearch vector store. For this you need to add the `spring-ai-opensearch-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-opensearch-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-opensearch-store'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nCreate an OpenSearch client bean:\n\n[source,java]\n----\n@Bean\npublic OpenSearchClient openSearchClient() {\n RestClient restClient = RestClient.builder(\n HttpHost.create(\"http://localhost:9200\"))\n .build();\n\n return new OpenSearchClient(new RestClientTransport(\n restClient, new JacksonJsonpMapper()));\n}\n----\n\nThen create the `OpenSearchVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(OpenSearchClient openSearchClient, EmbeddingModel embeddingModel) {\n return OpenSearchVectorStore.builder(openSearchClient, embeddingModel)\n .index(\"custom-index\") // Optional: defaults to \"spring-ai-document-index\"\n .similarityFunction(\"l2\") // Optional: defaults to \"cosinesimil\"\n .useApproximateKnn(true) // Optional: defaults to false (exact k-NN)\n .dimensions(1536) // Optional: defaults to 1536 or embedding model's dimensions\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Manual Configuration", "heading_level": 2, "file_order": 81, "section_index": 4, "content_hash": "fc671ef99e58b7a7ff7d364a14dfb6a47ff9e0d91d17ef3a194a1347359a28d1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:405e6b6542806b3b156814c294e6ce938604e2a2854a2bcd530fdee22461a02a", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with OpenSearch as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && 'article_type' == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary OpenSearch link:https://opensearch.org/docs/latest/query-dsl/full-text/query-string/[Query string query].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\nauthor in ['john', 'jill'] && 'article_type' == 'blog'\n----\n\nis converted into the proprietary OpenSearch filter format:\n\n[source,text]\n----\n(metadata.author:john OR jill) AND metadata.article_type:blog\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 81, "section_index": 5, "content_hash": "405e6b6542806b3b156814c294e6ce938604e2a2854a2bcd530fdee22461a02a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:39b1dd846b8a7b9288d7c12d39064705bd0e8095a3eb91e8a8b8f935667e09fd", "content": "The OpenSearch Vector Store implementation provides access to the underlying native OpenSearch client (`OpenSearchClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nOpenSearchVectorStore vectorStore = context.getBean(OpenSearchVectorStore.class);\nOptional<OpenSearchClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n OpenSearchClient client = nativeClient.get();\n // Use the native client for OpenSearch-specific operations\n}\n----\n\nThe native client gives you access to OpenSearch-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc", "title": "OpenSearch", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 81, "section_index": 6, "content_hash": "39b1dd846b8a7b9288d7c12d39064705bd0e8095a3eb91e8a8b8f935667e09fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/opensearch.adoc"}}
{"id": "sha256:4b0980bb47e2479a050b88c6196f06e9957f081ce759c09972175a6b97de6dd1", "content": "The link:https://docs.oracle.com/en/database/oracle/oracle-database/23/vecse/overview-ai-vector-search.html[AI Vector Search] capabilities of the Oracle Database 23ai (23.4+) are available as a Spring AI `VectorStore` to help you to store document embeddings and perform similarity searches. Of course, all other features are also available.\n\nTIP: The <<Run Oracle Database 23ai locally,Run Oracle Database 23ai locally>> appendix shows how to start a database with a lightweight Docker container.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Oracle Database 23ai - AI Vector Search", "heading_level": 1, "file_order": 82, "section_index": 0, "content_hash": "4b0980bb47e2479a050b88c6196f06e9957f081ce759c09972175a6b97de6dd1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:06dc4d403bd72af1c2b463b647a159b2f3a914e1f4a3df99de267ff628bed1c9", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nStart by adding the Oracle Vector Store boot starter dependency to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-vector-store-oracle</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-oracle'\n}\n----\n\nIf you need this vector store to initialize the schema for you then you'll need to pass true for the `initializeSchema` boolean parameter in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nThe Vector Store, also requires an `EmbeddingModel` instance to calculate embeddings for the documents.\nYou can pick one of the available xref:api/embeddings.adoc#available-implementations[EmbeddingModel Implementations].\n\nFor example to use the xref:api/embeddings/openai-embeddings.adoc[OpenAI EmbeddingModel] add the following dependency to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nTo connect to and configure the `OracleVectorStore`, you need to provide access details for your database.\nA simple configuration can either be provided via Spring Boot's `application.yml`\n\n[yml]\n----\nspring:\n datasource:\n url: jdbc:oracle:thin:@//localhost:1521/freepdb1\n username: mlops\n password: mlops\n ai:\n\tvectorstore:\n oracle:\n index-type: IVF\n distance-type: COSINE\n dimensions: 1536\n----\n\nTIP: Check the list of xref:#oracle-properties[configuration parameters] to learn about the default values and configuration options.\n\nNow you can Auto-wire the `OracleVectorStore` in your application and use it:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[oracle-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Auto-Configuration", "heading_level": 2, "file_order": 82, "section_index": 1, "content_hash": "06dc4d403bd72af1c2b463b647a159b2f3a914e1f4a3df99de267ff628bed1c9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:b333403313b7781defb0fd76453c5b45d433d99959147ca2c8ee0473b611aeee", "content": "You can use the following properties in your Spring Boot configuration to customize the `OracleVectorStore`.\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property| Description | Default value\n\n|`spring.ai.vectorstore.oracle.index-type`| Nearest neighbor search index type. Options are `NONE` - exact nearest neighbor search, `IVF` - Inverted Flat File index. It has faster build times and uses less memory than HNSW, but has lower query performance (in terms of speed-recall tradeoff). `HNSW` - creates a multilayer graph. It has slower build times and uses more memory than IVF, but has better query performance (in terms of speed-recall tradeoff). | NONE\n|`spring.ai.vectorstore.oracle.distance-type`| Search distance type among `COSINE` (default), `DOT`, `EUCLIDEAN`, `EUCLIDEAN_SQUARED`, and `MANHATTAN`.\n\nNOTE: If vectors are normalized, you can use `DOT` or `COSINE` for best performance.| COSINE\n|`spring.ai.vectorstore.oracle.forced-normalization`| Allows enabling vector normalization (if true) before insertion and for similarity search.\n\nCAUTION: Setting this to true is a requirement to allow for xref:api/vectordbs.adoc#api-overview[search request similarity threshold].\n\nNOTE: If vectors are normalized, you can use `DOT` or `COSINE` for best performance. | false\n|`spring.ai.vectorstore.oracle.dimensions`| Embeddings dimension. If not specified explicitly the OracleVectorStore will allow the maximum: 65535. Dimensions are set to the embedding column on table creation. If you change the dimensions your would have to re-create the table as well. | 65535\n|`spring.ai.vectorstore.oracle.remove-existing-vector-store-table` | Drops the existing table on start up. | false\n|`spring.ai.vectorstore.oracle.initialize-schema` | Whether to initialize the required schema. | false\n|`spring.ai.vectorstore.oracle.search-accuracy` | Denote the requested accuracy target in the presence of index. Disabled by default. You need to provide an integer in the range [1,100] to override the default index accuracy (95). Using lower accuracy provides approximate similarity search trading off speed versus accuracy. | -1 (`DEFAULT_SEARCH_ACCURACY`)\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Configuration properties", "heading_level": 3, "file_order": 82, "section_index": 2, "content_hash": "b333403313b7781defb0fd76453c5b45d433d99959147ca2c8ee0473b611aeee", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:4248059aade31fd60495b579a56107748b316e3c37a567e5b8d29ad9ddbed4ad", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the `OracleVectorStore`.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\",\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These filter expressions are converted into the equivalent `OracleVectorStore` filters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Metadata filtering", "heading_level": 2, "file_order": 82, "section_index": 3, "content_hash": "4248059aade31fd60495b579a56107748b316e3c37a567e5b8d29ad9ddbed4ad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:f53d005f8653d16b0ed0345692b265409961e24682056016d72127174e7d1d08", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the `OracleVectorStore`.\nFor this you need to add the Oracle JDBC driver and `JdbcTemplate` auto-configuration dependencies to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n\n<dependency>\n\t<groupId>com.oracle.database.jdbc</groupId>\n\t<artifactId>ojdbc11</artifactId>\n\t<scope>runtime</scope>\n</dependency>\n\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-oracle-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTo configure the `OracleVectorStore` in your application, you can use the following setup:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(JdbcTemplate jdbcTemplate, EmbeddingModel embeddingModel) {\n return OracleVectorStore.builder(jdbcTemplate, embeddingModel)\n .tableName(\"my_vectors\")\n .indexType(OracleVectorStoreIndexType.IVF)\n .distanceType(OracleVectorStoreDistanceType.COSINE)\n .dimensions(1536)\n .searchAccuracy(95)\n .initializeSchema(true)\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Manual Configuration", "heading_level": 2, "file_order": 82, "section_index": 4, "content_hash": "f53d005f8653d16b0ed0345692b265409961e24682056016d72127174e7d1d08", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:1dae188621a57ef6384b2fdff1521767283afce364a7f0eacd6295da40f709dd", "content": "----\ndocker run --rm --name oracle23ai -p 1521:1521 -e APP_USER=mlops -e APP_USER_PASSWORD=mlops -e ORACLE_PASSWORD=mlops gvenzl/oracle-free:23-slim\n----\n\nYou can then connect to the database using:\n\n----\nsql mlops/mlops@localhost/freepdb1\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Run Oracle Database 23ai locally", "heading_level": 2, "file_order": 82, "section_index": 5, "content_hash": "1dae188621a57ef6384b2fdff1521767283afce364a7f0eacd6295da40f709dd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:8d4fba65991aa81102b2e4f88f4802b42b7547be752288e7335afb4ee7676024", "content": "The Oracle Vector Store implementation provides access to the underlying native Oracle client (`OracleConnection`) through the `getNativeClient()` method:\n\n[source,java]\n----\nOracleVectorStore vectorStore = context.getBean(OracleVectorStore.class);\nOptional<OracleConnection> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n OracleConnection connection = nativeClient.get();\n // Use the native client for Oracle-specific operations\n}\n----\n\nThe native client gives you access to Oracle-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/oracle.adoc", "title": "Oracle Database 23ai - AI Vector Search", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 82, "section_index": 6, "content_hash": "8d4fba65991aa81102b2e4f88f4802b42b7547be752288e7335afb4ee7676024", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/oracle.adoc"}}
{"id": "sha256:cd34f861659f2624788744af3e145a154744ad4180eb1017f6e28ac2525902a4", "content": "This section walks you through setting up the PGvector `VectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://github.com/pgvector/pgvector[PGvector] is an open-source extension for PostgreSQL that enables storing and searching over machine learning-generated embeddings. It provides different capabilities that let users identify both exact and approximate nearest neighbors. It is designed to work seamlessly with other PostgreSQL features, including indexing and querying.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "PGvector", "heading_level": 1, "file_order": 83, "section_index": 0, "content_hash": "cd34f861659f2624788744af3e145a154744ad4180eb1017f6e28ac2525902a4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:920d2ffab3f757dde85d7c24ecab86160f0f569e4a63c88b8a2da92ada285aea", "content": "First you need access to PostgreSQL instance with enabled `vector`, `hstore` and `uuid-ossp` extensions.\n\nTIP: You can run a PGvector database as a Spring Boot dev service via xref:api/docker-compose.adoc[Docker Compose] or xref:api/testcontainers.adoc[Testcontainers]. In alternative, the <<Run Postgres & PGVector DB locally,setup local Postgres/PGVector>> appendix shows how to set up a DB locally with a Docker container.\n\nOn startup with the schema initialization feature explicitly enabled, the `PgVectorStore` will attempt to install the required database extensions and create the required `vector_store` table with an index if not existing.\n\nOptionally, you can do this manually like so:\n\n[sql]\n----\nCREATE EXTENSION IF NOT EXISTS vector;\nCREATE EXTENSION IF NOT EXISTS hstore;\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\nCREATE TABLE IF NOT EXISTS vector_store (\n\tid uuid DEFAULT uuid_generate_v4() PRIMARY KEY,\n\tcontent text,\n\tmetadata json,\n\tembedding vector(1536) // 1536 is the default embedding dimension\n);\n\nCREATE INDEX ON vector_store USING HNSW (embedding vector_cosine_ops);\n----\n\nTIP: replace the `1536` with the actual embedding dimension if you are using a different dimension. PGvector supports at most 2000 dimensions for HNSW indexes.\n\nNext, if required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `PgVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Prerequisites", "heading_level": 2, "file_order": 83, "section_index": 1, "content_hash": "920d2ffab3f757dde85d7c24ecab86160f0f569e4a63c88b8a2da92ada285aea", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:71800106b6befe6a8ff8d7e920fe3e0e017c0ac7000aefdc4a13ab213b760a45", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nThen add the PgVectorStore boot starter dependency to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-vector-store-pgvector</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-pgvector'\n}\n----\n\nThe vector store implementation can initialize the required schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: This is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nThe Vector Store also requires an `EmbeddingModel` instance to calculate embeddings for the documents.\nYou can pick one of the available xref:api/embeddings.adoc#available-implementations[EmbeddingModel Implementations].\n\nFor example, to use the xref:api/embeddings/openai-embeddings.adoc[OpenAI EmbeddingModel], add the following dependency to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-openai'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\nRefer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nTo connect to and configure the `PgVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`.\n\n[yml]\n----\nspring:\n datasource:\n url: jdbc:postgresql://localhost:5432/postgres\n username: postgres\n password: postgres\n ai:\n\tvectorstore:\n pgvector:\n index-type: HNSW\n distance-type: COSINE_DISTANCE\n dimensions: 1536\n max-document-batch-size: 10000 # Optional: Maximum number of documents per batch\n----\n\nTIP: If you run PGvector as a Spring Boot dev service via link:https://docs.spring.io/spring-boot/reference/features/dev-services.html#features.dev-services.docker-compose[Docker Compose]\nor link:https://docs.spring.io/spring-boot/reference/features/dev-services.html#features.dev-services.testcontainers[Testcontainers],\nyou don't need to configure URL, username and password since they are autoconfigured by Spring Boot.\n\nTIP: Check the list of xref:#pgvector-properties[configuration parameters] to learn about the default values and configuration options.\n\nNow you can auto-wire the `VectorStore` in your application and use it\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[pgvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Auto-Configuration", "heading_level": 2, "file_order": 83, "section_index": 2, "content_hash": "71800106b6befe6a8ff8d7e920fe3e0e017c0ac7000aefdc4a13ab213b760a45", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:836d9dc099bd8c721d5f895dd1390cfdf56a3e1c56c2516efcfe83431d7a5fc7", "content": "You can use the following properties in your Spring Boot configuration to customize the PGVector vector store.\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property| Description | Default value\n\n|`spring.ai.vectorstore.pgvector.index-type`| Nearest neighbor search index type. Options are `NONE` - exact nearest neighbor search, `IVFFlat` - index divides vectors into lists, and then searches a subset of those lists that are closest to the query vector. It has faster build times and uses less memory than HNSW, but has lower query performance (in terms of speed-recall tradeoff). `HNSW` - creates a multilayer graph. It has slower build times and uses more memory than IVFFlat, but has better query performance (in terms of speed-recall tradeoff). There's no training step like IVFFlat, so the index can be created without any data in the table.| HNSW\n|`spring.ai.vectorstore.pgvector.distance-type`| Search distance type. Defaults to `COSINE_DISTANCE`. But if vectors are normalized to length 1, you can use `EUCLIDEAN_DISTANCE` or `NEGATIVE_INNER_PRODUCT` for best performance.| COSINE_DISTANCE\n|`spring.ai.vectorstore.pgvector.dimensions`| Embeddings dimension. If not specified explicitly the PgVectorStore will retrieve the dimensions form the provided `EmbeddingModel`. Dimensions are set to the embedding column the on table creation. If you change the dimensions your would have to re-create the vector_store table as well. | -\n|`spring.ai.vectorstore.pgvector.remove-existing-vector-store-table` | Deletes the existing `vector_store` table on start up. | false\n|`spring.ai.vectorstore.pgvector.initialize-schema` | Whether to initialize the required schema | false\n|`spring.ai.vectorstore.pgvector.schema-name` | Vector store schema name | `public`\n|`spring.ai.vectorstore.pgvector.table-name` | Vector store table name | `vector_store`\n|`spring.ai.vectorstore.pgvector.schema-validation` | Enables schema and table name validation to ensure they are valid and existing objects. | false\n|`spring.ai.vectorstore.pgvector.max-document-batch-size` | Maximum number of documents to process in a single batch. | 10000\n\n|===\n\nTIP: If you configure a custom schema and/or table name, consider enabling schema validation by setting `spring.ai.vectorstore.pgvector.schema-validation=true`.\nThis ensures the correctness of the names and reduces the risk of SQL injection attacks.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Configuration properties", "heading_level": 3, "file_order": 83, "section_index": 3, "content_hash": "836d9dc099bd8c721d5f895dd1390cfdf56a3e1c56c2516efcfe83431d7a5fc7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:d3c7d4553d6111dc8513b8a8f5800e8fbf76779219f7d73b7565d1800cca33d3", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the PgVector store.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\",\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These filter expressions are converted into PostgreSQL JSON path expressions for efficient metadata filtering.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Metadata filtering", "heading_level": 2, "file_order": 83, "section_index": 4, "content_hash": "d3c7d4553d6111dc8513b8a8f5800e8fbf76779219f7d73b7565d1800cca33d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:e2aeb8b4fb56d5612e4d0b9f7da134ff9d6de0428f3b3a3a3dfd38a49d71d549", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the `PgVectorStore`.\nFor this you need to add the PostgreSQL connection and `JdbcTemplate` auto-configuration dependencies to your project:\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n\n<dependency>\n\t<groupId>org.postgresql</groupId>\n\t<artifactId>postgresql</artifactId>\n\t<scope>runtime</scope>\n</dependency>\n\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-pgvector-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTo configure PgVector in your application, you can use the following setup:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(JdbcTemplate jdbcTemplate, EmbeddingModel embeddingModel) {\n return PgVectorStore.builder(jdbcTemplate, embeddingModel)\n .dimensions(1536) // Optional: defaults to model dimensions or 1536\n .distanceType(COSINE_DISTANCE) // Optional: defaults to COSINE_DISTANCE\n .indexType(HNSW) // Optional: defaults to HNSW\n .initializeSchema(true) // Optional: defaults to false\n .schemaName(\"public\") // Optional: defaults to \"public\"\n .vectorTableName(\"vector_store\") // Optional: defaults to \"vector_store\"\n .maxDocumentBatchSize(10000) // Optional: defaults to 10000\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Manual Configuration", "heading_level": 2, "file_order": 83, "section_index": 5, "content_hash": "e2aeb8b4fb56d5612e4d0b9f7da134ff9d6de0428f3b3a3a3dfd38a49d71d549", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:5f668730b5beec596e1aca8b9b7b7e55dd6f816108999bb8397864ca45e91e58", "content": "----\ndocker run -it --rm --name postgres -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres pgvector/pgvector\n----\n\nYou can connect to this server like this:\n\n----\npsql -U postgres -h localhost -p 5432\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Run Postgres & PGVector DB locally", "heading_level": 2, "file_order": 83, "section_index": 6, "content_hash": "5f668730b5beec596e1aca8b9b7b7e55dd6f816108999bb8397864ca45e91e58", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:8045b2f0b10e4a4ddcbb0bd8b298a85cfdc7b0ddf6bde3eae8947ae795c907e9", "content": "The PGVector Store implementation provides access to the underlying native JDBC client (`JdbcTemplate`) through the `getNativeClient()` method:\n\n[source,java]\n----\nPgVectorStore vectorStore = context.getBean(PgVectorStore.class);\nOptional<JdbcTemplate> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n JdbcTemplate jdbc = nativeClient.get();\n // Use the native client for PostgreSQL-specific operations\n}\n----\n\nThe native client gives you access to PostgreSQL-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc", "title": "PGvector", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 83, "section_index": 7, "content_hash": "8045b2f0b10e4a4ddcbb0bd8b298a85cfdc7b0ddf6bde3eae8947ae795c907e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pgvector.adoc"}}
{"id": "sha256:1a774fd2253244b38d263b888ffb7db37116931d579b67ffe18feeaf61f4af6b", "content": "This section walks you through setting up the Pinecone `VectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://www.pinecone.io/[Pinecone] is a popular cloud-based vector database, which allows you to store and search vectors efficiently.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Pinecone", "heading_level": 1, "file_order": 84, "section_index": 0, "content_hash": "1a774fd2253244b38d263b888ffb7db37116931d579b67ffe18feeaf61f4af6b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:596783fd72bffcbc9e29ad520e4ca1059cd1383f8c53d899b2a5008b6196d627", "content": "1. Pinecone Account: Before you start, sign up for a link:https://app.pinecone.io/[Pinecone account].\n2. Pinecone Project: Once registered, generate an API key and create and index. You'll need these details for configuration.\n3. `EmbeddingModel` instance to compute the document embeddings. Several options are available:\n- If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `PineconeVectorStore`.\n\nTo set up `PineconeVectorStore`, gather the following details from your Pinecone account:\n\n* Pinecone API Key\n* Pinecone Index Name\n* Pinecone Namespace\n\n[NOTE]\n====\nThis information is available to you in the Pinecone UI portal.\nThe namespace support is not available in the Pinecone free tier.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Prerequisites", "heading_level": 2, "file_order": 84, "section_index": 1, "content_hash": "596783fd72bffcbc9e29ad520e4ca1059cd1383f8c53d899b2a5008b6196d627", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:a31c845a45988409b564882547eeaca1bbac9e435b531d49e8d05085dabeb2b4", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Pinecone Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-pinecone</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-pinecone'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nHere is an example of the needed bean:\n\n[source,java]\n----\n@Bean\npublic EmbeddingModel embeddingModel() {\n // Can be any other EmbeddingModel implementation.\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----\n\nTo connect to Pinecone you need to provide access details for your instance.\nA simple configuration can either be provided via Spring Boot's _application.properties_,\n\n[source,properties]\n----\nspring.ai.vectorstore.pinecone.apiKey=<your api key>\nspring.ai.vectorstore.pinecone.index-name=<your index name>\n\n# API key if needed, e.g. OpenAI\nspring.ai.openai.api.key=<api-key>\n----\n\nPlease have a look at the list of xref:#_configuration_properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nNow you can Auto-wire the Pinecone Vector Store in your application and use it\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Auto-configuration", "heading_level": 2, "file_order": 84, "section_index": 2, "content_hash": "a31c845a45988409b564882547eeaca1bbac9e435b531d49e8d05085dabeb2b4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:7de3ffcbd0e1e5e93df2c143b71f75803edf34e9080b35685dba2e928c020698", "content": "You can use the following properties in your Spring Boot configuration to customize the Pinecone vector store.\n\n[stripes=even]\n|===\n|Property| Description | Default value\n\n|`spring.ai.vectorstore.pinecone.api-key`| Pinecone API Key | -\n|`spring.ai.vectorstore.pinecone.index-name`| Pinecone index name | -\n|`spring.ai.vectorstore.pinecone.namespace`| Pinecone namespace | -\n|`spring.ai.vectorstore.pinecone.content-field-name`| Pinecone metadata field name used to store the original text content. | `document_content`\n|`spring.ai.vectorstore.pinecone.distance-metadata-field-name`| Pinecone metadata field name used to store the computed distance. | `distance`\n|`spring.ai.vectorstore.pinecone.server-side-timeout`| | 20 sec.\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Configuration properties", "heading_level": 3, "file_order": 84, "section_index": 3, "content_hash": "7de3ffcbd0e1e5e93df2c143b71f75803edf34e9080b35685dba2e928c020698", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:7a05698bc087482a3a73982b8e1f47afa736867b0fbd949d94a10aaeae83ef3c", "content": "You can leverage the generic, portable link:https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_metadata_filters[metadata filters] with the Pinecone store.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\",\"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These filter expressions are converted into the equivalent Pinecone filters.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Metadata filtering", "heading_level": 2, "file_order": 84, "section_index": 4, "content_hash": "7a05698bc087482a3a73982b8e1f47afa736867b0fbd949d94a10aaeae83ef3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:560d01b15bf047b681e588ad749772ca14443bd4b24fab25797ee1a5bc0d8adf", "content": "If you prefer to configure `PineconeVectorStore` manually, you can do so by using the `PineconeVectorStore#Builder`.\n\nAdd these dependencies to your project:\n\n* OpenAI: Required for calculating embeddings.\n\n[source,xml]\n----\n<dependency>\n\t<groupId>org.springframework.ai</groupId>\n\t<artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\n* Pinecone\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-pinecone-store</artifactId>\n</dependency>\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Manual Configuration", "heading_level": 2, "file_order": 84, "section_index": 5, "content_hash": "560d01b15bf047b681e588ad749772ca14443bd4b24fab25797ee1a5bc0d8adf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:b24bd398c43ca0353f0204883beb8be770681be83c257ec48061d50493d0c624", "content": "To configure Pinecone in your application, you can use the following setup:\n\n[source,java]\n----\n@Bean\npublic VectorStore pineconeVectorStore(EmbeddingModel embeddingModel) {\n return PineconeVectorStore.builder(embeddingModel)\n .apiKey(PINECONE_API_KEY)\n .indexName(PINECONE_INDEX_NAME)\n .namespace(PINECONE_NAMESPACE) // the free tier doesn't support namespaces.\n .contentFieldName(CUSTOM_CONTENT_FIELD_NAME) // optional field to store the original content. Defaults to `document_content`\n .build();\n}\n----\n\nIn your main code, create some documents:\n\n[source,java]\n----\nList<Document> documents = List.of(\n\tnew Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n\tnew Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n\tnew Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n----\n\nAdd the documents to Pinecone:\n\n[source,java]\n----\nvectorStore.add(documents);\n----\n\nAnd finally, retrieve documents similar to a query:\n\n[source,java]\n----\nList<Document> results = vectorStore.similaritySearch(SearchRequest.query(\"Spring\").topK(5).build());\n----\n\nIf all goes well, you should retrieve the document containing the text \"Spring AI rocks!!\".", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Sample Code", "heading_level": 3, "file_order": 84, "section_index": 6, "content_hash": "b24bd398c43ca0353f0204883beb8be770681be83c257ec48061d50493d0c624", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:c607da602dad7aa93b91b26c08c2e0c0a63382fae3cf4a06c0cfb9282dfcaf15", "content": "The Pinecone Vector Store implementation provides access to the underlying native Pinecone client (`PineconeConnection`) through the `getNativeClient()` method:\n\n[source,java]\n----\nPineconeVectorStore vectorStore = context.getBean(PineconeVectorStore.class);\nOptional<PineconeConnection> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n PineconeConnection client = nativeClient.get();\n // Use the native client for Pinecone-specific operations\n}\n----\n\nThe native client gives you access to Pinecone-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc", "title": "Pinecone", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 84, "section_index": 7, "content_hash": "c607da602dad7aa93b91b26c08c2e0c0a63382fae3cf4a06c0cfb9282dfcaf15", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/pinecone.adoc"}}
{"id": "sha256:14fe7d031451f725513ba0363bd625100f19dd19fe88985e6165dc1d2030332d", "content": "This section walks you through setting up the Qdrant `VectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://www.qdrant.tech/[Qdrant] is an open-source, high-performance vector search engine/database. It uses HNSW (Hierarchical Navigable Small World) algorithm for efficient k-NN search operations and provides advanced filtering capabilities for metadata-based queries.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Qdrant", "heading_level": 1, "file_order": 85, "section_index": 0, "content_hash": "14fe7d031451f725513ba0363bd625100f19dd19fe88985e6165dc1d2030332d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:15ef5c9a8a1d4db776a245a026d430ac694097ff9296d410c4ae3ddfe7df6381", "content": "* Qdrant Instance: Set up a Qdrant instance by following the link:https://qdrant.tech/documentation/guides/installation/[installation instructions] in the Qdrant documentation.\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `QdrantVectorStore`.\n\nNOTE: It is recommended that the Qdrant collection is link:https://qdrant.tech/documentation/concepts/collections/#create-a-collection[created] in advance with the appropriate dimensions and configurations.\nIf the collection is not created, the `QdrantVectorStore` will attempt to create one using the `Cosine` similarity and the dimension of the configured `EmbeddingModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Prerequisites", "heading_level": 2, "file_order": 85, "section_index": 1, "content_hash": "15ef5c9a8a1d4db776a245a026d430ac694097ff9296d410c4ae3ddfe7df6381", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:cf70368a8c5cdafbf4e07ca2ba7f893ebf0c34b779367f57cc86106eac3dece6", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Qdrant Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-qdrant</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-qdrant'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#qdrant-vectorstore-properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the builder or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `QdrantVectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[qdrant-vectorstore-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Auto-configuration", "heading_level": 2, "file_order": 85, "section_index": 2, "content_hash": "cf70368a8c5cdafbf4e07ca2ba7f893ebf0c34b779367f57cc86106eac3dece6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:89e2800038942384eeda5d3d2ffc4e8a9bb459167048781cc112546ffb5046a9", "content": "To connect to Qdrant and use the `QdrantVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n ai:\n vectorstore:\n qdrant:\n host: <qdrant host>\n port: <qdrant grpc port>\n api-key: <qdrant api key>\n collection-name: <collection name>\n content-field-name: <content field name>\n use-tls: false\n initialize-schema: true\n----\n\nProperties starting with `spring.ai.vectorstore.qdrant.*` are used to configure the `QdrantVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.qdrant.host`| The host of the Qdrant server | `localhost`\n|`spring.ai.vectorstore.qdrant.port`| The gRPC port of the Qdrant server | `6334`\n|`spring.ai.vectorstore.qdrant.api-key`| The API key to use for authentication | -\n|`spring.ai.vectorstore.qdrant.collection-name`| The name of the collection to use | `vector_store`\n|`spring.ai.vectorstore.qdrant.content-field-name`| The name of the field storing document content in Qdrant payloads. Useful when integrating with existing collections that use different field names (e.g., \"page_content\", \"text\", \"content\"). | `doc_content`\n|`spring.ai.vectorstore.qdrant.use-tls`| Whether to use TLS(HTTPS) | `false`\n|`spring.ai.vectorstore.qdrant.initialize-schema`| Whether to initialize the schema | `false`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Configuration Properties", "heading_level": 3, "file_order": 85, "section_index": 3, "content_hash": "89e2800038942384eeda5d3d2ffc4e8a9bb459167048781cc112546ffb5046a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:4ae5a37ef5267e8bc621577b380dd766098d20ea8f006e92c78c2e5025e103c1", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the Qdrant vector store. For this you need to add the `spring-ai-qdrant-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-qdrant-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-qdrant-store'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nCreate a Qdrant client bean:\n\n[source,java]\n----\n@Bean\npublic QdrantClient qdrantClient() {\n QdrantGrpcClient.Builder grpcClientBuilder =\n QdrantGrpcClient.newBuilder(\n \"<QDRANT_HOSTNAME>\",\n <QDRANT_GRPC_PORT>,\n <IS_TLS>);\n grpcClientBuilder.withApiKey(\"<QDRANT_API_KEY>\");\n\n return new QdrantClient(grpcClientBuilder.build());\n}\n----\n\nThen create the `QdrantVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(QdrantClient qdrantClient, EmbeddingModel embeddingModel) {\n return QdrantVectorStore.builder(qdrantClient, embeddingModel)\n .collectionName(\"custom-collection\") // Optional: defaults to \"vector_store\"\n .contentFieldName(\"page_content\") // Optional: defaults to \"doc_content\"\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Manual Configuration", "heading_level": 2, "file_order": 85, "section_index": 4, "content_hash": "4ae5a37ef5267e8bc621577b380dd766098d20ea8f006e92c78c2e5025e103c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:d9d002875bcc2554b52d5fcf6dddde372f921cf80d4052d425ba7a407a202c9d", "content": "When integrating Spring AI with pre-existing Qdrant collections, you may need to configure the content field name to match the schema already in use.\n\nBy default, `QdrantVectorStore` stores document content in a field named `doc_content`. However, existing collections might use different naming conventions such as `page_content`, `text`, `content`, or other custom names.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Working with Existing Collections", "heading_level": 2, "file_order": 85, "section_index": 5, "content_hash": "d9d002875bcc2554b52d5fcf6dddde372f921cf80d4052d425ba7a407a202c9d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:dd21a94d390a2fc014d6f9a41813d9c75d5e25eb2ca4fd5efec7022051cee7a0", "content": "You can configure the content field name to match your existing collection schema:\n\n**Via Properties:**\n[source,yaml]\n----\nspring:\n ai:\n vectorstore:\n qdrant:\n collection-name: my_existing_collection\n content-field-name: page_content # Match existing schema\n----\n\n**Programmatically:**\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(QdrantClient qdrantClient, EmbeddingModel embeddingModel) {\n return QdrantVectorStore.builder(qdrantClient, embeddingModel)\n .collectionName(\"my_existing_collection\")\n .contentFieldName(\"text\") // Use existing field name\n .initializeSchema(false) // Don't recreate existing schema\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Using Custom Content Field Names", "heading_level": 3, "file_order": 85, "section_index": 6, "content_hash": "dd21a94d390a2fc014d6f9a41813d9c75d5e25eb2ca4fd5efec7022051cee7a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:2d9d1f8620ebb60c38f179d0a7c81ed6b396f3446b3bdf741026ff6a85c2fff4", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Qdrant store as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"author in ['john', 'jill'] && article_type == 'blog'\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"author\", \"john\", \"jill\"),\n b.eq(\"article_type\", \"blog\")).build()).build());\n----\n\nNOTE: These (portable) filter expressions get automatically converted into the proprietary Qdrant link:https://qdrant.tech/documentation/concepts/filtering/[filter expressions].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 85, "section_index": 7, "content_hash": "2d9d1f8620ebb60c38f179d0a7c81ed6b396f3446b3bdf741026ff6a85c2fff4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:74c41483a2c3c8e6572e9d36621c76b48afc4bdaacd34c7c6b483bfb7ca35e49", "content": "The Qdrant Vector Store implementation provides access to the underlying native Qdrant client (`QdrantClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nQdrantVectorStore vectorStore = context.getBean(QdrantVectorStore.class);\nOptional<QdrantClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n QdrantClient client = nativeClient.get();\n // Use the native client for Qdrant-specific operations\n}\n----\n\nThe native client gives you access to Qdrant-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc", "title": "Qdrant", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 85, "section_index": 8, "content_hash": "74c41483a2c3c8e6572e9d36621c76b48afc4bdaacd34c7c6b483bfb7ca35e49", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/qdrant.adoc"}}
{"id": "sha256:574d5955d713481c56cf4837a2937ac7e2af5941556cb51ffc8cd144b104eff2", "content": "This section walks you through setting up `RedisVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://redis.io[Redis] is an open source (BSD licensed), in-memory data structure store used as a database, cache, message broker, and streaming engine. Redis provides data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes, and streams.\n\nlink:https://redis.io/docs/interact/search-and-query/[Redis Search and Query] extends the core features of Redis OSS and allows you to use Redis as a vector database:\n\n* Store vectors and the associated metadata within hashes or JSON documents\n* Retrieve vectors\n* Perform vector similarity searches (KNN)\n* Perform range-based vector searches with radius threshold\n* Perform full-text searches on TEXT fields\n* Support for multiple distance metrics (COSINE, L2, IP) and vector algorithms (HNSW, FLAT)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Redis", "heading_level": 1, "file_order": 86, "section_index": 0, "content_hash": "574d5955d713481c56cf4837a2937ac7e2af5941556cb51ffc8cd144b104eff2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:9f3e8724772b8d5f108e3f7e28db960fc314d7822c4b243f37ad44b6bbd81fd2", "content": "1. A Redis Stack instance\n- https://app.redislabs.com/#/[Redis Cloud] (recommended)\n- link:https://hub.docker.com/r/redis/redis-stack[Docker] image _redis/redis-stack:latest_\n\n2. `EmbeddingModel` instance to compute the document embeddings. Several options are available:\n- If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `RedisVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Prerequisites", "heading_level": 2, "file_order": 86, "section_index": 1, "content_hash": "9f3e8724772b8d5f108e3f7e28db960fc314d7822c4b243f37ad44b6bbd81fd2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:87289824d9a2bbdc25b40c0bdb331b37e7f14901be7b9dc54065fdde1e1217fa", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Redis Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-redis</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-redis'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you, but you must opt-in by specifying the `initializeSchema` boolean in the appropriate constructor or by setting `...initialize-schema=true` in the `application.properties` file.\n\nNOTE: this is a breaking change! In earlier versions of Spring AI, this schema initialization happened by default.\n\nPlease have a look at the list of <<redisvector-properties,configuration parameters>> for the vector store to learn about the default values and configuration options.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `RedisVectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[redisvector-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Auto-configuration", "heading_level": 2, "file_order": 86, "section_index": 2, "content_hash": "87289824d9a2bbdc25b40c0bdb331b37e7f14901be7b9dc54065fdde1e1217fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:3151e818a5b7a5d7ba5e07fbab4b7e471a57ead5dc47bf61210d46c62e94b23f", "content": "To connect to Redis and use the `RedisVectorStore`, you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`,\n\n[source,yaml]\n----\nspring:\n data:\n redis:\n url: <redis instance url>\n ai:\n vectorstore:\n redis:\n initialize-schema: true\n index-name: custom-index\n prefix: custom-prefix\n----\n\nFor redis connection configuration, alternatively, a simple configuration can be provided via Spring Boot's _application.properties_.\n\n[source,properties]\n----\nspring.data.redis.host=localhost\nspring.data.redis.port=6379\nspring.data.redis.username=default\nspring.data.redis.password=\n\n----\n\nProperties starting with `spring.ai.vectorstore.redis.*` are used to configure the `RedisVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.redis.initialize-schema`| Whether to initialize the required schema | `false`\n|`spring.ai.vectorstore.redis.index-name` | The name of the index to store the vectors | `spring-ai-index`\n|`spring.ai.vectorstore.redis.prefix` | The prefix for Redis keys | `embedding:`\n|`spring.ai.vectorstore.redis.distance-metric` | Distance metric for vector similarity (COSINE, L2, IP) | `COSINE`\n|`spring.ai.vectorstore.redis.vector-algorithm` | Vector indexing algorithm (HNSW, FLAT) | `HNSW`\n|`spring.ai.vectorstore.redis.hnsw-m` | HNSW: Number of maximum outgoing connections | `16`\n|`spring.ai.vectorstore.redis.hnsw-ef-construction` | HNSW: Number of maximum connections during index building | `200`\n|`spring.ai.vectorstore.redis.hnsw-ef-runtime` | HNSW: Number of connections to consider during search | `10`\n|`spring.ai.vectorstore.redis.default-range-threshold` | Default radius threshold for range searches | `0.8`\n|`spring.ai.vectorstore.redis.text-scorer` | Text scoring algorithm (BM25, TFIDF, BM25STD, DISMAX, DOCSCORE) | `BM25`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Configuration Properties", "heading_level": 3, "file_order": 86, "section_index": 3, "content_hash": "3151e818a5b7a5d7ba5e07fbab4b7e471a57ead5dc47bf61210d46c62e94b23f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:28550340e72a4b25941902081548e6451e7c88de2ce95ba51d5f243860080fc9", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Redis as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"country\", \"UK\", \"NL\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into link:https://redis.io/docs/interact/search-and-query/query/[Redis search queries].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\ncountry in ['UK', 'NL'] && year >= 2020\n----\n\nis converted into the proprietary Redis filter format:\n\n[source,text]\n----\n@country:{UK | NL} @year:[2020 inf]\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 86, "section_index": 4, "content_hash": "28550340e72a4b25941902081548e6451e7c88de2ce95ba51d5f243860080fc9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:52b9413ea5c191f5f260faea08497d5228b5207ab9e3f61e9bd705ce189371f4", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the Redis vector store. For this you need to add the `spring-ai-redis-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-redis-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-redis-store'\n}\n----\n\nCreate a `JedisPooled` bean:\n\n[source,java]\n----\n@Bean\npublic JedisPooled jedisPooled() {\n return new JedisPooled(\"<host>\", 6379);\n}\n----\n\nThen create the `RedisVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(JedisPooled jedisPooled, EmbeddingModel embeddingModel) {\n return RedisVectorStore.builder(jedisPooled, embeddingModel)\n .indexName(\"custom-index\") // Optional: defaults to \"spring-ai-index\"\n .prefix(\"custom-prefix\") // Optional: defaults to \"embedding:\"\n .contentFieldName(\"content\") // Optional: field for document content\n .embeddingFieldName(\"embedding\") // Optional: field for vector embeddings\n .vectorAlgorithm(Algorithm.HNSW) // Optional: HNSW or FLAT (defaults to HNSW)\n .distanceMetric(DistanceMetric.COSINE) // Optional: COSINE, L2, or IP (defaults to COSINE)\n .hnswM(16) // Optional: HNSW connections (defaults to 16)\n .hnswEfConstruction(200) // Optional: HNSW build parameter (defaults to 200)\n .hnswEfRuntime(10) // Optional: HNSW search parameter (defaults to 10)\n .defaultRangeThreshold(0.8) // Optional: default radius for range searches\n .textScorer(TextScorer.BM25) // Optional: text scoring algorithm (defaults to BM25)\n .metadataFields( // Optional: define metadata fields for filtering\n MetadataField.tag(\"country\"),\n MetadataField.numeric(\"year\"),\n MetadataField.text(\"description\"))\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----\n\n[NOTE]\n====\nYou must list explicitly all metadata field names and types (`TAG`, `TEXT`, or `NUMERIC`) for any metadata field used in filter expressions.\nThe `metadataFields` above registers filterable metadata fields: `country` of type `TAG`, `year` of type `NUMERIC`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Manual Configuration", "heading_level": 2, "file_order": 86, "section_index": 5, "content_hash": "52b9413ea5c191f5f260faea08497d5228b5207ab9e3f61e9bd705ce189371f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:ab9a0fd720a00a6c420472221fae98a825bee3f9ac75caf7e5322b8e6328eb8d", "content": "The Redis Vector Store implementation provides access to the underlying native Redis client (`JedisPooled`) through the `getNativeClient()` method:\n\n[source,java]\n----\nRedisVectorStore vectorStore = context.getBean(RedisVectorStore.class);\nOptional<JedisPooled> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n JedisPooled jedis = nativeClient.get();\n // Use the native client for Redis-specific operations\n}\n----\n\nThe native client gives you access to Redis-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 86, "section_index": 6, "content_hash": "ab9a0fd720a00a6c420472221fae98a825bee3f9ac75caf7e5322b8e6328eb8d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:83e37bdd177920d38cf5e8c13597a686e51bab5e79a67dcdd8845205c3b536ff", "content": "The Redis Vector Store supports three distance metrics for vector similarity:\n\n* **COSINE**: Cosine similarity (default) - measures the cosine of the angle between vectors\n* **L2**: Euclidean distance - measures the straight-line distance between vectors\n* **IP**: Inner Product - measures the dot product between vectors\n\nEach metric is automatically normalized to a 0-1 similarity score, where 1 is most similar.\n\n[source,java]\n----\nRedisVectorStore vectorStore = RedisVectorStore.builder(jedisPooled, embeddingModel)\n .distanceMetric(DistanceMetric.COSINE) // or L2, IP\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Distance Metrics", "heading_level": 2, "file_order": 86, "section_index": 7, "content_hash": "83e37bdd177920d38cf5e8c13597a686e51bab5e79a67dcdd8845205c3b536ff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:154c4e3867944f298641f449efc8ecb40cd0903a9c837a9255a805b784735ffb", "content": "The Redis Vector Store uses the HNSW (Hierarchical Navigable Small World) algorithm by default for efficient approximate nearest neighbor search. You can tune the HNSW parameters for your specific use case:\n\n[source,java]\n----\nRedisVectorStore vectorStore = RedisVectorStore.builder(jedisPooled, embeddingModel)\n .vectorAlgorithm(Algorithm.HNSW)\n .hnswM(32) // Maximum outgoing connections per node (default: 16)\n .hnswEfConstruction(100) // Connections during index building (default: 200)\n .hnswEfRuntime(50) // Connections during search (default: 10)\n .build();\n----\n\nParameter guidelines:\n\n* **M**: Higher values improve recall but increase memory usage and index time. Typical values: 12-48.\n* **EF_CONSTRUCTION**: Higher values improve index quality but increase build time. Typical values: 100-500.\n* **EF_RUNTIME**: Higher values improve search accuracy but increase latency. Typical values: 10-100.\n\nFor smaller datasets or when exact results are required, use the FLAT algorithm instead:\n\n[source,java]\n----\nRedisVectorStore vectorStore = RedisVectorStore.builder(jedisPooled, embeddingModel)\n .vectorAlgorithm(Algorithm.FLAT)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "HNSW Algorithm Configuration", "heading_level": 2, "file_order": 86, "section_index": 8, "content_hash": "154c4e3867944f298641f449efc8ecb40cd0903a9c837a9255a805b784735ffb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:eb02f86649999610617b1888f2a76b1639872a76478bd5985693c87da5cce35f", "content": "The Redis Vector Store provides text search capabilities using Redis Query Engine's full-text search features. This allows you to find documents based on keywords and phrases in TEXT fields:\n\n[source,java]\n----\nList<Document> textResults = vectorStore.searchByText(\n \"machine learning\", // search query\n \"content\", // field to search (must be TEXT type)\n 10, // limit\n \"category == 'AI'\" // optional filter expression\n);\n----\n\nText search supports:\n\n* Single word searches\n* Phrase searches with exact matching when `inOrder` is true\n* Term-based searches with OR semantics when `inOrder` is false\n* Stopword filtering to ignore common words\n* Multiple text scoring algorithms\n\nConfigure text search behavior at construction time:\n\n[source,java]\n----\nRedisVectorStore vectorStore = RedisVectorStore.builder(jedisPooled, embeddingModel)\n .textScorer(TextScorer.TFIDF) // Text scoring algorithm\n .inOrder(true) // Match terms in order\n .stopwords(Set.of(\"is\", \"a\", \"the\", \"and\")) // Ignore common words\n .metadataFields(MetadataField.text(\"description\")) // Define TEXT fields\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Text Search", "heading_level": 2, "file_order": 86, "section_index": 9, "content_hash": "eb02f86649999610617b1888f2a76b1639872a76478bd5985693c87da5cce35f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:94fc127dbe7387ffc7c2eadfe62ad633b5940df2a5392d6b71b95cb17d62952f", "content": "Several text scoring algorithms are available:\n\n* **BM25**: Modern version of TF-IDF with term saturation (default)\n* **TFIDF**: Classic term frequency-inverse document frequency\n* **BM25STD**: Standardized BM25\n* **DISMAX**: Disjunction max\n* **DOCSCORE**: Document score\n\nScores are normalized to a 0-1 range for consistency with vector similarity scores.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Text Scoring Algorithms", "heading_level": 3, "file_order": 86, "section_index": 10, "content_hash": "94fc127dbe7387ffc7c2eadfe62ad633b5940df2a5392d6b71b95cb17d62952f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:b9ec22e719419b3da3d1fc1399bab5693081d4d508db613bb1bc7f78833f7b94", "content": "The range search returns all documents within a specified radius threshold, rather than a fixed number of nearest neighbors:\n\n[source,java]\n----\nList<Document> rangeResults = vectorStore.searchByRange(\n \"AI and machine learning\", // query\n 0.8, // radius (similarity threshold)\n \"category == 'AI'\" // optional filter expression\n);\n----\n\nYou can also set a default range threshold at construction time:\n\n[source,java]\n----\nRedisVectorStore vectorStore = RedisVectorStore.builder(jedisPooled, embeddingModel)\n .defaultRangeThreshold(0.8) // Set default threshold\n .build();\n\nList<Document> results = vectorStore.searchByRange(\"query\");\n----\n\nRange search is useful when you want to retrieve all relevant documents above a similarity threshold, rather than limiting to a specific count.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Range Search", "heading_level": 2, "file_order": 86, "section_index": 11, "content_hash": "b9ec22e719419b3da3d1fc1399bab5693081d4d508db613bb1bc7f78833f7b94", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:6a0558578df97ce16a0a8280e7eda303d5e94638becc38b9e640b0d3c7482f1f", "content": "Semantic caching is a powerful optimization technique that leverages Redis vector search capabilities to cache and retrieve AI chat responses based on the *semantic similarity* of user queries rather than exact string matching.\nThis enables intelligent response reuse even when users phrase similar questions differently.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Semantic Caching", "heading_level": 2, "file_order": 86, "section_index": 12, "content_hash": "6a0558578df97ce16a0a8280e7eda303d5e94638becc38b9e640b0d3c7482f1f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:86aea8d596c593cc69e7b88b3cf6f401a9474fa84be85722d90e0cee47b195ae", "content": "Traditional caching relies on exact key matches, which fails when users ask semantically equivalent questions with different wording:\n\n* \"What is the capital of France?\"\n* \"Tell me France's capital city\"\n* \"Which city is the capital of France?\"\n\nAll three queries have the same answer, but traditional caching would treat them as different requests, resulting in redundant LLM API calls.\nSemantic caching solves this by comparing the *meaning* of queries using vector embeddings.\n\n**Benefits:**\n\n* **Reduced API costs**: Avoid redundant calls to expensive LLM APIs\n* **Lower latency**: Return cached responses instantly instead of waiting for model inference\n* **Improved scalability**: Handle higher query volumes without proportional API cost increases\n* **Consistent responses**: Return identical answers for semantically similar questions", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Why Semantic Caching?", "heading_level": 3, "file_order": 86, "section_index": 13, "content_hash": "86aea8d596c593cc69e7b88b3cf6f401a9474fa84be85722d90e0cee47b195ae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:de72413c8398c32e52bfc82fa96f8bb4477eacc64f8837dabdce302c3dec7158", "content": "Spring AI provides Spring Boot auto-configuration for the Redis Semantic Cache.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-redis-semantic-cache</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file:\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-redis-semantic-cache'\n}\n----\n\nTIP: The auto-configuration provides a default embedding model optimized for semantic caching (`redis/langcache-embed-v1`).\nYou can override this by providing your own `EmbeddingModel` bean.\n\n[[semantic-cache-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Auto-configuration", "heading_level": 3, "file_order": 86, "section_index": 14, "content_hash": "de72413c8398c32e52bfc82fa96f8bb4477eacc64f8837dabdce302c3dec7158", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:e4f740e5396f562539db465edeba7de8936c88881e422dac46bf02cb78ffba7a", "content": "Properties starting with `spring.ai.vectorstore.redis.semantic-cache.*` configure the semantic cache:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.redis.semantic-cache.enabled`| Enable or disable the semantic cache | `true`\n|`spring.ai.vectorstore.redis.semantic-cache.host`| Redis server host | `localhost`\n|`spring.ai.vectorstore.redis.semantic-cache.port`| Redis server port | `6379`\n|`spring.ai.vectorstore.redis.semantic-cache.similarity-threshold`| Similarity threshold for cache hits (0.0-1.0). Higher values require closer semantic matches. | `0.95`\n|`spring.ai.vectorstore.redis.semantic-cache.index-name`| Name of the Redis search index for cache entries | `semantic-cache-index`\n|`spring.ai.vectorstore.redis.semantic-cache.prefix`| Key prefix for cached entries in Redis | `semantic-cache:`\n|===\n\nExample configuration in `application.yml`:\n\n[source,yaml]\n----\nspring:\n ai:\n vectorstore:\n redis:\n semantic-cache:\n enabled: true\n host: localhost\n port: 6379\n similarity-threshold: 0.85\n index-name: my-app-cache\n prefix: \"my-app:semantic-cache:\"\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Configuration Properties", "heading_level": 3, "file_order": 86, "section_index": 15, "content_hash": "e4f740e5396f562539db465edeba7de8936c88881e422dac46bf02cb78ffba7a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:c21530a13efc5b389183313439f66fa2bc97c6defee937d9018c20bc359900ad", "content": "The `SemanticCacheAdvisor` integrates seamlessly with Spring AI's `ChatClient` advisor pattern.\nIt automatically caches responses and returns cached results for similar queries:\n\n[source,java]\n----\n@Autowired\nprivate SemanticCache semanticCache;\n\n@Autowired\nprivate ChatModel chatModel;\n\npublic void example() {\n // Create the cache advisor\n SemanticCacheAdvisor cacheAdvisor = SemanticCacheAdvisor.builder()\n .cache(semanticCache)\n .build();\n\n // First query - calls the LLM and caches the response\n ChatResponse response1 = ChatClient.builder(chatModel)\n .build()\n .prompt(\"What is the capital of France?\")\n .advisors(cacheAdvisor)\n .call()\n .chatResponse();\n\n // Similar query - returns cached response (no LLM call)\n ChatResponse response2 = ChatClient.builder(chatModel)\n .build()\n .prompt(\"Tell me the capital city of France\")\n .advisors(cacheAdvisor)\n .call()\n .chatResponse();\n\n // response1 and response2 contain the same cached answer\n}\n----\n\nThe advisor automatically:\n\n1. Checks the cache for semantically similar queries before calling the LLM\n2. Returns cached responses when a match is found above the similarity threshold\n3. Caches new responses after successful LLM calls\n4. Supports both synchronous and streaming chat operations", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Using the SemanticCacheAdvisor", "heading_level": 3, "file_order": 86, "section_index": 16, "content_hash": "c21530a13efc5b389183313439f66fa2bc97c6defee937d9018c20bc359900ad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:6ffb385c55557d26fdeae7b3fd4c20f3c461d65e6f8254d8bb33d15578577c28", "content": "You can also interact with the `SemanticCache` directly for fine-grained control:\n\n[source,java]\n----\n@Autowired\nprivate SemanticCache semanticCache;\n\nsemanticCache.set(\"What is the capital of France?\", chatResponse);\n\nsemanticCache.set(\"What's the weather today?\", weatherResponse, Duration.ofHours(1));\n\nOptional<ChatResponse> cached = semanticCache.get(\"Tell me France's capital\");\n\nif (cached.isPresent()) {\n // Use the cached response\n String answer = cached.get().getResult().getOutput().getText();\n}\n\nsemanticCache.clear();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Direct Cache Usage", "heading_level": 3, "file_order": 86, "section_index": 17, "content_hash": "6ffb385c55557d26fdeae7b3fd4c20f3c461d65e6f8254d8bb33d15578577c28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:bb396ebba9cb0d167bfb5e1e53fe956dcbf01f39b27a4d04db9b2817c808c798", "content": "For more control, you can manually configure the semantic cache components:\n\n[source,java]\n----\n@Configuration\npublic class SemanticCacheConfig {\n\n @Bean\n public JedisPooled jedisPooled() {\n return new JedisPooled(\"localhost\", 6379);\n }\n\n @Bean\n public SemanticCache semanticCache(JedisPooled jedisPooled, EmbeddingModel embeddingModel) {\n return DefaultSemanticCache.builder()\n .jedisClient(jedisPooled)\n .embeddingModel(embeddingModel)\n .distanceThreshold(0.3) // Lower = stricter matching\n .indexName(\"my-semantic-cache\")\n .prefix(\"cache:\")\n .build();\n }\n\n @Bean\n public SemanticCacheAdvisor semanticCacheAdvisor(SemanticCache cache) {\n return SemanticCacheAdvisor.builder()\n .cache(cache)\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Manual Configuration", "heading_level": 3, "file_order": 86, "section_index": 18, "content_hash": "bb396ebba9cb0d167bfb5e1e53fe956dcbf01f39b27a4d04db9b2817c808c798", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:f763b40b20550f546af0e0b5a32d1301ce0374aada9ccc1828f6e485a6c2065a", "content": "For multi-tenant applications or when you need separate cache spaces, use different index names to isolate cache entries:\n\n[source,java]\n----\nSemanticCache user1Cache = DefaultSemanticCache.builder()\n .jedisClient(jedisPooled)\n .embeddingModel(embeddingModel)\n .indexName(\"user-1-cache\")\n .build();\n\nSemanticCache user2Cache = DefaultSemanticCache.builder()\n .jedisClient(jedisPooled)\n .embeddingModel(embeddingModel)\n .indexName(\"user-2-cache\")\n .build();\n\nSemanticCacheAdvisor user1Advisor = SemanticCacheAdvisor.builder()\n .cache(user1Cache)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Cache Isolation with Namespaces", "heading_level": 3, "file_order": 86, "section_index": 19, "content_hash": "f763b40b20550f546af0e0b5a32d1301ce0374aada9ccc1828f6e485a6c2065a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:481ad513316c1e8e961dad8e32ab0f92a40d0ace232673e72429caafdb0c46cd", "content": "The `SemanticCacheAdvisor` automatically isolates cached responses based on the system prompt.\nThis ensures that the same user query with different system prompts returns different cached responses, which is essential for applications with multiple AI personas or context-dependent behavior.\n\n[source,java]\n----\nSemanticCacheAdvisor cacheAdvisor = SemanticCacheAdvisor.builder()\n .cache(semanticCache)\n .build();\n\nChatResponse technicalResponse = ChatClient.builder(chatModel)\n .build()\n .prompt()\n .system(\"You are a technical support specialist. Provide detailed technical answers.\")\n .user(\"How do I reset my password?\")\n .advisors(cacheAdvisor)\n .call()\n .chatResponse();\n\nChatResponse serviceResponse = ChatClient.builder(chatModel)\n .build()\n .prompt()\n .system(\"You are a friendly customer service agent. Keep responses brief and helpful.\")\n .user(\"How do I reset my password?\")\n .advisors(cacheAdvisor)\n .call()\n .chatResponse();\n\nChatResponse technicalAgain = ChatClient.builder(chatModel)\n .build()\n .prompt()\n .system(\"You are a technical support specialist. Provide detailed technical answers.\")\n .user(\"How do I reset my password?\")\n .advisors(cacheAdvisor)\n .call()\n .chatResponse();\n----\n\n**How it works:**\n\nThe advisor computes a deterministic hash of the system prompt and uses it as a metadata filter when storing and retrieving cached responses:\n\n* Same user question + same system prompt → cache hit\n* Same user question + different system prompt → cache miss (separate cache entry)\n* Queries without a system prompt share a common cache space", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "System Prompt Isolation", "heading_level": 3, "file_order": 86, "section_index": 20, "content_hash": "481ad513316c1e8e961dad8e32ab0f92a40d0ace232673e72429caafdb0c46cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:9a9936fd61cd7b18f39db8dd8e81151697329dca6bb3e7dd14c53169371402cb", "content": "For advanced use cases, you can use the context-aware cache methods directly:\n\n[source,java]\n----\nString contextHash = \"technical-support-context\";\nsemanticCache.set(\"How do I reset my password?\", response, contextHash);\n\nOptional<ChatResponse> cached = semanticCache.get(\"How do I reset my password?\", contextHash);\n\nOptional<ChatResponse> otherContext = semanticCache.get(\"How do I reset my password?\", \"billing-context\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Context-Aware Cache API", "heading_level": 3, "file_order": 86, "section_index": 21, "content_hash": "9a9936fd61cd7b18f39db8dd8e81151697329dca6bb3e7dd14c53169371402cb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:3067dd59ccfa452ea361a774c9abe84bd9fbcb7d7b67cc7e9bed2791b29ed580", "content": "The similarity threshold determines how closely a query must match a cached entry to be considered a hit.\nThe threshold is expressed as a value between 0.0 and 1.0:\n\n* **Higher threshold (e.g., 0.95)**: Requires very close semantic matches.\nReduces false positives but may miss valid cache hits.\n* **Lower threshold (e.g., 0.70)**: Allows broader semantic matches.\nIncreases cache hit rate but may return less relevant cached responses.\n\n[source,java]\n----\nSemanticCache strictCache = DefaultSemanticCache.builder()\n .jedisClient(jedisPooled)\n .embeddingModel(embeddingModel)\n .distanceThreshold(0.2) // Strict (distance-based, lower = stricter)\n .build();\n\nSemanticCache lenientCache = DefaultSemanticCache.builder()\n .jedisClient(jedisPooled)\n .embeddingModel(embeddingModel)\n .distanceThreshold(0.5) // Lenient\n .build();\n----\n\nTIP: Start with a higher threshold (stricter matching) and gradually lower it based on your application's tolerance for semantic variation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "Tuning the Similarity Threshold", "heading_level": 3, "file_order": 86, "section_index": 22, "content_hash": "3067dd59ccfa452ea361a774c9abe84bd9fbcb7d7b67cc7e9bed2791b29ed580", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:f7c52d7402d0e29902d7c9b0c1e3351512163564285caa27b206ffa74d3598d3", "content": "Cached responses can be configured with a time-to-live (TTL) for automatic expiration.\nThis is essential for time-sensitive data:\n\n[source,java]\n----\nsemanticCache.set(\"What's the weather in New York?\", weatherResponse, Duration.ofHours(1));\n\nsemanticCache.set(\"What is photosynthesis?\", scienceResponse);\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "TTL and Cache Expiration", "heading_level": 3, "file_order": 86, "section_index": 23, "content_hash": "f7c52d7402d0e29902d7c9b0c1e3351512163564285caa27b206ffa74d3598d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:7c2ec76c5d87fa98669c4b26249b540cba38af416830b57eca017992713cc792", "content": "The semantic cache operates using the following flow:\n\n1. **Query embedding**: When a query arrives, it is converted to a vector embedding using the configured `EmbeddingModel`\n\n2. **Vector search**: Redis performs a range-based vector search (`VECTOR_RANGE`) to find cached entries within the similarity threshold\n\n3. **Cache hit**: If a semantically similar query is found, the cached `ChatResponse` is returned immediately\n\n4. **Cache miss**: If no match is found, the query proceeds to the LLM, and the response is cached for future use\n\nThe implementation leverages Redis's efficient vector indexing (HNSW algorithm) for fast similarity searches, even with large cache sizes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/redis.adoc", "title": "Redis", "heading": "How It Works", "heading_level": 3, "file_order": 86, "section_index": 24, "content_hash": "7c2ec76c5d87fa98669c4b26249b540cba38af416830b57eca017992713cc792", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/redis.adoc"}}
{"id": "sha256:0b95733793b3f3ecc6ee1f6a95a3176cf4db036eb14a3553a5f7d74ed777d60b", "content": "This section walks you through setting up `S3VectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://aws.amazon.com/s3/features/vectors/[AWS S3 Vector Store] is a serverless object storage which supports storing and querying vector at scale.\n\nlink:https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors.html[S3 Vector Store API] extends the core features of AWS S3 Bucket and allows you to use S3 as a vector database:\n\n* Store vectors and the associated metadata within hashes or JSON documents\n* Retrieve vectors\n* Perform vector searches", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "S3 Vector Store", "heading_level": 1, "file_order": 87, "section_index": 0, "content_hash": "0b95733793b3f3ecc6ee1f6a95a3176cf4db036eb14a3553a5f7d74ed777d60b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:5b7cb8c6203be1cb1c1449a78b215ff2350ef69cec98064460fa0ef4bbdc83aa", "content": "1. A S3 Vector Store Bucket\n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-buckets-create.html[How to create S3 Vector Bucket]\n\n2. `EmbeddingModel` instance to compute the document embeddings. Several options are available:\n- If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `S3VectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Prerequisites", "heading_level": 2, "file_order": 87, "section_index": 1, "content_hash": "5b7cb8c6203be1cb1c1449a78b215ff2350ef69cec98064460fa0ef4bbdc83aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:878200674c30af87ce698a7b4caab1390bca15c220862ae458611b02f68fd197", "content": "Spring AI provides Spring Boot auto-configuration for the S3 Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-s3</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-s3'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nPlease have a look at the list of <<s3-properties,configuration parameters>> for the vector store to learn about the default values and configuration options.\n\nAdditionally, you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `S3VectorStore` as a vector store in your application.\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList <Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = this.vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----\n\n[[s3-properties]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Auto-configuration", "heading_level": 2, "file_order": 87, "section_index": 2, "content_hash": "878200674c30af87ce698a7b4caab1390bca15c220862ae458611b02f68fd197", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:63ca558e81f1cc19e7da863b1ed44bc8c1b35d6c4aa154b437c03d82f728067b", "content": "To connect to AWS S3 Vector Store and use the `S3VectorStore`, you will need to create a `Bean` of `S3VectorsClient` which needs to be supplied with correct Credentials and Region.\n\nProperties starting with `spring.ai.vectorstore.s3.*` are used to configure the `S3VectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n\n|`spring.ai.vectorstore.s3.index-name` | The name of the index to store the vectors | `spring-ai-index`\n|`spring.ai.vectorstore.s3.vector-bucket-name` | The name of bucket where vectors are located | `my-vector-bucket-on-aws`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Configuration Properties", "heading_level": 3, "file_order": 87, "section_index": 3, "content_hash": "63ca558e81f1cc19e7da863b1ed44bc8c1b35d6c4aa154b437c03d82f728067b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:94f055fd18d75fe17912246f1a68baa5e02a4a8e4e2a0555217574cdf87d0d79", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with S3 Vector Store as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"country\", \"UK\", \"NL\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into link:https://sdk.amazonaws.com/java/api/latest/software/amazon/awssdk/core/document/Document.html[AWS SDK Java V2 Filter Document object].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\ncountry in ['UK', 'NL'] && year >= 2020\n----\n\nis converted into the proprietary S3 Vector Store filter format:\n\n[source,text]\n----\n@country:{UK | NL} @year:[2020 inf]\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 87, "section_index": 4, "content_hash": "94f055fd18d75fe17912246f1a68baa5e02a4a8e4e2a0555217574cdf87d0d79", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:ad721e24c6a97835739a7fde862f1b7bf8c45a1b0d37b7fedbb1f62f169bab3d", "content": "Instead of using the Spring Boot auto-configuration, you can manually configure the S3 Vector Store. For this you need to add the `spring-ai-s3-vector-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-s3-vector-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-s3-vector-store'\n}\n----\n\nThen create the `S3VectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\nVectorStore s3VectorStore(S3VectorsClient s3VectorsClient, EmbeddingModel embeddingModel) {\n S3VectorStore.Builder builder = new S3VectorStore.Builder(s3VectorsClient, embeddingModel); // Required a must\n builder.indexName(properties.getIndexName()) // Required indexName must be specified\n .vectorBucketName(properties.getVectorBucketName()) // Required vectorBucketName must be specified\n .filterExpressionConverter(yourConverter); // Optional if you want to override default filterConverter\n return builder.build();\n\t}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Manual Configuration", "heading_level": 2, "file_order": 87, "section_index": 5, "content_hash": "ad721e24c6a97835739a7fde862f1b7bf8c45a1b0d37b7fedbb1f62f169bab3d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:7a2b2ddf69274a110e7f2da34dee659afffbddd784056ca6f09567a7cca7dfbf", "content": "The S3 Vector Store implementation provides access to the underlying native S3VectorsClient client:\n\n[source,java]\n----\nS3VectorStore vectorStore = context.getBean(S3VectorStore.class);\nOptional<S3VectorsClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n S3VectorsClient s3Client = nativeClient.get();\n // Use the native client for S3-Vector-Store-specific operations\n}\n----\n\nThe native client gives you access to S3-Vector-Store-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc", "title": "S3 Vector Store", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 87, "section_index": 6, "content_hash": "7a2b2ddf69274a110e7f2da34dee659afffbddd784056ca6f09567a7cca7dfbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/s3-vector-store.adoc"}}
{"id": "sha256:136c3b226e7cc6b16c6e7de91fe6e079354a1b4a1db32d863427c371ec744054", "content": "This section walks you through setting up `TypesenseVectorStore` to store document embeddings and perform similarity searches.\n\nlink:https://typesense.org[Typesense] is an open source typo tolerant search engine that is optimized for instant sub-50ms searches while providing an intuitive developer experience. It provides vector search capabilities that allow you to store and query high-dimensional vectors alongside your regular search data.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Typesense", "heading_level": 1, "file_order": 88, "section_index": 0, "content_hash": "136c3b226e7cc6b16c6e7de91fe6e079354a1b4a1db32d863427c371ec744054", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:b6452ad5c37477b313504df8e49926da62f0ea2965c88ec1a20df0e2f2e80f5d", "content": "* A running Typesense instance. The following options are available:\n** link:https://typesense.org/docs/guide/install-typesense.html[Typesense Cloud] (recommended)\n** link:https://hub.docker.com/r/typesense/typesense/[Docker] image _typesense/typesense:latest_\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `TypesenseVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Prerequisites", "heading_level": 2, "file_order": 88, "section_index": 1, "content_hash": "b6452ad5c37477b313504df8e49926da62f0ea2965c88ec1a20df0e2f2e80f5d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:a33aa23fff75aca522a2d7eafcf2ea8d6d68ac29d6f41580515c3967d8aa8a23", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nSpring AI provides Spring Boot auto-configuration for the Typesense Vector Store.\nTo enable it add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-typesense</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-typesense'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#_configuration_properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nThe vector store implementation can initialize the requisite schema for you but you must opt-in by setting `...initialize-schema=true` in the `application.properties` file.\n\nAdditionally you will need a configured `EmbeddingModel` bean. Refer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nNow you can auto-wire the `TypesenseVectorStore` as a vector store in your application:\n\n[source,java]\n----\n@Autowired VectorStore vectorStore;\n\nList<Document> documents = List.of(\n new Document(\"Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!! Spring AI rocks!!\", Map.of(\"meta1\", \"meta1\")),\n new Document(\"The World is Big and Salvation Lurks Around the Corner\"),\n new Document(\"You walk forward facing the past and you turn back toward the future.\", Map.of(\"meta2\", \"meta2\")));\n\nvectorStore.add(documents);\n\nList<Document> results = vectorStore.similaritySearch(SearchRequest.builder().query(\"Spring\").topK(5).build());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Auto-configuration", "heading_level": 2, "file_order": 88, "section_index": 2, "content_hash": "a33aa23fff75aca522a2d7eafcf2ea8d6d68ac29d6f41580515c3967d8aa8a23", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:1286a7e13d958933fec83779c766e9a6a7469e393e02c41e0f5de3902594be27", "content": "To connect to Typesense and use the `TypesenseVectorStore` you need to provide access details for your instance.\nA simple configuration can be provided via Spring Boot's `application.yml`:\n\n[source,yaml]\n----\nspring:\n ai:\n vectorstore:\n typesense:\n initialize-schema: true\n collection-name: vector_store\n embedding-dimension: 1536\n client:\n protocol: http\n host: localhost\n port: 8108\n api-key: xyz\n----\n\nProperties starting with `spring.ai.vectorstore.typesense.*` are used to configure the `TypesenseVectorStore`:\n\n[cols=\"2,5,1\",stripes=even]\n|===\n|Property |Description |Default Value\n\n|`spring.ai.vectorstore.typesense.initialize-schema`\n|Whether to initialize the required schema\n|`false`\n\n|`spring.ai.vectorstore.typesense.collection-name`\n|The name of the collection to store vectors\n|`vector_store`\n\n|`spring.ai.vectorstore.typesense.embedding-dimension`\n|The number of dimensions in the vector\n|`1536`\n\n|`spring.ai.vectorstore.typesense.client.protocol`\n|HTTP Protocol\n|`http`\n\n|`spring.ai.vectorstore.typesense.client.host`\n|Hostname\n|`localhost`\n\n|`spring.ai.vectorstore.typesense.client.port`\n|Port\n|`8108`\n\n|`spring.ai.vectorstore.typesense.client.api-key`\n|API Key\n|`xyz`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Configuration Properties", "heading_level": 3, "file_order": 88, "section_index": 3, "content_hash": "1286a7e13d958933fec83779c766e9a6a7469e393e02c41e0f5de3902594be27", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:a4f812e80e8636ee99a9d08ed69155360d286a050180d665bafd8d536ec32b47", "content": "Instead of using the Spring Boot auto-configuration you can manually configure the Typesense vector store. For this you need to add the `spring-ai-typesense-store` to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-typesense-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-typesense-store'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nCreate a Typesense `Client` bean:\n\n[source,java]\n----\n@Bean\npublic Client typesenseClient() {\n List<Node> nodes = new ArrayList<>();\n nodes.add(new Node(\"http\", \"localhost\", \"8108\"));\n Configuration configuration = new Configuration(nodes, Duration.ofSeconds(5), \"xyz\");\n return new Client(configuration);\n}\n----\n\nThen create the `TypesenseVectorStore` bean using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic VectorStore vectorStore(Client client, EmbeddingModel embeddingModel) {\n return TypesenseVectorStore.builder(client, embeddingModel)\n .collectionName(\"custom_vectors\") // Optional: defaults to \"vector_store\"\n .embeddingDimension(1536) // Optional: defaults to 1536\n .initializeSchema(true) // Optional: defaults to false\n .batchingStrategy(new TokenCountBatchingStrategy()) // Optional: defaults to TokenCountBatchingStrategy\n .build();\n}\n\n@Bean\npublic EmbeddingModel embeddingModel() {\n return new OpenAiEmbeddingModel(new OpenAiApi(System.getenv(\"OPENAI_API_KEY\")));\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Manual Configuration", "heading_level": 2, "file_order": 88, "section_index": 4, "content_hash": "a4f812e80e8636ee99a9d08ed69155360d286a050180d665bafd8d536ec32b47", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:7c22e49100a2231ea4ab5ae61bce0af875bdeed6a8b52b525ef7440f7704b1f7", "content": "You can leverage the generic portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Typesense store as well.\n\nFor example you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"country\", \"UK\", \"NL\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into link:https://typesense.org/docs/0.24.0/api/search.html#filter-parameters[Typesense Search Filters].\n\nFor example this portable filter expression:\n\n[source,sql]\n----\ncountry in ['UK', 'NL'] && year >= 2020\n----\n\nis converted into the proprietary Typesense filter format:\n\n[source,text]\n----\ncountry: ['UK', 'NL'] && year: >=2020\n----\n\n[NOTE]\n====\nIf you are not retrieving the documents in the expected order or the search results are not as expected, check the embedding model you are using.\n\nEmbedding models can have a significant impact on the search results (i.e. make sure if your data is in Spanish to use a Spanish or multilingual embedding model).\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Metadata Filtering", "heading_level": 2, "file_order": 88, "section_index": 5, "content_hash": "7c22e49100a2231ea4ab5ae61bce0af875bdeed6a8b52b525ef7440f7704b1f7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:c4e020e65b5d675ad08871fb2a5db7db08d1af88bfdb1154c52dcf62043e122f", "content": "The Typesense Vector Store implementation provides access to the underlying native Typesense client (`Client`) through the `getNativeClient()` method:\n\n[source,java]\n----\nTypesenseVectorStore vectorStore = context.getBean(TypesenseVectorStore.class);\nOptional<Client> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n Client client = nativeClient.get();\n // Use the native client for Typesense-specific operations\n}\n----\n\nThe native client gives you access to Typesense-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/typesense.adoc", "title": "Typesense", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 88, "section_index": 6, "content_hash": "c4e020e65b5d675ad08871fb2a5db7db08d1af88bfdb1154c52dcf62043e122f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/typesense.adoc"}}
{"id": "sha256:9f840158fd9501eabb0f8d5479fc11bebcc7316710ed729ec63fb4d00cc828e9", "content": "[[understand-vector-databases]]\n\nimage::vector_2d_coordinates.png[width=150, role = \"right\"]\n\nVectors have dimensionality and a direction.\nFor example, the following image depicts a two-dimensional vector stem:[\\vec{a}] in the cartesian coordinate system pictured as an arrow.\n\nThe head of the vector stem:[\\vec{a}] is at the point stem:[(a_1, a_2)].\nThe *x* coordinate value is stem:[a_1] and the *y* coordinate value is stem:[a_2]. The coordinates are also referred to as the components of the vector.\n\n[[vectordbs-similarity]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/understand-vectordbs.adoc", "title": "understand-vectordbs", "heading": "understand-vectordbs", "heading_level": 1, "file_order": 89, "section_index": 0, "content_hash": "9f840158fd9501eabb0f8d5479fc11bebcc7316710ed729ec63fb4d00cc828e9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/understand-vectordbs.adoc"}}
{"id": "sha256:ea6fbdebb3b1cc1fe50089865348e76359e359846ffd587672eea8e148d27d74", "content": "Several mathematical formulas can be used to determine if two vectors are similar.\nOne of the most intuitive to visualize and understand is cosine similarity.\nConsider the following images that show three sets of graphs:\n\nimage::vector_similarity.png[align=\"center\",width=600]\n\nThe vectors stem:[\\vec{A}] and stem:[\\vec{B}] are considered similar, when they are pointing close to each other, as in the first diagram.\nThe vectors are considered unrelated when pointing perpendicular to each other and opposite when they point away from each other.\n\nThe angle between them, stem:[\\theta], is a good measure of their similarity.\nHow can the angle stem:[\\theta] be computed?\n\nimage:pythagorean-triangle.png[align=\"center\",width=100, role=\"left\", trim=\"10 10 10 100\"]\n\nWe are all familiar with the https://en.wikipedia.org/wiki/Pythagorean_theorem#History[Pythagorean Theorem].\n\nWhat about when the angle between *a* and *b* is not 90 degrees?\n\nEnter the https://en.wikipedia.org/wiki/Law_of_cosines[Law of cosines].\n\n.Law of Cosines\n****\nstem:[a^2 + b^2 - 2ab\\cos\\theta = c^2]\n****\n\nThe following image shows this approach as a vector diagram:\nimage:lawofcosines.png[align=\"center\",width=200]\n\nThe magnitude of this vector is defined in terms of its components as:\n\n.Magnitude\n****\nstem:[\\vec{A} * \\vec{A} = ||\\vec{A}||^2 = A_1^2 + A_2^2 ]\n****\n\nThe dot product between two vectors stem:[\\vec{A}] and stem:[\\vec{B}] is defined in terms of its components as:\n\n.Dot Product\n****\nstem:[\\vec{A} * \\vec{B} = A_1B_1 + A_2B_2]\n****\n\nRewriting the Law of Cosines with vector magnitudes and dot products gives the following:\n\n.Law of Cosines in Vector form\n****\nstem:[||\\vec{A}||^2 + ||\\vec{B}||^2 - 2||\\vec{A}||||\\vec{B}||\\cos\\theta = ||\\vec{C}||^2]\n****\n\nReplacing stem:[||\\vec{C}||^2] with stem:[||\\vec{B} - \\vec{A}||^2] gives the following:\n\n.Law of Cosines in Vector form only in terms of stem:[\\vec{A}] and stem:[\\vec{B}]\n\n****\nstem:[||\\vec{A}||^2 + ||\\vec{B}||^2 - 2||\\vec{A}||||\\vec{B}||\\cos\\theta = ||\\vec{B} - \\vec{A}||^2]\n****\n\nhttps://towardsdatascience.com/cosine-similarity-how-does-it-measure-the-similarity-maths-behind-and-usage-in-python-50ad30aad7db[Expanding this out] gives us the formula for https://en.wikipedia.org/wiki/Cosine_similarity[Cosine Similarity].\n\n.Cosine Similarity\n****\nstem:[similarity(vec{A},vec{B}) = \\cos(\\theta) = \\frac{\\vec{A}\\cdot\\vec{B}}{||\\vec{A}\\||\\cdot||\\vec{B}||]\n****\n\nThis formula works for dimensions higher than 2 or 3, though it is hard to visualize. However, https://projector.tensorflow.org/[it can be visualized to some extent].\nIt is common for vectors in AI/ML applications to have hundreds or even thousands of dimensions.\n\nThe similarity function in higher dimensions using the components of the vector is shown below.\nIt expands the two-dimensional definitions of Magnitude and Dot Product given previously to *N* dimensions by using https://en.wikipedia.org/wiki/Summation[Summation mathematical syntax].\n\n.Cosine Similarity with vector components\n****\nstem:[similarity(vec{A},vec{B}) = \\cos(\\theta) = \\frac{ \\sum_{i=1}^{n} {A_i B_i} }{ \\sqrt{\\sum_{i=1}^{n}{A_i^2} \\cdot \\sum_{i=1}^{n}{B_i^2}}]\n****\n\nThis is the key formula used in the simple implementation of a vector store and can be found in the `SimpleVectorStore` implementation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/understand-vectordbs.adoc", "title": "understand-vectordbs", "heading": "Similarity", "heading_level": 2, "file_order": 89, "section_index": 1, "content_hash": "ea6fbdebb3b1cc1fe50089865348e76359e359846ffd587672eea8e148d27d74", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/understand-vectordbs.adoc"}}
{"id": "sha256:2bee1592251c73dd3375bc55449a3f6ab4f534e16561dabdc2e0f730ee72f79b", "content": "This section walks you through setting up the Weaviate VectorStore to store document embeddings and perform similarity searches.\n\nlink:https://weaviate.io/[Weaviate] is an open-source vector database that allows you to store data objects and vector embeddings from your favorite ML-models and scale seamlessly into billions of data objects.\nIt provides tools to store document embeddings, content, and metadata and to search through those embeddings, including metadata filtering.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Weaviate", "heading_level": 1, "file_order": 90, "section_index": 0, "content_hash": "2bee1592251c73dd3375bc55449a3f6ab4f534e16561dabdc2e0f730ee72f79b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:cccd27a958ab543014d35557c37c4d38aa93100956e33d3656c4060467bf97ef", "content": "* A running Weaviate instance. The following options are available:\n** link:https://console.weaviate.cloud/[Weaviate Cloud Service] (requires account creation and API key)\n** link:https://weaviate.io/developers/weaviate/installation/docker[Docker container]\n* If required, an API key for the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] to generate the embeddings stored by the `WeaviateVectorStore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Prerequisites", "heading_level": 2, "file_order": 90, "section_index": 1, "content_hash": "cccd27a958ab543014d35557c37c4d38aa93100956e33d3656c4060467bf97ef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:03386c9cd2fd5988edcf7969f6a19452fd56f08111c95a9a88290ee48e906ff5", "content": "[NOTE]\n====\nThere has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.\nPlease refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.\n====\n\nAdd the Weaviate Vector Store dependency to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-weaviate-store</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-weaviate-store'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Dependencies", "heading_level": 2, "file_order": 90, "section_index": 2, "content_hash": "03386c9cd2fd5988edcf7969f6a19452fd56f08111c95a9a88290ee48e906ff5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:0d0b8ac25c03a4f8ddee999c56f1937ba47c0757a77aec82a8194fcd25e51fd4", "content": "To connect to Weaviate and use the `WeaviateVectorStore`, you need to provide access details for your instance.\nConfiguration can be provided via Spring Boot's _application.properties_:\n\n[source,properties]\n----\nspring.ai.vectorstore.weaviate.host=<host_of_your_weaviate_instance>\nspring.ai.vectorstore.weaviate.scheme=<http_or_https>\nspring.ai.vectorstore.weaviate.api-key=<your_api_key>\n# API key if needed, e.g. OpenAI\nspring.ai.openai.api-key=<api-key>\n----\n\nIf you prefer to use environment variables for sensitive information like API keys, you have multiple options:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Configuration", "heading_level": 2, "file_order": 90, "section_index": 3, "content_hash": "0d0b8ac25c03a4f8ddee999c56f1937ba47c0757a77aec82a8194fcd25e51fd4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:96e1ccd1d5b254449f8c2eb51274f263b501f7695f25b88e09895e3d09a80108", "content": "You can use custom environment variable names and reference them in your application configuration:\n\n[source,yaml]\n----\n# In application.yml\nspring:\n ai:\n vectorstore:\n weaviate:\n host: ${WEAVIATE_HOST}\n scheme: ${WEAVIATE_SCHEME}\n api-key: ${WEAVIATE_API_KEY}\n openai:\n api-key: ${OPENAI_API_KEY}\n----\n\n[source,bash]\n----\n# In your environment or .env file\nexport WEAVIATE_HOST=<host_of_your_weaviate_instance>\nexport WEAVIATE_SCHEME=<http_or_https>\nexport WEAVIATE_API_KEY=<your_api_key>\nexport OPENAI_API_KEY=<api-key>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Option 1: Using Spring Expression Language (SpEL)", "heading_level": 3, "file_order": 90, "section_index": 4, "content_hash": "96e1ccd1d5b254449f8c2eb51274f263b501f7695f25b88e09895e3d09a80108", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:4f1fe507ea74bc47761ef6ba810c56e5c67cb624a8131c53ee898c34c7259273", "content": "Alternatively, you can access environment variables in your Java code:\n\n[source,java]\n----\nString weaviateApiKey = System.getenv(\"WEAVIATE_API_KEY\");\nString openAiApiKey = System.getenv(\"OPENAI_API_KEY\");\n----\n\nNOTE: If you choose to create a shell script to manage your environment variables, be sure to run it prior to starting your application by \"sourcing\" the file, i.e. `source <your_script_name>.sh`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Option 2: Accessing Environment Variables Programmatically", "heading_level": 3, "file_order": 90, "section_index": 5, "content_hash": "4f1fe507ea74bc47761ef6ba810c56e5c67cb624a8131c53ee898c34c7259273", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:ae55c1fd60add774dc33d6d896ff324e7d2bd19a6de95599595ef54996dc802c", "content": "Spring AI provides Spring Boot auto-configuration for the Weaviate Vector Store.\nTo enable it, add the following dependency to your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-vector-store-weaviate</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-vector-store-weaviate'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\nPlease have a look at the list of xref:#_weaviatevectorstore_properties[configuration parameters] for the vector store to learn about the default values and configuration options.\n\nTIP: Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add Maven Central and/or Snapshot Repositories to your build file.\n\nAdditionally, you will need a configured `EmbeddingModel` bean.\nRefer to the xref:api/embeddings.adoc#available-implementations[EmbeddingModel] section for more information.\n\nHere is an example of the required bean:\n\n[source,java]\n----\n@Bean\npublic EmbeddingModel embeddingModel() {\n // Retrieve API key from a secure source or environment variable\n String apiKey = System.getenv(\"OPENAI_API_KEY\");\n\n // Can be any other EmbeddingModel implementation\n return new OpenAiEmbeddingModel(OpenAiApi.builder().apiKey(apiKey).build());\n}\n----\n\nNow you can auto-wire the `WeaviateVectorStore` as a vector store in your application.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Auto-configuration", "heading_level": 2, "file_order": 90, "section_index": 6, "content_hash": "ae55c1fd60add774dc33d6d896ff324e7d2bd19a6de95599595ef54996dc802c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:45ce6ce56b3a616d403362d8435331750e65b6763b0f2cc6a90073a60c7cb91c", "content": "Instead of using Spring Boot auto-configuration, you can manually configure the `WeaviateVectorStore` using the builder pattern:\n\n[source,java]\n----\n@Bean\npublic WeaviateClient weaviateClient() {\n return new WeaviateClient(new Config(\"http\", \"localhost:8080\"));\n}\n\n@Bean\npublic VectorStore vectorStore(WeaviateClient weaviateClient, EmbeddingModel embeddingModel) {\n return WeaviateVectorStore.builder(weaviateClient, embeddingModel)\n .options(options) // Optional: use custom options\n .consistencyLevel(ConsistentLevel.QUORUM) // Optional: defaults to ConsistentLevel.ONE\n .filterMetadataFields(List.of( // Optional: fields that can be used in filters\n MetadataField.text(\"country\"),\n MetadataField.number(\"year\")))\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Manual Configuration", "heading_level": 2, "file_order": 90, "section_index": 7, "content_hash": "45ce6ce56b3a616d403362d8435331750e65b6763b0f2cc6a90073a60c7cb91c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:c5e229a7e765429c8bdb1af3c2ac36851bd60928d38cf9bfd11aa1aa7c0b9c41", "content": "You can leverage the generic, portable xref:api/vectordbs.adoc#metadata-filters[metadata filters] with Weaviate store as well.\n\nFor example, you can use either the text expression language:\n\n[source,java]\n----\nvectorStore.similaritySearch(\n SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(\"country in ['UK', 'NL'] && year >= 2020\").build());\n----\n\nor programmatically using the `Filter.Expression` DSL:\n\n[source,java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\n\nvectorStore.similaritySearch(SearchRequest.builder()\n .query(\"The World\")\n .topK(TOP_K)\n .similarityThreshold(SIMILARITY_THRESHOLD)\n .filterExpression(b.and(\n b.in(\"country\", \"UK\", \"NL\"),\n b.gte(\"year\", 2020)).build()).build());\n----\n\nNOTE: Those (portable) filter expressions get automatically converted into the proprietary Weaviate link:https://weaviate.io/developers/weaviate/api/graphql/filters[where filters].\n\nFor example, this portable filter expression:\n\n[source,sql]\n----\ncountry in ['UK', 'NL'] && year >= 2020\n----\n\nis converted into the proprietary Weaviate GraphQL filter format:\n\n[source,graphql]\n----\noperator: And\noperands:\n [{\n operator: Or\n operands:\n [{\n path: [\"meta_country\"]\n operator: Equal\n valueText: \"UK\"\n },\n {\n path: [\"meta_country\"]\n operator: Equal\n valueText: \"NL\"\n }]\n },\n {\n path: [\"meta_year\"]\n operator: GreaterThanEqual\n valueNumber: 2020\n }]\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Metadata filtering", "heading_level": 2, "file_order": 90, "section_index": 8, "content_hash": "c5e229a7e765429c8bdb1af3c2ac36851bd60928d38cf9bfd11aa1aa7c0b9c41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:1c153dfaf4e965f6a696fb9937b1a2d04c4816b3675e69e1632ed08290d65aad", "content": "To quickly get started with a local Weaviate instance, you can run it in Docker:\n\n[source,bash]\n----\ndocker run -it --rm --name weaviate \\\n -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \\\n -e PERSISTENCE_DATA_PATH=/var/lib/weaviate \\\n -e QUERY_DEFAULTS_LIMIT=25 \\\n -e DEFAULT_VECTORIZER_MODULE=none \\\n -e CLUSTER_HOSTNAME=node1 \\\n -p 8080:8080 \\\n semitechnologies/weaviate:1.22.4\n----\n\nThis starts a Weaviate instance accessible at http://localhost:8080.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Run Weaviate in Docker", "heading_level": 2, "file_order": 90, "section_index": 9, "content_hash": "1c153dfaf4e965f6a696fb9937b1a2d04c4816b3675e69e1632ed08290d65aad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:53793a622169c2eeb1a9f35a2ddff22380c5138c68aa1df0c4d4a7c393a9fa0e", "content": "You can use the following properties in your Spring Boot configuration to customize the Weaviate vector store.\n\n[stripes=even]\n|===\n|Property|Description|Default value\n\n|`spring.ai.vectorstore.weaviate.host`|The host of the Weaviate server|localhost:8080\n|`spring.ai.vectorstore.weaviate.scheme`|Connection schema|http\n|`spring.ai.vectorstore.weaviate.api-key`|The API key for authentication|\n|`spring.ai.vectorstore.weaviate.object-class`|The class name for storing documents. |SpringAiWeaviate\n|`spring.ai.vectorstore.weaviate.content-field-name`|The field name for content|content\n|`spring.ai.vectorstore.weaviate.meta-field-prefix`|The field prefix for metadata|meta_\n|`spring.ai.vectorstore.weaviate.consistency-level`|Desired tradeoff between consistency and speed|ConsistentLevel.ONE\n|`spring.ai.vectorstore.weaviate.filter-field`|Configures metadata fields that can be used in filters. Format: spring.ai.vectorstore.weaviate.filter-field.<field-name>=<field-type>|\n|===\n\nTIP: Object class names should start with an uppercase letter, and field names should start with a lowercase letter.\nSee link:https://weaviate.io/developers/weaviate/concepts/data#data-object-concepts[data-object-concepts]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "WeaviateVectorStore properties", "heading_level": 2, "file_order": 90, "section_index": 10, "content_hash": "53793a622169c2eeb1a9f35a2ddff22380c5138c68aa1df0c4d4a7c393a9fa0e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:6c0d7e0fd493311455ccc84980c6791bc04d32d69aac1ae23bfea2da0f958379", "content": "The Weaviate Vector Store implementation provides access to the underlying native Weaviate client (`WeaviateClient`) through the `getNativeClient()` method:\n\n[source,java]\n----\nWeaviateVectorStore vectorStore = context.getBean(WeaviateVectorStore.class);\nOptional<WeaviateClient> nativeClient = vectorStore.getNativeClient();\n\nif (nativeClient.isPresent()) {\n WeaviateClient client = nativeClient.get();\n // Use the native client for Weaviate-specific operations\n}\n----\n\nThe native client gives you access to Weaviate-specific features and operations that might not be exposed through the `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc", "title": "Weaviate", "heading": "Accessing the Native Client", "heading_level": 2, "file_order": 90, "section_index": 11, "content_hash": "6c0d7e0fd493311455ccc84980c6791bc04d32d69aac1ae23bfea2da0f958379", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs/weaviate.adoc"}}
{"id": "sha256:422488a696b7137953872850df11f728c9565928e4c54a8216a7ac48ea97fdcc", "content": "[[Advisors-Recursive]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "advisors-recursive", "heading_level": 1, "file_order": 91, "section_index": 0, "content_hash": "422488a696b7137953872850df11f728c9565928e4c54a8216a7ac48ea97fdcc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:8d64b5e18bb09c4e4db0aa06792f53654af70ed2e14bde6522330d6b9613db41", "content": "image:advisors-recursive.png[Advisors Recursive, width=230, float=\"right\", align=\"center\", alt=\"Advisors Recursive\"]\nRecursive advisors are a special type of advisor that can loop through the downstream advisor chain multiple times.\nThis pattern is useful when you need to repeatedly call the LLM until a certain condition is met, such as:\n\n* Executing tool calls in a loop until no more tools need to be called\n* Validating structured output and retrying if validation fails\n* Implementing Evaluation logic with modifications to the request\n* Implementing retry logic with modifications to the request\n\nThe `CallAdvisorChain.copy(CallAdvisor after)` method is the key utility that enables recursive advisor patterns.\nIt creates a new advisor chain that contains only the advisors that come after the specified advisor in the original chain\nand allows the recursive advisor to call this sub-chain as needed.\nThis approach ensures that:\n\n* The recursive advisor can loop through the remaining advisors in the chain\n* Other advisors in the chain can observe and intercept each iteration\n* The advisor chain maintains proper ordering and observability\n* The recursive advisor doesn't re-execute advisors that came before it", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "What is a Recursive Advisor?", "heading_level": 2, "file_order": 91, "section_index": 1, "content_hash": "8d64b5e18bb09c4e4db0aa06792f53654af70ed2e14bde6522330d6b9613db41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:7e36ce042da9998f0e3438dcccc2af760dc1697be9ab1264d675490ba4d1c9da", "content": "Spring AI provides two built-in recursive advisors that demonstrate this pattern:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "Built-in Recursive Advisors", "heading_level": 2, "file_order": 91, "section_index": 2, "content_hash": "7e36ce042da9998f0e3438dcccc2af760dc1697be9ab1264d675490ba4d1c9da", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:75dcb895ff84f7617c57e90c8ea6aef379fd385e78086b674b3e7b6168f354dd", "content": "The `ToolCallAdvisor` implements the tool calling loop as part of the advisor chain, rather than relying on the model's internal tool execution. This enables other advisors in the chain to intercept and observe the tool calling process.\n\nKey features:\n\n* Disables the model's internal tool execution by setting `setInternalToolExecutionEnabled(false)`\n* Loops through the advisor chain until no more tool calls are present\n* Supports \"return direct\" functionality - when a tool execution has `returnDirect=true`, it interrupts the tool calling loop and returns the tool execution result directly to the client application instead of sending it back to the LLM\n* Uses `callAdvisorChain.copy(this)` to create a sub-chain for recursive calls\n* Includes null safety checks to handle cases where the chat response might be null\n* Supports configurable conversation history management via `conversationHistoryEnabled`\n\nExample usage:\n\n[source,java]\n----\nvar toolCallAdvisor = ToolCallAdvisor.builder()\n .toolCallingManager(toolCallingManager)\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 300)\n .build();\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(toolCallAdvisor)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "ToolCallAdvisor", "heading_level": 3, "file_order": 91, "section_index": 3, "content_hash": "75dcb895ff84f7617c57e90c8ea6aef379fd385e78086b674b3e7b6168f354dd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:9b22b389055d4b60aaaf01fd78d27fde2bb55b166fa27f8b2366dfb61bfbdbae", "content": "The `ToolCallAdvisor` includes a `conversationHistoryEnabled` configuration option that controls how conversation history is managed during tool calling iterations.\n\nBy default (`conversationHistoryEnabled=true`), the advisor maintains the full conversation history internally during tool call iterations. This means each subsequent LLM call in the tool calling loop includes all previous messages (user message, assistant responses, tool responses).\n\nUse the `.disableMemory()` method to disable internal conversation history management. When disabled, only the last tool response message is passed to the next iteration. This is useful when:\n\n* You have a Chat Memory Advisor registered next in the chain that already manages conversation history\n* You want to reduce token usage by not duplicating history management\n* You're integrating with external conversation memory systems\n\nExample with conversation history disabled:\n\n[source,java]\n----\nvar toolCallAdvisor = ToolCallAdvisor.builder()\n .toolCallingManager(toolCallingManager)\n .disableMemory() // Disable internal history - let ChatMemory handle it\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 300)\n .build();\n\nvar chatMemoryAdvisor = MessageChatMemoryAdvisor.builder(chatMemory)\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 200) // Positioned before ToolCallAdvisor\n .build();\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(chatMemoryAdvisor, toolCallAdvisor)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "Conversation History Management", "heading_level": 4, "file_order": 91, "section_index": 4, "content_hash": "9b22b389055d4b60aaaf01fd78d27fde2bb55b166fa27f8b2366dfb61bfbdbae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:931a626c8993ace4341179c4a64a2fc6f2f220f0c22f7d9ab015c92cd6fc1270", "content": "The \"return direct\" feature allows tools to bypass the LLM and return their results directly to the client application. This is useful when:\n\n* The tool's output is the final answer and doesn't need LLM processing\n* You want to reduce latency by avoiding an additional LLM call\n* The tool result should be returned as-is without interpretation\n\nWhen a tool execution has `returnDirect=true`, the `ToolCallAdvisor` will:\n\n1. Execute the tool call as normal\n2. Detect the `returnDirect` flag in the `ToolExecutionResult`\n3. Break out of the tool calling loop\n4. Return the tool execution result directly to the client application as a `ChatResponse` with the tool's output as the generation content", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "Return Direct Functionality", "heading_level": 4, "file_order": 91, "section_index": 5, "content_hash": "931a626c8993ace4341179c4a64a2fc6f2f220f0c22f7d9ab015c92cd6fc1270", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:d8b67b77a7f623e6328a97df35202740efd752143b20b2d46e0c540894228db0", "content": "The `StructuredOutputValidationAdvisor` validates the structured JSON output against a generated JSON schema and retries the call if validation fails, up to a specified number of attempts.\n\nKey features:\n\n* Automatically generates a JSON schema from the expected output type\n* Validates the LLM response against the schema\n* Retries the call if validation fails, up to a configurable number of attempts\n* Augments the prompt with validation error messages on retry attempts to help the LLM correct its output\n* Uses `callAdvisorChain.copy(this)` to create a sub-chain for recursive calls\n* Optionally supports a custom `ObjectMapper` for JSON processing\n\nExample usage:\n\n[source,java]\n----\nvar validationAdvisor = StructuredOutputValidationAdvisor.builder()\n .outputType(MyResponseType.class)\n .maxRepeatAttempts(3)\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 1000)\n .build();\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(validationAdvisor)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors-recursive.adoc", "title": "advisors-recursive", "heading": "StructuredOutputValidationAdvisor", "heading_level": 3, "file_order": 91, "section_index": 6, "content_hash": "d8b67b77a7f623e6328a97df35202740efd752143b20b2d46e0c540894228db0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors-recursive.adoc"}}
{"id": "sha256:ed38af249666662db7e5fd9cff3d218e06c0b75da890e2fd4361ae1beea36c6b", "content": "[[Advisors]]\n\nThe Spring AI Advisors API provides a flexible and powerful way to intercept, modify, and enhance AI-driven interactions in your Spring applications.\nBy leveraging the Advisors API, developers can create more sophisticated, reusable, and maintainable AI components.\n\nThe key benefits include encapsulating recurring Generative AI patterns, transforming data sent to and from Large Language Models (LLMs), and providing portability across various models and use cases.\n\nYou can configure existing advisors using the xref:api/chatclient.adoc#_advisor_configuration_in_chatclient[ChatClient API] as shown in the following example:\n\n[source,java]\n----\n\nChatMemory chatMemory = ... // Initialize your chat memory store\nVectorStore vectorStore = ... // Initialize your vector store\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(\n MessageChatMemoryAdvisor.builder(chatMemory).build(), // chat-memory advisor\n QuestionAnswerAdvisor.builder(vectorStore).build() // RAG advisor\n )\n .build();\n\nvar conversationId = \"678\";\n\nString response = this.chatClient.prompt()\n // Set advisor parameters at runtime\n .advisors(advisor -> advisor.param(ChatMemory.CONVERSATION_ID, conversationId))\n .user(userText)\n .call()\n\t.content();\n----\n\nIt is recommend to register the advisors at build time using builder's `defaultAdvisors()` method.\n\nAdvisors also participate in the Observability stack, so you can view metrics and traces related to their execution.\n\n- xref:ROOT:api/retrieval-augmented-generation.adoc#_questionansweradvisor[Learn about Question Answer Advisor]\n- xref:ROOT:api/chat-memory.adoc#_memory_in_chat_client[Learn about Chat Memory Advisor]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "advisors", "heading_level": 1, "file_order": 92, "section_index": 0, "content_hash": "ed38af249666662db7e5fd9cff3d218e06c0b75da890e2fd4361ae1beea36c6b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:c4664de034b0101fab4c4d76c3a9dd63d2dcaf2f30359f4be6912bb9fc798020", "content": "The API consists of `CallAdvisor` and `CallAdvisorChain` for non-streaming scenarios, and `StreamAdvisor` and `StreamAdvisorChain` for streaming scenarios.\nIt also includes `ChatClientRequest` to represent the unsealed Prompt request, `ChatClientResponse` for the Chat Completion response. Both hold an `advise-context` to share state across the advisor chain.\n\nimage::advisors-api-classes.jpg[Advisors API Classes, width=600, align=\"center\"]\n\nThe `adviseCall()` and the `adviseStream()` are the key advisor methods, typically performing actions such as examining the unsealed Prompt data, customizing and augmenting the Prompt data, invoking the next entity in the advisor chain, optionally blocking the request, examining the chat completion response, and throwing exceptions to indicate processing errors.\n\nIn addition the `getOrder()` method determines advisor order in the chain, while `getName()` provides a unique advisor name.\n\nThe Advisor Chain, created by the Spring AI framework, allows sequential invocation of multiple advisors ordered by their `getOrder()` values.\nThe lower values are executed first.\nThe last advisor, added automatically, sends the request to the LLM.\n\nFollowing flow diagram illustrates the interaction between the advisor chain and the Chat Model:\n\nimage::advisors-flow.jpg[Advisors API Flow, width=400, align=\"center\"]\n\n. The Spring AI framework creates an `ChatClientRequest` from user's `Prompt` along with an empty advisor `context` object.\n. Each advisor in the chain processes the request, potentially modifying it. Alternatively, it can choose to block the request by not making the call to invoke the next entity. In the latter case, the advisor is responsible for filling out the response.\n. The final advisor, provided by the framework, sends the request to the `Chat Model`.\n. The Chat Model's response is then passed back through the advisor chain and converted into `ChatClientResponse`. Later includes the shared advisor `context` instance.\n. Each advisor can process or modify the response.\n. The final `ChatClientResponse` is returned to the client by extracting the `ChatCompletion`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Core Components", "heading_level": 2, "file_order": 92, "section_index": 1, "content_hash": "c4664de034b0101fab4c4d76c3a9dd63d2dcaf2f30359f4be6912bb9fc798020", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:23afae0df368fa9a4e4abaa78dd3ca15f36f19731d4ea1ee6c3e0ab722064551", "content": "The execution order of advisors in the chain is determined by the `getOrder()` method. Key points to understand:\n\n* Advisors with lower order values are executed first.\n* The advisor chain operates as a stack:\n** The first advisor in the chain is the first to process the request.\n** It is also the last to process the response.\n* To control execution order:\n** Set the order close to `Ordered.HIGHEST_PRECEDENCE` to ensure an advisor is executed first in the chain (first for request processing, last for response processing).\n** Set the order close to `Ordered.LOWEST_PRECEDENCE` to ensure an advisor is executed last in the chain (last for request processing, first for response processing).\n* Higher values are interpreted as lower priority.\n* If multiple advisors have the same order value, their execution order is not guaranteed.\n\n[NOTE]\n====\nThe seeming contradiction between order and execution sequence is due to the stack-like nature of the advisor chain:\n\n- An advisor with the highest precedence (lowest order value) is added to the top of the stack.\n- It will be the first to process the request as the stack unwinds.\n- It will be the last to process the response as the stack rewinds.\n\n====\n\nAs a reminder, here are the semantics of the Spring `Ordered` interface:\n\n[source,java]\n----\npublic interface Ordered {\n\n /**\n * Constant for the highest precedence value.\n * @see java.lang.Integer#MIN_VALUE\n */\n int HIGHEST_PRECEDENCE = Integer.MIN_VALUE;\n\n /**\n * Constant for the lowest precedence value.\n * @see java.lang.Integer#MAX_VALUE\n */\n int LOWEST_PRECEDENCE = Integer.MAX_VALUE;\n\n /**\n * Get the order value of this object.\n * <p>Higher values are interpreted as lower priority. As a consequence,\n * the object with the lowest value has the highest priority (somewhat\n * analogous to Servlet {@code load-on-startup} values).\n * <p>Same order values will result in arbitrary sort positions for the\n * affected objects.\n * @return the order value\n * @see #HIGHEST_PRECEDENCE\n * @see #LOWEST_PRECEDENCE\n */\n int getOrder();\n}\n----\n\n[TIP]\n====\nFor use cases that need to be first in the chain on both the input and output sides:\n\n1. Use separate advisors for each side.\n2. Configure them with different order values.\n3. Use the advisor context to share state between them.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Advisor Order", "heading_level": 3, "file_order": 92, "section_index": 2, "content_hash": "23afae0df368fa9a4e4abaa78dd3ca15f36f19731d4ea1ee6c3e0ab722064551", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:a801e9cd65fcaefe3ae3d619ed8ce0da3f5c32e5ce5d86f1aaa92672142691dc", "content": "The main Advisor interfaces are located in the package `org.springframework.ai.chat.client.advisor.api`. Here are the key interfaces you'll encounter when creating your own advisor:\n\n```java\npublic interface Advisor extends Ordered {\n\n\tString getName();\n\n}\n```\n\nThe two sub-interfaces for synchronous and reactive Advisors are\n\n```java\npublic interface CallAdvisor extends Advisor {\n\n\tChatClientResponse adviseCall(\n ChatClientRequest chatClientRequest, CallAdvisorChain callAdvisorChain);\n\n}\n\n```\n\nand\n\n```java\npublic interface StreamAdvisor extends Advisor {\n\n\tFlux<ChatClientResponse> adviseStream(\n ChatClientRequest chatClientRequest, StreamAdvisorChain streamAdvisorChain);\n\n}\n```\n\nTo continue the chain of Advice, use `CallAdvisorChain` and `StreamAdvisorChain` in your Advice implementation:\n\nThe interfaces are\n\n```java\npublic interface CallAdvisorChain extends AdvisorChain {\n\n\t/**\n * Invokes the next {@link CallAdvisor} in the {@link CallAdvisorChain} with the given\n * request.\n */\n\tChatClientResponse nextCall(ChatClientRequest chatClientRequest);\n\n\t/**\n * Returns the list of all the {@link CallAdvisor} instances included in this chain at\n * the time of its creation.\n */\n\tList<CallAdvisor> getCallAdvisors();\n\n}\n```\n\nand\n\n```java\npublic interface StreamAdvisorChain extends AdvisorChain {\n\n\t/**\n * Invokes the next {@link StreamAdvisor} in the {@link StreamAdvisorChain} with the\n * given request.\n */\n\tFlux<ChatClientResponse> nextStream(ChatClientRequest chatClientRequest);\n\n\t/**\n * Returns the list of all the {@link StreamAdvisor} instances included in this chain\n * at the time of its creation.\n */\n\tList<StreamAdvisor> getStreamAdvisors();\n\n}\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "API Overview", "heading_level": 2, "file_order": 92, "section_index": 3, "content_hash": "a801e9cd65fcaefe3ae3d619ed8ce0da3f5c32e5ce5d86f1aaa92672142691dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:1705cba3e31bb9d25b60846b221e2857eaeeeefe9b9e85e256c696f3b395ae42", "content": "To create an advisor, implement either `CallAdvisor` or `StreamAdvisor` (or both). The key method to implement is `nextCall()` for non-streaming or `nextStream()` for streaming advisors.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Implementing an Advisor", "heading_level": 2, "file_order": 92, "section_index": 4, "content_hash": "1705cba3e31bb9d25b60846b221e2857eaeeeefe9b9e85e256c696f3b395ae42", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:ff17d7f8c9e4e5ccdf08f56359aae11be35e9515e6171c11e5296950e281c833", "content": "We will provide few hands-on examples to illustrate how to implement advisors for observing and augmenting use-cases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Examples", "heading_level": 3, "file_order": 92, "section_index": 5, "content_hash": "ff17d7f8c9e4e5ccdf08f56359aae11be35e9515e6171c11e5296950e281c833", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:dac165e06a6d41f230db2c71ce06970a9ed6ea7095de4a604b2df52dbcf4e1bf", "content": "We can implement a simple logging advisor that logs the `ChatClientRequest` before and the `ChatClientResponse` after the call to the next advisor in the chain.\nNote that the advisor only observes the request and response and does not modify them.\nThis implementation support both non-streaming and streaming scenarios.\n\n[source,java]\n----\npublic class SimpleLoggerAdvisor implements CallAdvisor, StreamAdvisor {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(SimpleLoggerAdvisor.class);\n\n\t@Override\n\tpublic String getName() { // <1>\n return this.getClass().getSimpleName();\n\t}\n\n\t@Override\n\tpublic int getOrder() { // <2>\n return 0;\n\t}\n\n\t@Override\n\tpublic ChatClientResponse adviseCall(ChatClientRequest chatClientRequest, CallAdvisorChain callAdvisorChain) {\n logRequest(chatClientRequest);\n\n ChatClientResponse chatClientResponse = callAdvisorChain.nextCall(chatClientRequest);\n\n logResponse(chatClientResponse);\n\n return chatClientResponse;\n\t}\n\n\t@Override\n\tpublic Flux<ChatClientResponse> adviseStream(ChatClientRequest chatClientRequest,\n StreamAdvisorChain streamAdvisorChain) {\n logRequest(chatClientRequest);\n\n Flux<ChatClientResponse> chatClientResponses = streamAdvisorChain.nextStream(chatClientRequest);\n\n return new ChatClientMessageAggregator().aggregateChatClientResponse(chatClientResponses, this::logResponse); // <3>\n\t}\n\n\tprivate void logRequest(ChatClientRequest request) {\n logger.debug(\"request: {}\", request);\n\t}\n\n\tprivate void logResponse(ChatClientResponse chatClientResponse) {\n logger.debug(\"response: {}\", chatClientResponse);\n\t}\n\n}\n----\n<1> Provides a unique name for the advisor.\n<2> You can control the order of execution by setting the order value. Lower values execute first.\n<3> The `MessageAggregator` is a utility class that aggregates the Flux responses into a single ChatClientResponse.\nThis can be useful for logging or other processing that observe the entire response rather than individual items in the stream.\nNote that you can not alter the response in the `MessageAggregator` as it is a read-only operation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Logging Advisor", "heading_level": 4, "file_order": 92, "section_index": 6, "content_hash": "dac165e06a6d41f230db2c71ce06970a9ed6ea7095de4a604b2df52dbcf4e1bf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:195074df00d7a86811249f48b5842792021eb108521a9434ba5d8e07e2f77c8f", "content": "The \"https://arxiv.org/pdf/2309.06275[Re-Reading Improves Reasoning in Large Language Models]\" article introduces a technique called Re-Reading (Re2) that improves the reasoning capabilities of Large Language Models.\nThe Re2 technique requires augmenting the input prompt like this:\n\n----\n{Input_Query}\nRead the question again: {Input_Query}\n----\n\nImplementing an advisor that applies the Re2 technique to the user's input query can be done like this:\n\n[source,java]\n----\n\npublic class ReReadingAdvisor implements BaseAdvisor {\n\n\tprivate static final String DEFAULT_RE2_ADVISE_TEMPLATE = \"\"\"\n {re2_input_query}\n Read the question again: {re2_input_query}\n \"\"\";\n\n\tprivate final String re2AdviseTemplate;\n\n\tprivate int order = 0;\n\n\tpublic ReReadingAdvisor() {\n this(DEFAULT_RE2_ADVISE_TEMPLATE);\n\t}\n\n\tpublic ReReadingAdvisor(String re2AdviseTemplate) {\n this.re2AdviseTemplate = re2AdviseTemplate;\n\t}\n\n\t@Override\n\tpublic ChatClientRequest before(ChatClientRequest chatClientRequest, AdvisorChain advisorChain) { // <1>\n String augmentedUserText = PromptTemplate.builder()\n .template(this.re2AdviseTemplate)\n .variables(Map.of(\"re2_input_query\", chatClientRequest.prompt().getUserMessage().getText()))\n .build()\n .render();\n\n return chatClientRequest.mutate()\n .prompt(chatClientRequest.prompt().augmentUserMessage(augmentedUserText))\n .build();\n\t}\n\n\t@Override\n\tpublic ChatClientResponse after(ChatClientResponse chatClientResponse, AdvisorChain advisorChain) {\n return chatClientResponse;\n\t}\n\n\t@Override\n\tpublic int getOrder() { // <2>\n return this.order;\n\t}\n\n\tpublic ReReadingAdvisor withOrder(int order) {\n this.order = order;\n return this;\n\t}\n\n}\n----\n<1> The `before` method augments the user's input query applying the Re-Reading technique.\n<2> You can control the order of execution by setting the order value. Lower values execute first.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Re-Reading (Re2) Advisor", "heading_level": 4, "file_order": 92, "section_index": 7, "content_hash": "195074df00d7a86811249f48b5842792021eb108521a9434ba5d8e07e2f77c8f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:6f860816d2ddbceedc6e31f163fc1a60ad9856d6c35d36bb9e8328f18cffd8d0", "content": "Spring AI framework provides several built-in advisors to enhance your AI interactions. Here's an overview of the available advisors:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Spring AI Built-in Advisors", "heading_level": 4, "file_order": 92, "section_index": 8, "content_hash": "6f860816d2ddbceedc6e31f163fc1a60ad9856d6c35d36bb9e8328f18cffd8d0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:665daff5d404e79c0488293c0eb58fae6c55203b3cfbad8f7a99f916980c36f4", "content": "These advisors manage conversation history in a chat memory store:\n\n* `MessageChatMemoryAdvisor`\n+\nRetrieves memory and adds it as a collection of messages to the prompt. This approach maintains the structure of the conversation history. Note, not all AI Models support this approach.\n\n* `PromptChatMemoryAdvisor`\n+\nRetrieves memory and incorporates it into the prompt's system text.\n\n* `VectorStoreChatMemoryAdvisor`\n+\nRetrieves memory from a VectorStore and adds it into the prompt's system text. This advisor is useful for efficiently searching and retrieving relevant information from large datasets.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Chat Memory Advisors", "heading_level": 5, "file_order": 92, "section_index": 9, "content_hash": "665daff5d404e79c0488293c0eb58fae6c55203b3cfbad8f7a99f916980c36f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:2d9daa306c61376cfc41b2df75ea35d9444318ddc800f120422230ae8a995042", "content": "* `QuestionAnswerAdvisor`\n+\nThis advisor uses a vector store to provide question-answering capabilities, implementing the Naive RAG (Retrieval-Augmented Generation) pattern.\n\n* `RetrievalAugmentationAdvisor`\n+\n Advisor that implements common Retrieval Augmented Generation (RAG) flows using the building blocks defined in the `org.springframework.ai.rag` package and following the Modular RAG Architecture.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Question Answering Advisor", "heading_level": 5, "file_order": 92, "section_index": 10, "content_hash": "2d9daa306c61376cfc41b2df75ea35d9444318ddc800f120422230ae8a995042", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:39548c9b1f91d145d65107103e840e7a2c53d3ff0406a7c3308a6df8cbc01b2e", "content": "* `ReReadingAdvisor`\n+\nImplements a re-reading strategy for LLM reasoning, dubbed RE2, to enhance understanding in the input phase.\nBased on the article: [Re-Reading Improves Reasoning in LLMs](https://arxiv.org/pdf/2309.06275).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Reasoning Advisor", "heading_level": 5, "file_order": 92, "section_index": 11, "content_hash": "39548c9b1f91d145d65107103e840e7a2c53d3ff0406a7c3308a6df8cbc01b2e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:d9e06556064bcbfe9976a7cb9a9e51b9e6dd85541649c292408de3919ca2fa0b", "content": "* `SafeGuardAdvisor`\n+\nA simple advisor designed to prevent the model from generating harmful or inappropriate content.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Content Safety Advisor", "heading_level": 5, "file_order": 92, "section_index": 12, "content_hash": "d9e06556064bcbfe9976a7cb9a9e51b9e6dd85541649c292408de3919ca2fa0b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:83b77e5ee048fe3498da8aa59c5ab5fccd190c2e2793f3a9ea052da2088dcdb3", "content": "image::advisors-non-stream-vs-stream.jpg[Advisors Streaming vs Non-Streaming Flow, width=800, align=\"center\"]\n\n* Non-streaming advisors work with complete requests and responses.\n* Streaming advisors handle requests and responses as continuous streams, using reactive programming concepts (e.g., Flux for responses).\n\n[source,java]\n----\n@Override\npublic Flux<ChatClientResponse> adviseStream(ChatClientRequest chatClientRequest, StreamAdvisorChain chain) {\n\n return Mono.just(chatClientRequest)\n .publishOn(Schedulers.boundedElastic())\n .map(request -> {\n // This can be executed by blocking and non-blocking Threads.\n // Advisor before next section\n })\n .flatMapMany(request -> chain.nextStream(request))\n .map(response -> {\n // Advisor after next section\n });\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Streaming vs Non-Streaming", "heading_level": 3, "file_order": 92, "section_index": 13, "content_hash": "83b77e5ee048fe3498da8aa59c5ab5fccd190c2e2793f3a9ea052da2088dcdb3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:9a9c831ee77e325abdd917fc6041cf050ddbe666f4a9f122e553338be94a163a", "content": ". Keep advisors focused on specific tasks for better modularity.\n. Use the `adviseContext` to share state between advisors when necessary.\n. Implement both streaming and non-streaming versions of your advisor for maximum flexibility.\n. Carefully consider the order of advisors in your chain to ensure proper data flow.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Best Practices", "heading_level": 3, "file_order": 92, "section_index": 14, "content_hash": "9a9c831ee77e325abdd917fc6041cf050ddbe666f4a9f122e553338be94a163a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:88f0a89b5d036221c6c158c79328bc9caf4d3e2f5e9d2bb88bd8f637989ef5bc", "content": "* In 1.0 M2, there were separate `RequestAdvisor` and `ResponseAdvisor` interfaces.\n** `RequestAdvisor` was invoked before the `ChatModel.call` and `ChatModel.stream` methods.\n** `ResponseAdvisor` was called after these methods.\n* In 1.0 M3, these interfaces have been replaced with:\n** `CallAroundAdvisor`\n** `StreamAroundAdvisor`\n* The `StreamResponseMode`, previously part of `ResponseAdvisor`, has been removed.\n* In 1.0.0 these interfaces have been replaced:\n** `CallAroundAdvisor` -> `CallAdvisor`, `StreamAroundAdvisor` -> `StreamAdvisor`, `CallAroundAdvisorChain` -> `CallAdvisorChain` and `StreamAroundAdvisorChain` -> `StreamAdvisorChain`.\n** `AdvisedRequest` -> `ChatClientRequest` and `AdivsedResponse` -> `ChatClientResponse`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Advisor Interfaces", "heading_level": 3, "file_order": 92, "section_index": 15, "content_hash": "88f0a89b5d036221c6c158c79328bc9caf4d3e2f5e9d2bb88bd8f637989ef5bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:2bbf8c0957804d510bb4d88b4dedc0e69a504c5d275d474c36f071787b7bcf03", "content": "* In 1.0 M2:\n** The context map was a separate method argument.\n** The map was mutable and passed along the chain.\n* In 1.0 M3:\n** The context map is now part of the `AdvisedRequest` and `AdvisedResponse` records.\n** The map is immutable.\n** To update the context, use the `updateContext` method, which creates a new unmodifiable map with the updated contents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/advisors.adoc", "title": "advisors", "heading": "Context Map Handling", "heading_level": 3, "file_order": 92, "section_index": 16, "content_hash": "2bbf8c0957804d510bb4d88b4dedc0e69a504c5d275d474c36f071787b7bcf03", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/advisors.adoc"}}
{"id": "sha256:8d518be10795fea01e085d6cfa401e39d8d73593b506eb6fdb25d2360a529f35", "content": "[[AiMetadata]]\n\nUse of an AI, such as OpenAI's ChatGPT, consumes resources and generates metrics returned by the AI provider based on the usage and requests made to the AI through the API.\nConsumption is typically in the form of requests made or tokens used in a given timeframe, such as monthly, that AI providers use to measure this consumption and reset limits.\nYour rate limits are directly determined by your plan when you signed up with your AI provider. For instance, you can review details on OpenAI's https://platform.openai.com/docs/guides/rate-limits?context=tier-free[rate limits] and https://openai.com/pricing#language-models[plans] by following the links.\n\nTo help garner insight into your AI (model) consumption and general usage, Spring AI provides an API to introspect the metadata that is returned by AI providers in their APIs.\n\nSpring AI defines 3 primary interfaces to examine these metrics: `GenerationMetadata`, `RateLimit` and `Usage`. All of these interface can be accessed programmatically from the `ChatResponse` returned and initiated by an AI request.\n\n[[AiMetadata-GenerationMetadata]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/aimetadata.adoc", "title": "aimetadata", "heading": "aimetadata", "heading_level": 1, "file_order": 93, "section_index": 0, "content_hash": "8d518be10795fea01e085d6cfa401e39d8d73593b506eb6fdb25d2360a529f35", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/aimetadata.adoc"}}
{"id": "sha256:e338630c82ed42e480f70eab5a58b3c0c800fea198f9a4f12a4dc2bd41fc6c61", "content": "The `GenerationMetadata` interface is defined as:\n\n.GenerationMetadata interface\n[source,java]\n----\ninterface GenerationMetadata {\n\n\tdefault RateLimit getRateLimit() {\n return RateLimit.NULL;\n\t}\n\n\tdefault Usage getUsage() {\n return Usage.NULL;\n\t}\n\n}\n----\n\nAn instance of `GenerationMetadata` is automatically created by Spring AI when an AI request is made through the AI provider's API and an AI response is returned. You can get access to the AI provider metadata from the `ChatResponse` using:\n\n.Get access to `GenerationMetadata` from `ChatResponse`\n[source,java]\n----\n@Service\nclass MyService {\n\n\tApplicationObjectType askTheAi(ServiceRequest request) {\n\n Prompt prompt = createPrompt(request);\n\n ChatResponse response = chatModel.call(prompt);\n\n // Process the chat response\n\n GenerationMetadata metadata = response.getMetadata();\n\n // Inspect the AI metadata returned in the chat response of the AI providers API\n\n Long totalTokensUsedInAiPromptAndResponse = metadata.getUsage().getTotalTokens();\n\n // Act on this information somehow\n\t}\n}\n----\n\nYou might imagine that you can rate limit your own Spring applications using AI, or restrict `Prompt` sizes, which affect your token usage, in an automated, intelligent and realtime manner.\n\nMinimally, you can simply gather these metrics to monitor and report on your consumption.\n\n[[AiMetadata-RateLimit]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/aimetadata.adoc", "title": "aimetadata", "heading": "`GenerationMetadata` interface", "heading_level": 2, "file_order": 93, "section_index": 1, "content_hash": "e338630c82ed42e480f70eab5a58b3c0c800fea198f9a4f12a4dc2bd41fc6c61", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/aimetadata.adoc"}}
{"id": "sha256:970d0d32bdb424014a9a6e5ba0adee87efcc26f6fe9b07df85b3e0614d21212e", "content": "The `RateLimit` interface provides access to actual information returned by an AI provider on your API usage when making AI requests.\n\n.`RateLimit` interface\n[source,java]\n----\ninterface RateLimit {\n\n\tLong getRequestsLimit();\n\n\tLong getRequestsRemaining();\n\n\tDuration getRequestsReset();\n\n\tLong getTokensLimit();\n\n\tLong getTokensRemaining();\n\n\tDuration getTokensReset();\n\n}\n----\n\n`requestsLimit` and `requestsRemaining` let you know how many AI requests, based on the AI provider plan you chose when you signed up, that you can make in total along with your remaining balance within the given timeframe. `requestsReset` returns a `Duration` of time before the timeframe expires and your limits reset based on your chosen plan.\n\nThe methods for `tokensLimit`, `tokensRemaining` and `tokensReset` are similar to the methods for requests, but focus on token limits, balance and resets instead.\n\nThe `RateLimit` instance can be acquired from the `GenerationMetadata`, like so:\n\n.Get access to `RateLimit` from `GenerationMetadata`\n[source,java]\n----\nRateLimit rateLimit = generationMetadata.getRateLimit();\n\nLong tokensRemaining = this.rateLimit.getTokensRemaining();\n\n----\n\nFor AI providers like OpenAI, the rate limit metadata is returned in https://platform.openai.com/docs/guides/rate-limits/rate-limits-in-headers[HTTP headers] from their (REST) API accessible through HTTP clients, like OkHttp.\n\nBecause this can be potentially a costly operation, the collection of rate limit AI metadata must be explicitly enabled. You can enable this collection with a Spring AI property in Spring Boot application.properties; for example:\n\n.Enable API rate limit collection from AI metadata\n[source,properties]\n----\n# Spring Boot application.properties\nspring.ai.openai.metadata.rate-limit-metrics-enabled=true\n----\n\n[[AiMetadata-Usage]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/aimetadata.adoc", "title": "aimetadata", "heading": "RateLimit", "heading_level": 2, "file_order": 93, "section_index": 2, "content_hash": "970d0d32bdb424014a9a6e5ba0adee87efcc26f6fe9b07df85b3e0614d21212e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/aimetadata.adoc"}}
{"id": "sha256:b2d7edbbe61a7af22ebb98ab4a7a5a509c531f4f50b73da3f661a6eb9712e368", "content": "As shown <<AiMetadata-GenerationMetadata,above>>, `Usage` data can be obtained from the `GenerationMetadata` object. The `Usage` interface is defined as:\n\n.`Usage` interface\n[source,java]\n----\ninterface Usage {\n\n\tLong getPromptTokens();\n\n\tLong getGenerationTokens();\n\n\tdefault Long getTotalTokens() {\n return getPromptTokens() + getGenerationTokens();\n\t}\n\n}\n----\n\nThe method names are self-explanatory, but tells you the tokens that the AI required to process the `Prompt` and generate a response.\n\n`totalTokens` is the sum of `promptTokens` and `generationTokens`. Spring AI computes this by default, but the information is returned in the AI response from OpenAI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/aimetadata.adoc", "title": "aimetadata", "heading": "Usage", "heading_level": 2, "file_order": 93, "section_index": 3, "content_hash": "b2d7edbbe61a7af22ebb98ab4a7a5a509c531f4f50b73da3f661a6eb9712e368", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/aimetadata.adoc"}}
{"id": "sha256:ab387c04dedd772f18dab2db26ba93e970ecb7401880438ea64d4b3acfb47527", "content": "= Amazon Bedrock\n\n[NOTE]\n====\nFollowing the Bedrock recommendations, Spring AI transitioned to using Amazon Bedrock's Converse API for all Chat conversation implementations in Spring AI.\nThe xref:api/chat/bedrock-converse.adoc[Bedrock Converse API] has the following key benefits:\n\n- Unified Interface: Write your code once and use it with any supported Amazon Bedrock model\n- Model Flexibility: Seamlessly switch between different conversation models without code changes\n- Extended Functionality: Support for model-specific parameters through dedicated structures\n- Tool Support: Native integration with function calling and tool usage capabilities\n- Multimodal Capabilities: Built-in support for vision and other multimodal features\n- Future-Proof: Aligned with Amazon Bedrock's recommended best practices\n\nThe Converse API does not support embedding operations, so these will remain in the current API and the embedding model functionality in the existing `InvokeModel API` will be maintained\n====\n\n\nlink:https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html[Amazon Bedrock] is a managed service that provides foundation models from various AI providers, available through a unified API.\n\nSpring AI supports https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html[the Embedding AI models] available through Amazon Bedrock by implementing the Spring `EmbeddingModel` interface.\n\nAdditionally, Spring AI provides Spring Auto-Configurations and Boot Starters for all clients, making it easy to bootstrap and configure for the Bedrock models.\n\n== Getting Started\n\nThere are a few steps to get started\n\n* Add the Spring Boot starter for Bedrock to your project.\n* Obtain AWS credentials: If you don't have an AWS account and AWS CLI configured yet, this video guide can help you configure it: link:https://youtu.be/gswVHTrRX8I?si=buaY7aeI0l3-bBVb[AWS CLI & SDK Setup in Less Than 4 Minutes!]. You should be able to obtain your access and security keys.\n* Enable the Models to use: Go to link:https://us-east-1.console.aws.amazon.com/bedrock/home[Amazon Bedrock] and from the link:https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess[Model Access] menu on the left, configure access to the models you are going to use.\n\n=== Project Dependencies\n\nThen add the Spring Boot Starter dependency to your project's Maven `pom.xml` build file:\n\n[source,xml]\n----\n<dependency>\n <artifactId>spring-ai-starter-model-bedrock</artifactId>\n <groupId>org.springframework.ai</groupId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n    implementation 'org.springframework.ai:spring-ai-starter-model-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.\n\n=== Connect to AWS Bedrock\n\nUse the `BedrockAwsConnectionProperties` to configure AWS credentials and region:\n\n[source,shell]\n----\nspring.ai.bedrock.aws.region=us-east-1\n\nspring.ai.bedrock.aws.access-key=YOUR_ACCESS_KEY\nspring.ai.bedrock.aws.secret-key=YOUR_SECRET_KEY\n\nspring.ai.bedrock.aws.profile.name=YOUR_PROFILE_NAME\nspring.ai.bedrock.aws.profile.credentials-path=YOUR_CREDENTIALS_PATH\nspring.ai.bedrock.aws.profile.configuration-path=YOUR_CONFIGURATION_PATH\n\nspring.ai.bedrock.aws.timeout=10m\n----\n\nThe `region` property is compulsory.\n\nAWS credentials are resolved in the following order:\n\n1. Spring-AI Bedrock `spring.ai.bedrock.aws.access-key` and `spring.ai.bedrock.aws.secret-key` properties.\n2. Spring-AI Bedrock `spring.ai.bedrock.aws.profile.name`, If `spring.ai.bedrock.aws.profile.credentials-path` and `spring.ai.bedrock.aws.profile.configuration-path` are not specified, Spring AI use the standard AWS shared files: `~/.aws/credentials` for credentials and `~/.aws/config` for configuration.\n3. Java System Properties - `aws.accessKeyId` and `aws.secretAccessKey`.\n4. Environment Variables - `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.\n5. Web Identity Token credentials from system properties or environment variables.\n6. Credential profiles file at the default location (`~/.aws/credentials`) shared by all AWS SDKs and the AWS CLI.\n7. Credentials delivered through the Amazon EC2 container service if the `AWS_CONTAINER_CREDENTIALS_RELATIVE_URI` environment variable is set and the security manager has permission to access the variable.\n8. Instance profile credentials delivered through the Amazon EC2 metadata service or set the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables.\n\nAWS region is resolved in the following order:\n\n1. Spring-AI Bedrock `spring.ai.bedrock.aws.region` property.\n2. Java System Properties - `aws.region`.\n3. Environment Variables - `AWS_REGION`.\n4. Credential profiles file at the default location (`~/.aws/credentials`) shared by all AWS SDKs and the AWS CLI.\n5. Instance profile region delivered through the Amazon EC2 metadata service.\n\nIn addition to the standard Spring-AI Bedrock credentials and region properties configuration, Spring-AI provides support for custom `AwsCredentialsProvider` and `AwsRegionProvider` beans.\n\nNOTE: For example, using Spring-AI and https://spring.io/projects/spring-cloud-aws[Spring Cloud for Amazon Web Services] at the same time. Spring-AI is compatible with Spring Cloud for Amazon Web Services credential configuration.\n\n=== Enable selected Bedrock model\n\nNOTE: By default, all models are disabled. You have to enable the chosen Bedrock models explicitly using the `spring.ai.bedrock.<model>.embedding.enabled=true` property.\n\nHere are the supported `<model>`s:\n\n[cols=\"|,|,|,|\"]\n|====\n| Model\n| cohere\n| titan (no batch support yet)\n|====\n\nFor example, to enable the Bedrock Cohere embedding model, you need to set `spring.ai.bedrock.cohere.embedding.enabled=true`.\n\nNext, you can use the `spring.ai.bedrock.<model>.embedding.*` properties to configure each model as provided.\n\nFor more information, refer to the documentation below for each supported model.\n\n* xref:api/embeddings/bedrock-cohere-embedding.adoc[Spring AI Bedrock Cohere Embeddings]: `spring.ai.bedrock.cohere.embedding.enabled=true`\n* xref:api/embeddings/bedrock-titan-embedding.adoc[Spring AI Bedrock Titan Embeddings]: `spring.ai.bedrock.titan.embedding.enabled=true`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock-chat.adoc", "title": "bedrock-chat", "heading": "bedrock-chat", "heading_level": 1, "file_order": 94, "section_index": 0, "content_hash": "ab387c04dedd772f18dab2db26ba93e970ecb7401880438ea64d4b3acfb47527", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock-chat.adoc"}}
{"id": "sha256:64ee89cf59504f2eaf05638bc71063168bd359605060bfbeb01c8e8cfcc93d74", "content": "[NOTE]\n====\nFollowing the Bedrock recommendations, Spring AI transitioned to using Amazon Bedrock's Converse API for all Chat conversation implementations in Spring AI.\nThe xref:api/chat/bedrock-converse.adoc[Bedrock Converse API] has the following key benefits:\n\n- Unified Interface: Write your code once and use it with any supported Amazon Bedrock model\n- Model Flexibility: Seamlessly switch between different conversation models without code changes\n- Extended Functionality: Support for model-specific parameters through dedicated structures\n- Tool Support: Native integration with function calling and tool usage capabilities\n- Multimodal Capabilities: Built-in support for vision and other multimodal features\n- Future-Proof: Aligned with Amazon Bedrock's recommended best practices\n\nThe Converse API does not support embedding operations, so these will remain in the current API and the embedding model functionality in the existing `InvokeModel API` will be maintained\n====\n\nlink:https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html[Amazon Bedrock] is a managed service that provides foundation models from various AI providers, available through a unified API.\n\nSpring AI supports https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html[the Embedding AI models] available through Amazon Bedrock by implementing the Spring `EmbeddingModel` interface.\n\nAdditionally, Spring AI provides Spring Auto-Configurations and Boot Starters for all clients, making it easy to bootstrap and configure for the Bedrock models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock.adoc", "title": "Amazon Bedrock", "heading": "Amazon Bedrock", "heading_level": 1, "file_order": 95, "section_index": 0, "content_hash": "64ee89cf59504f2eaf05638bc71063168bd359605060bfbeb01c8e8cfcc93d74", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock.adoc"}}
{"id": "sha256:6f0aa73a38d95fcd4c5d96d11198e8dcebfe0493898348ba193e4f6daeb4d1b1", "content": "There are a few steps to get started\n\n* Add the Spring Boot starter for Bedrock to your project.\n* Obtain AWS credentials: If you don't have an AWS account and AWS CLI configured yet, this video guide can help you configure it: link:https://youtu.be/gswVHTrRX8I?si=buaY7aeI0l3-bBVb[AWS CLI & SDK Setup in Less Than 4 Minutes!]. You should be able to obtain your access and security keys.\n* Enable the Models to use: Go to link:https://us-east-1.console.aws.amazon.com/bedrock/home[Amazon Bedrock] and from the link:https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess[Model Access] menu on the left, configure access to the models you are going to use.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock.adoc", "title": "Amazon Bedrock", "heading": "Getting Started", "heading_level": 2, "file_order": 95, "section_index": 1, "content_hash": "6f0aa73a38d95fcd4c5d96d11198e8dcebfe0493898348ba193e4f6daeb4d1b1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock.adoc"}}
{"id": "sha256:39507bdf8371b3278899df9efb35aedfd324af8074f5aae02797d5a1732878fa", "content": "Then add the Spring Boot Starter dependency to your project's Maven `pom.xml` build file:\n\n[source,xml]\n----\n<dependency>\n <artifactId>spring-ai-starter-model-bedrock</artifactId>\n <groupId>org.springframework.ai</groupId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-bedrock'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock.adoc", "title": "Amazon Bedrock", "heading": "Project Dependencies", "heading_level": 3, "file_order": 95, "section_index": 2, "content_hash": "39507bdf8371b3278899df9efb35aedfd324af8074f5aae02797d5a1732878fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock.adoc"}}
{"id": "sha256:6aa9dc0ea38161e88b53ba0114c12c46ad8ea5307c43e7d084029ebe85c20e8d", "content": "Use the `BedrockAwsConnectionProperties` to configure AWS credentials and region:\n\n[source,shell]\n----\nspring.ai.bedrock.aws.region=us-east-1\n\nspring.ai.bedrock.aws.access-key=YOUR_ACCESS_KEY\nspring.ai.bedrock.aws.secret-key=YOUR_SECRET_KEY\n\nspring.ai.bedrock.aws.profile.name=YOUR_PROFILE_NAME\nspring.ai.bedrock.aws.profile.credentials-path=YOUR_CREDENTIALS_PATH\nspring.ai.bedrock.aws.profile.configuration-path=YOUR_CONFIGURATION_PATH\n\nspring.ai.bedrock.aws.timeout=10m\n----\n\nThe `region` property is compulsory.\n\nAWS credentials are resolved in the following order:\n\n1. Spring-AI Bedrock `spring.ai.bedrock.aws.access-key` and `spring.ai.bedrock.aws.secret-key` properties.\n2. Spring-AI Bedrock `spring.ai.bedrock.aws.profile.name`, If `spring.ai.bedrock.aws.profile.credentials-path` and `spring.ai.bedrock.aws.profile.configuration-path` are not specified, Spring AI use the standard AWS shared files: `~/.aws/credentials` for credentials and `~/.aws/config` for configuration.\n3. Java System Properties - `aws.accessKeyId` and `aws.secretAccessKey`.\n4. Environment Variables - `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.\n5. Web Identity Token credentials from system properties or environment variables.\n6. Credential profiles file at the default location (`~/.aws/credentials`) shared by all AWS SDKs and the AWS CLI.\n7. Credentials delivered through the Amazon EC2 container service if the `AWS_CONTAINER_CREDENTIALS_RELATIVE_URI` environment variable is set and the security manager has permission to access the variable.\n8. Instance profile credentials delivered through the Amazon EC2 metadata service or set the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables.\n\nAWS region is resolved in the following order:\n\n1. Spring-AI Bedrock `spring.ai.bedrock.aws.region` property.\n2. Java System Properties - `aws.region`.\n3. Environment Variables - `AWS_REGION`.\n4. Credential profiles file at the default location (`~/.aws/credentials`) shared by all AWS SDKs and the AWS CLI.\n5. Instance profile region delivered through the Amazon EC2 metadata service.\n\nIn addition to the standard Spring-AI Bedrock credentials and region properties configuration, Spring-AI provides support for custom `AwsCredentialsProvider` and `AwsRegionProvider` beans.\n\nNOTE: For example, using Spring-AI and https://spring.io/projects/spring-cloud-aws[Spring Cloud for Amazon Web Services] at the same time. Spring-AI is compatible with Spring Cloud for Amazon Web Services credential configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock.adoc", "title": "Amazon Bedrock", "heading": "Connect to AWS Bedrock", "heading_level": 3, "file_order": 95, "section_index": 3, "content_hash": "6aa9dc0ea38161e88b53ba0114c12c46ad8ea5307c43e7d084029ebe85c20e8d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock.adoc"}}
{"id": "sha256:d1b30503eb0b28bf41660ea6fd48f79dd3e91fb91a91cf00ecd4cfea071441b9", "content": "NOTE: By default, all models are disabled. You have to enable the chosen Bedrock models explicitly using the `spring.ai.bedrock.<model>.embedding.enabled=true` property.\n\nHere are the supported `<model>`s:\n\n[cols=\"|,|,|,|\"]\n|====\n| Model\n| cohere\n| titan (no batch support yet)\n|====\n\nFor example, to enable the Bedrock Cohere embedding model, you need to set `spring.ai.bedrock.cohere.embedding.enabled=true`.\n\nNext, you can use the `spring.ai.bedrock.<model>.embedding.*` properties to configure each model as provided.\n\nFor more information, refer to the documentation below for each supported model.\n\n* xref:api/embeddings/bedrock-cohere-embedding.adoc[Spring AI Bedrock Cohere Embeddings]: `spring.ai.bedrock.cohere.embedding.enabled=true`\n* xref:api/embeddings/bedrock-titan-embedding.adoc[Spring AI Bedrock Titan Embeddings]: `spring.ai.bedrock.titan.embedding.enabled=true`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/bedrock.adoc", "title": "Amazon Bedrock", "heading": "Enable selected Bedrock model", "heading_level": 3, "file_order": 95, "section_index": 4, "content_hash": "d1b30503eb0b28bf41660ea6fd48f79dd3e91fb91a91cf00ecd4cfea071441b9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/bedrock.adoc"}}
{"id": "sha256:77372d42e94099ea9b6a10c20f8d466c9419efe873aebba56c51774aa0c35b78", "content": "[[ChatMemory]]\n\nLarge language models (LLMs) are stateless, meaning they do not retain information about previous interactions. This can be a limitation when you want to maintain context or state across multiple interactions. To address this, Spring AI provides chat memory features that allow you to store and retrieve information across multiple interactions with the LLM.\n\nThe `ChatMemory` abstraction allows you to implement various types of memory to support different use cases. The underlying storage of the messages is handled by the `ChatMemoryRepository`, whose sole responsibility is to store and retrieve messages. It's up to the `ChatMemory` implementation to decide which messages to keep and when to remove them. Examples of strategies could include keeping the last N messages, keeping messages for a certain time period, or keeping messages up to a certain token limit.\n\nBefore choosing a memory type, it's essential to understand the difference between chat memory and chat history.\n\n* *Chat Memory*. The information that a large-language model retains and uses to maintain contextual awareness throughout a conversation.\n* *Chat History*. The entire conversation history, including all messages exchanged between the user and the model.\n\nThe `ChatMemory` abstraction is designed to manage the _chat memory_. It allows you to store and retrieve messages that are relevant to the current conversation context. However, it is not the best fit for storing the _chat history_. If you need to maintain a complete record of all the messages exchanged, you should consider using a different approach, such as relying on Spring Data for efficient storage and retrieval of the complete chat history.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "chat-memory", "heading_level": 1, "file_order": 96, "section_index": 0, "content_hash": "77372d42e94099ea9b6a10c20f8d466c9419efe873aebba56c51774aa0c35b78", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:c9117a8b8536583d0f9b5862d4f1bd49afc020231aadbcb015cbc57b34a727e6", "content": "Spring AI auto-configures a `ChatMemory` bean that you can use directly in your application. By default, it uses an in-memory repository to store messages (`InMemoryChatMemoryRepository`) and a `MessageWindowChatMemory` implementation to manage the conversation history. If a different repository is already configured (e.g., Cassandra, JDBC, or Neo4j), Spring AI will use that instead.\n\n[source,java]\n----\n@Autowired\nChatMemory chatMemory;\n----\n\nThe following sections will describe further the different memory types and repositories available in Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Quick Start", "heading_level": 2, "file_order": 96, "section_index": 1, "content_hash": "c9117a8b8536583d0f9b5862d4f1bd49afc020231aadbcb015cbc57b34a727e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:3791ff05df111ca53ed2a4cd40a33a6593bc7177486998ac013e0bf0e2bf5bff", "content": "The `ChatMemory` abstraction allows you to implement various types of memory to suit different use cases. The choice of memory type can significantly impact the performance and behavior of your application. This section describes the built-in memory types provided by Spring AI and their characteristics.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Memory Types", "heading_level": 2, "file_order": 96, "section_index": 2, "content_hash": "3791ff05df111ca53ed2a4cd40a33a6593bc7177486998ac013e0bf0e2bf5bff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:eb46f70585651e809d68beb3e2de06a988355f7e662310170319760e1658b91d", "content": "`MessageWindowChatMemory` maintains a window of messages up to a specified maximum size. When the number of messages exceeds the maximum, older messages are removed while preserving system messages. The default window size is 20 messages.\n\n[source,java]\n----\nMessageWindowChatMemory memory = MessageWindowChatMemory.builder()\n .maxMessages(10)\n .build();\n----\n\nThis is the default message type used by Spring AI to auto-configure a `ChatMemory` bean.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Message Window Chat Memory", "heading_level": 3, "file_order": 96, "section_index": 3, "content_hash": "eb46f70585651e809d68beb3e2de06a988355f7e662310170319760e1658b91d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:2d515dc54a006d74eba0ee07e19fd0940e09ab61135f78ee3bc3967e7fb7b98c", "content": "Spring AI offers the `ChatMemoryRepository` abstraction for storing chat memory. This section describes the built-in repositories provided by Spring AI and how to use them, but you can also implement your own repository if needed.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Memory Storage", "heading_level": 2, "file_order": 96, "section_index": 4, "content_hash": "2d515dc54a006d74eba0ee07e19fd0940e09ab61135f78ee3bc3967e7fb7b98c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:9fd143b62b4ec6d89d05e8cea75273c28cf7989d498eab1cc58e939df3a831db", "content": "`InMemoryChatMemoryRepository` stores messages in memory using a `ConcurrentHashMap`.\n\nBy default, if no other repository is already configured, Spring AI auto-configures a `ChatMemoryRepository` bean of type `InMemoryChatMemoryRepository` that you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nChatMemoryRepository chatMemoryRepository;\n----\n\nIf you'd rather create the `InMemoryChatMemoryRepository` manually, you can do so as follows:\n\n[source,java]\n----\nChatMemoryRepository repository = new InMemoryChatMemoryRepository();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "In-Memory Repository", "heading_level": 3, "file_order": 96, "section_index": 5, "content_hash": "9fd143b62b4ec6d89d05e8cea75273c28cf7989d498eab1cc58e939df3a831db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:e66257c6ddfa8132dbd5ad2291ff2ef6abd4d9e85c945765264652f33a1dbd50", "content": "`JdbcChatMemoryRepository` is a built-in implementation that uses JDBC to store messages in a relational database. It supports multiple databases out-of-the-box and is suitable for applications that require persistent storage of chat memory.\n\nMessages are retrieved in ascending timestamp order (oldest-to-newest), which is the expected format for LLM conversation history.\n\nFirst, add the following dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-jdbc</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-jdbc'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `JdbcChatMemoryRepository`, that you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nJdbcChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `JdbcChatMemoryRepository` manually, you can do so by providing a `JdbcTemplate` instance and a `JdbcChatMemoryRepositoryDialect`:\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = JdbcChatMemoryRepository.builder()\n .jdbcTemplate(jdbcTemplate)\n .dialect(new PostgresChatMemoryRepositoryDialect())\n .build();\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "JdbcChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 6, "content_hash": "e66257c6ddfa8132dbd5ad2291ff2ef6abd4d9e85c945765264652f33a1dbd50", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:05405a3469bce8f91dae02f5fef0fa8e0453f846b443d4b1eb48d6eb6afa469c", "content": "Spring AI supports multiple relational databases via a dialect abstraction. The following databases are supported out-of-the-box:\n\n- PostgreSQL\n- MySQL / MariaDB\n- SQL Server\n- HSQLDB\n- Oracle Database\n\nThe correct dialect can be auto-detected from the JDBC URL when using `JdbcChatMemoryRepositoryDialect.from(DataSource)`. You can extend support for other databases by implementing the `JdbcChatMemoryRepositoryDialect` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Supported Databases and Dialect Abstraction", "heading_level": 4, "file_order": 96, "section_index": 7, "content_hash": "05405a3469bce8f91dae02f5fef0fa8e0453f846b443d4b1eb48d6eb6afa469c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:db551d38d7ed3f8962512da6cee3b034fc46afbec005a7001c494150ed053713", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.ai.chat.memory.repository.jdbc.initialize-schema` | Controls when to initialize the schema. Values: `embedded` (default), `always`, `never`. | `embedded`\n| `spring.ai.chat.memory.repository.jdbc.schema` | Location of the schema script to use for initialization. Supports `classpath:` URLs and platform placeholders. | `classpath:org/springframework/ai/chat/memory/repository/jdbc/schema-@@platform@@.sql`\n| `spring.ai.chat.memory.repository.jdbc.platform` | Platform to use in initialization scripts if the @@platform@@ placeholder is used. | _auto-detected_\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 8, "content_hash": "db551d38d7ed3f8962512da6cee3b034fc46afbec005a7001c494150ed053713", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:1240623ea23adfa0b9db006eaaaf7a924fbaf7a8a63f82b18a948c83291de408", "content": "The auto-configuration will automatically create the `SPRING_AI_CHAT_MEMORY` table on startup, using a vendor-specific SQL script for your database. By default, schema initialization runs only for embedded databases (H2, HSQL, Derby, etc.).\n\nYou can control schema initialization using the `spring.ai.chat.memory.repository.jdbc.initialize-schema` property:\n\n[source,properties]\n----\nspring.ai.chat.memory.repository.jdbc.initialize-schema=embedded # Only for embedded DBs (default)\nspring.ai.chat.memory.repository.jdbc.initialize-schema=always # Always initialize\nspring.ai.chat.memory.repository.jdbc.initialize-schema=never # Never initialize (useful with Flyway/Liquibase)\n----\n\nTo override the schema script location, use:\n\n[source,properties]\n----\nspring.ai.chat.memory.repository.jdbc.schema=classpath:/custom/path/schema-mysql.sql\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Schema Initialization", "heading_level": 4, "file_order": 96, "section_index": 9, "content_hash": "1240623ea23adfa0b9db006eaaaf7a924fbaf7a8a63f82b18a948c83291de408", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:9f343aafeee0f67c788b51c6b9fe30f2dbd4e57f2705ea57303557dbd21e48c5", "content": "To add support for a new database, implement the `JdbcChatMemoryRepositoryDialect` interface and provide SQL for selecting, inserting, and deleting messages. You can then pass your custom dialect to the repository builder.\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = JdbcChatMemoryRepository.builder()\n .jdbcTemplate(jdbcTemplate)\n .dialect(new MyCustomDbDialect())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Extending Dialects", "heading_level": 4, "file_order": 96, "section_index": 10, "content_hash": "9f343aafeee0f67c788b51c6b9fe30f2dbd4e57f2705ea57303557dbd21e48c5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:fb2e6b9a9c2b95e3640aa3f98a5023d013916b99ccb42878fac79334ac7fab77", "content": "`CassandraChatMemoryRepository` uses Apache Cassandra to store messages. It is suitable for applications that require persistent storage of chat memory, especially for availability, durability, scale, and when taking advantage of time-to-live (TTL) feature.\n\n`CassandraChatMemoryRepository` has a time-series schema, keeping record of all past chat windows, valuable for governance and auditing. Setting time-to-live to some value, for example three years, is recommended.\n\nMessages are retrieved in ascending timestamp order (oldest-to-newest), which is the expected format for LLM conversation history.\n\nTo use `CassandraChatMemoryRepository` first, add the dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-cassandra</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-cassandra'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `CassandraChatMemoryRepository` that you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nCassandraChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `CassandraChatMemoryRepository` manually, you can do so by providing a `CassandraChatMemoryRepositoryConfig` instance:\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = CassandraChatMemoryRepository\n .create(CassandraChatMemoryRepositoryConfig.builder().withCqlSession(cqlSession));\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "CassandraChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 11, "content_hash": "fb2e6b9a9c2b95e3640aa3f98a5023d013916b99ccb42878fac79334ac7fab77", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:df4f548442cf4a8d2e4d6f6acad27f7f787238df2cb4e4bc436314e40761b6ef", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.cassandra.contactPoints` | Host(s) to initiate cluster discovery | `127.0.0.1`\n| `spring.cassandra.port` | Cassandra native protocol port to connect to | `9042`\n| `spring.cassandra.localDatacenter` | Cassandra datacenter to connect to | `datacenter1`\n| `spring.ai.chat.memory.cassandra.time-to-live` | Time to live (TTL) for messages written in Cassandra |\n| `spring.ai.chat.memory.cassandra.keyspace` | Cassandra keyspace | `springframework`\n| `spring.ai.chat.memory.cassandra.messages-column` | Cassandra column name for messages | `springframework`\n| `spring.ai.chat.memory.cassandra.table` | Cassandra table | `ai_chat_memory`\n| `spring.ai.chat.memory.cassandra.initialize-schema` | Whether to initialize the schema on startup. | `true`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 12, "content_hash": "df4f548442cf4a8d2e4d6f6acad27f7f787238df2cb4e4bc436314e40761b6ef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:fba8c28d7276e38af650d7cab61c24d13366ee4bf087ef55d18dbb74dcdf144d", "content": "The auto-configuration will automatically create the `ai_chat_memory` table.\n\nYou can disable the schema initialization by setting the property `spring.ai.chat.memory.repository.cassandra.initialize-schema` to `false`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Schema Initialization", "heading_level": 4, "file_order": 96, "section_index": 13, "content_hash": "fba8c28d7276e38af650d7cab61c24d13366ee4bf087ef55d18dbb74dcdf144d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:d71f0fe797dff69da814a0fb311795970792613585e2176bd60a3bb12f01fc9e", "content": "`Neo4jChatMemoryRepository` is a built-in implementation that uses Neo4j to store chat messages as nodes and relationships in a property graph database. It is suitable for applications that want to leverage Neo4j's graph capabilities for chat memory persistence.\n\nMessages are retrieved in ascending message index order (oldest-to-newest), which is the expected format for LLM conversation history.\n\nFirst, add the following dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-neo4j</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-neo4j'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `Neo4jChatMemoryRepository`, which you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nNeo4jChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `Neo4jChatMemoryRepository` manually, you can do so by providing a Neo4j `Driver` instance:\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = Neo4jChatMemoryRepository.builder()\n .driver(driver)\n .build();\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Neo4j ChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 14, "content_hash": "d71f0fe797dff69da814a0fb311795970792613585e2176bd60a3bb12f01fc9e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:20e222c7b5c4947b1ca06063186b53a553bc7f3042ac59312d50172b6fca3450", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.ai.chat.memory.repository.neo4j.sessionLabel` | The label for the nodes that store conversation sessions | `Session`\n| `spring.ai.chat.memory.repository.neo4j.messageLabel` | The label for the nodes that store messages | `Message`\n| `spring.ai.chat.memory.repository.neo4j.toolCallLabel` | The label for nodes that store tool calls (e.g. in Assistant Messages) | `ToolCall`\n| `spring.ai.chat.memory.repository.neo4j.metadataLabel` | The label for nodes that store message metadata | `Metadata`\n| `spring.ai.chat.memory.repository.neo4j.toolResponseLabel` | The label for the nodes that store tool responses | `ToolResponse`\n| `spring.ai.chat.memory.repository.neo4j.mediaLabel` | The label for the nodes that store media associated with a message | `Media`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 15, "content_hash": "20e222c7b5c4947b1ca06063186b53a553bc7f3042ac59312d50172b6fca3450", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:eb8f531279dfb4b0c1b5d40901ce0745b8062a0d95adec1d414ab8836777bb9e", "content": "The Neo4j repository will automatically ensure that indexes are created for conversation IDs and message indices to optimize performance. If you use custom labels, indexes will be created for those labels as well. No schema initialization is required, but you should ensure your Neo4j instance is accessible to your application.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Index Initialization", "heading_level": 4, "file_order": 96, "section_index": 16, "content_hash": "eb8f531279dfb4b0c1b5d40901ce0745b8062a0d95adec1d414ab8836777bb9e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:b1bf2bed5981207c13f1dc89b3533aedf1381f5f23234e96e8b21d915bdba9f4", "content": "`CosmosDBChatMemoryRepository` is a built-in implementation that uses Azure Cosmos DB NoSQL API to store messages. It is suitable for applications that require a globally distributed, highly scalable document database for chat memory persistence. The repository uses the conversation ID as the partition key to ensure efficient data distribution and fast retrieval.\n\nMessages are retrieved in ascending timestamp order (oldest-to-newest), which is the expected format for LLM conversation history.\n\nFirst, add the following dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-cosmos-db</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-cosmos-db'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `CosmosDBChatMemoryRepository`, which you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nCosmosDBChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `CosmosDBChatMemoryRepository` manually, you can do so by providing a `CosmosDBChatMemoryRepositoryConfig` instance:\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = CosmosDBChatMemoryRepository\n .create(CosmosDBChatMemoryRepositoryConfig.builder()\n .withCosmosClient(cosmosAsyncClient)\n .withDatabaseName(\"chat-memory-db\")\n .withContainerName(\"conversations\")\n .build());\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "CosmosDBChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 17, "content_hash": "b1bf2bed5981207c13f1dc89b3533aedf1381f5f23234e96e8b21d915bdba9f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:2609033459e2cd83a5d1f908cc76370b12c651e8c93a15e723a383bcc9979783", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.ai.chat.memory.repository.cosmosdb.endpoint` | Azure Cosmos DB endpoint URI. Required for auto-configuration. |\n| `spring.ai.chat.memory.repository.cosmosdb.key` | Azure Cosmos DB primary or secondary key. If not provided, Azure Identity authentication will be used. |\n| `spring.ai.chat.memory.repository.cosmosdb.connection-mode` | Connection mode for Cosmos DB client (`direct` or `gateway`). | `gateway`\n| `spring.ai.chat.memory.repository.cosmosdb.database-name` | Name of the Cosmos DB database. | `SpringAIChatMemory`\n| `spring.ai.chat.memory.repository.cosmosdb.container-name` | Name of the Cosmos DB container. | `ChatMemory`\n| `spring.ai.chat.memory.repository.cosmosdb.partition-key-path` | Partition key path for the container. | `/conversationId`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 18, "content_hash": "2609033459e2cd83a5d1f908cc76370b12c651e8c93a15e723a383bcc9979783", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:65891329a115aa3d1e9d46c4b0a7c3bf50219f5ec99a7c209a2b7cc68f683e57", "content": "The Cosmos DB Chat Memory Repository supports two authentication methods:\n\n1. **Key-based authentication**: Provide the `spring.ai.chat.memory.repository.cosmosdb.key` property with your Cosmos DB primary or secondary key.\n2. **Azure Identity authentication**: When no key is provided, the repository uses Azure Identity (`DefaultAzureCredential`) to authenticate with managed identity, service principal, or other Azure credential sources.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Authentication", "heading_level": 4, "file_order": 96, "section_index": 19, "content_hash": "65891329a115aa3d1e9d46c4b0a7c3bf50219f5ec99a7c209a2b7cc68f683e57", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:bc1e8518273ccb22bee93d186bb3842641c82fc6d1906c04eafc9fdd248e6068", "content": "The auto-configuration will automatically create the specified database and container if they don't exist. The container is configured with the conversation ID as the partition key (`/conversationId`) to ensure optimal performance for chat memory operations. No manual schema setup is required.\n\nYou can customize the database and container names using the configuration properties mentioned above.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Schema Initialization", "heading_level": 4, "file_order": 96, "section_index": 20, "content_hash": "bc1e8518273ccb22bee93d186bb3842641c82fc6d1906c04eafc9fdd248e6068", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:6db04e4b45dcd431ef3060d0f65b676c42d4ece3c4a9623698623f8e5e087182", "content": "`MongoChatMemoryRepository` is a built-in implementation that uses MongoDB to store messages. It is suitable for applications that require a flexible, document-oriented database for chat memory persistence.\n\nMessages are retrieved in ascending timestamp order (oldest-to-newest), which is the expected format for LLM conversation history. This ordering is consistent across all chat memory repository implementations.\n\nFirst, add the following dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-mongodb</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-mongodb'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `MongoChatMemoryRepository`, which you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nMongoChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `MongoChatMemoryRepository` manually, you can do so by providing a `MongoTemplate` instance:\n\n[source,java]\n----\nChatMemoryRepository chatMemoryRepository = MongoChatMemoryRepository.builder()\n .mongoTemplate(mongoTemplate)\n .build();\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "MongoChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 21, "content_hash": "6db04e4b45dcd431ef3060d0f65b676c42d4ece3c4a9623698623f8e5e087182", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:2ba0f929a9e85a88a0dc959b13ae1f50966f0e229b31b8d52314ac32eb657409", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.ai.chat.memory.repository.mongo.create-indices` | Should indices be created or recreated automatically on startup. Note: Changing the\n* TTL value will drop the TTL index and recreate it | `false`\n| `spring.ai.chat.memory.repository.mongo.ttl` | Time to live (TTL) for messages written in MongoDB, in seconds. If not set, messages will be stored indefinitely. | `0`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 22, "content_hash": "2ba0f929a9e85a88a0dc959b13ae1f50966f0e229b31b8d52314ac32eb657409", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:71fb241fe83390c96c3ca510a2ec556fd30a2bc78573929fd2809784723dc8a3", "content": "The auto-configuration will automatically create the `ai_chat_memory` collection on startup if it does not already exist.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Collection Initialization", "heading_level": 4, "file_order": 96, "section_index": 23, "content_hash": "71fb241fe83390c96c3ca510a2ec556fd30a2bc78573929fd2809784723dc8a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:540e0c404b35e76470f21c5006ca3f4d0723586b3af076770e2f2a8b53f987d0", "content": "`RedisChatMemoryRepository` is a built-in implementation that uses Redis Stack (with Redis Query Engine and RedisJSON) to store chat messages.\nIt is suitable for applications that require high-performance, low-latency chat memory persistence with optional TTL (time-to-live) support and advanced querying capabilities.\n\nThe repository stores messages as JSON documents and creates a search index for efficient querying.\nIt also provides extended query capabilities through the `AdvancedRedisChatMemoryRepository` interface for searching messages by content, type, time range, and metadata.\n\nMessages are retrieved in ascending timestamp order (oldest-to-newest), which is the expected format for LLM conversation history.\n\nFirst, add the following dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-chat-memory-repository-redis</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-starter-model-chat-memory-repository-redis'\n}\n----\n======\n\nSpring AI provides auto-configuration for the `RedisChatMemoryRepository`, which you can use directly in your application.\n\n[source,java]\n----\n@Autowired\nRedisChatMemoryRepository chatMemoryRepository;\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----\n\nIf you'd rather create the `RedisChatMemoryRepository` manually, you can do so by providing a `JedisPooled` client:\n\n[source,java]\n----\nJedisPooled jedisClient = new JedisPooled(\"localhost\", 6379);\n\nChatMemoryRepository chatMemoryRepository = RedisChatMemoryRepository.builder()\n .jedisClient(jedisClient)\n .indexName(\"my-chat-index\")\n .keyPrefix(\"my-chat:\")\n .timeToLive(Duration.ofHours(24))\n .build();\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n .chatMemoryRepository(chatMemoryRepository)\n .maxMessages(10)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "RedisChatMemoryRepository", "heading_level": 3, "file_order": 96, "section_index": 24, "content_hash": "540e0c404b35e76470f21c5006ca3f4d0723586b3af076770e2f2a8b53f987d0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:bc45ab451679c1a6dab86daa6ff41fcab35886f40389673bf9583cffd7a8e936", "content": "[cols=\"2,5,1\",stripes=even]\n|===\n|Property | Description | Default Value\n| `spring.ai.chat.memory.redis.host` | Redis server host | `localhost`\n| `spring.ai.chat.memory.redis.port` | Redis server port | `6379`\n| `spring.ai.chat.memory.redis.index-name` | Name of the Redis search index | `chat-memory-idx`\n| `spring.ai.chat.memory.redis.key-prefix` | Key prefix for chat memory entries | `chat-memory:`\n| `spring.ai.chat.memory.redis.time-to-live` | Time to live for chat memory entries (e.g., `24h`, `30d`) | _no expiration_\n| `spring.ai.chat.memory.redis.initialize-schema` | Whether to initialize the Redis schema on startup | `true`\n| `spring.ai.chat.memory.redis.max-conversation-ids` | Maximum number of conversation IDs to return | `1000`\n| `spring.ai.chat.memory.redis.max-messages-per-conversation` | Maximum number of messages to return per conversation | `1000`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Configuration Properties", "heading_level": 4, "file_order": 96, "section_index": 25, "content_hash": "bc45ab451679c1a6dab86daa6ff41fcab35886f40389673bf9583cffd7a8e936", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:f4ac29d35c43e888bd945ecf45f7865f592f0ad67f3a7bb6e0184a15238aa0d7", "content": "The `RedisChatMemoryRepository` also implements `AdvancedRedisChatMemoryRepository`, which provides extended query capabilities:\n\n[source,java]\n----\nAdvancedRedisChatMemoryRepository advancedRepo = (AdvancedRedisChatMemoryRepository) chatMemoryRepository;\n\nList<MessageWithConversation> userMessages = advancedRepo.findByType(MessageType.USER, 100);\n\nList<MessageWithConversation> results = advancedRepo.findByContent(\"Spring AI\", 50);\n\nList<MessageWithConversation> recentMessages = advancedRepo.findByTimeRange(\n conversationId,\n Instant.now().minus(Duration.ofHours(1)),\n Instant.now(),\n 100\n);\n\nList<MessageWithConversation> priorityMessages = advancedRepo.findByMetadata(\"priority\", \"high\", 50);\n\nList<MessageWithConversation> customResults = advancedRepo.executeQuery(\"@type:USER @content:Redis\", 100);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Advanced Querying", "heading_level": 4, "file_order": 96, "section_index": 26, "content_hash": "f4ac29d35c43e888bd945ecf45f7865f592f0ad67f3a7bb6e0184a15238aa0d7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:98519abe531e800125cc7a3f57836c6e2cc62391fea057fde57bff91dfd42072", "content": "To enable efficient querying on custom metadata fields, you can configure metadata field definitions:\n\n[source,properties]\n----\nspring.ai.chat.memory.redis.metadata-fields[0].name=priority\nspring.ai.chat.memory.redis.metadata-fields[0].type=tag\nspring.ai.chat.memory.redis.metadata-fields[1].name=score\nspring.ai.chat.memory.redis.metadata-fields[1].type=numeric\nspring.ai.chat.memory.redis.metadata-fields[2].name=category\nspring.ai.chat.memory.redis.metadata-fields[2].type=tag\n----\n\nSupported field types are: `tag` (for exact match filtering), `text` (for full-text search), and `numeric` (for range queries).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Metadata Field Indexing", "heading_level": 4, "file_order": 96, "section_index": 27, "content_hash": "98519abe531e800125cc7a3f57836c6e2cc62391fea057fde57bff91dfd42072", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:a1f89620a17c786e1511980ea95019501c7065fb28f68f91376687d16f607a04", "content": "The auto-configuration will automatically create the Redis search index on startup if it does not already exist.\nYou can disable this behavior by setting `spring.ai.chat.memory.redis.initialize-schema=false`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Schema Initialization", "heading_level": 4, "file_order": 96, "section_index": 28, "content_hash": "a1f89620a17c786e1511980ea95019501c7065fb28f68f91376687d16f607a04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:d7b40da674d0dadbf07cb0791c8501f9839300e4a7c54791297d66c5b3da5857", "content": "* Redis Stack 7.0 or higher (includes Redis Query Engine and RedisJSON modules)\n* Jedis client library (included as a dependency)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Requirements", "heading_level": 4, "file_order": 96, "section_index": 29, "content_hash": "d7b40da674d0dadbf07cb0791c8501f9839300e4a7c54791297d66c5b3da5857", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:e6ebda4354bbd0773082465acd64b5d0b0921ad6f7982696e2bb1114a882a8da", "content": "When using the ChatClient API, you can provide a `ChatMemory` implementation to maintain conversation context across multiple interactions.\n\nSpring AI provides a few built-in Advisors that you can use to configure the memory behavior of the `ChatClient`, based on your needs.\n\nWARNING: Currently, the intermediate messages exchanged with a large-language model when performing tool calls are not stored in the memory. This is a limitation of the current implementation and will be addressed in future releases. If you need to store these messages, refer to the instructions for the xref:api/tools.adoc#_user_controlled_tool_execution[User Controlled Tool Execution].\n\n* `MessageChatMemoryAdvisor`. This advisor manages the conversation memory using the provided `ChatMemory` implementation. On each interaction, it retrieves the conversation history from the memory and includes it in the prompt as a collection of messages.\n* `PromptChatMemoryAdvisor`. This advisor manages the conversation memory using the provided `ChatMemory` implementation. On each interaction, it retrieves the conversation history from the memory and appends it to the system prompt as plain text.\n* `VectorStoreChatMemoryAdvisor`. This advisor manages the conversation memory using the provided `VectorStore` implementation. On each interaction, it retrieves the conversation history from the vector store and appends it to the system message as plain text.\n\nFor example, if you want to use `MessageWindowChatMemory` with the `MessageChatMemoryAdvisor`, you can configure it as follows:\n\n[source,java]\n----\nChatMemory chatMemory = MessageWindowChatMemory.builder().build();\n\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(MessageChatMemoryAdvisor.builder(chatMemory).build())\n .build();\n----\n\nWhen performing a call to the `ChatClient`, the memory will be automatically managed by the `MessageChatMemoryAdvisor`. The conversation history will be retrieved from the memory based on the specified conversation ID:\n\n[source,java]\n----\nString conversationId = \"007\";\n\nchatClient.prompt()\n .user(\"Do I have license to code?\")\n .advisors(a -> a.param(ChatMemory.CONVERSATION_ID, conversationId))\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Memory in Chat Client", "heading_level": 2, "file_order": 96, "section_index": 30, "content_hash": "e6ebda4354bbd0773082465acd64b5d0b0921ad6f7982696e2bb1114a882a8da", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:62782a5908b9da15770e0f808cb23fba29a7b52b0a7587f7f46e104a9aca1d7c", "content": "The `PromptChatMemoryAdvisor` uses a default template to augment the system message with the retrieved conversation memory. You can customize this behavior by providing your own `PromptTemplate` object via the `.promptTemplate()` builder method.\n\nNOTE: The `PromptTemplate` provided here customizes how the advisor merges retrieved memory with the system message. This is distinct from configuring a `TemplateRenderer` on the `ChatClient` itself (using `.templateRenderer()`), which affects the rendering of the initial user/system prompt content *before* the advisor runs. See xref:api/chatclient.adoc#_prompt_templates[ChatClient Prompt Templates] for more details on client-level template rendering.\n\nThe custom `PromptTemplate` can use any `TemplateRenderer` implementation (by default, it uses `StPromptTemplate` based on the https://www.stringtemplate.org/[StringTemplate] engine). The important requirement is that the template must contain the following two placeholders:\n\n* an `instructions` placeholder to receive the original system message.\n* a `memory` placeholder to receive the retrieved conversation memory.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Custom Template", "heading_level": 4, "file_order": 96, "section_index": 31, "content_hash": "62782a5908b9da15770e0f808cb23fba29a7b52b0a7587f7f46e104a9aca1d7c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:fd3121fa47e5a7982210f00a28618c8b22adff787ab20b2ed170188e9a860c3d", "content": "The `VectorStoreChatMemoryAdvisor` uses a default template to augment the system message with the retrieved conversation memory. You can customize this behavior by providing your own `PromptTemplate` object via the `.promptTemplate()` builder method.\n\nNOTE: The `PromptTemplate` provided here customizes how the advisor merges retrieved memory with the system message. This is distinct from configuring a `TemplateRenderer` on the `ChatClient` itself (using `.templateRenderer()`), which affects the rendering of the initial user/system prompt content *before* the advisor runs. See xref:api/chatclient.adoc#_prompt_templates[ChatClient Prompt Templates] for more details on client-level template rendering.\n\nThe custom `PromptTemplate` can use any `TemplateRenderer` implementation (by default, it uses `StPromptTemplate` based on the https://www.stringtemplate.org/[StringTemplate] engine). The important requirement is that the template must contain the following two placeholders:\n\n* an `instructions` placeholder to receive the original system message.\n* a `long_term_memory` placeholder to receive the retrieved conversation memory.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Custom Template", "heading_level": 4, "file_order": 96, "section_index": 32, "content_hash": "fd3121fa47e5a7982210f00a28618c8b22adff787ab20b2ed170188e9a860c3d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:bf2f4811c41b66e945442e4d6cfb0134c0e3d3a7829e5f9400344e77f73a5a97", "content": "If you're working directly with a `ChatModel` instead of a `ChatClient`, you can manage the memory explicitly:\n\n[source,java]\n----\nChatMemory chatMemory = MessageWindowChatMemory.builder().build();\nString conversationId = \"007\";\n\nUserMessage userMessage1 = new UserMessage(\"My name is James Bond\");\nchatMemory.add(conversationId, userMessage1);\nChatResponse response1 = chatModel.call(new Prompt(chatMemory.get(conversationId)));\nchatMemory.add(conversationId, response1.getResult().getOutput());\n\nUserMessage userMessage2 = new UserMessage(\"What is my name?\");\nchatMemory.add(conversationId, userMessage2);\nChatResponse response2 = chatModel.call(new Prompt(chatMemory.get(conversationId)));\nchatMemory.add(conversationId, response2.getResult().getOutput());\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chat-memory.adoc", "title": "chat-memory", "heading": "Memory in Chat Model", "heading_level": 2, "file_order": 96, "section_index": 33, "content_hash": "bf2f4811c41b66e945442e4d6cfb0134c0e3d3a7829e5f9400344e77f73a5a97", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chat-memory.adoc"}}
{"id": "sha256:e67c4a36e8be021501e538ef3370360d475634b33c337a669e4fed1432022ee0", "content": "[[ChatClient]]\n\nThe `ChatClient` offers a fluent API for communicating with an AI Model.\nIt supports both a synchronous and streaming programming model.\n\n[NOTE]\n====\nSee the xref:api/chatclient.adoc#_implementation_notes[Implementation Notes] at the bottom of this document related to the combined use of imperative and reactive programming models in `ChatClient`\n====\n\nThe fluent API has methods for building up the constituent parts of a xref:api/prompt.adoc#_prompt[Prompt] that is passed to the AI model as input.\nThe `Prompt` contains the instructional text to guide the AI model's output and behavior. From the API point of view, prompts consist of a collection of messages.\n\nThe AI model processes two main types of messages: user messages, which are direct inputs from the user, and system messages, which are generated by the system to guide the conversation.\n\nThese messages often contain placeholders that are substituted at runtime based on user input to customize the response of the AI model to the user input.\n\nThere are also Prompt options that can be specified, such as the name of the AI Model to use and the temperature setting that controls the randomness or creativity of the generated output.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "chatclient", "heading_level": 1, "file_order": 97, "section_index": 0, "content_hash": "e67c4a36e8be021501e538ef3370360d475634b33c337a669e4fed1432022ee0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:0ecde15c39d69ebf9bb8dca199c6d78a7b2d75267e765619605efba1530f0495", "content": "The `ChatClient` is created using a `ChatClient.Builder` object.\nYou can obtain an autoconfigured `ChatClient.Builder` instance for any xref:api/chatmodel.adoc[ChatModel] Spring Boot autoconfiguration or create one programmatically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Creating a ChatClient", "heading_level": 2, "file_order": 97, "section_index": 1, "content_hash": "0ecde15c39d69ebf9bb8dca199c6d78a7b2d75267e765619605efba1530f0495", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:c618ba585a6ea78eb443c4c91391ad2d761cc3629a1927a498c14ea54bb24e6a", "content": "In the most simple use case, Spring AI provides Spring Boot autoconfiguration, creating a prototype `ChatClient.Builder` bean for you to inject into your class.\nHere is a simple example of retrieving a `String` response to a simple user request.\n\n[source,java]\n----\n@RestController\nclass MyController {\n\n private final ChatClient chatClient;\n\n public MyController(ChatClient.Builder chatClientBuilder) {\n this.chatClient = chatClientBuilder.build();\n }\n\n @GetMapping(\"/ai\")\n String generation(String userInput) {\n return this.chatClient.prompt()\n .user(userInput)\n .call()\n .content();\n }\n}\n----\n\nIn this simple example, the user input sets the contents of the user message.\nThe `call()` method sends a request to the AI model, and the `content()` method returns the AI model's response as a `String`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Using an autoconfigured ChatClient.Builder", "heading_level": 3, "file_order": 97, "section_index": 2, "content_hash": "c618ba585a6ea78eb443c4c91391ad2d761cc3629a1927a498c14ea54bb24e6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:5c93d5c378e6781b56103124a12804420d00b8af307560e2841c2917883d9b04", "content": "There are several scenarios where you might need to work with multiple chat models in a single application:\n\n* Using different models for different types of tasks (e.g., a powerful model for complex reasoning and a faster, cheaper model for simpler tasks)\n* Implementing fallback mechanisms when one model service is unavailable\n* A/B testing different models or configurations\n* Providing users with a choice of models based on their preferences\n* Combining specialized models (one for code generation, another for creative content, etc.)\n\nBy default, Spring AI autoconfigures a single `ChatClient.Builder` bean.\nHowever, you may need to work with multiple chat models in your application.\nHere's how to handle this scenario:\n\nIn all cases, you need to disable the `ChatClient.Builder` autoconfiguration by setting the property `spring.ai.chat.client.enabled=false`.\n\nThis allows you to create multiple `ChatClient` instances manually.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Working with Multiple Chat Models", "heading_level": 3, "file_order": 97, "section_index": 3, "content_hash": "5c93d5c378e6781b56103124a12804420d00b8af307560e2841c2917883d9b04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:f63a8e9c8dbbdcaf937ae7d912f7df11dcf90865b3031774ed889b2613b7c9f2", "content": "This section covers a common use case where you need to create multiple ChatClient instances that all use the same underlying model type but with different configurations.\n\n[source,java]\n----\nChatModel myChatModel = ... // already autoconfigured by Spring Boot\nChatClient chatClient = ChatClient.create(myChatModel);\n\nChatClient.Builder builder = ChatClient.builder(myChatModel);\nChatClient customChatClient = builder\n .defaultSystemPrompt(\"You are a helpful assistant.\")\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Multiple ChatClients with a Single Model Type", "heading_level": 4, "file_order": 97, "section_index": 4, "content_hash": "f63a8e9c8dbbdcaf937ae7d912f7df11dcf90865b3031774ed889b2613b7c9f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:ce8b918ad848db88e70676afde11e3db538ccd97c1e0aa9f95c6500fdb89b741", "content": "When working with multiple AI models, you can define separate `ChatClient` beans for each model:\n\n[source,java]\n----\nimport org.springframework.ai.chat.ChatClient;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class ChatClientConfig {\n\n @Bean\n public ChatClient openAiChatClient(OpenAiChatModel chatModel) {\n return ChatClient.create(chatModel);\n }\n\n @Bean\n public ChatClient anthropicChatClient(AnthropicChatModel chatModel) {\n return ChatClient.create(chatModel);\n }\n}\n----\n\nYou can then inject these beans into your application components using the `@Qualifier` annotation:\n\n[source,java]\n----\n\n@Configuration\npublic class ChatClientExample {\n\n @Bean\n CommandLineRunner cli(\n @Qualifier(\"openAiChatClient\") ChatClient openAiChatClient,\n @Qualifier(\"anthropicChatClient\") ChatClient anthropicChatClient) {\n\n return args -> {\n var scanner = new Scanner(System.in);\n ChatClient chat;\n\n // Model selection\n System.out.println(\"\\nSelect your AI model:\");\n System.out.println(\"1. OpenAI\");\n System.out.println(\"2. Anthropic\");\n System.out.print(\"Enter your choice (1 or 2): \");\n\n String choice = scanner.nextLine().trim();\n\n if (choice.equals(\"1\")) {\n chat = openAiChatClient;\n System.out.println(\"Using OpenAI model\");\n } else {\n chat = anthropicChatClient;\n System.out.println(\"Using Anthropic model\");\n }\n\n // Use the selected chat client\n System.out.print(\"\\nEnter your question: \");\n String input = scanner.nextLine();\n String response = chat.prompt(input).call().content();\n System.out.println(\"ASSISTANT: \" + response);\n\n scanner.close();\n };\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "ChatClients for Different Model Types", "heading_level": 4, "file_order": 97, "section_index": 5, "content_hash": "ce8b918ad848db88e70676afde11e3db538ccd97c1e0aa9f95c6500fdb89b741", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:e4e15dcfde606981f7485c8524d0be0c6dc8461d5bf37d8db5663c1475fd002b", "content": "The `OpenAiApi` and `OpenAiChatModel` classes provide a `mutate()` method that allows you to create variations of existing instances with different properties.\nThis is particularly useful when you need to work with multiple OpenAI-compatible APIs.\n\n[source,java]\n----\n\n@Service\npublic class MultiModelService {\n\n private static final Logger logger = LoggerFactory.getLogger(MultiModelService.class);\n\n @Autowired\n private OpenAiChatModel baseChatModel;\n\n @Autowired\n private OpenAiApi baseOpenAiApi;\n\n public void multiClientFlow() {\n try {\n // Derive a new OpenAiApi for Groq (Llama3)\n OpenAiApi groqApi = baseOpenAiApi.mutate()\n .baseUrl(\"https://api.groq.com/openai\")\n .apiKey(System.getenv(\"GROQ_API_KEY\"))\n .build();\n\n // Derive a new OpenAiApi for OpenAI GPT-4\n OpenAiApi gpt4Api = baseOpenAiApi.mutate()\n .baseUrl(\"https://api.openai.com\")\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n\n // Derive a new OpenAiChatModel for Groq\n OpenAiChatModel groqModel = baseChatModel.mutate()\n .openAiApi(groqApi)\n .defaultOptions(OpenAiChatOptions.builder().model(\"llama3-70b-8192\").temperature(0.5).build())\n .build();\n\n // Derive a new OpenAiChatModel for GPT-4\n OpenAiChatModel gpt4Model = baseChatModel.mutate()\n .openAiApi(gpt4Api)\n .defaultOptions(OpenAiChatOptions.builder().model(\"gpt-4\").temperature(0.7).build())\n .build();\n\n // Simple prompt for both models\n String prompt = \"What is the capital of France?\";\n\n String groqResponse = ChatClient.builder(groqModel).build().prompt(prompt).call().content();\n String gpt4Response = ChatClient.builder(gpt4Model).build().prompt(prompt).call().content();\n\n logger.info(\"Groq (Llama3) response: {}\", groqResponse);\n logger.info(\"OpenAI GPT-4 response: {}\", gpt4Response);\n }\n catch (Exception e) {\n logger.error(\"Error in multi-client flow\", e);\n }\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Multiple OpenAI-Compatible API Endpoints", "heading_level": 4, "file_order": 97, "section_index": 6, "content_hash": "e4e15dcfde606981f7485c8524d0be0c6dc8461d5bf37d8db5663c1475fd002b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:242e9cef46fcfa1d827785f9d53d5885ba0819570ed27754f70c82103fc1ea1f", "content": "The `ChatClient` fluent API allows you to create a prompt in three distinct ways using an overloaded `prompt` method to initiate the fluent API:\n\n* `prompt()`: This method with no arguments lets you start using the fluent API, allowing you to build up user, system, and other parts of the prompt.\n\n* `prompt(Prompt prompt)`: This method accepts a `Prompt` argument, letting you pass in a `Prompt` instance that you have created using the Prompt's non-fluent APIs.\n\n* `prompt(String content)`: This is a convenience method similar to the previous overload. It takes the user's text content.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "ChatClient Fluent API", "heading_level": 2, "file_order": 97, "section_index": 7, "content_hash": "242e9cef46fcfa1d827785f9d53d5885ba0819570ed27754f70c82103fc1ea1f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:601e3b351268e9df7eb5368129faaf95240133418db88a706a56d803cef81cf0", "content": "The `ChatClient` API offers several ways to format the response from the AI Model using the fluent API.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "ChatClient Responses", "heading_level": 2, "file_order": 97, "section_index": 8, "content_hash": "601e3b351268e9df7eb5368129faaf95240133418db88a706a56d803cef81cf0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:9d336074f439cec0ddda599e65814c52655d6b4ee0204367843767f65b5464a9", "content": "The response from the AI model is a rich structure defined by the type `xref:api/chatmodel.adoc#ChatResponse[ChatResponse]`.\nIt includes metadata about how the response was generated and can also contain multiple responses, known as xref:api/chatmodel.adoc#Generation[Generation]s, each with its own metadata.\nThe metadata includes the number of tokens (each token is approximately 3/4 of a word) used to create the response.\nThis information is important because hosted AI models charge based on the number of tokens used per request.\n\nAn example to return the `ChatResponse` object that contains the metadata is shown below by invoking `chatResponse()` after the `call()` method.\n\n[source,java]\n----\nChatResponse chatResponse = chatClient.prompt()\n .user(\"Tell me a joke\")\n .call()\n .chatResponse();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Returning a ChatResponse", "heading_level": 3, "file_order": 97, "section_index": 9, "content_hash": "9d336074f439cec0ddda599e65814c52655d6b4ee0204367843767f65b5464a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:255d5ece497c38ade2297ef163f6902d7efcf0aa70f782464ac354fc6cbce7db", "content": "You often want to return an entity class that is mapped from the returned `String`.\nThe `entity()` method provides this functionality.\n\nFor example, given the Java record:\n\n[source,java]\n----\nrecord ActorFilms(String actor, List<String> movies) {}\n----\n\nYou can easily map the AI model's output to this record using the `entity()` method, as shown below:\n\n[source,java]\n----\nActorFilms actorFilms = chatClient.prompt()\n .user(\"Generate the filmography for a random actor.\")\n .call()\n .entity(ActorFilms.class);\n----\n\nThere is also an overloaded `entity` method with the signature `entity(ParameterizedTypeReference<T> type)` that lets you specify types such as generic Lists:\n\n[source,java]\n----\nList<ActorFilms> actorFilms = chatClient.prompt()\n .user(\"Generate the filmography of 5 movies for Tom Hanks and Bill Murray.\")\n .call()\n .entity(new ParameterizedTypeReference<List<ActorFilms>>() {});\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Returning an Entity", "heading_level": 3, "file_order": 97, "section_index": 10, "content_hash": "255d5ece497c38ade2297ef163f6902d7efcf0aa70f782464ac354fc6cbce7db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:d2fd5016ff2a3b461030a6878967dcb5b6b588ac47ef29409e42d1173a9cc237", "content": "As more AI models support structured output natively, you can take advantage of this feature by using the `AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT` advisor parameter when calling the `ChatClient`.\nYou can use the `defaultAdvisors()` method on the `ChatClient.Builder` to set this parameter globally for all calls or set it per call as shown below:\n\n[source,java]\n----\nActorFilms actorFilms = chatClient.prompt()\n .advisors(AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT)\n .user(\"Generate the filmography for a random actor.\")\n .call()\n .entity(ActorFilms.class);\n----\n\nNOTE: Some AI models such as OpenAI don't support arrays of objects natively.\nIn such cases, you can use the Spring AI default structured output conversion.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Native Structured Output", "heading_level": 4, "file_order": 97, "section_index": 11, "content_hash": "d2fd5016ff2a3b461030a6878967dcb5b6b588ac47ef29409e42d1173a9cc237", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:25a5d36f302b4526ac2f34cb10b2d7c18c39b90ed987d81b3eb14c537aa385c8", "content": "The `stream()` method lets you get an asynchronous response as shown below:\n\n[source,java]\n----\n\nFlux<String> output = chatClient.prompt()\n .user(\"Tell me a joke\")\n .stream()\n .content();\n----\n\nYou can also stream the `ChatResponse` using the method `Flux<ChatResponse> chatResponse()`.\n\nIn the future, we will offer a convenience method that will let you return a Java entity with the reactive `stream()` method.\nIn the meantime, you should use the xref:api/structured-output-converter.adoc#StructuredOutputConverter[Structured Output Converter] to convert the aggregated response explicitly as shown below.\nThis also demonstrates the use of parameters in the fluent API that will be discussed in more detail in a later section of the documentation.\n\n[source,java]\n----\nvar converter = new BeanOutputConverter<>(new ParameterizedTypeReference<List<ActorsFilms>>() {});\n\nFlux<String> flux = this.chatClient.prompt()\n .user(u -> u.text(\"\"\"\n Generate the filmography for a random actor.\n {format}\n \"\"\")\n .param(\"format\", this.converter.getFormat()))\n .stream()\n .content();\n\nString content = this.flux.collectList().block().stream().collect(Collectors.joining());\n\nList<ActorsFilms> actorFilms = this.converter.convert(this.content);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Streaming Responses", "heading_level": 3, "file_order": 97, "section_index": 12, "content_hash": "25a5d36f302b4526ac2f34cb10b2d7c18c39b90ed987d81b3eb14c537aa385c8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:069447d8c92d1276bdb7e31b66597456fe73fa5285b3c5ffc39d472d92ef27e8", "content": "The `ChatClient` fluent API lets you provide user and system text as templates with variables that are replaced at runtime.\n\n[source,java]\n----\nString answer = ChatClient.create(chatModel).prompt()\n .user(u -> u\n .text(\"Tell me the names of 5 movies whose soundtrack was composed by {composer}\")\n .param(\"composer\", \"John Williams\"))\n .call()\n .content();\n----\n\nInternally, the ChatClient uses the `PromptTemplate` class to handle the user and system text and replace the variables with the values provided at runtime relying on a given `TemplateRenderer` implementation.\nBy default, Spring AI uses the `StTemplateRenderer` implementation, which is based on the open-source https://www.stringtemplate.org/[StringTemplate] engine developed by Terence Parr.\n\nSpring AI also provides a `NoOpTemplateRenderer` for cases where no template processing is desired.\n\nNOTE: The `TemplateRenderer` configured directly on the `ChatClient` (via `.templateRenderer()`) applies only to the prompt content defined directly in the `ChatClient` builder chain (e.g., via `.user()`, `.system()`).\nIt does *not* affect templates used internally by xref:api/retrieval-augmented-generation.adoc#_questionansweradvisor[Advisors] like `QuestionAnswerAdvisor`, which have their own template customization mechanisms (see xref:api/retrieval-augmented-generation.adoc#_custom_template[Custom Advisor Templates]).\n\nIf you'd rather use a different template engine, you can provide a custom implementation of the `TemplateRenderer` interface directly to the ChatClient. You can also keep using the default `StTemplateRenderer`, but with a custom configuration.\n\nFor example, by default, template variables are identified by the `{}` syntax.\nIf you're planning to include JSON in your prompt, you might want to use a different syntax to avoid conflicts with JSON syntax. For example, you can use the `<` and `>` delimiters.\n\n[source,java]\n----\nString answer = ChatClient.create(chatModel).prompt()\n .user(u -> u\n .text(\"Tell me the names of 5 movies whose soundtrack was composed by <composer>\")\n .param(\"composer\", \"John Williams\"))\n .templateRenderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Prompt Templates", "heading_level": 2, "file_order": 97, "section_index": 13, "content_hash": "069447d8c92d1276bdb7e31b66597456fe73fa5285b3c5ffc39d472d92ef27e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:f5bb545a82658c5167d0e900ee4509f4321a413afb678bd56fe053c90ee25617", "content": "After specifying the `call()` method on `ChatClient`, there are a few different options for the response type.\n\n* `String content()`: returns the String content of the response\n* `ChatResponse chatResponse()`: returns the `ChatResponse` object that contains multiple generations and also metadata about the response, for example how many token were used to create the response.\n* `ChatClientResponse chatClientResponse()`: returns a `ChatClientResponse` object that contains the `ChatResponse` object and the ChatClient execution context, giving you access to additional data used during the execution of advisors (e.g. the relevant documents retrieved in a RAG flow).\n* `entity()` to return a Java type\n** `entity(ParameterizedTypeReference<T> type)`: used to return a `Collection` of entity types.\n** `entity(Class<T> type)`: used to return a specific entity type.\n** `entity(StructuredOutputConverter<T> structuredOutputConverter)`: used to specify an instance of a `StructuredOutputConverter` to convert a `String` to an entity type.\n* `responseEntity()` to return both the `ChatResponse` and a Java type. This is useful when you need access to both the complete AI model response (with metadata and generations) and the structured output entity in a single call.\n** `responseEntity(Class<T> type)`: used to return a `ResponseEntity` containing both the complete `ChatResponse` object and a specific entity type.\n** `responseEntity(ParameterizedTypeReference<T> type)`: used to return a `ResponseEntity` containing both the complete `ChatResponse` object and a `Collection` of entity types.\n** `responseEntity(StructuredOutputConverter<T> structuredOutputConverter)`: used to return a `ResponseEntity` containing both the complete `ChatResponse` object and an entity converted using a specified `StructuredOutputConverter`.\n\nYou can also invoke the `stream()` method instead of `call()`.\n\nNOTE: Calling the `call()` method does not actually trigger the AI model execution. Instead, it only instructs Spring AI whether to use synchronous or streaming calls.\nThe actual AI model invocation occurs when methods such as `content()`, `chatResponse()`, and `responseEntity()` are called.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "call() return values", "heading_level": 2, "file_order": 97, "section_index": 14, "content_hash": "f5bb545a82658c5167d0e900ee4509f4321a413afb678bd56fe053c90ee25617", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:81d99ba6d75322c343bab2c8a6d64a657f691008e801caea44350c1d9b8f4158", "content": "After specifying the `stream()` method on `ChatClient`, there are a few options for the response type:\n\n* `Flux<String> content()`: Returns a `Flux` of the string being generated by the AI model.\n* `Flux<ChatResponse> chatResponse()`: Returns a `Flux` of the `ChatResponse` object, which contains additional metadata about the response.\n* `Flux<ChatClientResponse> chatClientResponse()`: returns a `Flux` of the `ChatClientResponse` object that contains the `ChatResponse` object and the ChatClient execution context, giving you access to additional data used during the execution of advisors (e.g. the relevant documents retrieved in a RAG flow).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "stream() return values", "heading_level": 2, "file_order": 97, "section_index": 15, "content_hash": "81d99ba6d75322c343bab2c8a6d64a657f691008e801caea44350c1d9b8f4158", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:c55af121da0060a16227824233c5a1e0002859afbd57d3c2fab807c0a750569f", "content": "The ChatClient supports adding metadata to both user and system messages.\nMetadata provides additional context and information about messages that can be used by the AI model or downstream processing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Message Metadata", "heading_level": 2, "file_order": 97, "section_index": 16, "content_hash": "c55af121da0060a16227824233c5a1e0002859afbd57d3c2fab807c0a750569f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:caaac2ec7783ed19fabceb7c39f88737b6d7dd8e098e517ad629290ea64ca227", "content": "You can add metadata to user messages using the `metadata()` methods:\n\n[source,java]\n----\nString response = chatClient.prompt()\n .user(u -> u.text(\"What's the weather like?\")\n .metadata(\"messageId\", \"msg-123\")\n .metadata(\"userId\", \"user-456\")\n .metadata(\"priority\", \"high\"))\n .call()\n .content();\n\nMap<String, Object> userMetadata = Map.of(\n \"messageId\", \"msg-123\",\n \"userId\", \"user-456\",\n \"timestamp\", System.currentTimeMillis()\n);\n\nString response = chatClient.prompt()\n .user(u -> u.text(\"What's the weather like?\")\n .metadata(userMetadata))\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Adding Metadata to User Messages", "heading_level": 3, "file_order": 97, "section_index": 17, "content_hash": "caaac2ec7783ed19fabceb7c39f88737b6d7dd8e098e517ad629290ea64ca227", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:fde41a26e9ba8e8806f08d5e4c5c64c22eca8c26aa9e874b14d533b086b9496a", "content": "Similarly, you can add metadata to system messages:\n\n[source,java]\n----\nString response = chatClient.prompt()\n .system(s -> s.text(\"You are a helpful assistant.\")\n .metadata(\"version\", \"1.0\")\n .metadata(\"model\", \"gpt-4\"))\n .user(\"Tell me a joke\")\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Adding Metadata to System Messages", "heading_level": 3, "file_order": 97, "section_index": 18, "content_hash": "fde41a26e9ba8e8806f08d5e4c5c64c22eca8c26aa9e874b14d533b086b9496a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:3f8cae2db8dd08763ca2853dab547b52fd2257d7d49917f695d20bdd987f02c8", "content": "You can also configure default metadata at the ChatClient builder level:\n\n[source,java]\n----\n@Configuration\nclass Config {\n @Bean\n ChatClient chatClient(ChatClient.Builder builder) {\n return builder\n .defaultSystem(s -> s.text(\"You are a helpful assistant\")\n .metadata(\"assistantType\", \"general\")\n .metadata(\"version\", \"1.0\"))\n .defaultUser(u -> u.text(\"Default user context\")\n .metadata(\"sessionId\", \"default-session\"))\n .build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Default Metadata Support", "heading_level": 3, "file_order": 97, "section_index": 19, "content_hash": "3f8cae2db8dd08763ca2853dab547b52fd2257d7d49917f695d20bdd987f02c8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:116bb3a2e5c6f17739d3f2b1ec00ee4509e2cd74234abd2bcced3c140ab47b9e", "content": "The ChatClient validates metadata to ensure data integrity:\n\n* Metadata keys cannot be null or empty\n* Metadata values cannot be null\n* When passing a Map, neither keys nor values can contain null elements\n\n[source,java]\n----\nchatClient.prompt()\n .user(u -> u.text(\"Hello\")\n .metadata(null, \"value\")) // Invalid: null key\n .call()\n .content();\n\nchatClient.prompt()\n .user(u -> u.text(\"Hello\")\n .metadata(\"key\", null)) // Invalid: null value\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Metadata Validation", "heading_level": 3, "file_order": 97, "section_index": 20, "content_hash": "116bb3a2e5c6f17739d3f2b1ec00ee4509e2cd74234abd2bcced3c140ab47b9e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:dd8c19d5aa978098b39c2ed52d1f501dd3935f1ca0282310f9f9d5681b563cd5", "content": "The metadata is included in the generated UserMessage and SystemMessage objects and can be accessed through the message's `getMetadata()` method.\nThis is particularly useful when processing messages in advisors or when examining the conversation history.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Accessing Metadata", "heading_level": 3, "file_order": 97, "section_index": 21, "content_hash": "dd8c19d5aa978098b39c2ed52d1f501dd3935f1ca0282310f9f9d5681b563cd5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:22958f98a35c955c5024e0f8b6318ef0626d0f5d0d09e85b91ca29e8e5663513", "content": "Creating a `ChatClient` with a default system text in an `@Configuration` class simplifies runtime code.\nBy setting defaults, you only need to specify the user text when calling `ChatClient`, eliminating the need to set a system text for each request in your runtime code path.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Using Defaults", "heading_level": 2, "file_order": 97, "section_index": 22, "content_hash": "22958f98a35c955c5024e0f8b6318ef0626d0f5d0d09e85b91ca29e8e5663513", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:b23f736501cf53e1426b2fb3d4c37f4bdf5f25ac9a08bbb6175aea0ced2e7895", "content": "In the following example, we will configure the system text to always reply in a pirate's voice.\nTo avoid repeating the system text in runtime code, we will create a `ChatClient` instance in a `@Configuration` class.\n\n[source,java]\n----\n@Configuration\nclass Config {\n\n @Bean\n ChatClient chatClient(ChatClient.Builder builder) {\n return builder.defaultSystem(\"You are a friendly chat bot that answers question in the voice of a Pirate\")\n .build();\n }\n\n}\n----\n\nand a `@RestController` to invoke it:\n\n[source,java]\n----\n@RestController\nclass AIController {\n\n\tprivate final ChatClient chatClient;\n\n\tAIController(ChatClient chatClient) {\n this.chatClient = chatClient;\n\t}\n\n\t@GetMapping(\"/ai/simple\")\n\tpublic Map<String, String> completion(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message) {\n return Map.of(\"completion\", this.chatClient.prompt().user(message).call().content());\n\t}\n}\n----\n\nWhen calling the application endpoint via curl, the result is:\n\n[source,bash]\n----\n❯ curl localhost:8080/ai/simple\n{\"completion\":\"Why did the pirate go to the comedy club? To hear some arrr-rated jokes! Arrr, matey!\"}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Default System Text", "heading_level": 3, "file_order": 97, "section_index": 23, "content_hash": "b23f736501cf53e1426b2fb3d4c37f4bdf5f25ac9a08bbb6175aea0ced2e7895", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:651b23f5ce29e9e396cf8fdd4d3a2b7e31e97dfe99e94757877008b4459da3aa", "content": "In the following example, we will use a placeholder in the system text to specify the voice of the completion at runtime instead of design time.\n\n[source,java]\n----\n@Configuration\nclass Config {\n\n @Bean\n ChatClient chatClient(ChatClient.Builder builder) {\n return builder.defaultSystem(\"You are a friendly chat bot that answers question in the voice of a {voice}\")\n .build();\n }\n\n}\n----\n\n[source,java]\n----\n@RestController\nclass AIController {\n\tprivate final ChatClient chatClient;\n\n\tAIController(ChatClient chatClient) {\n this.chatClient = chatClient;\n\t}\n\n\t@GetMapping(\"/ai\")\n\tMap<String, String> completion(@RequestParam(value = \"message\", defaultValue = \"Tell me a joke\") String message, String voice) {\n return Map.of(\"completion\",\n this.chatClient.prompt()\n .system(sp -> sp.param(\"voice\", voice))\n .user(message)\n .call()\n .content());\n\t}\n\n}\n----\n\nWhen calling the application endpoint via httpie, the result is:\n\n[source.bash]\n----\nhttp localhost:8080/ai voice=='Robert DeNiro'\n{\n \"completion\": \"You talkin' to me? Okay, here's a joke for ya: Why couldn't the bicycle stand up by itself? Because it was two tired! Classic, right?\"\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Default System Text with parameters", "heading_level": 3, "file_order": 97, "section_index": 24, "content_hash": "651b23f5ce29e9e396cf8fdd4d3a2b7e31e97dfe99e94757877008b4459da3aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:dbcccfb131947760247349fc1732cba0452b5afbd2e11ac27bd88cc00d3a7572", "content": "At the `ChatClient.Builder` level, you can specify the default prompt configuration.\n\n* `defaultOptions(ChatOptions chatOptions)`: Pass in either portable options defined in the `ChatOptions` class or model-specific options such as those in `OpenAiChatOptions`.\nFor more information on model-specific `ChatOptions` implementations, refer to the JavaDocs.\n\n* `defaultFunction(String name, String description, java.util.function.Function<I, O> function)`: The `name` is used to refer to the function in user text.\nThe `description` explains the function's purpose and helps the AI model choose the correct function for an accurate response.\nThe `function` argument is a Java function instance that the model will execute when necessary.\n\n* `defaultFunctions(String... functionNames)`: The bean names of `java.util.Function`s defined in the application context.\n\n* `defaultUser(String text)`, `defaultUser(Resource text)`, `defaultUser(Consumer<UserSpec> userSpecConsumer)`: These methods let you define the user text.\nThe `Consumer<UserSpec>` allows you to use a lambda to specify the user text and any default parameters.\n\n* `defaultAdvisors(Advisor... advisor)`: Advisors allow modification of the data used to create the `Prompt`.\nThe `QuestionAnswerAdvisor` implementation enables the pattern of `Retrieval Augmented Generation` by appending the prompt with context information related to the user text.\n\n* `defaultAdvisors(Consumer<AdvisorSpec> advisorSpecConsumer)`: This method allows you to define a `Consumer` to configure multiple advisors using the `AdvisorSpec`. Advisors can modify the data used to create the final `Prompt`.\nThe `Consumer<AdvisorSpec>` lets you specify a lambda to add advisors, such as `QuestionAnswerAdvisor`, which supports `Retrieval Augmented Generation` by appending the prompt with relevant context information based on the user text.\n\nYou can override these defaults at runtime using the corresponding methods without the `default` prefix.\n\n* `options(ChatOptions chatOptions)`\n\n* `function(String name, String description,\njava.util.function.Function<I, O> function)`\n\n* `functions(String... functionNames)`\n\n* `user(String text)`, `user(Resource text)`, `user(Consumer<UserSpec> userSpecConsumer)`\n\n* `advisors(Advisor... advisor)`\n\n* `advisors(Consumer<AdvisorSpec> advisorSpecConsumer)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Other defaults", "heading_level": 3, "file_order": 97, "section_index": 25, "content_hash": "dbcccfb131947760247349fc1732cba0452b5afbd2e11ac27bd88cc00d3a7572", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:2544155faacc50d5d78546398d2dc4a82766014aa00a88492e2064b6b6e5c737", "content": "The xref:api/advisors.adoc[Advisors API] provides a flexible and powerful way to intercept, modify, and enhance AI-driven interactions in your Spring applications.\n\nA common pattern when calling an AI model with user text is to append or augment the prompt with contextual data.\n\nThis contextual data can be of different types. Common types include:\n\n* **Your own data**: This is data the AI model hasn't been trained on.\nEven if the model has seen similar data, the appended contextual data takes precedence in generating the response.\n\n* **Conversational history**: The chat model's API is stateless.\nIf you tell the AI model your name, it won't remember it in subsequent interactions.\nConversational history must be sent with each request to ensure previous interactions are considered when generating a response.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Advisors", "heading_level": 2, "file_order": 97, "section_index": 26, "content_hash": "2544155faacc50d5d78546398d2dc4a82766014aa00a88492e2064b6b6e5c737", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:1794d6bd8811b19c9ea5121fd2ab3d61f03b6df2ce2ea7f559ad644bf897d826", "content": "The ChatClient fluent API provides an `AdvisorSpec` interface for configuring advisors.\nThis interface offers methods to add parameters, set multiple parameters at once, and add one or more advisors to the chain.\n\n[source,java]\n----\ninterface AdvisorSpec {\n AdvisorSpec param(String k, Object v);\n AdvisorSpec params(Map<String, Object> p);\n AdvisorSpec advisors(Advisor... advisors);\n AdvisorSpec advisors(List<Advisor> advisors);\n}\n----\n\nIMPORTANT: The order in which advisors are added to the chain is crucial, as it determines the sequence of their execution.\nEach advisor modifies the prompt or the context in some way, and the changes made by one advisor are passed on to the next in the chain.\n\n[source,java]\n----\nChatClient.builder(chatModel)\n .build()\n .prompt()\n .advisors(\n MessageChatMemoryAdvisor.builder(chatMemory).build(),\n QuestionAnswerAdvisor.builder(vectorStore).build()\n )\n .user(userText)\n .call()\n .content();\n----\n\nIn this configuration, the `MessageChatMemoryAdvisor` will be executed first, adding the conversation history to the prompt.\nThen, the `QuestionAnswerAdvisor` will perform its search based on the user's question and the added conversation history, potentially providing more relevant results.\n\nxref:ROOT:api/retrieval-augmented-generation.adoc#_questionansweradvisor[Learn about Question Answer Advisor]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Advisor Configuration in ChatClient", "heading_level": 3, "file_order": 97, "section_index": 27, "content_hash": "1794d6bd8811b19c9ea5121fd2ab3d61f03b6df2ce2ea7f559ad644bf897d826", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:b20cbf869f692650e9397a6d04579a9d656c374a5c1217239ec3d25cd04089a0", "content": "Refer to the xref:ROOT:api/retrieval-augmented-generation.adoc[Retrieval Augmented Generation] guide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Retrieval Augmented Generation", "heading_level": 3, "file_order": 97, "section_index": 28, "content_hash": "b20cbf869f692650e9397a6d04579a9d656c374a5c1217239ec3d25cd04089a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:bc5b5f9950ae990f19745253e08e3c019b54069037ee78251fd61af32a150a48", "content": "The `SimpleLoggerAdvisor` is an advisor that logs the `request` and `response` data of the `ChatClient`.\nThis can be useful for debugging and monitoring your AI interactions.\n\nTIP: Spring AI supports observability for LLM and vector store interactions.\nRefer to the xref:observability/index.adoc[Observability] guide for more information.\n\nTo enable logging, add the `SimpleLoggerAdvisor` to the advisor chain when creating your ChatClient.\nIt's recommended to add it toward the end of the chain:\n\n[source,java]\n----\nChatResponse response = ChatClient.create(chatModel).prompt()\n .advisors(new SimpleLoggerAdvisor())\n .user(\"Tell me a joke?\")\n .call()\n .chatResponse();\n----\n\nTo see the logs, set the logging level for the advisor package to `DEBUG`:\n\n----\nlogging.level.org.springframework.ai.chat.client.advisor=DEBUG\n----\n\nAdd this to your `application.properties` or `application.yaml` file.\n\nYou can customize what data from `AdvisedRequest` and `ChatResponse` is logged by using the following constructor:\n\n[source,java]\n----\nSimpleLoggerAdvisor(\n Function<ChatClientRequest, String> requestToString,\n Function<ChatResponse, String> responseToString,\n int order\n)\n----\n\nExample usage:\n\n[source,java]\n----\nSimpleLoggerAdvisor customLogger = new SimpleLoggerAdvisor(\n request -> \"Custom request: \" + request.prompt().getUserMessage(),\n response -> \"Custom response: \" + response.getResult(),\n 0\n);\n----\n\nThis allows you to tailor the logged information to your specific needs.\n\nTIP: Be cautious about logging sensitive information in production environments.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Logging", "heading_level": 3, "file_order": 97, "section_index": 29, "content_hash": "bc5b5f9950ae990f19745253e08e3c019b54069037ee78251fd61af32a150a48", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:b7a02cd049de7c4f098de78a3481ec25423c5f602cc1e75cbe3e7aa665ede113", "content": "The interface `ChatMemory` represents a storage for chat conversation memory.\nIt provides methods to add messages to a conversation, retrieve messages from a conversation, and clear the conversation history.\n\nThere is currently one built-in implementation: `MessageWindowChatMemory`.\n\n`MessageWindowChatMemory` is a chat memory implementation that maintains a window of messages up to a specified maximum size (default: 20 messages).\nWhen the number of messages exceeds this limit, older messages are evicted, but system messages are preserved.\nIf a new system message is added, all previous system messages are removed from memory.\nThis ensures that the most recent context is always available for the conversation while keeping memory usage bounded.\n\nThe `MessageWindowChatMemory` is backed by the `ChatMemoryRepository` abstraction which provides storage implementations for the chat conversation memory.\nThere are several implementations available, including the `InMemoryChatMemoryRepository`, `JdbcChatMemoryRepository`, `CassandraChatMemoryRepository`, `Neo4jChatMemoryRepository`, `CosmosDBChatMemoryRepository`, `MongoChatMemoryRepository`, and `RedisChatMemoryRepository`.\n\nFor more details and usage examples, see the xref:api/chat-memory.adoc[Chat Memory] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Chat Memory", "heading_level": 2, "file_order": 97, "section_index": 30, "content_hash": "b7a02cd049de7c4f098de78a3481ec25423c5f602cc1e75cbe3e7aa665ede113", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:42f70a3ee21b1f9c7932ad3eccb3cdb1ded1c924162cf20e9bcea9e3a6616f04", "content": "The combined use of imperative and reactive programming models in `ChatClient` is a unique aspect of the API.\nOften an application will be either reactive or imperative, but not both.\n\n* When customizing the HTTP client interactions of a Model implementation, both the RestClient and the WebClient must be configured.\n\n[IMPORTANT]\n====\nDue to a bug in Spring Boot 3.4, the \"spring.http.client.factory=jdk\" property must be set.\nOtherwise, it's set to \"reactor\" by default, which breaks certain AI workflows like the ImageModel.\n====\n\n* Streaming is only supported via the Reactive stack.\nImperative applications must include the Reactive stack for this reason (e.g. spring-boot-starter-webflux).\n* Non-streaming is only supportive via the Servlet stack.\nReactive applications must include the Servlet stack for this reason (e.g. spring-boot-starter-web) and expect some calls to be blocking.\n* Tool calling is imperative, leading to blocking workflows.\nThis also results in partial/interrupted Micrometer observations (e.g. the ChatClient spans and the tool calling spans are not connected, with the first one remaining incomplete for that reason).\n* The built-in advisors perform blocking operations for standards calls, and non-blocking operations for streaming calls.\nThe Reactor Scheduler used for the advisor streaming calls can be configured via the Builder on each Advisor class.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatclient.adoc", "title": "chatclient", "heading": "Implementation Notes", "heading_level": 2, "file_order": 97, "section_index": 31, "content_hash": "42f70a3ee21b1f9c7932ad3eccb3cdb1ded1c924162cf20e9bcea9e3a6616f04", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatclient.adoc"}}
{"id": "sha256:b7d3d32e161123a884d0a3e31d5be14c1796c1b101587f538677874a25f014e7", "content": "[[ChatModel]]\n\nThe Chat Model API offers developers the ability to integrate AI-powered chat completion capabilities into their applications. It leverages pre-trained language models, such as GPT (Generative Pre-trained Transformer), to generate human-like responses to user inputs in natural language.\n\nThe API typically works by sending a prompt or partial conversation to the AI model, which then generates a completion or continuation of the conversation based on its training data and understanding of natural language patterns. The completed response is then returned to the application, which can present it to the user or use it for further processing.\n\nThe `Spring AI Chat Model API` is designed to be a simple and portable interface for interacting with various xref:concepts.adoc#_models[AI Models], allowing developers to switch between different models with minimal code changes.\nThis design aligns with Spring's philosophy of modularity and interchangeability.\n\nAlso with the help of companion classes like `Prompt` for input encapsulation and `ChatResponse` for output handling, the Chat Model API unifies the communication with AI Models.\nIt manages the complexity of request preparation and response parsing, offering a direct and simplified API interaction.\n\nYou can find more about available implementations in the xref:api/chatmodel.adoc#_available_implementations[Available Implementations] section as well as detailed comparison in the xref:api/chat/comparison.adoc[Chat Models Comparison] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "chatmodel", "heading_level": 1, "file_order": 98, "section_index": 0, "content_hash": "b7d3d32e161123a884d0a3e31d5be14c1796c1b101587f538677874a25f014e7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:b3bc18c7a29aee990724ebf0ef848b8e844296e1a765ca7fec722ea6f4c4e86b", "content": "This section provides a guide to the Spring AI Chat Model API interface and associated classes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "API Overview", "heading_level": 2, "file_order": 98, "section_index": 1, "content_hash": "b3bc18c7a29aee990724ebf0ef848b8e844296e1a765ca7fec722ea6f4c4e86b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:797e739d1ca2fdcaabc8354d4aff181cfee589e4f5118d2aee31b1cb24e1adaf", "content": "Here is the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/model/ChatModel.java[ChatModel] interface definition:\n\n[source,java]\n----\npublic interface ChatModel extends Model<Prompt, ChatResponse>, StreamingChatModel {\n\n\tdefault String call(String message) {...}\n\n @Override\n\tChatResponse call(Prompt prompt);\n}\n\n----\n\nThe `call()` method with a `String` parameter simplifies initial use, avoiding the complexities of the more sophisticated `Prompt` and `ChatResponse` classes.\nIn real-world applications, it is more common to use the `call()` method that takes a `Prompt` instance and returns a `ChatResponse`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "ChatModel", "heading_level": 3, "file_order": 98, "section_index": 2, "content_hash": "797e739d1ca2fdcaabc8354d4aff181cfee589e4f5118d2aee31b1cb24e1adaf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:fbb5ddfa37282abd9df458d06f5e5202f1e8f96f4a9c3964877eb8c256a51795", "content": "Here is the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/model/StreamingChatModel.java[StreamingChatModel] interface definition:\n\n[source,java]\n----\npublic interface StreamingChatModel extends StreamingModel<Prompt, ChatResponse> {\n\n default Flux<String> stream(String message) {...}\n\n @Override\n\tFlux<ChatResponse> stream(Prompt prompt);\n}\n----\n\nThe `stream()` method takes a `String` or `Prompt` parameter similar to `ChatModel` but it streams the responses using the reactive Flux API.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "StreamingChatModel", "heading_level": 3, "file_order": 98, "section_index": 3, "content_hash": "fbb5ddfa37282abd9df458d06f5e5202f1e8f96f4a9c3964877eb8c256a51795", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:d5594ec304fc506830d2bc8fa576375eeaf123ff75c26372ea66537271fc6f6e", "content": "The https://github.com/spring-projects/spring-ai/blob/main/spring-ai-client-chat/src/main/java/org/springframework/ai/chat/prompt/Prompt.java[Prompt] is a `ModelRequest` that encapsulates a list of https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java[Message] objects and optional model request options.\nThe following listing shows a truncated version of the `Prompt` class, excluding constructors and other utility methods:\n\n[source,java]\n----\npublic class Prompt implements ModelRequest<List<Message>> {\n\n private final List<Message> messages;\n\n private ChatOptions modelOptions;\n\n\t@Override\n\tpublic ChatOptions getOptions() {...}\n\n\t@Override\n\tpublic List<Message> getInstructions() {...}\n\n // constructors and utility methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Prompt", "heading_level": 3, "file_order": 98, "section_index": 4, "content_hash": "d5594ec304fc506830d2bc8fa576375eeaf123ff75c26372ea66537271fc6f6e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:203119665ab7da076e2d5d05e715be7265bb73f3e33427bf030d71f0d57d4d15", "content": "The `Message` interface encapsulates a `Prompt` textual content, a collection of metadata attributes, and a categorization known as `MessageType`.\n\nThe interface is defined as follows:\n\n[source,java]\n----\npublic interface Content {\n\n\tString getText();\n\n\tMap<String, Object> getMetadata();\n}\n\npublic interface Message extends Content {\n\n\tMessageType getMessageType();\n}\n----\n\nThe multimodal message types implement also the `MediaContent` interface providing a list of `Media` content objects.\n\n[source,java]\n----\npublic interface MediaContent extends Content {\n\n\tCollection<Media> getMedia();\n\n}\n----\n\nThe `Message` interface has various implementations that correspond to the categories of messages that an AI model can process:\n\nimage::spring-ai-message-api.jpg[Spring AI Message API, width=800, align=\"center\"]\n\nThe chat completion endpoint, distinguish between message categories based on conversational roles, effectively mapped by the `MessageType`.\n\nFor instance, OpenAI recognizes message categories for distinct conversational roles such as `system`, `user`, `function`, or `assistant`.\n\nWhile the term `MessageType` might imply a specific message format, in this context it effectively designates the role a message plays in the dialogue.\n\nFor AI models that do not use specific roles, the `UserMessage` implementation acts as a standard category, typically representing user-generated inquiries or instructions.\nTo understand the practical application and the relationship between `Prompt` and `Message`, especially in the context of these roles or message categories, see the detailed explanations in the xref:api/prompt.adoc[Prompts] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Message", "heading_level": 4, "file_order": 98, "section_index": 5, "content_hash": "203119665ab7da076e2d5d05e715be7265bb73f3e33427bf030d71f0d57d4d15", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:1180e41cb1177b20aa57c21950d595d2495fc3b682e6817365592d4aa4d7ed23", "content": "Represents the options that can be passed to the AI model. The `ChatOptions` class is a subclass of `ModelOptions` and is used to define few portable options that can be passed to the AI model.\nThe `ChatOptions` class is defined as follows:\n\n[source,java]\n----\npublic interface ChatOptions extends ModelOptions {\n\n\tString getModel();\n\tFloat getFrequencyPenalty();\n\tInteger getMaxTokens();\n\tFloat getPresencePenalty();\n\tList<String> getStopSequences();\n\tFloat getTemperature();\n\tInteger getTopK();\n\tFloat getTopP();\n\tChatOptions copy();\n\n}\n----\n\nAdditionally, every model specific ChatModel/StreamingChatModel implementation can have its own options that can be passed to the AI model. For example, the OpenAI Chat Completion model has its own options like `logitBias`, `seed`, and `user`.\n\nThis is a powerful feature that allows developers to use model-specific options when starting the application and then override them at runtime using the `Prompt` request.\n\nSpring AI provides a sophisticated system for configuring and using Chat Models.\nIt allows for default configurations to be set at start-up, while also providing the flexibility to override these settings on a per-request basis.\nThis approach enables developers to easily work with different AI models and adjust parameters as needed, all within a consistent interface provided by the Spring AI framework.\n\nFollowing flow diagram illustrates how Spring AI handles the configuration and execution of Chat Models, combining start-up and runtime options:\n\nimage::chat-options-flow.jpg[align=\"center\", width=\"800px\"]\n\n1. Start-up Configuration - The ChatModel/StreamingChatModel is initialized with \"Start-Up\" Chat Options.\nThese options are set during the ChatModel initialization and are meant to provide default configurations.\n2. Runtime Configuration - For each request, the Prompt can contain a Runtime Chat Options: These can override the start-up options.\n3. Option Merging Process - The \"Merge Options\" step combines the start-up and runtime options.\nIf runtime options are provided, they take precedence over the start-up options.\n4. Input Processing - The \"Convert Input\" step transforms the input instructions into native, model-specific formats.\n5. Output Processing - The \"Convert Output\" step transforms the model's response into a standardized `ChatResponse` format.\n\nThe separation of start-up and runtime options allows for both global configurations and request-specific adjustments.\n\n[[ChatResponse]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Chat Options", "heading_level": 4, "file_order": 98, "section_index": 6, "content_hash": "1180e41cb1177b20aa57c21950d595d2495fc3b682e6817365592d4aa4d7ed23", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:be561864c6fc3fec1d10674235dab8800fc90cd4432fabfcedb062e7a95ec776", "content": "The structure of the `ChatResponse` class is as follows:\n\n[source,java]\n----\npublic class ChatResponse implements ModelResponse<Generation> {\n\n private final ChatResponseMetadata chatResponseMetadata;\n\tprivate final List<Generation> generations;\n\n\t@Override\n\tpublic ChatResponseMetadata getMetadata() {...}\n\n @Override\n\tpublic List<Generation> getResults() {...}\n\n // other methods omitted\n}\n----\n\nThe https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/model/ChatResponse.java[ChatResponse] class holds the AI Model's output, with each `Generation` instance containing one of potentially multiple outputs resulting from a single prompt.\n\nThe `ChatResponse` class also carries a `ChatResponseMetadata` metadata about the AI Model's response.\n\n[[Generation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "ChatResponse", "heading_level": 3, "file_order": 98, "section_index": 7, "content_hash": "be561864c6fc3fec1d10674235dab8800fc90cd4432fabfcedb062e7a95ec776", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:777219c91a4bc37efe596372f2a234f24a9a84a42422595f83fdd01f7a972bb5", "content": "Finally, the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/model/Generation.java[Generation] class extends from the `ModelResult` to represent the model output (assistant message) and related metadata:\n\n[source,java]\n----\npublic class Generation implements ModelResult<AssistantMessage> {\n\n\tprivate final AssistantMessage assistantMessage;\n\tprivate ChatGenerationMetadata chatGenerationMetadata;\n\n\t@Override\n\tpublic AssistantMessage getOutput() {...}\n\n\t@Override\n\tpublic ChatGenerationMetadata getMetadata() {...}\n\n // other methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Generation", "heading_level": 3, "file_order": 98, "section_index": 8, "content_hash": "777219c91a4bc37efe596372f2a234f24a9a84a42422595f83fdd01f7a972bb5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:85de28a7e0138aa682851da49db8757abac236d41ba998134df2ffad2abd9819", "content": "This diagram illustrates the unified interfaces, `ChatModel` and `StreamingChatModel`, are used for interacting with various AI chat models from different providers, allowing easy integration and switching between different AI services while maintaining a consistent API for the client application.\n\nimage::spring-ai-chat-completions-clients.jpg[align=\"center\", width=\"1000px\"]\n\n* xref:api/chat/openai-chat.adoc[OpenAI Chat Completion] (streaming, multi-modality & function-calling support)\n* xref:api/chat/azure-openai-chat.adoc[Microsoft Azure Open AI Chat Completion] (streaming & function-calling support)\n* xref:api/chat/ollama-chat.adoc[Ollama Chat Completion] (streaming, multi-modality & function-calling support)\n* xref:api/chat/huggingface.adoc[Hugging Face Chat Completion] (no streaming support)\n* xref:api/chat/vertexai-gemini-chat.adoc[Google Vertex AI Gemini Chat Completion] (streaming, multi-modality & function-calling support)\n* xref:api/bedrock.adoc[Amazon Bedrock]\n* xref:api/chat/mistralai-chat.adoc[Mistral AI Chat Completion] (streaming & function-calling support)\n* xref:api/chat/anthropic-chat.adoc[Anthropic Chat Completion] (streaming & function-calling support)\n\nTIP: Find a detailed comparison of the available Chat Models in the xref:api/chat/comparison.adoc[Chat Models Comparison] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Available Implementations", "heading_level": 2, "file_order": 98, "section_index": 9, "content_hash": "85de28a7e0138aa682851da49db8757abac236d41ba998134df2ffad2abd9819", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:6f8c9a136e106d30bb43ce9f5d4ebd24d3fdabc287f7f8bda1395f844c2c8ed8", "content": "The Spring AI Chat Model API is built on top of the Spring AI `Generic Model API` providing Chat specific abstractions and implementations.\nThis allows an easy integration and switching between different AI services while maintaining a consistent API for the client application.\nThe following class diagram illustrates the main classes and interfaces of the Spring AI Chat Model API.\n\nimage::spring-ai-chat-api.jpg[align=\"center\", width=\"1000px\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/chatmodel.adoc", "title": "chatmodel", "heading": "Chat Model API", "heading_level": 2, "file_order": 98, "section_index": 10, "content_hash": "6f8c9a136e106d30bb43ce9f5d4ebd24d3fdabc287f7f8bda1395f844c2c8ed8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/chatmodel.adoc"}}
{"id": "sha256:26a91615b8d100d545efea07d8c2bdf6d584f0e453f3b535b6a06d736d0ad8eb", "content": "[[cloud-bindings]]\n\nSpring AI provides support for cloud bindings based on the foundations in https://github.com/spring-cloud/spring-cloud-bindings[spring-cloud-bindings].\nThis allows applications to specify a binding type for a provider and then express properties using a generic format.\nThe spring-ai cloud bindings will process these properties and bind them to spring-ai native properties.\n\nFor example, when using `OpenAi`, the binding type is `openai`.\nUsing the property `spring.ai.cloud.bindings.openai.enabled`, the binding processor can be enabled or disabled.\nBy default, when specifying a binding type, this property will be enabled.\nConfiguration for `api-key`, `uri`, `username`, `password`, etc. can be specified and spring-ai will map them to the corresponding properties in the supported system.\n\nTo enable cloud binding support, include the following dependency in the application.\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-spring-cloud-bindings</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-spring-cloud-bindings'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/cloud-bindings.adoc", "title": "cloud-bindings", "heading": "cloud-bindings", "heading_level": 1, "file_order": 99, "section_index": 0, "content_hash": "26a91615b8d100d545efea07d8c2bdf6d584f0e453f3b535b6a06d736d0ad8eb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/cloud-bindings.adoc"}}
{"id": "sha256:7fe073a4209a9814138c7185701210f3b49dc15c02de33379e8d5aa02240afcd", "content": "The following are the components for which the cloud binding support is currently available in the `spring-ai-spring-cloud-bindings` module:\n\n[cols=\"|,|\"]\n|====\n| Service Type | Binding Type | Source Properties | Target Properties\n| `Chroma Vector Store`\n| `chroma` | `uri`, `username`, `password` | `spring.ai.vectorstore.chroma.client.host`, `spring.ai.vectorstore.chroma.client.port`, `spring.ai.vectorstore.chroma.client.username`, `spring.ai.vectorstore.chroma.client.host.password`\n\n| `Mistral AI`\n| `mistralai` | `api-key`, `uri` | `spring.ai.mistralai.api-key`, `spring.ai.mistralai.base-url`\n\n| `Ollama`\n| `ollama` | `uri` | `spring.ai.ollama.base-url`\n\n| `OpenAi`\n| `openai` | `api-key`, `uri` | `spring.ai.openai.api-key`, `spring.ai.openai.base-url`\n\n| `Weaviate`\n| `weaviate` | `uri`, `api-key` | `spring.ai.vectorstore.weaviate.scheme`, `spring.ai.vectorstore.weaviate.host`, `spring.ai.vectorstore.weaviate.api-key`\n\n| `Tanzu GenAI`\n| `genai` | `uri`, `api-key`, `model-capabilities` (`chat` and `embedding`), `model-name` | `spring.ai.openai.chat.base-url`, `spring.ai.openai.chat.api-key`, `spring.ai.openai.chat.options.model`, `spring.ai.openai.embedding.base-url`, `spring.ai.openai.embedding.api-key`, `spring.ai.openai.embedding.options.model`\n|====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/cloud-bindings.adoc", "title": "cloud-bindings", "heading": "Available Cloud Bindings", "heading_level": 2, "file_order": 99, "section_index": 1, "content_hash": "7fe073a4209a9814138c7185701210f3b49dc15c02de33379e8d5aa02240afcd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/cloud-bindings.adoc"}}
{"id": "sha256:b125ca9a59afa2e695c02103f892195e5fa47bb7dfcaa1da11fe01fd78b2808e", "content": "[[docker-compose]]\n\nSpring AI provides Spring Boot auto-configuration for establishing a connection to a model service\nor vector store running via Docker Compose. To enable it, add the following dependency\nto your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-spring-boot-docker-compose</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-spring-boot-docker-compose'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/docker-compose.adoc", "title": "docker-compose", "heading": "docker-compose", "heading_level": 1, "file_order": 100, "section_index": 0, "content_hash": "b125ca9a59afa2e695c02103f892195e5fa47bb7dfcaa1da11fe01fd78b2808e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/docker-compose.adoc"}}
{"id": "sha256:64f971a9ff853bdd07b3bb2835a2ba6aa53649e8ad91c6c989c5d40082e3435b", "content": "The following service connection factories are provided in the `spring-ai-spring-boot-docker-compose` module:\n\n[cols=\"|,|\"]\n|====\n| Connection Details | Matched on\n| `AwsOpenSearchConnectionDetails`\n| Containers named `localstack/localstack`\n\n| `ChromaConnectionDetails`\n| Containers named `chromadb/chroma`, `ghcr.io/chroma-core/chroma`\n\n| `OllamaConnectionDetails`\n| Containers named `ollama/ollama`\n\n| `OpenSearchConnectionDetails`\n| Containers named `opensearchproject/opensearch`\n\n| `QdrantConnectionDetails`\n| Containers named `qdrant/qdrant`\n\n| `TypesenseConnectionDetails`\n| Containers named `typesense/typesense`\n\n| `WeaviateConnectionDetails`\n| Containers named `semitechnologies/weaviate`, `cr.weaviate.io/semitechnologies/weaviate`\n\n| `McpSseClientConnectionDetails`\n| Containers named `docker/mcp-gateway`\n|====\n\nMore service connections are provided by the spring boot module `spring-boot-docker-compose`. Refer to the https://docs.spring.io/spring-boot/reference/features/dev-services.html#features.dev-services.docker-compose[Docker Compose Support] documentation page for the full list.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/docker-compose.adoc", "title": "docker-compose", "heading": "Service Connections", "heading_level": 2, "file_order": 100, "section_index": 1, "content_hash": "64f971a9ff853bdd07b3bb2835a2ba6aa53649e8ad91c6c989c5d40082e3435b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/docker-compose.adoc"}}
{"id": "sha256:cd90631955ee9e9c628809e5749fa9ec1cd36027d4dfdfab029731115390abc8", "content": "[[effective-agents]]\n\nIn a recent research publication, https://www.anthropic.com/research/building-effective-agents[Building Effective Agents], Anthropic shared valuable insights about building effective Large Language Model (LLM) agents. What makes this research particularly interesting is its emphasis on simplicity and composability over complex frameworks. Let's explore how these principles translate into practical implementations using https://docs.spring.io/spring-ai/reference/index.html[Spring AI].\n\nimage::https://raw.githubusercontent.com/spring-io/spring-io-static/refs/heads/main/blog/tzolov/spring-ai-agentic-systems.jpg[Agent Systems, width=350]\n\nWhile the pattern descriptions and diagrams are sourced from Anthropic's original publication, we'll focus on how to implement these patterns using Spring AI's features for model portability and structured output. We recommend reading the original paper first.\n\nThe https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns[agentic-patterns] directory in the spring-ai-examples repository contains all the code for the examples that follow.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "effective-agents", "heading_level": 1, "file_order": 101, "section_index": 0, "content_hash": "cd90631955ee9e9c628809e5749fa9ec1cd36027d4dfdfab029731115390abc8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:58b1cdbafc117e539f0d5cf9283bd50afeffa059e55d74289096a6504df22991", "content": "The research publication makes an important architectural distinction between two types of agentic systems:\n\n. *Workflows*: Systems where LLMs and tools are orchestrated through predefined code paths (e.g., prescriptive systems)\n. *Agents*: Systems where LLMs dynamically direct their own processes and tool usage\n\nThe key insight is that while fully autonomous agents might seem appealing, workflows often provide better predictability and consistency for well-defined tasks. This aligns perfectly with enterprise requirements where reliability and maintainability are crucial.\n\nLet's examine how Spring AI implements these concepts through five fundamental patterns, each serving specific use cases:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "Agentic Systems", "heading_level": 2, "file_order": 101, "section_index": 1, "content_hash": "58b1cdbafc117e539f0d5cf9283bd50afeffa059e55d74289096a6504df22991", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:6f2e371afd576eb43ca64526c9580454aa45757e77466ab4ebcadfa56dbd7efa", "content": "The Chain Workflow pattern exemplifies the principle of breaking down complex tasks into simpler, more manageable steps.\n\nimage::https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75[Prompt Chaining Workflow]\n\n*When to Use:*\n- Tasks with clear sequential steps\n- When you want to trade latency for higher accuracy\n- When each step builds on the previous step's output\n\nHere's a practical example from Spring AI's implementation:\n\n[source,java]\n----\npublic class ChainWorkflow {\n private final ChatClient chatClient;\n private final String[] systemPrompts;\n\n public String chain(String userInput) {\n String response = userInput;\n for (String prompt : systemPrompts) {\n String input = String.format(\"{%s}\\n {%s}\", prompt, response);\n response = chatClient.prompt(input).call().content();\n }\n return response;\n }\n}\n----\n\nThis implementation demonstrates several key principles:\n\n- Each step has a focused responsibility\n- Output from one step becomes input for the next\n- The chain is easily extensible and maintainable", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "1. https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns/chain-workflow[Chain Workflow]", "heading_level": 3, "file_order": 101, "section_index": 2, "content_hash": "6f2e371afd576eb43ca64526c9580454aa45757e77466ab4ebcadfa56dbd7efa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:af7b164e469c0fa7c199c8b3ca79f99f3c5f60132db4787da88bac8705540e59", "content": "LLMs can work simultaneously on tasks and have their outputs aggregated programmatically.\n\nimage::https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75[Parallelization Workflow]\n\n*When to Use:*\n- Processing large volumes of similar but independent items\n- Tasks requiring multiple independent perspectives\n- When processing time is critical and tasks are parallelizable\n\n[source,java]\n----\nList<String> parallelResponse = new ParallelizationWorkflow(chatClient)\n .parallel(\n \"Analyze how market changes will impact this stakeholder group.\",\n List.of(\n \"Customers: ...\",\n \"Employees: ...\",\n \"Investors: ...\",\n \"Suppliers: ...\"\n ),\n 4\n );\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "2. https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns/parallelization-workflow[Parallelization Workflow]", "heading_level": 3, "file_order": 101, "section_index": 3, "content_hash": "af7b164e469c0fa7c199c8b3ca79f99f3c5f60132db4787da88bac8705540e59", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:0b669932e330d3111b350d0973925dc3546623766989cba3f8bb5ef430a3dff3", "content": "The Routing pattern implements intelligent task distribution, enabling specialized handling for different types of input.\n\nimage::https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75[Routing Workflow]\n\n*When to Use:*\n- Complex tasks with distinct categories of input\n- When different inputs require specialized processing\n- When classification can be handled accurately\n\n[source,java]\n----\n@Autowired\nprivate ChatClient chatClient;\n\nRoutingWorkflow workflow = new RoutingWorkflow(chatClient);\n\nMap<String, String> routes = Map.of(\n \"billing\", \"You are a billing specialist. Help resolve billing issues...\",\n \"technical\", \"You are a technical support engineer. Help solve technical problems...\",\n \"general\", \"You are a customer service representative. Help with general inquiries...\"\n);\n\nString input = \"My account was charged twice last week\";\nString response = workflow.route(input, routes);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "3. https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns/routing-workflow[Routing Workflow]", "heading_level": 3, "file_order": 101, "section_index": 4, "content_hash": "0b669932e330d3111b350d0973925dc3546623766989cba3f8bb5ef430a3dff3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:10431d0768bf8286c62fc221fb66f7efab8a898cf6f2d0d5cf067f2ed99d597b", "content": "image::https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75[Orchestration Workflow]\n\n*When to Use:*\n- Complex tasks where subtasks can't be predicted upfront\n- Tasks requiring different approaches or perspectives\n- Situations needing adaptive problem-solving\n\n[source,java]\n----\npublic class OrchestratorWorkersWorkflow {\n public WorkerResponse process(String taskDescription) {\n // 1. Orchestrator analyzes task and determines subtasks\n OrchestratorResponse orchestratorResponse = // ...\n\n // 2. Workers process subtasks in parallel\n List<String> workerResponses = // ...\n\n // 3. Results are combined into final response\n return new WorkerResponse(/*...*/);\n }\n}\n----\n\nUsage Example:\n\n[source,java]\n----\nChatClient chatClient = // ... initialize chat client\nOrchestratorWorkersWorkflow workflow = new OrchestratorWorkersWorkflow(chatClient);\n\nWorkerResponse response = workflow.process(\n \"Generate both technical and user-friendly documentation for a REST API endpoint\"\n);\n\nSystem.out.println(\"Analysis: \" + response.analysis());\nSystem.out.println(\"Worker Outputs: \" + response.workerResponses());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "4. https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns/orchestrator-workers[Orchestrator-Workers]", "heading_level": 3, "file_order": 101, "section_index": 5, "content_hash": "10431d0768bf8286c62fc221fb66f7efab8a898cf6f2d0d5cf067f2ed99d597b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:6a6571e46231e0598ef4b90750f112a76bcbd85c0109262d2bf9925726c308d6", "content": "image::https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75[Evaluator-Optimizer Workflow]\n\n*When to Use:*\n- Clear evaluation criteria exist\n- Iterative refinement provides measurable value\n- Tasks benefit from multiple rounds of critique\n\n[source,java]\n----\npublic class EvaluatorOptimizerWorkflow {\n public RefinedResponse loop(String task) {\n Generation generation = generate(task, context);\n EvaluationResponse evaluation = evaluate(generation.response(), task);\n return new RefinedResponse(finalSolution, chainOfThought);\n }\n}\n----\n\nUsage Example:\n\n[source,java]\n----\nChatClient chatClient = // ... initialize chat client\nEvaluatorOptimizerWorkflow workflow = new EvaluatorOptimizerWorkflow(chatClient);\n\nRefinedResponse response = workflow.loop(\n \"Create a Java class implementing a thread-safe counter\"\n);\n\nSystem.out.println(\"Final Solution: \" + response.solution());\nSystem.out.println(\"Evolution: \" + response.chainOfThought());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "5. https://github.com/spring-projects/spring-ai-examples/tree/main/agentic-patterns/evaluator-optimizer[Evaluator-Optimizer]", "heading_level": 3, "file_order": 101, "section_index": 6, "content_hash": "6a6571e46231e0598ef4b90750f112a76bcbd85c0109262d2bf9925726c308d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:ac22f44b0a91728bd326ca9c75f6033e54526e8a5e144de34b823ed7d00340d6", "content": "Spring AI's implementation of these patterns offers several benefits that align with Anthropic's recommendations:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "Spring AI's Implementation Advantages", "heading_level": 2, "file_order": 101, "section_index": 7, "content_hash": "ac22f44b0a91728bd326ca9c75f6033e54526e8a5e144de34b823ed7d00340d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:abafff73318cb439cd38aeca01cffa528065313e5f6f5ac94ebb6ac929624a4d", "content": "[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai-spring-boot-starter</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "https://docs.spring.io/spring-ai/reference/api/chat/comparison.html[Model Portability]", "heading_level": 3, "file_order": 101, "section_index": 8, "content_hash": "abafff73318cb439cd38aeca01cffa528065313e5f6f5ac94ebb6ac929624a4d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:468c3a62afdb872e37c697e78da752b0185ef81c4029b236954812a45c23427b", "content": "[source,java]\n----\nEvaluationResponse response = chatClient.prompt(prompt)\n .call()\n .entity(EvaluationResponse.class);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "https://docs.spring.io/spring-ai/reference/api/structured-output-converter.html[Structured Output]", "heading_level": 3, "file_order": 101, "section_index": 9, "content_hash": "468c3a62afdb872e37c697e78da752b0185ef81c4029b236954812a45c23427b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:a079174ea5ff321e0fb08899ef216d709835cda8543bc917dd708412240cee68", "content": "- Uniform interface across different LLM providers\n- Built-in error handling and retries\n- Flexible prompt management", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "https://docs.spring.io/spring-ai/reference/api/chatclient.html[Consistent API]", "heading_level": 3, "file_order": 101, "section_index": 10, "content_hash": "a079174ea5ff321e0fb08899ef216d709835cda8543bc917dd708412240cee68", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:118ddf9033bfb0fb5e5760af9a81f7050cd11b2a0f354f862fb4ad9d5e0941f4", "content": "- *Start Simple*\n- Begin with basic workflows before adding complexity\n- Use the simplest pattern that meets your requirements\n- Add sophistication only when needed\n\n- *Design for Reliability*\n- Implement clear error handling\n- Use type-safe responses where possible\n- Build in validation at each step\n\n- *Consider Trade-offs*\n- Balance latency vs. accuracy\n- Evaluate when to use parallel processing\n- Choose between fixed workflows and dynamic agents", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "Best Practices and Recommendations", "heading_level": 2, "file_order": 101, "section_index": 11, "content_hash": "118ddf9033bfb0fb5e5760af9a81f7050cd11b2a0f354f862fb4ad9d5e0941f4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:c78a1d4aeb76d561e9c7efde506a338230cbfe52a9e6c0d225d2ec4bf7f5c3cd", "content": "These guides will be updated to explore how to build more advanced Agents that combine these foundational patterns with sophisticated features:\n\n*Pattern Composition*\n- Combining multiple patterns to create more powerful workflows\n- Building hybrid systems that leverage the strengths of each pattern\n- Creating flexible architectures that can adapt to changing requirements\n\n*Advanced Agent Memory Management*\n- Implementing persistent memory across conversations\n- Managing context windows efficiently\n- Developing strategies for long-term knowledge retention\n\n*Tools and Model-Context Protocol (MCP) Integration*\n- Leveraging external tools through standardized interfaces\n- Implementing MCP for enhanced model interactions\n- Building extensible agent architectures", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "Future Work", "heading_level": 2, "file_order": 101, "section_index": 12, "content_hash": "c78a1d4aeb76d561e9c7efde506a338230cbfe52a9e6c0d225d2ec4bf7f5c3cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:c8ab4a78f964f3eda1f12a7bf1b0d4380d0a865df946c34279322e806e022096", "content": "The combination of Anthropic's research insights and Spring AI's practical implementations provides a powerful framework for building effective LLM-based systems.\n\nBy following these patterns and principles, developers can create robust, maintainable, and effective AI applications that deliver real value while avoiding unnecessary complexity.\n\nThe key is to remember that sometimes the simplest solution is the most effective. Start with basic patterns, understand your use case thoroughly, and only add complexity when it demonstrably improves your system's performance or capabilities.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/effective-agents.adoc", "title": "effective-agents", "heading": "Conclusion", "heading_level": 2, "file_order": 101, "section_index": 13, "content_hash": "c8ab4a78f964f3eda1f12a7bf1b0d4380d0a865df946c34279322e806e022096", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/effective-agents.adoc"}}
{"id": "sha256:b4c361dec93291cbd2e4d9e71373339dcee820ec7b4e7b3cd524b7cd3e8cfbb0", "content": "[[EmbeddingModel]]\n\nEmbeddings are numerical representations of text, images, or videos that capture relationships between inputs.\n\nEmbeddings work by converting text, image, and video into arrays of floating point numbers, called vectors.\nThese vectors are designed to capture the meaning of the text, images, and videos.\nThe length of the embedding array is called the vector's dimensionality.\n\nBy calculating the numerical distance between the vector representations of two pieces of text, an application can determine the similarity between the objects used to generate the embedding vectors.\n\nThe `EmbeddingModel` interface is designed for straightforward integration with embedding models in AI and machine learning.\nIts primary function is to convert text into numerical vectors, commonly referred to as embeddings.\nThese embeddings are crucial for various tasks such as semantic analysis and text classification.\n\nThe design of the EmbeddingModel interface centers around two primary goals:\n\n* *Portability*: This interface ensures easy adaptability across various embedding models.\nIt allows developers to switch between different embedding techniques or models with minimal code changes.\nThis design aligns with Spring's philosophy of modularity and interchangeability.\n\n* *Simplicity*: EmbeddingModel simplifies the process of converting text to embeddings.\nBy providing straightforward methods like `embed(String text)` and `embed(Document document)`, it takes the complexity out of dealing with raw text data and embedding algorithms. This design choice makes it easier for developers, especially those new to AI, to utilize embeddings in their applications without delving deep into the underlying mechanics.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "embeddings", "heading_level": 1, "file_order": 102, "section_index": 0, "content_hash": "b4c361dec93291cbd2e4d9e71373339dcee820ec7b4e7b3cd524b7cd3e8cfbb0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:8705f26fa99805357aaa13f691946e7703807acfd99c2bf891f82c3feeee9f59", "content": "The Embedding Model API is built on top of the generic https://github.com/spring-projects/spring-ai/tree/main/spring-ai-model/src/main/java/org/springframework/ai/model[Spring AI Model API], which is a part of the Spring AI library.\nAs such, the EmbeddingModel interface extends the `Model` interface, which provides a standard set of methods for interacting with AI models. The `EmbeddingRequest` and `EmbeddingResponse` classes extend from the `ModelRequest` and `ModelResponse` are used to encapsulate the input and output of the embedding models, respectively.\n\nThe Embedding API in turn is used by higher-level components to implement Embedding Models for specific embedding models, such as OpenAI, Titan, Azure OpenAI, Ollie, and others.\n\nFollowing diagram illustrates the Embedding API and its relationship with the Spring AI Model API and the Embedding Models:\n\nimage:embeddings-api.jpg[title=Embeddings API,align=center,width=900]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "API Overview", "heading_level": 2, "file_order": 102, "section_index": 1, "content_hash": "8705f26fa99805357aaa13f691946e7703807acfd99c2bf891f82c3feeee9f59", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:8a960a288c804f1e7818ab94f22712e3a8f4a6093cfddba965f36f0b28706723", "content": "This section provides a guide to the `EmbeddingModel` interface and associated classes.\n\n[source,java]\n----\npublic interface EmbeddingModel extends Model<EmbeddingRequest, EmbeddingResponse> {\n\n\t@Override\n\tEmbeddingResponse call(EmbeddingRequest request);\n\n\t/**\n * Embeds the given document's content into a vector.\n * @param document the document to embed.\n * @return the embedded vector.\n */\n\tfloat[] embed(Document document);\n\n\t/**\n * Embeds the given text into a vector.\n * @param text the text to embed.\n * @return the embedded vector.\n */\n\tdefault float[] embed(String text) {\n Assert.notNull(text, \"Text must not be null\");\n return this.embed(List.of(text)).iterator().next();\n\t}\n\n\t/**\n * Embeds a batch of texts into vectors.\n * @param texts list of texts to embed.\n * @return list of list of embedded vectors.\n */\n\tdefault List<float[]> embed(List<String> texts) {\n Assert.notNull(texts, \"Texts must not be null\");\n return this.call(new EmbeddingRequest(texts, EmbeddingOptions.EMPTY))\n .getResults()\n .stream()\n .map(Embedding::getOutput)\n .toList();\n\t}\n\n\t/**\n * Embeds a batch of texts into vectors and returns the {@link EmbeddingResponse}.\n * @param texts list of texts to embed.\n * @return the embedding response.\n */\n\tdefault EmbeddingResponse embedForResponse(List<String> texts) {\n Assert.notNull(texts, \"Texts must not be null\");\n return this.call(new EmbeddingRequest(texts, EmbeddingOptions.EMPTY));\n\t}\n\n\t/**\n * @return the number of dimensions of the embedded vectors. It is generative\n * specific.\n */\n\tdefault int dimensions() {\n return embed(\"Test String\").size();\n\t}\n\n}\n----\n\nThe embed methods offer various options for converting text into embeddings, accommodating single strings, structured `Document` objects, or batches of text.\n\nMultiple shortcut methods are provided for embedding text, including the `embed(String text)` method, which takes a single string and returns the corresponding embedding vector.\nAll shortcuts are implemented around the `call` method, which is the primary method for invoking the embedding model.\n\nTypically the embedding returns a lists of floats, representing the embeddings in a numerical vector format.\n\nThe `embedForResponse` method provides a more comprehensive output, potentially including additional information about the embeddings.\n\nThe dimensions method is a handy tool for developers to quickly ascertain the size of the embedding vectors, which is important for understanding the embedding space and for subsequent processing steps.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "EmbeddingModel", "heading_level": 3, "file_order": 102, "section_index": 2, "content_hash": "8a960a288c804f1e7818ab94f22712e3a8f4a6093cfddba965f36f0b28706723", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:7e8f26e83e798478340e1d3327d9830fed23e3cfac9c8de448bc67034b90f4a7", "content": "The `EmbeddingRequest` is a `ModelRequest` that takes a list of text objects and optional embedding request options.\nThe following listing shows a truncated version of the EmbeddingRequest class, excluding constructors and other utility methods:\n\n[source,java]\n----\npublic class EmbeddingRequest implements ModelRequest<List<String>> {\n\tprivate final List<String> inputs;\n\tprivate final EmbeddingOptions options;\n\t// other methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "EmbeddingRequest", "heading_level": 4, "file_order": 102, "section_index": 3, "content_hash": "7e8f26e83e798478340e1d3327d9830fed23e3cfac9c8de448bc67034b90f4a7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:50ecaf390f2b27d1c7530566da72bbd18d75b2ebed11d620f62070cff4b75441", "content": "The structure of the `EmbeddingResponse` class is as follows:\n\n[source,java]\n----\npublic class EmbeddingResponse implements ModelResponse<Embedding> {\n\n\tprivate List<Embedding> embeddings;\n\tprivate EmbeddingResponseMetadata metadata = new EmbeddingResponseMetadata();\n\t// other methods omitted\n}\n----\n\nThe `EmbeddingResponse` class holds the AI Model's output, with each `Embedding` instance containing the result vector data from a single text input.\n\nThe `EmbeddingResponse` class also carries a `EmbeddingResponseMetadata` metadata about the AI Model's response.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "EmbeddingResponse", "heading_level": 4, "file_order": 102, "section_index": 4, "content_hash": "50ecaf390f2b27d1c7530566da72bbd18d75b2ebed11d620f62070cff4b75441", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:97249c03008b661e7d50b855a44bc4f8c567e2f1fbf30ac251d8acf18508f74d", "content": "The `Embedding` represents a single embedding vector.\n\n[source,java]\n----\npublic class Embedding implements ModelResult<float[]> {\n\tprivate float[] embedding;\n\tprivate Integer index;\n\tprivate EmbeddingResultMetadata metadata;\n\t// other methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "Embedding", "heading_level": 4, "file_order": 102, "section_index": 5, "content_hash": "97249c03008b661e7d50b855a44bc4f8c567e2f1fbf30ac251d8acf18508f74d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:63ff48e1d2f1b08989e54d32b6e41e35b87d7c3f68344de36291fa70c4fbbb36", "content": "Internally the various `EmbeddingModel` implementations use different low-level libraries and APIs to perform the embedding tasks. The following are some of the available implementations of the `EmbeddingModel` implementations:\n\n* xref:api/embeddings/openai-embeddings.adoc[Spring AI OpenAI Embeddings]\n* xref:api/embeddings/azure-openai-embeddings.adoc[Spring AI Azure OpenAI Embeddings]\n* xref:api/embeddings/ollama-embeddings.adoc[Spring AI Ollama Embeddings]\n* xref:api/embeddings/onnx.adoc[Spring AI Transformers (ONNX) Embeddings]\n* xref:api/embeddings/postgresml-embeddings.adoc[Spring AI PostgresML Embeddings]\n* xref:api/embeddings/bedrock-cohere-embedding.adoc[Spring AI Bedrock Cohere Embeddings]\n* xref:api/embeddings/bedrock-titan-embedding.adoc[Spring AI Bedrock Titan Embeddings]\n* xref:api/embeddings/vertexai-embeddings-text.adoc[Spring AI VertexAI Embeddings]\n* xref:api/embeddings/mistralai-embeddings.adoc[Spring AI Mistral AI Embeddings]\n* xref:api/embeddings/oci-genai-embeddings.adoc[Spring AI Oracle Cloud Infrastructure GenAI Embeddings]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/embeddings.adoc", "title": "embeddings", "heading": "Available Implementations [[available-implementations]]", "heading_level": 2, "file_order": 102, "section_index": 6, "content_hash": "63ff48e1d2f1b08989e54d32b6e41e35b87d7c3f68344de36291fa70c4fbbb36", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/embeddings.adoc"}}
{"id": "sha256:1ea73cc4c10bd837804921e6bb76773aa529517b214df63babe8fce9034c6cb0", "content": "The Extract, Transform, and Load (ETL) framework serves as the backbone of data processing within the Retrieval Augmented Generation (RAG) use case.\n\nThe ETL pipeline orchestrates the flow from raw data sources to a structured vector store, ensuring data is in the optimal format for retrieval by the AI model.\n\nThe RAG use case is text to augment the capabilities of generative models by retrieving relevant information from a body of data to enhance the quality and relevance of the generated output.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "ETL Pipeline", "heading_level": 1, "file_order": 103, "section_index": 0, "content_hash": "1ea73cc4c10bd837804921e6bb76773aa529517b214df63babe8fce9034c6cb0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:600800f36b9ec891bfbfb3d6183b87567ff3bc517b33773702516d9ad9d3c0a7", "content": "The ETL pipelines creates, transforms and stores `Document` instances.\n\nimage::spring-ai-document1-api.jpg[Spring AI Message API, width=400, align=\"center\"]\n\nThe `Document` class contains text, metadata and optionally additional media types like images, audio and video.\n\nThere are three main components of the ETL pipeline,\n\n* `DocumentReader` that implements `Supplier<List<Document>>`\n* `DocumentTransformer` that implements `Function<List<Document>, List<Document>>`\n* `DocumentWriter` that implements `Consumer<List<Document>>`\n\nThe `Document` class content is created from PDFs, text files and other document types with the help of `DocumentReader`.\n\nTo construct a simple ETL pipeline, you can chain together an instance of each type.\n\nimage::etl-pipeline.jpg[align=\"center\"]\n\nLet's say we have the following instances of those three ETL types\n\n* `PagePdfDocumentReader` an implementation of `DocumentReader`\n* `TokenTextSplitter` an implementation of `DocumentTransformer`\n* `VectorStore` an implementation of `DocumentWriter`\n\nTo perform the basic loading of data into a Vector Database for use with the Retrieval Augmented Generation pattern, use the following code in Java function style syntax.\n\n[source,java]\n----\nvectorStore.accept(tokenTextSplitter.apply(pdfReader.get()));\n----\n\nAlternatively, you can use method names that are more naturally expressive for the domain\n\n[source,java]\n----\nvectorStore.write(tokenTextSplitter.split(pdfReader.read()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "API Overview", "heading_level": 2, "file_order": 103, "section_index": 1, "content_hash": "600800f36b9ec891bfbfb3d6183b87567ff3bc517b33773702516d9ad9d3c0a7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:0222f8521044f2cbebcbcc86ac6cc34e4beb89efcb8d5e2662ebb1a7e8a63222", "content": "The ETL pipeline is composed of the following interfaces and implementations.\nDetailed ETL class diagram is shown in the <<etl-class-diagram>> section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "ETL Interfaces", "heading_level": 2, "file_order": 103, "section_index": 2, "content_hash": "0222f8521044f2cbebcbcc86ac6cc34e4beb89efcb8d5e2662ebb1a7e8a63222", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:bec434cf79a6d587f6d6e60d4e1f57353d3924283d48f9985d81cc63ceb2a2f3", "content": "Provides a source of documents from diverse origins.\n[source,java]\n----\npublic interface DocumentReader extends Supplier<List<Document>> {\n\n default List<Document> read() {\n return get();\n\t}\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "DocumentReader", "heading_level": 3, "file_order": 103, "section_index": 3, "content_hash": "bec434cf79a6d587f6d6e60d4e1f57353d3924283d48f9985d81cc63ceb2a2f3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:40d3b5e758815b0879552a5f7445bc00aeb68f80816ca10b565746f2d6184a60", "content": "Transforms a batch of documents as part of the processing workflow.\n\n[source,java]\n----\npublic interface DocumentTransformer extends Function<List<Document>, List<Document>> {\n\n default List<Document> transform(List<Document> transform) {\n return apply(transform);\n\t}\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "DocumentTransformer", "heading_level": 3, "file_order": 103, "section_index": 4, "content_hash": "40d3b5e758815b0879552a5f7445bc00aeb68f80816ca10b565746f2d6184a60", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d80dcd0403d4e7e42e4200bc0dae3b1fab0ee7a50c1d654aa02dc2147538ca17", "content": "Manages the final stage of the ETL process, preparing documents for storage.\n\n```java\npublic interface DocumentWriter extends Consumer<List<Document>> {\n\n default void write(List<Document> documents) {\n accept(documents);\n\t}\n}\n```\n\n[[etl-class-diagram]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "DocumentWriter", "heading_level": 3, "file_order": 103, "section_index": 5, "content_hash": "d80dcd0403d4e7e42e4200bc0dae3b1fab0ee7a50c1d654aa02dc2147538ca17", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:b11bec0dd65760a58f254d1cbd66f427a20a4ef0e031e6230eea1de564543f51", "content": "The following class diagram illustrates the ETL interfaces and implementations.\n\nimage::etl-class-diagram.jpg[align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "ETL Class Diagram", "heading_level": 3, "file_order": 103, "section_index": 6, "content_hash": "b11bec0dd65760a58f254d1cbd66f427a20a4ef0e031e6230eea1de564543f51", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:13331b96cbcc34de82a52bffd90a516ec1c22087604a06a0a85f59a722242125", "content": "The `JsonReader` processes JSON documents, converting them into a list of `Document` objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "JSON", "heading_level": 3, "file_order": 103, "section_index": 7, "content_hash": "13331b96cbcc34de82a52bffd90a516ec1c22087604a06a0a85f59a722242125", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:f8ecd5b6ba6a23a9b1b7bc55a0f95e6e6dd8b4a694736d7d9723f67966aa4a65", "content": "[source,java]\n----\n@Component\nclass MyJsonReader {\n\n\tprivate final Resource resource;\n\n MyJsonReader(@Value(\"classpath:bikes.json\") Resource resource) {\n this.resource = resource;\n }\n\n\tList<Document> loadJsonAsDocuments() {\n JsonReader jsonReader = new JsonReader(this.resource, \"description\", \"content\");\n return jsonReader.get();\n\t}\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 8, "content_hash": "f8ecd5b6ba6a23a9b1b7bc55a0f95e6e6dd8b4a694736d7d9723f67966aa4a65", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:035e1c22ddaf45f0693559c3f4629c1ae9d734fa200f71efac159736c6eeb315", "content": "The `JsonReader` provides several constructor options:\n\n1. `JsonReader(Resource resource)`\n2. `JsonReader(Resource resource, String... jsonKeysToUse)`\n3. `JsonReader(Resource resource, JsonMetadataGenerator jsonMetadataGenerator, String... jsonKeysToUse)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructor Options", "heading_level": 4, "file_order": 103, "section_index": 9, "content_hash": "035e1c22ddaf45f0693559c3f4629c1ae9d734fa200f71efac159736c6eeb315", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:dafe2d6e7948d02ad0662df1e29fb53c38969af3b12fa042d197ace49707aa67", "content": "* `resource`: A Spring `Resource` object pointing to the JSON file.\n* `jsonKeysToUse`: An array of keys from the JSON that should be used as the text content in the resulting `Document` objects.\n* `jsonMetadataGenerator`: An optional `JsonMetadataGenerator` to create metadata for each `Document`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 4, "file_order": 103, "section_index": 10, "content_hash": "dafe2d6e7948d02ad0662df1e29fb53c38969af3b12fa042d197ace49707aa67", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:351405d127f287332cd54357d18355573289e6d9373505a60ceed04f2c78a6af", "content": "The `JsonReader` processes JSON content as follows:\n\n* It can handle both JSON arrays and single JSON objects.\n* For each JSON object (either in an array or a single object):\n** It extracts the content based on the specified `jsonKeysToUse`.\n** If no keys are specified, it uses the entire JSON object as content.\n** It generates metadata using the provided `JsonMetadataGenerator` (or an empty one if not provided).\n** It creates a `Document` object with the extracted content and metadata.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 11, "content_hash": "351405d127f287332cd54357d18355573289e6d9373505a60ceed04f2c78a6af", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:0e9841b556f8c4821bf4445689a4f8a71002bf1fea548677f95e4aa3647812bf", "content": "The `JsonReader` now supports retrieving specific parts of a JSON document using JSON Pointers. This feature allows you to easily extract nested data from complex JSON structures.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Using JSON Pointers", "heading_level": 4, "file_order": 103, "section_index": 12, "content_hash": "0e9841b556f8c4821bf4445689a4f8a71002bf1fea548677f95e4aa3647812bf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:7b6e6aa2a8b9479406c62ee22710c2d858a2647876a6c5c760c46fcc34d2d0a3", "content": "[source,java]\n----\npublic List<Document> get(String pointer)\n----\n\nThis method allows you to use a JSON Pointer to retrieve a specific part of the JSON document.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "The `get(String pointer)` method", "heading_level": 5, "file_order": 103, "section_index": 13, "content_hash": "7b6e6aa2a8b9479406c62ee22710c2d858a2647876a6c5c760c46fcc34d2d0a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d71fb30d77e29ff19bb6a977628dbe2626e80c98539779f9d6c6874778a1c78e", "content": "* `pointer`: A JSON Pointer string (as defined in RFC 6901) to locate the desired element within the JSON structure.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 6, "file_order": 103, "section_index": 14, "content_hash": "d71fb30d77e29ff19bb6a977628dbe2626e80c98539779f9d6c6874778a1c78e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:7bca88ed7f5a3e8d1c44796dfafb0eaf9d0f9794c41cdaadfdb0e058bf3ab45f", "content": "* Returns a `List<Document>` containing the documents parsed from the JSON element located by the pointer.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Return Value", "heading_level": 6, "file_order": 103, "section_index": 15, "content_hash": "7bca88ed7f5a3e8d1c44796dfafb0eaf9d0f9794c41cdaadfdb0e058bf3ab45f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:6392b2273ddc48d4e4ea80b42ef092eee0b50092f3d12c74f1ba9c4b032ac7dc", "content": "* The method uses the provided JSON Pointer to navigate to a specific location in the JSON structure.\n* If the pointer is valid and points to an existing element:\n** For a JSON object: it returns a list with a single Document.\n** For a JSON array: it returns a list of Documents, one for each element in the array.\n* If the pointer is invalid or points to a non-existent element, it throws an `IllegalArgumentException`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 6, "file_order": 103, "section_index": 16, "content_hash": "6392b2273ddc48d4e4ea80b42ef092eee0b50092f3d12c74f1ba9c4b032ac7dc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d56ff5e2f1540f13645b19af9d4af947fc4b34b20ed08066fc16f596c1c72df6", "content": "[source,java]\n----\nJsonReader jsonReader = new JsonReader(resource, \"description\");\nList<Document> documents = this.jsonReader.get(\"/store/books/0\");\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 6, "file_order": 103, "section_index": 17, "content_hash": "d56ff5e2f1540f13645b19af9d4af947fc4b34b20ed08066fc16f596c1c72df6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:901e07e9c665231c4d6c403b337e10c5543a142f49412754e335e41c82c24f20", "content": "[source,json]\n----\n[\n {\n \"id\": 1,\n \"brand\": \"Trek\",\n \"description\": \"A high-performance mountain bike for trail riding.\"\n },\n {\n \"id\": 2,\n \"brand\": \"Cannondale\",\n \"description\": \"An aerodynamic road bike for racing enthusiasts.\"\n }\n]\n----\n\nIn this example, if the `JsonReader` is configured with `\"description\"` as the `jsonKeysToUse`, it will create `Document` objects where the content is the value of the \"description\" field for each bike in the array.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example JSON Structure", "heading_level": 4, "file_order": 103, "section_index": 18, "content_hash": "901e07e9c665231c4d6c403b337e10c5543a142f49412754e335e41c82c24f20", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:ed4ef3c574cbd8c73ad912e9f93378fefeadc51fc1487dfc8b1e567faddb77e6", "content": "* The `JsonReader` uses Jackson for JSON parsing.\n* It can handle large JSON files efficiently by using streaming for arrays.\n* If multiple keys are specified in `jsonKeysToUse`, the content will be a concatenation of the values for those keys.\n* The reader is flexible and can be adapted to various JSON structures by customizing the `jsonKeysToUse` and `JsonMetadataGenerator`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 19, "content_hash": "ed4ef3c574cbd8c73ad912e9f93378fefeadc51fc1487dfc8b1e567faddb77e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:ae88228ed9423c60280dc12f997b62b1909a15b1ec8e47e6383d17b78e94e160", "content": "The `TextReader` processes plain text documents, converting them into a list of `Document` objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Text", "heading_level": 3, "file_order": 103, "section_index": 20, "content_hash": "ae88228ed9423c60280dc12f997b62b1909a15b1ec8e47e6383d17b78e94e160", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:ad28a207b09c72371ceebcaee9510229fdcaf3b755edc7d046e4603badb7be95", "content": "[source,java]\n----\n@Component\nclass MyTextReader {\n\n private final Resource resource;\n\n MyTextReader(@Value(\"classpath:text-source.txt\") Resource resource) {\n this.resource = resource;\n }\n\n\tList<Document> loadText() {\n TextReader textReader = new TextReader(this.resource);\n textReader.getCustomMetadata().put(\"filename\", \"text-source.txt\");\n\n return textReader.read();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 21, "content_hash": "ad28a207b09c72371ceebcaee9510229fdcaf3b755edc7d046e4603badb7be95", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:be1c2fcb9848af6103a99d75c9e257bad4700706993eb9119d06cb3f7c5f4bad", "content": "The `TextReader` provides two constructor options:\n\n1. `TextReader(String resourceUrl)`\n2. `TextReader(Resource resource)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructor Options", "heading_level": 4, "file_order": 103, "section_index": 22, "content_hash": "be1c2fcb9848af6103a99d75c9e257bad4700706993eb9119d06cb3f7c5f4bad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:03263eb1507258a350e61f30b24bab7e8e663b4d3be4d0eb222e55b083163245", "content": "* `resourceUrl`: A string representing the URL of the resource to be read.\n* `resource`: A Spring `Resource` object pointing to the text file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 4, "file_order": 103, "section_index": 23, "content_hash": "03263eb1507258a350e61f30b24bab7e8e663b4d3be4d0eb222e55b083163245", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:85f98412003e803aaf1f8b005a303f17f1c13fe6b5ab12cc363791b3eb1738aa", "content": "* `setCharset(Charset charset)`: Sets the character set used for reading the text file. Default is UTF-8.\n* `getCustomMetadata()`: Returns a mutable map where you can add custom metadata for the documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Configuration", "heading_level": 4, "file_order": 103, "section_index": 24, "content_hash": "85f98412003e803aaf1f8b005a303f17f1c13fe6b5ab12cc363791b3eb1738aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:df0456c75a36cc91e8da3e1250a945864c6371657a60c6dd88ca507a30f198fd", "content": "The `TextReader` processes text content as follows:\n\n* It reads the entire content of the text file into a single `Document` object.\n* The content of the file becomes the content of the `Document`.\n* Metadata is automatically added to the `Document`:\n** `charset`: The character set used to read the file (default: \"UTF-8\").\n** `source`: The filename of the source text file.\n* Any custom metadata added via `getCustomMetadata()` is included in the `Document`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 25, "content_hash": "df0456c75a36cc91e8da3e1250a945864c6371657a60c6dd88ca507a30f198fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:b5a62f3f187a07926e5d942d856f2c4d9a0f33490bc45dd3c528e670fe3ddd41", "content": "* The `TextReader` reads the entire file content into memory, so it may not be suitable for very large files.\n* If you need to split the text into smaller chunks, you can use a text splitter like `TokenTextSplitter` after reading the document:\n\n[source,java]\n----\nList<Document> documents = textReader.get();\nList<Document> splitDocuments = new TokenTextSplitter().apply(this.documents);\n----\n\n* The reader uses Spring's `Resource` abstraction, allowing it to read from various sources (classpath, file system, URL, etc.).\n* Custom metadata can be added to all documents created by the reader using the `getCustomMetadata()` method.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 26, "content_hash": "b5a62f3f187a07926e5d942d856f2c4d9a0f33490bc45dd3c528e670fe3ddd41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d62929513f74361ccd5c799dcd9f09e742a2e4e8803e0a4822b1d7970c3fff8d", "content": "The `JsoupDocumentReader` processes HTML documents, converting them into a list of `Document` objects using the JSoup library.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "HTML (JSoup)", "heading_level": 3, "file_order": 103, "section_index": 27, "content_hash": "d62929513f74361ccd5c799dcd9f09e742a2e4e8803e0a4822b1d7970c3fff8d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:0003002fbfa05c5589141f2326cc6dfa9ecf3fe4500a2cfbf9929c9b628b01ba", "content": "Add the dependency to your project using Maven or Gradle.\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-jsoup-document-reader</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-jsoup-document-reader'\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Dependencies", "heading_level": 4, "file_order": 103, "section_index": 28, "content_hash": "0003002fbfa05c5589141f2326cc6dfa9ecf3fe4500a2cfbf9929c9b628b01ba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:311fbd6fad48aa866b34de85972c3612c4e769a123fd400090bc6d2ddef3d91e", "content": "[source,java]\n----\n@Component\nclass MyHtmlReader {\n\n private final Resource resource;\n\n MyHtmlReader(@Value(\"classpath:/my-page.html\") Resource resource) {\n this.resource = resource;\n }\n\n List<Document> loadHtml() {\n JsoupDocumentReaderConfig config = JsoupDocumentReaderConfig.builder()\n .selector(\"article p\") // Extract paragraphs within <article> tags\n .charset(\"ISO-8859-1\") // Use ISO-8859-1 encoding\n .includeLinkUrls(true) // Include link URLs in metadata\n .metadataTags(List.of(\"author\", \"date\")) // Extract author and date meta tags\n .additionalMetadata(\"source\", \"my-page.html\") // Add custom metadata\n .build();\n\n JsoupDocumentReader reader = new JsoupDocumentReader(this.resource, config);\n return reader.get();\n }\n}\n----\n\nThe `JsoupDocumentReaderConfig` allows you to customize the behavior of the `JsoupDocumentReader`:\n\n* `charset`: Specifies the character encoding of the HTML document (defaults to \"UTF-8\").\n* `selector`: A JSoup CSS selector to specify which elements to extract text from (defaults to \"body\").\n* `separator`: The string used to join text from multiple selected elements (defaults to \"\\n\").\n* `allElements`: If `true`, extracts all text from the `<body>` element, ignoring the `selector` (defaults to `false`).\n* `groupByElement`: If `true`, creates a separate `Document` for each element matched by the `selector` (defaults to `false`).\n* `includeLinkUrls`: If `true`, extracts absolute link URLs and adds them to the metadata (defaults to `false`).\n* `metadataTags`: A list of `<meta>` tag names to extract content from (defaults to `[\"description\", \"keywords\"]`).\n* `additionalMetadata`: Allows you to add custom metadata to all created `Document` objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 29, "content_hash": "311fbd6fad48aa866b34de85972c3612c4e769a123fd400090bc6d2ddef3d91e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:b587541bc4f378de36b25a0e367e4b6462bf15695df9bedf8a12742748e56f7a", "content": "[source,html]\n----\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n <meta charset=\"UTF-8\">\n <title>My Web Page</title>\n <meta name=\"description\" content=\"A sample web page for Spring AI\">\n <meta name=\"keywords\" content=\"spring, ai, html, example\">\n <meta name=\"author\" content=\"John Doe\">\n <meta name=\"date\" content=\"2024-01-15\">\n <link rel=\"stylesheet\" href=\"style.css\">\n</head>\n<body>\n <header>\n <h1>Welcome to My Page</h1>\n </header>\n <nav>\n <ul>\n <li><a href=\"/\">Home</a></li>\n <li><a href=\"/about\">About</a></li>\n </ul>\n </nav>\n <article>\n <h2>Main Content</h2>\n <p>This is the main content of my web page.</p>\n <p>It contains multiple paragraphs.</p>\n <a href=\"https://www.example.com\">External Link</a>\n </article>\n <footer>\n <p>&copy; 2024 John Doe</p>\n </footer>\n</body>\n</html>\n----\n\nBehavior:\n\nThe `JsoupDocumentReader` processes the HTML content and creates `Document` objects based on the configuration:\n\n* The `selector` determines which elements are used for text extraction.\n* If `allElements` is `true`, all text within the `<body>` is extracted into a single `Document`.\n* If `groupByElement` is `true`, each element matching the `selector` creates a separate `Document`.\n* If neither `allElements` nor `groupByElement` is `true`, text from all elements matching the `selector` is joined using the `separator`.\n* The document title, content from specified `<meta>` tags, and (optionally) link URLs are added to the `Document` metadata.\n* The base URI, for resolving relative links, will be extracted from URL resources.\n\nThe reader preserves the text content of the selected elements, but removes any HTML tags within them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Sample Document: my-page.html", "heading_level": 4, "file_order": 103, "section_index": 30, "content_hash": "b587541bc4f378de36b25a0e367e4b6462bf15695df9bedf8a12742748e56f7a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:1ce90dacd04f915025ed53045bfc6025dd9e5d845422b158ac251e47e1ac1dbf", "content": "The `MarkdownDocumentReader` processes Markdown documents, converting them into a list of `Document` objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Markdown", "heading_level": 3, "file_order": 103, "section_index": 31, "content_hash": "1ce90dacd04f915025ed53045bfc6025dd9e5d845422b158ac251e47e1ac1dbf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:7e0fb750a8efa03b3ac8b6108972287f8476dc6b7a290a92c20cf515f38d9fd3", "content": "Add the dependency to your project using Maven or Gradle.\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-markdown-document-reader</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-markdown-document-reader'\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Dependencies", "heading_level": 4, "file_order": 103, "section_index": 32, "content_hash": "7e0fb750a8efa03b3ac8b6108972287f8476dc6b7a290a92c20cf515f38d9fd3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d6df9a528268e1c95ff4e3cc6799b8f3807eef286e2098863adf8ed75b4f4b5c", "content": "[source,java]\n----\n@Component\nclass MyMarkdownReader {\n\n private final Resource resource;\n\n MyMarkdownReader(@Value(\"classpath:code.md\") Resource resource) {\n this.resource = resource;\n }\n\n List<Document> loadMarkdown() {\n MarkdownDocumentReaderConfig config = MarkdownDocumentReaderConfig.builder()\n .withHorizontalRuleCreateDocument(true)\n .withIncludeCodeBlock(false)\n .withIncludeBlockquote(false)\n .withAdditionalMetadata(\"filename\", \"code.md\")\n .build();\n\n MarkdownDocumentReader reader = new MarkdownDocumentReader(this.resource, config);\n return reader.get();\n }\n}\n----\n\nThe `MarkdownDocumentReaderConfig` allows you to customize the behavior of the MarkdownDocumentReader:\n\n* `horizontalRuleCreateDocument`: When set to `true`, horizontal rules in the Markdown will create new `Document` objects.\n* `includeCodeBlock`: When set to `true`, code blocks will be included in the same `Document` as the surrounding text. When `false`, code blocks create separate `Document` objects.\n* `includeBlockquote`: When set to `true`, blockquotes will be included in the same `Document` as the surrounding text. When `false`, blockquotes create separate `Document` objects.\n* `additionalMetadata`: Allows you to add custom metadata to all created `Document` objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 33, "content_hash": "d6df9a528268e1c95ff4e3cc6799b8f3807eef286e2098863adf8ed75b4f4b5c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:527f23bdd106396dcde96c7f12a4dd1177bbbf1d89b4352048301326488ba91e", "content": "[source,markdown]\n----\nThis is a Java sample application:\n\n```java\npackage com.example.demo;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class DemoApplication {\n public static void main(String[] args) {\n SpringApplication.run(DemoApplication.class, args);\n }\n}\n```\n\nMarkdown also provides the possibility to `use inline code formatting throughout` the entire sentence.\n\n---\n\nAnother possibility is to set block code without specific highlighting:\n\n```\n./mvnw spring-javaformat:apply\n```\n----\n\nBehavior: The MarkdownDocumentReader processes the Markdown content and creates Document objects based on the configuration:\n\n* Headers become metadata in the Document objects.\n* Paragraphs become the content of Document objects.\n* Code blocks can be separated into their own Document objects or included with surrounding text.\n* Blockquotes can be separated into their own Document objects or included with surrounding text.\n* Horizontal rules can be used to split the content into separate Document objects.\n\nThe reader preserves formatting like inline code, lists, and text styling within the content of the Document objects.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Sample Document: code.md", "heading_level": 4, "file_order": 103, "section_index": 34, "content_hash": "527f23bdd106396dcde96c7f12a4dd1177bbbf1d89b4352048301326488ba91e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:80b3417baba96d1f0d9fddd9805a47b47b45d770573e5e0bf95fcce9031e39d6", "content": "The `PagePdfDocumentReader` uses Apache PdfBox library to parse PDF documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "PDF Page", "heading_level": 3, "file_order": 103, "section_index": 35, "content_hash": "80b3417baba96d1f0d9fddd9805a47b47b45d770573e5e0bf95fcce9031e39d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:4dcb0e92365761628e6a8286636b929185b427501745a8818e44c9653a07f5cd", "content": "Add the dependency to your project using Maven or Gradle.\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-pdf-document-reader</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-pdf-document-reader'\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Dependencies", "heading_level": 4, "file_order": 103, "section_index": 36, "content_hash": "4dcb0e92365761628e6a8286636b929185b427501745a8818e44c9653a07f5cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:105cccab8448fddbef782808c6a0175769b022f2e358345360ca4f46de0c3f9a", "content": "[source,java]\n----\n@Component\npublic class MyPagePdfDocumentReader {\n\n\tList<Document> getDocsFromPdf() {\n\n PagePdfDocumentReader pdfReader = new PagePdfDocumentReader(\"classpath:/sample1.pdf\",\n PdfDocumentReaderConfig.builder()\n .withPageTopMargin(0)\n .withPageExtractedTextFormatter(ExtractedTextFormatter.builder()\n .withNumberOfTopTextLinesToDelete(0)\n .build())\n .withPagesPerDocument(1)\n .build());\n\n return pdfReader.read();\n }\n\n}\n\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 37, "content_hash": "105cccab8448fddbef782808c6a0175769b022f2e358345360ca4f46de0c3f9a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:62a4f4c3f3441299405e111aa50808d4c0609be274c1bc014fa47b00bd165919", "content": "The `ParagraphPdfDocumentReader` uses the PDF catalog (e.g. TOC) information to split the input PDF into text paragraphs and output a single `Document` per paragraph.\nNOTE: Not all PDF documents contain the PDF catalog.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "PDF Paragraph", "heading_level": 3, "file_order": 103, "section_index": 38, "content_hash": "62a4f4c3f3441299405e111aa50808d4c0609be274c1bc014fa47b00bd165919", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:4dcb0e92365761628e6a8286636b929185b427501745a8818e44c9653a07f5cd", "content": "Add the dependency to your project using Maven or Gradle.\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-pdf-document-reader</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-pdf-document-reader'\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Dependencies", "heading_level": 4, "file_order": 103, "section_index": 39, "content_hash": "4dcb0e92365761628e6a8286636b929185b427501745a8818e44c9653a07f5cd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d8c829e075144ae3ea2f4af47d68fb2069f4615a71350b3d0141c9ed5c945de1", "content": "[source,java]\n----\n@Component\npublic class MyPagePdfDocumentReader {\n\n\tList<Document> getDocsFromPdfWithCatalog() {\n\n ParagraphPdfDocumentReader pdfReader = new ParagraphPdfDocumentReader(\"classpath:/sample1.pdf\",\n PdfDocumentReaderConfig.builder()\n .withPageTopMargin(0)\n .withPageExtractedTextFormatter(ExtractedTextFormatter.builder()\n .withNumberOfTopTextLinesToDelete(0)\n .build())\n .withPagesPerDocument(1)\n .build());\n\n return pdfReader.read();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 40, "content_hash": "d8c829e075144ae3ea2f4af47d68fb2069f4615a71350b3d0141c9ed5c945de1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:5620677b446d2b87209e55e96d8960b445c4d6c7328c5dcc25c31521e6f06b8a", "content": "The `TikaDocumentReader` uses Apache Tika to extract text from a variety of document formats, such as PDF, DOC/DOCX, PPT/PPTX, and HTML. For a comprehensive list of supported formats, refer to the https://tika.apache.org/3.1.0/formats.html[Tika documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Tika (DOCX, PPTX, HTML...)", "heading_level": 3, "file_order": 103, "section_index": 41, "content_hash": "5620677b446d2b87209e55e96d8960b445c4d6c7328c5dcc25c31521e6f06b8a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:77cfab0d999178349b1c359429e86658d36c81d6fcfef0f641967aa9d2991a30", "content": "Add the dependency to your project using Maven or Gradle.\n\n[tabs]\n======\nMaven::\n+\n[source, xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-tika-document-reader</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-tika-document-reader'\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Dependencies", "heading_level": 4, "file_order": 103, "section_index": 42, "content_hash": "77cfab0d999178349b1c359429e86658d36c81d6fcfef0f641967aa9d2991a30", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:e9f6f46a173bb4b9e8ebe65f01593dd5d8b2dcf05822a71b79ed07dbf39a5a6e", "content": "[source,java]\n----\n@Component\nclass MyTikaDocumentReader {\n\n private final Resource resource;\n\n MyTikaDocumentReader(@Value(\"classpath:/word-sample.docx\")\n Resource resource) {\n this.resource = resource;\n }\n\n List<Document> loadText() {\n TikaDocumentReader tikaDocumentReader = new TikaDocumentReader(this.resource);\n return tikaDocumentReader.read();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 43, "content_hash": "e9f6f46a173bb4b9e8ebe65f01593dd5d8b2dcf05822a71b79ed07dbf39a5a6e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:87ee465c9736cbc2afcc112afc4126970910c5d8b4beeadc3a05356c3e3f1649", "content": "The `TextSplitter` an abstract base class that helps divides documents to fit the AI model's context window.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "TextSplitter", "heading_level": 3, "file_order": 103, "section_index": 44, "content_hash": "87ee465c9736cbc2afcc112afc4126970910c5d8b4beeadc3a05356c3e3f1649", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:8ee7cf63b09e32c64d8904f850d1b952c5325b8a268127ecd9db1be92a7c0f29", "content": "The `TokenTextSplitter` is an implementation of `TextSplitter` that splits text into chunks based on token count, using the CL100K_BASE encoding.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "TokenTextSplitter", "heading_level": 3, "file_order": 103, "section_index": 45, "content_hash": "8ee7cf63b09e32c64d8904f850d1b952c5325b8a268127ecd9db1be92a7c0f29", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:8272fa1a68c76b253be4caa1b3970e985d45a688597fd39bf134d82ec84fea5c", "content": "[source,java]\n----\n@Component\nclass MyTokenTextSplitter {\n\n public List<Document> splitDocuments(List<Document> documents) {\n TokenTextSplitter splitter = new TokenTextSplitter();\n return splitter.apply(documents);\n }\n\n public List<Document> splitCustomized(List<Document> documents) {\n TokenTextSplitter splitter = new TokenTextSplitter(1000, 400, 10, 5000, true, List.of('.', '?', '!', '\\n'));\n return splitter.apply(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Basic Usage", "heading_level": 5, "file_order": 103, "section_index": 46, "content_hash": "8272fa1a68c76b253be4caa1b3970e985d45a688597fd39bf134d82ec84fea5c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:38a40cda9b7c18ed780cb151a32eecc9f6317cea70c68efface602bcb0f21471", "content": "The recommended way to create a `TokenTextSplitter` is using the builder pattern, which provides a more readable and flexible API:\n\n[source,java]\n----\n@Component\nclass MyTokenTextSplitter {\n\n public List<Document> splitWithBuilder(List<Document> documents) {\n TokenTextSplitter splitter = TokenTextSplitter.builder()\n .withChunkSize(1000)\n .withMinChunkSizeChars(400)\n .withMinChunkLengthToEmbed(10)\n .withMaxNumChunks(5000)\n .withKeepSeparator(true)\n .build();\n\n return splitter.apply(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Using the Builder Pattern", "heading_level": 5, "file_order": 103, "section_index": 47, "content_hash": "38a40cda9b7c18ed780cb151a32eecc9f6317cea70c68efface602bcb0f21471", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:6bd0a52ce14ce84ab6121bd9923894c531af6c555952b0ba31cf0c26098219e8", "content": "You can customize the punctuation marks used for splitting text into semantically meaningful chunks. This is particularly useful for internationalization:\n\n[source,java]\n----\n@Component\nclass MyInternationalTextSplitter {\n\n public List<Document> splitChineseText(List<Document> documents) {\n // Use Chinese punctuation marks\n TokenTextSplitter splitter = TokenTextSplitter.builder()\n .withChunkSize(800)\n .withMinChunkSizeChars(350)\n .withPunctuationMarks(List.of('。', '？', '！', '；')) // Chinese punctuation\n .build();\n\n return splitter.apply(documents);\n }\n\n public List<Document> splitWithCustomMarks(List<Document> documents) {\n // Mix of English and other punctuation marks\n TokenTextSplitter splitter = TokenTextSplitter.builder()\n .withChunkSize(800)\n .withPunctuationMarks(List.of('.', '?', '!', '\\n', ';', ':', '。'))\n .build();\n\n return splitter.apply(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Custom Punctuation Marks", "heading_level": 5, "file_order": 103, "section_index": 48, "content_hash": "6bd0a52ce14ce84ab6121bd9923894c531af6c555952b0ba31cf0c26098219e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:6496321d8c96e32f18dfcb977b37cc57042a005356986072f1f3dad484bf50da", "content": "The `TokenTextSplitter` provides three constructor options:\n\n1. `TokenTextSplitter()`: Creates a splitter with default settings.\n2. `TokenTextSplitter(boolean keepSeparator)`: Creates a splitter with custom separator behavior.\n3. `TokenTextSplitter(int chunkSize, int minChunkSizeChars, int minChunkLengthToEmbed, int maxNumChunks, boolean keepSeparator, List<Character> punctuationMarks)`: Full constructor with all customization options.\n\nNOTE: The builder pattern (shown above) is the recommended approach for creating instances with custom configurations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructor Options", "heading_level": 4, "file_order": 103, "section_index": 49, "content_hash": "6496321d8c96e32f18dfcb977b37cc57042a005356986072f1f3dad484bf50da", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:260f3f63c6131ef086e9f754358512bdbd16026845ac4cdb8e80f9f52d2c626d", "content": "* `chunkSize`: The target size of each text chunk in tokens (default: 800).\n* `minChunkSizeChars`: The minimum size of each text chunk in characters (default: 350).\n* `minChunkLengthToEmbed`: The minimum length of a chunk to be included (default: 5).\n* `maxNumChunks`: The maximum number of chunks to generate from a text (default: 10000).\n* `keepSeparator`: Whether to keep separators (like newlines) in the chunks (default: true).\n* `punctuationMarks`: List of characters to use as sentence boundaries for splitting (default: `.`, `?`, `!`, `\\n`).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 4, "file_order": 103, "section_index": 50, "content_hash": "260f3f63c6131ef086e9f754358512bdbd16026845ac4cdb8e80f9f52d2c626d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:8d662ee338a60d0323f3e877c14c2f3329f4208555d9083a25b09e2fbca27823", "content": "The `TokenTextSplitter` processes text content as follows:\n\n1. It encodes the input text into tokens using the CL100K_BASE encoding.\n2. It splits the encoded text into chunks based on the `chunkSize`.\n3. For each chunk:\n a. It decodes the chunk back into text.\n b. *Only if the total token count exceeds the chunk size*, it attempts to find a suitable break point (using the configured `punctuationMarks`) after the `minChunkSizeChars`.\n c. If a break point is found, it truncates the chunk at that point.\n d. It trims the chunk and optionally removes newline characters based on the `keepSeparator` setting.\n e. If the resulting chunk is longer than `minChunkLengthToEmbed`, it's added to the output.\n4. This process continues until all tokens are processed or `maxNumChunks` is reached.\n5. Any remaining text is added as a final chunk if it's longer than `minChunkLengthToEmbed`.\n\nIMPORTANT: Punctuation-based splitting only applies when the token count exceeds the chunk size. Text that exactly matches or is smaller than the chunk size is returned as a single chunk without punctuation-based truncation. This prevents unnecessary splitting of small texts.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 51, "content_hash": "8d662ee338a60d0323f3e877c14c2f3329f4208555d9083a25b09e2fbca27823", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:d902d79ad6f051e295588cfed05705d2688172ef46055c2ad5a087a3f8c41a61", "content": "[source,java]\n----\nDocument doc1 = new Document(\"This is a long piece of text that needs to be split into smaller chunks for processing.\",\n Map.of(\"source\", \"example.txt\"));\nDocument doc2 = new Document(\"Another document with content that will be split based on token count.\",\n Map.of(\"source\", \"example2.txt\"));\n\nTokenTextSplitter splitter = new TokenTextSplitter();\nList<Document> splitDocuments = this.splitter.apply(List.of(this.doc1, this.doc2));\n\nfor (Document doc : splitDocuments) {\n System.out.println(\"Chunk: \" + doc.getContent());\n System.out.println(\"Metadata: \" + doc.getMetadata());\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 52, "content_hash": "d902d79ad6f051e295588cfed05705d2688172ef46055c2ad5a087a3f8c41a61", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:40a609d4b97d8d82ec44ccda852c79baf4101af155b837805d15f294fddd551c", "content": "* The `TokenTextSplitter` uses the CL100K_BASE encoding from the `jtokkit` library, which is compatible with newer OpenAI models.\n* The splitter attempts to create semantically meaningful chunks by breaking at sentence boundaries where possible.\n* Metadata from the original documents is preserved and copied to all chunks derived from that document.\n* The content formatter (if set) from the original document is also copied to the derived chunks if `copyContentFormatter` is set to `true` (default behavior).\n* This splitter is particularly useful for preparing text for large language models that have token limits, ensuring that each chunk is within the model's processing capacity.\n* *Custom Punctuation Marks*: The default punctuation marks (`.`, `?`, `!`, `\\n`) work well for English text. For other languages or specialized content, customize the punctuation marks using the builder's `withPunctuationMarks()` method.\n* *Performance Consideration*: While the splitter can handle any number of punctuation marks, it's recommended to keep the list reasonably small (under 20 characters) for optimal performance, as each mark is checked for every chunk.\n* *Extensibility*: The `getLastPunctuationIndex(String)` method is `protected`, allowing subclasses to override the punctuation detection logic for specialized use cases.\n* *Small Text Handling*: As of version 2.0, small texts (with token count at or below the chunk size) are no longer split at punctuation marks, preventing unnecessary fragmentation of content that already fits within the size limits.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 53, "content_hash": "40a609d4b97d8d82ec44ccda852c79baf4101af155b837805d15f294fddd551c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:8f373843b5387313df7f8bef4882c8001fc0aee661e046317a5650ccb309672a", "content": "Ensures uniform content formats across all documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "ContentFormatTransformer", "heading_level": 3, "file_order": 103, "section_index": 54, "content_hash": "8f373843b5387313df7f8bef4882c8001fc0aee661e046317a5650ccb309672a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:638ac1af33c1c5ed585467a23c1a0ec09c5ca063f1cb26937e4ff0f100836fda", "content": "The `KeywordMetadataEnricher` is a `DocumentTransformer` that uses a generative AI model to extract keywords from document content and add them as metadata.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "KeywordMetadataEnricher", "heading_level": 3, "file_order": 103, "section_index": 55, "content_hash": "638ac1af33c1c5ed585467a23c1a0ec09c5ca063f1cb26937e4ff0f100836fda", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:3d9a611aa024a6d8897fe7cbb5164fadadf23556995bd48d89d8fdccc93553e7", "content": "[source,java]\n----\n@Component\nclass MyKeywordEnricher {\n\n private final ChatModel chatModel;\n\n MyKeywordEnricher(ChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n List<Document> enrichDocuments(List<Document> documents) {\n KeywordMetadataEnricher enricher = KeywordMetadataEnricher.builder(chatModel)\n .keywordCount(5)\n .build();\n\n // Or use custom templates\n KeywordMetadataEnricher enricher = KeywordMetadataEnricher.builder(chatModel)\n .keywordsTemplate(YOUR_CUSTOM_TEMPLATE)\n .build();\n\n return enricher.apply(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Usage", "heading_level": 4, "file_order": 103, "section_index": 56, "content_hash": "3d9a611aa024a6d8897fe7cbb5164fadadf23556995bd48d89d8fdccc93553e7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:45f7c119c8bb80a7fc602705e72000706b5a03e9bc6e91fdbd70d44810133508", "content": "The `KeywordMetadataEnricher` provides two constructor options:\n\n1. `KeywordMetadataEnricher(ChatModel chatModel, int keywordCount)`: To use the default template and extract a specified number of keywords.\n2. `KeywordMetadataEnricher(ChatModel chatModel, PromptTemplate keywordsTemplate)`: To use a custom template for keyword extraction.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructor Options", "heading_level": 4, "file_order": 103, "section_index": 57, "content_hash": "45f7c119c8bb80a7fc602705e72000706b5a03e9bc6e91fdbd70d44810133508", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:098a342b70490d3da76cba298fbb0b814f34077cd14923175c90414b2e3f0bca", "content": "The `KeywordMetadataEnricher` processes documents as follows:\n\n1. For each input document, it creates a prompt using the document's content.\n2. It sends this prompt to the provided `ChatModel` to generate keywords.\n3. The generated keywords are added to the document's metadata under the key \"excerpt_keywords\".\n4. The enriched documents are returned.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 58, "content_hash": "098a342b70490d3da76cba298fbb0b814f34077cd14923175c90414b2e3f0bca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:14093a6cc26859597029c0b328b6462228874b8be62946eb19aae4c9e68907e0", "content": "You can use the default template or customize the template through the keywordsTemplate parameter.\nThe default template is:\n\n[source,java]\n----\n\\{context_str}. Give %s unique keywords for this document. Format as comma separated. Keywords:\n----\n\nWhere `+{context_str}+` is replaced with the document content, and `%s` is replaced with the specified keyword count.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Customization", "heading_level": 4, "file_order": 103, "section_index": 59, "content_hash": "14093a6cc26859597029c0b328b6462228874b8be62946eb19aae4c9e68907e0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:c886c0eb76ba11026d1ab76a3af0d5e4db9ecdc4f2089c99306d5bc422f67420", "content": "[source,java]\n----\nChatModel chatModel = // initialize your chat model\nKeywordMetadataEnricher enricher = KeywordMetadataEnricher.builder(chatModel)\n .keywordCount(5)\n .build();\n\nKeywordMetadataEnricher enricher = KeywordMetadataEnricher.builder(chatModel)\n .keywordsTemplate(new PromptTemplate(\"Extract 5 important keywords from the following text and separate them with commas:\\n{context_str}\"))\n .build();\n\nDocument doc = new Document(\"This is a document about artificial intelligence and its applications in modern technology.\");\n\nList<Document> enrichedDocs = enricher.apply(List.of(this.doc));\n\nDocument enrichedDoc = this.enrichedDocs.get(0);\nString keywords = (String) this.enrichedDoc.getMetadata().get(\"excerpt_keywords\");\nSystem.out.println(\"Extracted keywords: \" + keywords);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 60, "content_hash": "c886c0eb76ba11026d1ab76a3af0d5e4db9ecdc4f2089c99306d5bc422f67420", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:f7ac64c0e467ebdffa2ef49442718ece4b22251998a7205f91fe9177a05ed8f1", "content": "* The `KeywordMetadataEnricher` requires a functioning `ChatModel` to generate keywords.\n* The keyword count must be 1 or greater.\n* The enricher adds the \"excerpt_keywords\" metadata field to each processed document.\n* The generated keywords are returned as a comma-separated string.\n* This enricher is particularly useful for improving document searchability and for generating tags or categories for documents.\n* In the Builder pattern, if the `keywordsTemplate` parameter is set, the `keywordCount` parameter will be ignored.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 61, "content_hash": "f7ac64c0e467ebdffa2ef49442718ece4b22251998a7205f91fe9177a05ed8f1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:2265b86d28eff6c541206d1d37177fa600fcf40c320399ac0e71cacc05c73b28", "content": "The `SummaryMetadataEnricher` is a `DocumentTransformer` that uses a generative AI model to create summaries for documents and add them as metadata. It can generate summaries for the current document, as well as adjacent documents (previous and next).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "SummaryMetadataEnricher", "heading_level": 3, "file_order": 103, "section_index": 62, "content_hash": "2265b86d28eff6c541206d1d37177fa600fcf40c320399ac0e71cacc05c73b28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:b59ab304f2a06f9d93e10730bc72735ab3a0afa3662b61ebd52c57d15767b4e3", "content": "[source,java]\n----\n@Configuration\nclass EnricherConfig {\n\n @Bean\n public SummaryMetadataEnricher summaryMetadata(OpenAiChatModel aiClient) {\n return new SummaryMetadataEnricher(aiClient,\n List.of(SummaryType.PREVIOUS, SummaryType.CURRENT, SummaryType.NEXT));\n }\n}\n\n@Component\nclass MySummaryEnricher {\n\n private final SummaryMetadataEnricher enricher;\n\n MySummaryEnricher(SummaryMetadataEnricher enricher) {\n this.enricher = enricher;\n }\n\n List<Document> enrichDocuments(List<Document> documents) {\n return this.enricher.apply(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Usage", "heading_level": 4, "file_order": 103, "section_index": 63, "content_hash": "b59ab304f2a06f9d93e10730bc72735ab3a0afa3662b61ebd52c57d15767b4e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:7c8a6516f3709b14a5fd68fd51b8c33d489a0197579e1fddd28c13cc4a4dc71f", "content": "The `SummaryMetadataEnricher` provides two constructors:\n\n1. `SummaryMetadataEnricher(ChatModel chatModel, List<SummaryType> summaryTypes)`\n2. `SummaryMetadataEnricher(ChatModel chatModel, List<SummaryType> summaryTypes, String summaryTemplate, MetadataMode metadataMode)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructor", "heading_level": 4, "file_order": 103, "section_index": 64, "content_hash": "7c8a6516f3709b14a5fd68fd51b8c33d489a0197579e1fddd28c13cc4a4dc71f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:f012f9fdae092f18a3bb3a5f8b2dd82934cc823f6124b9cac3320875a4940c59", "content": "* `chatModel`: The AI model used for generating summaries.\n* `summaryTypes`: A list of `SummaryType` enum values indicating which summaries to generate (PREVIOUS, CURRENT, NEXT).\n* `summaryTemplate`: A custom template for summary generation (optional).\n* `metadataMode`: Specifies how to handle document metadata when generating summaries (optional).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 4, "file_order": 103, "section_index": 65, "content_hash": "f012f9fdae092f18a3bb3a5f8b2dd82934cc823f6124b9cac3320875a4940c59", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:718489f1bdf1096ea49c77c39f59dcdd7c7521a39894baab7ba05cfc780bec1d", "content": "The `SummaryMetadataEnricher` processes documents as follows:\n\n1. For each input document, it creates a prompt using the document's content and the specified summary template.\n2. It sends this prompt to the provided `ChatModel` to generate a summary.\n3. Depending on the specified `summaryTypes`, it adds the following metadata to each document:\n* `section_summary`: Summary of the current document.\n* `prev_section_summary`: Summary of the previous document (if available and requested).\n* `next_section_summary`: Summary of the next document (if available and requested).\n4. The enriched documents are returned.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 66, "content_hash": "718489f1bdf1096ea49c77c39f59dcdd7c7521a39894baab7ba05cfc780bec1d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:a0bb47c7939f2abc76905931fa541043cbba2f159b0d511b64daae1452276544", "content": "The summary generation prompt can be customized by providing a custom `summaryTemplate`. The default template is:\n\n[source,java]\n----\n\"\"\"\nHere is the content of the section:\n{context_str}\n\nSummarize the key topics and entities of the section.\n\nSummary:\n\"\"\"\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Customization", "heading_level": 4, "file_order": 103, "section_index": 67, "content_hash": "a0bb47c7939f2abc76905931fa541043cbba2f159b0d511b64daae1452276544", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:a19e9fa375ffb571e8b222d551d4d12e832e26847e12b0ccdf12f3671b9da405", "content": "[source,java]\n----\nChatModel chatModel = // initialize your chat model\nSummaryMetadataEnricher enricher = new SummaryMetadataEnricher(chatModel,\n List.of(SummaryType.PREVIOUS, SummaryType.CURRENT, SummaryType.NEXT));\n\nDocument doc1 = new Document(\"Content of document 1\");\nDocument doc2 = new Document(\"Content of document 2\");\n\nList<Document> enrichedDocs = enricher.apply(List.of(this.doc1, this.doc2));\n\nfor (Document doc : enrichedDocs) {\n System.out.println(\"Current summary: \" + doc.getMetadata().get(\"section_summary\"));\n System.out.println(\"Previous summary: \" + doc.getMetadata().get(\"prev_section_summary\"));\n System.out.println(\"Next summary: \" + doc.getMetadata().get(\"next_section_summary\"));\n}\n----\n\nThe provided example demonstrates the expected behavior:\n\n* For a list of two documents, both documents receive a `section_summary`.\n* The first document receives a `next_section_summary` but no `prev_section_summary`.\n* The second document receives a `prev_section_summary` but no `next_section_summary`.\n* The `section_summary` of the first document matches the `prev_section_summary` of the second document.\n* The `next_section_summary` of the first document matches the `section_summary` of the second document.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 68, "content_hash": "a19e9fa375ffb571e8b222d551d4d12e832e26847e12b0ccdf12f3671b9da405", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:e3e14ebd8e3caaa07c0e22f99493f297a46f20f17f4c82f4eda003b931deb351", "content": "* The `SummaryMetadataEnricher` requires a functioning `ChatModel` to generate summaries.\n* The enricher can handle document lists of any size, properly handling edge cases for the first and last documents.\n* This enricher is particularly useful for creating context-aware summaries, allowing for better understanding of document relationships in a sequence.\n* The `MetadataMode` parameter allows control over how existing metadata is incorporated into the summary generation process.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 69, "content_hash": "e3e14ebd8e3caaa07c0e22f99493f297a46f20f17f4c82f4eda003b931deb351", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:9998fccc313dcd4c33603453647ba9cf13a16ef337c3dd5aa37d70a8d722e769", "content": "The `FileDocumentWriter` is a `DocumentWriter` implementation that writes the content of a list of `Document` objects into a file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "File", "heading_level": 3, "file_order": 103, "section_index": 70, "content_hash": "9998fccc313dcd4c33603453647ba9cf13a16ef337c3dd5aa37d70a8d722e769", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:32ee01d860a9ccd60b6c58b8a150efcf1683f070fc4ce29b7a23fd29ec83c7fa", "content": "[source,java]\n----\n@Component\nclass MyDocumentWriter {\n\n public void writeDocuments(List<Document> documents) {\n FileDocumentWriter writer = new FileDocumentWriter(\"output.txt\", true, MetadataMode.ALL, false);\n writer.accept(documents);\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Usage", "heading_level": 4, "file_order": 103, "section_index": 71, "content_hash": "32ee01d860a9ccd60b6c58b8a150efcf1683f070fc4ce29b7a23fd29ec83c7fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:fead37210fbf2a9c50a1cede0f8bf6cf0aaa7fb988ed07b96aa55e19dbe35db1", "content": "The `FileDocumentWriter` provides three constructors:\n\n1. `FileDocumentWriter(String fileName)`\n2. `FileDocumentWriter(String fileName, boolean withDocumentMarkers)`\n3. `FileDocumentWriter(String fileName, boolean withDocumentMarkers, MetadataMode metadataMode, boolean append)`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Constructors", "heading_level": 4, "file_order": 103, "section_index": 72, "content_hash": "fead37210fbf2a9c50a1cede0f8bf6cf0aaa7fb988ed07b96aa55e19dbe35db1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:4fda49547f7dd5c3c68b71e8eec996cc67f24eaf21620980d75ea7a1fe81c0db", "content": "* `fileName`: The name of the file to write the documents to.\n* `withDocumentMarkers`: Whether to include document markers in the output (default: false).\n* `metadataMode`: Specifies what document content to be written to the file (default: MetadataMode.NONE).\n* `append`: If true, data will be written to the end of the file rather than the beginning (default: false).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Parameters", "heading_level": 4, "file_order": 103, "section_index": 73, "content_hash": "4fda49547f7dd5c3c68b71e8eec996cc67f24eaf21620980d75ea7a1fe81c0db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:0d1c8eff8dc40aab9e58e1c65e3f1e830f0d6ca0aa54c5ec269cc4fe7648bed7", "content": "The `FileDocumentWriter` processes documents as follows:\n\n1. It opens a FileWriter for the specified file name.\n2. For each document in the input list:\na. If `withDocumentMarkers` is true, it writes a document marker including the document index and page numbers.\nb. It writes the formatted content of the document based on the specified `metadataMode`.\n3. The file is closed after all documents have been written.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Behavior", "heading_level": 4, "file_order": 103, "section_index": 74, "content_hash": "0d1c8eff8dc40aab9e58e1c65e3f1e830f0d6ca0aa54c5ec269cc4fe7648bed7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:24a23cb1bdc2bb1784cc925a76d107ed6ec0cf22c4b94d7fbc40eadf10e8eff0", "content": "When `withDocumentMarkers` is set to true, the writer includes markers for each document in the following format:\n\n[source]\n----\n### Doc: [index], pages:[start_page_number,end_page_number]\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Document Markers", "heading_level": 4, "file_order": 103, "section_index": 75, "content_hash": "24a23cb1bdc2bb1784cc925a76d107ed6ec0cf22c4b94d7fbc40eadf10e8eff0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:4fe5fcc15ced2fe5c47df5a7ea962941fad096cc14ca690afac427b514d23015", "content": "The writer uses two specific metadata keys:\n\n* `page_number`: Represents the starting page number of the document.\n* `end_page_number`: Represents the ending page number of the document.\n\nThese are used when writing document markers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Metadata Handling", "heading_level": 4, "file_order": 103, "section_index": 76, "content_hash": "4fe5fcc15ced2fe5c47df5a7ea962941fad096cc14ca690afac427b514d23015", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:55b7d558c02c7c018300e396fbb8f40bc9db9ad8a305f83f3959c315c4193819", "content": "[source,java]\n----\nList<Document> documents = // initialize your documents\nFileDocumentWriter writer = new FileDocumentWriter(\"output.txt\", true, MetadataMode.ALL, true);\nwriter.accept(documents);\n----\n\nThis will write all documents to \"output.txt\", including document markers, using all available metadata, and appending to the file if it already exists.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Example", "heading_level": 4, "file_order": 103, "section_index": 77, "content_hash": "55b7d558c02c7c018300e396fbb8f40bc9db9ad8a305f83f3959c315c4193819", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:12ddd623e17f8763cd23b56799aaa688799ee8215320fd11613002b0326abc6d", "content": "* The writer uses `FileWriter`, so it writes text files with the default character encoding of the operating system.\n* If an error occurs during writing, a `RuntimeException` is thrown with the original exception as its cause.\n* The `metadataMode` parameter allows control over how existing metadata is incorporated into the written content.\n* This writer is particularly useful for debugging or creating human-readable outputs of document collections.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "Notes", "heading_level": 4, "file_order": 103, "section_index": 78, "content_hash": "12ddd623e17f8763cd23b56799aaa688799ee8215320fd11613002b0326abc6d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:72326991f9a53095dd229b5db884412b597e3376c315cfd27d3b158e8f4b12f9", "content": "Provides integration with various vector stores.\nSee xref:api/vectordbs.adoc[Vector DB Documentation] for a full listing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/etl-pipeline.adoc", "title": "ETL Pipeline", "heading": "VectorStore", "heading_level": 3, "file_order": 103, "section_index": 79, "content_hash": "72326991f9a53095dd229b5db884412b597e3376c315cfd27d3b158e8f4b12f9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/etl-pipeline.adoc"}}
{"id": "sha256:ff5537474b52a2d3c4ce1636edba65f1e97b99aced426cb2335e89e440b10106", "content": "[[generic-model-api]]\n\nIn order to provide a foundation for all AI Models, the Generic Model API was created.\nThis makes it easy to contribute new AI Model support to Spring AI by following a common pattern.\nThe following sections walk through this API.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "generic-model", "heading_level": 1, "file_order": 104, "section_index": 0, "content_hash": "ff5537474b52a2d3c4ce1636edba65f1e97b99aced426cb2335e89e440b10106", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:492af43e6be6b83e87ff39a154b3d3dc83e9cf72ab8e512618517450dbfb00df", "content": "image::spring-ai-generic-model-api.jpg[width=900, align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "Class Diagram", "heading_level": 2, "file_order": 104, "section_index": 1, "content_hash": "492af43e6be6b83e87ff39a154b3d3dc83e9cf72ab8e512618517450dbfb00df", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:abd2ed331406067343fd2e40ca228a52798748f48cb3f2df01aa4ae7372ff8da", "content": "The `Model` interface provides a generic API for invoking AI models. It is designed to handle the interaction with various types of AI models by abstracting the process of sending requests and receiving responses. The interface uses Java generics to accommodate different types of requests and responses, enhancing flexibility and adaptability across different AI model implementations.\n\nThe interface is defined below:\n\n[source,java]\n----\npublic interface Model<TReq extends ModelRequest<?>, TRes extends ModelResponse<?>> {\n\n\t/**\n * Executes a method call to the AI model.\n * @param request the request object to be sent to the AI model\n * @return the response from the AI model\n */\n\tTRes call(TReq request);\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "Model", "heading_level": 2, "file_order": 104, "section_index": 2, "content_hash": "abd2ed331406067343fd2e40ca228a52798748f48cb3f2df01aa4ae7372ff8da", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:6973ef22a333eac9c5b5f41196d94e50249749861665c503a88b6be056446480", "content": "The `StreamingModel` interface provides a generic API for invoking an AI model with streaming response. It abstracts the process of sending requests and receiving a streaming response. The interface uses Java generics to accommodate different types of requests and responses, enhancing flexibility and adaptability across different AI model implementations.\n\n[source,java]\n----\npublic interface StreamingModel<TReq extends ModelRequest<?>, TResChunk extends ModelResponse<?>> {\n\n\t/**\n * Executes a method call to the AI model.\n * @param request the request object to be sent to the AI model\n * @return the streaming response from the AI model\n */\n\tFlux<TResChunk> stream(TReq request);\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "StreamingModel", "heading_level": 2, "file_order": 104, "section_index": 3, "content_hash": "6973ef22a333eac9c5b5f41196d94e50249749861665c503a88b6be056446480", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:27cb733db8bf4391a52540c52547568a48f84af40e5979da9a9522897b969858", "content": "The `ModelRequest` interface represents a request to an AI model. It encapsulates the necessary information required to interact with an AI model, including instructions or inputs (of generic type `T`) and additional model options. It provides a standardized way to send requests to AI models, ensuring that all necessary details are included and can be easily managed.\n\n[source,java]\n----\npublic interface ModelRequest<T> {\n\n\t/**\n * Retrieves the instructions or input required by the AI model.\n * @return the instructions or input required by the AI model\n */\n\tT getInstructions(); // required input\n\n\t/**\n * Retrieves the customizable options for AI model interactions.\n * @return the customizable options for AI model interactions\n */\n\tModelOptions getOptions();\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "ModelRequest", "heading_level": 2, "file_order": 104, "section_index": 4, "content_hash": "27cb733db8bf4391a52540c52547568a48f84af40e5979da9a9522897b969858", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:54bbbda2d05814211ce09af08104a66062dbefffcd6fa87e1bf0f197d80deb37", "content": "The `ModelOptions` interface represents the customizable options for AI model interactions. This marker interface allows for the specification of various settings and parameters that can influence the behavior and output of AI models. It is designed to provide flexibility and adaptability in different AI scenarios, ensuring that the AI models can be fine-tuned according to specific requirements.\n\n[source,java]\n----\npublic interface ModelOptions {\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "ModelOptions", "heading_level": 2, "file_order": 104, "section_index": 5, "content_hash": "54bbbda2d05814211ce09af08104a66062dbefffcd6fa87e1bf0f197d80deb37", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:4a98e0e2e3b1bddcddb33fbe087f26621000b8645ad3df2f19f8a0a4a08d79a0", "content": "The `ModelResponse` interface represents the response received from an AI model. This interface provides methods to access the main result or a list of results generated by the AI model, along with the response metadata. It serves as a standardized way to encapsulate and manage the output from AI models, ensuring easy retrieval and processing of the generated information.\n\n[source,java]\n----\npublic interface ModelResponse<T extends ModelResult<?>> {\n\n\t/**\n * Retrieves the result of the AI model.\n * @return the result generated by the AI model\n */\n\tT getResult();\n\n\t/**\n * Retrieves the list of generated outputs by the AI model.\n * @return the list of generated outputs\n */\n\tList<T> getResults();\n\n\t/**\n * Retrieves the response metadata associated with the AI model's response.\n * @return the response metadata\n */\n\tResponseMetadata getMetadata();\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "ModelResponse", "heading_level": 2, "file_order": 104, "section_index": 6, "content_hash": "4a98e0e2e3b1bddcddb33fbe087f26621000b8645ad3df2f19f8a0a4a08d79a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:274bb6a9d077e6e4f82e7eb1a3c0a6ffc89aa47a2ed917bdc261480aa3a7195d", "content": "The `ModelResult` interface provides methods to access the main output of the AI model and the metadata associated with this result. It is designed to offer a standardized and comprehensive way to handle and interpret the outputs generated by AI models.\n\n[source,java]\n----\npublic interface ModelResult<T> {\n\n\t/**\n * Retrieves the output generated by the AI model.\n * @return the output generated by the AI model\n */\n\tT getOutput();\n\n\t/**\n * Retrieves the metadata associated with the result of an AI model.\n * @return the metadata associated with the result\n */\n\tResultMetadata getMetadata();\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/generic-model.adoc", "title": "generic-model", "heading": "ModelResult", "heading_level": 2, "file_order": 104, "section_index": 7, "content_hash": "274bb6a9d077e6e4f82e7eb1a3c0a6ffc89aa47a2ed917bdc261480aa3a7195d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/generic-model.adoc"}}
{"id": "sha256:5bcca10afdbc8321decff65a09b7cf46d3b07b5d6664227a14f90c647aa651cc", "content": "[[ImageModel]]\n\nThe `Spring Image Model API` is designed to be a simple and portable interface for interacting with various xref:concepts.adoc#_models[AI Models] specialized in image generation, allowing developers to switch between different image-related models with minimal code changes.\nThis design aligns with Spring's philosophy of modularity and interchangeability, ensuring developers can quickly adapt their applications to different AI capabilities related to image processing.\n\nAdditionally, with the support of companion classes like `ImagePrompt` for input encapsulation and `ImageResponse` for output handling, the Image Model API unifies the communication with AI Models dedicated to image generation.\nIt manages the complexity of request preparation and response parsing, offering a direct and simplified API interaction for image-generation functionalities.\n\nThe Spring Image Model API is built on top of the Spring AI `Generic Model API`, providing image-specific abstractions and implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "imageclient", "heading_level": 1, "file_order": 105, "section_index": 0, "content_hash": "5bcca10afdbc8321decff65a09b7cf46d3b07b5d6664227a14f90c647aa651cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:59f3fa76de066804114531eedceffa04238a88be3e9fddbe0cbdaa79f978dcdc", "content": "This section provides a guide to the Spring Image Model API interface and associated classes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "API Overview", "heading_level": 2, "file_order": 105, "section_index": 1, "content_hash": "59f3fa76de066804114531eedceffa04238a88be3e9fddbe0cbdaa79f978dcdc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:949e7cd6ba1153552c9f6dc71718e83fe46bdf68d02ee7366c9b91775178e672", "content": "Here is the link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageModel.java[ImageModel] interface definition:\n\n[source,java]\n----\n@FunctionalInterface\npublic interface ImageModel extends Model<ImagePrompt, ImageResponse> {\n\n\tImageResponse call(ImagePrompt request);\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "Image Model", "heading_level": 2, "file_order": 105, "section_index": 2, "content_hash": "949e7cd6ba1153552c9f6dc71718e83fe46bdf68d02ee7366c9b91775178e672", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:3f59eccec4ecd111af8c31f71f4552057e283383ffe84d9a40b8513c1650910e", "content": "The https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImagePrompt.java[ImagePrompt] is a `ModelRequest` that encapsulates a list of https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageMessage.java[ImageMessage] objects and optional model request options.\nThe following listing shows a truncated version of the `ImagePrompt` class, excluding constructors and other utility methods:\n\n[source,java]\n----\npublic class ImagePrompt implements ModelRequest<List<ImageMessage>> {\n\n private final List<ImageMessage> messages;\n\n\tprivate ImageOptions imageModelOptions;\n\n @Override\n\tpublic List<ImageMessage> getInstructions() {...}\n\n\t@Override\n\tpublic ImageOptions getOptions() {...}\n\n // constructors and utility methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "ImagePrompt", "heading_level": 3, "file_order": 105, "section_index": 3, "content_hash": "3f59eccec4ecd111af8c31f71f4552057e283383ffe84d9a40b8513c1650910e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:a54ca4edbf3548e79053725c48265eb84bf047909a0049a8e09ed47a4603a1a6", "content": "The `ImageMessage` class encapsulates the text to use and the weight that the text should have in influencing the generated image. For models that support weights, they can be positive or negative.\n\n[source,java]\n----\npublic class ImageMessage {\n\n\tprivate String text;\n\n\tprivate Float weight;\n\n public String getText() {...}\n\n\tpublic Float getWeight() {...}\n\n // constructors and utility methods omitted\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "ImageMessage", "heading_level": 4, "file_order": 105, "section_index": 4, "content_hash": "a54ca4edbf3548e79053725c48265eb84bf047909a0049a8e09ed47a4603a1a6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:cce071ef9f00644fde990a2219ce8b43ddc2b630b43fcbb7bec06cd01fb8f388", "content": "Represents the options that can be passed to the Image generation model. The `ImageOptions` interface extends the `ModelOptions` interface and is used to define few portable options that can be passed to the AI model.\n\nThe `ImageOptions` interface is defined as follows:\n\n[source,java]\n----\npublic interface ImageOptions extends ModelOptions {\n\n\tInteger getN();\n\n\tString getModel();\n\n\tInteger getWidth();\n\n\tInteger getHeight();\n\n\tString getResponseFormat(); // openai - url or base64 : stability ai byte[] or base64\n\n}\n----\n\nAdditionally, every model specific ImageModel implementation can have its own options that can be passed to the AI model. For example, the OpenAI Image Generation model has its own options like `quality`, `style`, etc.\n\nThis is a powerful feature that allows developers to use model specific options when starting the application and then override them at runtime using the `ImagePrompt`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "ImageOptions", "heading_level": 4, "file_order": 105, "section_index": 5, "content_hash": "cce071ef9f00644fde990a2219ce8b43ddc2b630b43fcbb7bec06cd01fb8f388", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:c265a8dfdca861417007789c5715262f4dc847300dce31003fed1f9562240203", "content": "The structure of the `ImageResponse` class is as follows:\n\n[source,java]\n----\npublic class ImageResponse implements ModelResponse<ImageGeneration> {\n\n\tprivate final ImageResponseMetadata imageResponseMetadata;\n\n\tprivate final List<ImageGeneration> imageGenerations;\n\n\t@Override\n\tpublic ImageGeneration getResult() {\n // get the first result\n\t}\n\n\t@Override\n\tpublic List<ImageGeneration> getResults() {...}\n\n\t@Override\n\tpublic ImageResponseMetadata getMetadata() {...}\n\n // other methods omitted\n\n}\n----\n\nThe https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageResponse.java[ImageResponse] class holds the AI Model's output, with each `ImageGeneration` instance containing one of potentially multiple outputs resulting from a single prompt.\n\nThe `ImageResponse` class also carries a `ImageResponseMetadata` object holding metadata about the AI Model's response.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "ImageResponse", "heading_level": 3, "file_order": 105, "section_index": 6, "content_hash": "c265a8dfdca861417007789c5715262f4dc847300dce31003fed1f9562240203", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:82f8a7aea6e73e902ce67c060226312b896822a7fe5145c305de7fcf367c4548", "content": "Finally, the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/image/ImageGeneration.java[ImageGeneration] class extends from the `ModelResult` to represent the output response and related metadata about this result:\n\n[source,java]\n----\npublic class ImageGeneration implements ModelResult<Image> {\n\n\tprivate ImageGenerationMetadata imageGenerationMetadata;\n\n\tprivate Image image;\n\n @Override\n\tpublic Image getOutput() {...}\n\n\t@Override\n\tpublic ImageGenerationMetadata getMetadata() {...}\n\n // other methods omitted\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "ImageGeneration", "heading_level": 3, "file_order": 105, "section_index": 7, "content_hash": "82f8a7aea6e73e902ce67c060226312b896822a7fe5145c305de7fcf367c4548", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:39c10f25578896af081419411c37118230a5a6e43981eed5386cdb5153ba34c4", "content": "`ImageModel` implementations are provided for the following Model providers:\n\n* xref:api/image/openai-image.adoc[OpenAI Image Generation]\n* xref:api/image/azure-openai-image.adoc[Azure OpenAI Image Generation]\n* xref:api/image/qianfan-image.adoc[QianFan Image Generation]\n* xref:api/image/stabilityai-image.adoc[StabilityAI Image Generation]\n* xref:api/image/zhipuai-image.adoc[ZhiPuAI Image Generation]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "Available Implementations", "heading_level": 2, "file_order": 105, "section_index": 8, "content_hash": "39c10f25578896af081419411c37118230a5a6e43981eed5386cdb5153ba34c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:7469295ac2cc5d065e8a92d47b2140b9f81a2ef6788a76de5452f2616a31acab", "content": "You can find the Javadoc https://docs.spring.io/spring-ai/docs/current-SNAPSHOT/[here].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "API Docs", "heading_level": 2, "file_order": 105, "section_index": 9, "content_hash": "7469295ac2cc5d065e8a92d47b2140b9f81a2ef6788a76de5452f2616a31acab", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:839f914a991781908f283279ae2a830d31be465ec770db135ca8ee185f305e8b", "content": "The project's https://github.com/spring-projects/spring-ai/discussions[GitHub discussions] is a great place to send feedback.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/imageclient.adoc", "title": "imageclient", "heading": "Feedback and Contributions", "heading_level": 2, "file_order": 105, "section_index": 10, "content_hash": "839f914a991781908f283279ae2a830d31be465ec770db135ca8ee185f305e8b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/imageclient.adoc"}}
{"id": "sha256:bd4b9594ff76107313856494e5ffb0f68fa8141c0295b4c3e46796bddf2badd4", "content": "The Spring AI API covers a wide range of functionalities.\nEach major feature is detailed in its own dedicated section.\nTo provide an overview, the following key functionalities are available:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "Introduction", "heading_level": 2, "file_order": 106, "section_index": 0, "content_hash": "bd4b9594ff76107313856494e5ffb0f68fa8141c0295b4c3e46796bddf2badd4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:f09959691ee7783ee49f41e4704ad8877100aa047878a74bb898178fb6cfed1f", "content": "Portable `Model API` across AI providers for `Chat`, `Text to Image`, `Audio Transcription`, `Text to Speech`, and `Embedding` models.\nBoth `synchronous` and `stream` API options are supported.\nDropping down to access model specific features is also supported.\n\nimage::model-hierarchy.jpg[Model hierarchy, width=900, align=\"center\"]\n\nWith support for AI Models from OpenAI, Microsoft, Amazon, Google, Amazon Bedrock, Hugging Face and more.\n\nimage::spring-ai-chat-completions-clients.jpg[align=\"center\", width=\"800px\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "AI Model API", "heading_level": 3, "file_order": 106, "section_index": 1, "content_hash": "f09959691ee7783ee49f41e4704ad8877100aa047878a74bb898178fb6cfed1f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:e795f109092ef1084f7d6a2041fcdf5909648de02b1b7fb550609227bae108f3", "content": "Portable `Vector Store API` across multiple providers, including a novel `SQL-like metadata filter API` that is also portable. Support for 14 vector databases are available.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "Vector Store API", "heading_level": 3, "file_order": 106, "section_index": 2, "content_hash": "e795f109092ef1084f7d6a2041fcdf5909648de02b1b7fb550609227bae108f3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:ea7071948f82899172de6e113a4898539d1239b47e245d0da57615768fa1848c", "content": "Spring AI makes it easy to have the AI model invoke your services as `@Tool`-annotated methods or POJO `java.util.Function` objects.\n\nimage::tools/tool-calling-01.jpg[The main sequence of actions for tool calling, width=500, align=\"center\"]\n\nCheck the Spring AI xref::api/tools.adoc[Tool Calling] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "Tool Calling API", "heading_level": 3, "file_order": 106, "section_index": 3, "content_hash": "ea7071948f82899172de6e113a4898539d1239b47e245d0da57615768fa1848c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:53bc95a1554f13db46c12161d6ebe856d0dafc9eb6b65555d4e8a69afd181268", "content": "Spring Boot Auto Configuration and Starters for AI Models and Vector Stores.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "Auto Configuration", "heading_level": 3, "file_order": 106, "section_index": 4, "content_hash": "53bc95a1554f13db46c12161d6ebe856d0dafc9eb6b65555d4e8a69afd181268", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:4f677604e8c31d8f0f74e13e97f85ca16106f137e0ffe5f129f2769a6895213f", "content": "ETL framework for Data Engineering. This provides the basis of loading data into a vector database, helping implement the Retrieval Augmented Generation pattern that enables you to bring your data to the AI model to incorporate into its response.\n\nimage::etl-pipeline.jpg[align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "ETL Data Engineering", "heading_level": 3, "file_order": 106, "section_index": 5, "content_hash": "4f677604e8c31d8f0f74e13e97f85ca16106f137e0ffe5f129f2769a6895213f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:839fb7cfb379c00c574b37c923ea8364923817e290b67ae5d9190c235785bf9a", "content": "The project's https://github.com/spring-projects/spring-ai/discussions[GitHub discussions] is a great place to send feedback.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/index.adoc", "title": "Spring AI API", "heading": "Feedback and Contributions", "heading_level": 2, "file_order": 106, "section_index": 6, "content_hash": "839fb7cfb379c00c574b37c923ea8364923817e290b67ae5d9190c235785bf9a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/index.adoc"}}
{"id": "sha256:50c2c347bddfe7c2a296e4639c6ac067fe453d94190ebcf6f08067c2cb176906", "content": "[[Multimodality]]\n\n> \"All things that are naturally connected ought to be taught in combination\" - John Amos Comenius, \"Orbis Sensualium Pictus\", 1658\n\nHumans process knowledge, simultaneously across multiple modes of data inputs.\nThe way we learn, our experiences are all multimodal.\nWe don't have just vision, just audio and just text.\n\nContrary to those principles, the Machine Learning was often focused on specialized models tailored to process a single modality.\nFor instance, we developed audio models for tasks like text-to-speech or speech-to-text, and computer vision models for tasks such as object detection and classification.\n\nHowever, a new wave of multimodal large language models starts to emerge.\nExamples include OpenAI's GPT-4o , Google's Vertex AI Gemini 1.5, Anthropic's Claude3, and open source offerings Llama3.2, LLaVA and BakLLaVA are able to accept multiple inputs, including text images, audio and video and generate text responses by integrating these inputs.\n\nNOTE: The multimodal large language model (LLM) features enable the models to process and generate text in conjunction with other modalities such as images, audio, or video.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/multimodality.adoc", "title": "multimodality", "heading": "multimodality", "heading_level": 1, "file_order": 107, "section_index": 0, "content_hash": "50c2c347bddfe7c2a296e4639c6ac067fe453d94190ebcf6f08067c2cb176906", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/multimodality.adoc"}}
{"id": "sha256:7eba6237427d815ca7713f91c3e6da0114f796e564a3f011f89876e6deb4a54a", "content": "Multimodality refers to a model’s ability to simultaneously understand and process information from various sources, including text, images, audio, and other data formats.\n\nThe Spring AI Message API provides all necessary abstractions to support multimodal LLMs.\n\nimage::spring-ai-message-api.jpg[Spring AI Message API, width=800, align=\"center\"]\n\nThe UserMessage’s `content` field is used primarily for text inputs, while the optional `media` field allows adding one or more additional content of different modalities such as images, audio and video.\nThe `MimeType` specifies the modality type.\nDepending on the used LLMs, the `Media` data field can be either the raw media content as a `Resource` object or a `URI` to the content.\n\nNOTE: The media field is currently applicable only for user input messages (e.g., `UserMessage`). It does not hold significance for system messages. The `AssistantMessage`, which includes the LLM response, provides text content only. To generate non-text media outputs, you should utilize one of the dedicated, single-modality models.*\n\nFor example, we can take the following picture (`multimodal.test.png`) as an input and ask the LLM to explain what it sees.\n\nimage::multimodal.test.png[Multimodal Test Image, 200, 200, align=\"left\"]\n\nFor most of the multimodal LLMs, the Spring AI code would look something like this:\n\n[source,java]\n----\nvar imageResource = new ClassPathResource(\"/multimodal.test.png\");\n\nvar userMessage = UserMessage.builder()\n .text(\"Explain what do you see in this picture?\") // content\n .media(new Media(MimeTypeUtils.IMAGE_PNG, this.imageResource)) // media\n .build();\n\nChatResponse response = chatModel.call(new Prompt(this.userMessage));\n----\n\nor with the fluent xref::api/chatclient.adoc[ChatClient] API:\n\n[source,java]\n----\nString response = ChatClient.create(chatModel).prompt()\n .user(u -> u.text(\"Explain what do you see on this picture?\")\n .media(MimeTypeUtils.IMAGE_PNG, new ClassPathResource(\"/multimodal.test.png\")))\n .call()\n .content();\n----\n\nand produce a response like:\n\n> This is an image of a fruit bowl with a simple design. The bowl is made of metal with curved wire edges that create an open structure, allowing the fruit to be visible from all angles. Inside the bowl, there are two yellow bananas resting on top of what appears to be a red apple. The bananas are slightly overripe, as indicated by the brown spots on their peels. The bowl has a metal ring at the top, likely to serve as a handle for carrying. The bowl is placed on a flat surface with a neutral-colored background that provides a clear view of the fruit inside.\n\nSpring AI provides multimodal support for the following chat models:\n\n* xref:api/chat/anthropic-chat.adoc#_multimodal[Anthropic Claude 3]\n* xref:api/chat/bedrock-converse.adoc#_multimodal[AWS Bedrock Converse]\n* xref:api/chat/azure-openai-chat.adoc#_multimodal[Azure Open AI (e.g. GPT-4o models)]\n* xref:api/chat/mistralai-chat.adoc#_multimodal[Mistral AI (e.g. Mistral Pixtral models)]\n* xref:api/chat/ollama-chat.adoc#_multimodal[Ollama (e.g. LLaVA, BakLLaVA, Llama3.2 models)]\n* xref:api/chat/openai-chat.adoc#_multimodal[OpenAI (e.g. GPT-4 and GPT-4o models)]\n* xref:api/chat/vertexai-gemini-chat.adoc#_multimodal[Vertex AI Gemini (e.g. gemini-1.5-pro-001, gemini-1.5-flash-001 models)]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/multimodality.adoc", "title": "multimodality", "heading": "Spring AI Multimodality", "heading_level": 2, "file_order": 107, "section_index": 1, "content_hash": "7eba6237427d815ca7713f91c3e6da0114f796e564a3f011f89876e6deb4a54a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/multimodality.adoc"}}
{"id": "sha256:16c2fda74f836290c9043513869fe9b9cb50e2d5dcd6886085b3d896a2db93dd", "content": "[[prompts]]\n\nPrompts are the inputs that guide an AI model to generate specific outputs.\nThe design and phrasing of these prompts significantly influence the model's responses.\n\nAt the lowest level of interaction with AI models in Spring AI, handling prompts in Spring AI is somewhat similar to managing the \"View\" in Spring MVC.\nThis involves creating extensive text with placeholders for dynamic content.\nThese placeholders are then replaced based on user requests or other code in the application.\nAnother analogy is a SQL statement that contain placeholders for certain expressions.\n\nAs Spring AI evolves, it will introduce higher levels of abstraction for interacting with AI models.\nThe foundational classes described in this section can be likened to JDBC in terms of their role and functionality.\nThe `ChatModel` class, for instance, is analogous to the core JDBC library in the JDK.\nThe `ChatClient` class can be likened to the `JdbcClient`, built on top of `ChatModel` and providing more advanced constructs via `Advisor`\nto consider past interactions with the model, augment the prompt with additional contextual documents, and introduce agentic behavior.\n\nThe structure of prompts has evolved over time within the AI field.\nInitially, prompts were simple strings.\nOver time, they grew to include placeholders for specific inputs, like \"USER:\", which the AI model recognizes.\nOpenAI have introduced even more structure to prompts by categorizing multiple message strings into distinct roles before they are processed by the AI model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "prompt", "heading_level": 1, "file_order": 108, "section_index": 0, "content_hash": "16c2fda74f836290c9043513869fe9b9cb50e2d5dcd6886085b3d896a2db93dd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:fd600c8f1d855f1075ae5997304cf0a26e5f170fceb23251115c79d66e3f9e82", "content": "It is common to use the `call()` method of `ChatModel` that takes a `Prompt` instance and returns a `ChatResponse`.\n\nThe `Prompt` class functions as a container for an organized series of `Message` objects and a request `ChatOptions`.\nEvery `Message` embodies a unique role within the prompt, differing in its content and intent.\nThese roles can encompass a variety of elements, from user inquiries to AI-generated responses to relevant background information.\nThis arrangement enables intricate and detailed interactions with AI models, as the prompt is constructed from multiple messages, each assigned a specific role to play in the dialogue.\n\nBelow is a truncated version of the Prompt class, with constructors and utility methods omitted for brevity:\n\n[source,java]\n----\npublic class Prompt implements ModelRequest<List<Message>> {\n\n private final List<Message> messages;\n\n private ChatOptions chatOptions;\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Prompt", "heading_level": 3, "file_order": 108, "section_index": 1, "content_hash": "fd600c8f1d855f1075ae5997304cf0a26e5f170fceb23251115c79d66e3f9e82", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:820f3824074b39495308fd3ee85d5f4b965e2bcc0562a80ee0539aeed4c14aad", "content": "The `Prompt` class provides several convenience methods for accessing messages by their role:\n\n**Single Message Access:**\n\n* `getUserMessage()`: Returns the last user message in the prompt, or an empty `UserMessage` if none exists\n* `getSystemMessage()`: Returns the first system message in the prompt, or an empty `SystemMessage` if none exists\n* `getLastUserOrToolResponseMessage()`: Returns the last user or tool response message, useful for conversation continuity\n\n**Multiple Message Access:**\n\n* `getUserMessages()`: Returns a list of all user messages in the prompt, preserving their order\n* `getSystemMessages()`: Returns a list of all system messages in the prompt, preserving their order\n\nThese methods are particularly useful when working with multi-turn conversations or when you need to process messages by role.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Convenience Methods", "heading_level": 4, "file_order": 108, "section_index": 2, "content_hash": "820f3824074b39495308fd3ee85d5f4b965e2bcc0562a80ee0539aeed4c14aad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:120eb54e25a67f8c5184e8ce0a314bc8ff432ce8c7bfa74d88635b7f62fba57d", "content": "The `Message` interface encapsulates a `Prompt` textual content, a collection of metadata attributes, and a categorization known as `MessageType`.\n\nThe interface is defined as follows:\n\n[source,java]\n----\npublic interface Content {\n\n\tString getContent();\n\n\tMap<String, Object> getMetadata();\n}\n\npublic interface Message extends Content {\n\n\tMessageType getMessageType();\n}\n----\n\nThe multimodal message types implement also the `MediaContent` interface providing a list of `Media` content objects.\n\n[source,java]\n----\npublic interface MediaContent extends Content {\n\n\tCollection<Media> getMedia();\n\n}\n----\n\nVarious implementations of the `Message` interface correspond to different categories of messages that an AI model can process.\nThe Models distinguish between message categories based on conversational roles.\n\nimage::spring-ai-message-api.jpg[Spring AI Message API, width=800, align=\"center\"]\n\nThese roles are effectively mapped by the `MessageType`, as discussed below.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Message", "heading_level": 3, "file_order": 108, "section_index": 3, "content_hash": "120eb54e25a67f8c5184e8ce0a314bc8ff432ce8c7bfa74d88635b7f62fba57d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:648ab62731317adc113042d81dc2fbfe83d6b7905a785abb9a9280f5971d939b", "content": "Each message is assigned a specific role.\nThese roles categorize the messages, clarifying the context and purpose of each segment of the prompt for the AI model.\nThis structured approach enhances the nuance and effectiveness of communication with the AI, as each part of the prompt plays a distinct and defined role in the interaction.\n\nThe primary roles are:\n\n* System Role: Guides the AI's behavior and response style, setting parameters or rules for how the AI interprets and replies to the input. It's akin to providing instructions to the AI before initiating a conversation.\n* User Role: Represents the user's input – their questions, commands, or statements to the AI. This role is fundamental as it forms the basis of the AI's response.\n* Assistant Role: The AI's response to the user's input.\nMore than just an answer or reaction, it's crucial for maintaining the flow of the conversation.\nBy tracking the AI's previous responses (its 'Assistant Role' messages), the system ensures coherent and contextually relevant interactions.\nThe Assistant message may contain Function Tool Call request information as well.\nIt's like a special feature in the AI, used when needed to perform specific functions such as calculations, fetching data, or other tasks beyond just talking.\n* Tool/Function Role: The Tool/Function Role focuses on returning additional information in response to Tool Call Assistant Messages.\n\nRoles are represented as an enumeration in Spring AI as shown below\n\n[source,java]\n----\npublic enum MessageType {\n\n\tUSER(\"user\"),\n\n\tASSISTANT(\"assistant\"),\n\n\tSYSTEM(\"system\"),\n\n\tTOOL(\"tool\");\n\n ...\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Roles", "heading_level": 4, "file_order": 108, "section_index": 4, "content_hash": "648ab62731317adc113042d81dc2fbfe83d6b7905a785abb9a9280f5971d939b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:e6bdb2a16d333790ec6b7ef4fb029f479745360d71dff5450dc0652f615d784f", "content": "A key component for prompt templating in Spring AI is the `PromptTemplate` class, designed to facilitate the creation of structured prompts that are then sent to the AI model for processing\n\n[source,java]\n----\npublic class PromptTemplate implements PromptTemplateActions, PromptTemplateMessageActions {\n\n // Other methods to be discussed later\n}\n----\n\nThis class uses the `TemplateRenderer` API to render templates. By default, Spring AI uses the `StTemplateRenderer` implementation, which is based on the open-source https://www.stringtemplate.org/[StringTemplate] engine developed by Terence Parr. Template variables are identified by the `{}` syntax, but you can configure the delimiters to use other syntax as well.\n\n[source,java]\n----\npublic interface TemplateRenderer extends BiFunction<String, Map<String, Object>, String> {\n\n\t@Override\n\tString apply(String template, Map<String, Object> variables);\n\n}\n----\n\nSpring AI uses the `TemplateRenderer` interface to handle the actual substitution of variables into the template string.\nThe default implementation uses <<StringTemplate>>.\nYou can provide your own implementation of `TemplateRenderer` if you need custom logic.\nFor scenarios where no template rendering is required (e.g., the template string is already complete), you can use the provided `NoOpTemplateRenderer`.\n\n.Example using a custom StringTemplate renderer with '<' and '>' delimiters\n[source,java]\n----\nPromptTemplate promptTemplate = PromptTemplate.builder()\n .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())\n .template(\"\"\"\n Tell me the names of 5 movies whose soundtrack was composed by <composer>.\n \"\"\")\n .build();\n\nString prompt = promptTemplate.render(Map.of(\"composer\", \"John Williams\"));\n----\n\nThe interfaces implemented by this class support different aspects of prompt creation:\n\n`PromptTemplateStringActions` focuses on creating and rendering prompt strings, representing the most basic form of prompt generation.\n\n`PromptTemplateMessageActions` is tailored for prompt creation through the generation and manipulation of `Message` objects.\n\n`PromptTemplateActions` is designed to return the `Prompt` object, which can be passed to `ChatModel` for generating a response.\n\nWhile these interfaces might not be used extensively in many projects, they show the different approaches to prompt creation.\n\nThe implemented interfaces are\n\n[source,java]\n----\npublic interface PromptTemplateStringActions {\n\n\tString render();\n\n\tString render(Map<String, Object> model);\n\n}\n----\n\nThe method `String render()`: Renders a prompt template into a final string format without external input, suitable for templates without placeholders or dynamic content.\n\nThe method `String render(Map<String, Object> model)`: Enhances rendering functionality to include dynamic content. It uses a `Map<String, Object>` where map keys are placeholder names in the prompt template, and values are the dynamic content to be inserted.\n\n[source,java]\n----\npublic interface PromptTemplateMessageActions {\n\n\tMessage createMessage();\n\n Message createMessage(List<Media> mediaList);\n\n\tMessage createMessage(Map<String, Object> model);\n\n}\n----\n\nThe method `Message createMessage()`: Creates a `Message` object without additional data, used for static or predefined message content.\n\nThe method `Message createMessage(List<Media> mediaList)`: Creates a `Message` object with static textual and media content.\n\nThe method `Message createMessage(Map<String, Object> model)`: Extends message creation to integrate dynamic content, accepting a `Map<String, Object>` where each entry represents a placeholder in the message template and its corresponding dynamic value.\n\n[source,java]\n----\npublic interface PromptTemplateActions extends PromptTemplateStringActions {\n\n\tPrompt create();\n\n\tPrompt create(ChatOptions modelOptions);\n\n\tPrompt create(Map<String, Object> model);\n\n\tPrompt create(Map<String, Object> model, ChatOptions modelOptions);\n\n}\n----\n\nThe method `Prompt create()`: Generates a `Prompt` object without external data inputs, ideal for static or predefined prompts.\n\nThe method `Prompt create(ChatOptions modelOptions)`: Generates a `Prompt` object without external data inputs and with specific options for the chat request.\n\nThe method `Prompt create(Map<String, Object> model)`: Expands prompt creation capabilities to include dynamic content, taking a `Map<String, Object>` where each map entry is a placeholder in the prompt template and its associated dynamic value.\n\nThe method `Prompt create(Map<String, Object> model, ChatOptions modelOptions)`: Expands prompt creation capabilities to include dynamic content, taking a `Map<String, Object>` where each map entry is a placeholder in the prompt template and its associated dynamic value, and specific options for the chat request.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "PromptTemplate", "heading_level": 3, "file_order": 108, "section_index": 5, "content_hash": "e6bdb2a16d333790ec6b7ef4fb029f479745360d71dff5450dc0652f615d784f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:4bb805f5ff4cef0b454aeeab29db84ca878479f1bceaea783f5d016acc28772a", "content": "A simple example taken from the https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/2-README-prompt-templating.md[AI Workshop on PromptTemplates] is shown below.\n\n[source,java]\n----\nPromptTemplate promptTemplate = new PromptTemplate(\"Tell me a {adjective} joke about {topic}\");\n\nPrompt prompt = promptTemplate.create(Map.of(\"adjective\", adjective, \"topic\", topic));\n\nreturn chatModel.call(prompt).getResult();\n----\n\nAnother example taken from the https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/3-README-prompt-roles.md[AI Workshop on Roles] is shown below.\n\n[source,java]\n----\nString userText = \"\"\"\n Tell me about three famous pirates from the Golden Age of Piracy and why they did.\n Write at least a sentence for each pirate.\n \"\"\";\n\nMessage userMessage = new UserMessage(userText);\n\nString systemText = \"\"\"\n You are a helpful AI assistant that helps people find information.\n Your name is {name}\n You should reply to the user's request with your name and also in the style of a {voice}.\n \"\"\";\n\nSystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemText);\nMessage systemMessage = systemPromptTemplate.createMessage(Map.of(\"name\", name, \"voice\", voice));\n\nPrompt prompt = new Prompt(List.of(userMessage, systemMessage));\n\nList<Generation> response = chatModel.call(prompt).getResults();\n----\n\nThis shows how you can build up the `Prompt` instance by using the `SystemPromptTemplate` to create a `Message` with the system role passing in placeholder values.\nThe message with the role `user` is then combined with the message of the role `system` to form the prompt.\nThe prompt is then passed to the ChatModel to get a generative response.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Example Usage", "heading_level": 2, "file_order": 108, "section_index": 6, "content_hash": "4bb805f5ff4cef0b454aeeab29db84ca878479f1bceaea783f5d016acc28772a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:3ff31b1f7e7884f619077a1827228f3243e8499741cf1ec99d89626704d18883", "content": "You can use a custom template renderer by implementing the `TemplateRenderer` interface and passing it to the `PromptTemplate` constructor. You can also keep using the default `StTemplateRenderer`, but with a custom configuration.\n\nBy default, template variables are identified by the `{}` syntax. If you're planning to include JSON in your prompt, you might want to use a different syntax to avoid conflicts with JSON syntax. For example, you can use the `<` and `>` delimiters.\n\n[source,java]\n----\nPromptTemplate promptTemplate = PromptTemplate.builder()\n .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())\n .template(\"\"\"\n Tell me the names of 5 movies whose soundtrack was composed by <composer>.\n \"\"\")\n .build();\n\nString prompt = promptTemplate.render(Map.of(\"composer\", \"John Williams\"));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Using a custom template renderer", "heading_level": 3, "file_order": 108, "section_index": 7, "content_hash": "3ff31b1f7e7884f619077a1827228f3243e8499741cf1ec99d89626704d18883", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:fa900ed31de49829a8ecc13d35eaae60759042e22586e56ffe1ee211ce8af462", "content": "Spring AI supports the `org.springframework.core.io.Resource` abstraction, so you can put prompt data in a file that can directly be used in a `PromptTemplate`.\nFor example, you can define a field in your Spring managed component to retrieve the `Resource`.\n\n[source,java]\n----\n@Value(\"classpath:/prompts/system-message.st\")\nprivate Resource systemResource;\n----\n\nand then pass that resource to the `SystemPromptTemplate` directly.\n\n[source,java]\n----\nSystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemResource);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Using resources instead of raw Strings", "heading_level": 3, "file_order": 108, "section_index": 8, "content_hash": "fa900ed31de49829a8ecc13d35eaae60759042e22586e56ffe1ee211ce8af462", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:278f1118b6b53f3847e762b9ddc962f34f0d973f1d06258570b44b03fea635f9", "content": "In generative AI, the creation of prompts is a crucial task for developers.\nThe quality and structure of these prompts significantly influence the effectiveness of the AI's output.\nInvesting time and effort in designing thoughtful prompts can greatly improve the results from the AI.\n\nSharing and discussing prompts is a common practice in the AI community.\nThis collaborative approach not only creates a shared learning environment but also leads to the identification and use of highly effective prompts.\n\nResearch in this area often involves analyzing and comparing different prompts to assess their effectiveness in various situations.\nFor example, a significant study demonstrated that starting a prompt with \"Take a deep breath and work on this problem step by step\" significantly enhanced problem-solving efficiency.\nThis highlights the impact that well-chosen language can have on generative AI systems' performance.\n\nGrasping the most effective use of prompts, particularly with the rapid advancement of AI technologies, is a continuous challenge.\nYou should recognize the importance of prompt engineering and consider using insights from the community and research to improve prompt creation strategies.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Prompt Engineering", "heading_level": 2, "file_order": 108, "section_index": 9, "content_hash": "278f1118b6b53f3847e762b9ddc962f34f0d973f1d06258570b44b03fea635f9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:c807baff18f9495cb02d81b3ec765b92962f6ccdb6cfc94c604abacda6b13d7d", "content": "When developing prompts, it's important to integrate several key components to ensure clarity and effectiveness:\n\n* *Instructions*: Offer clear and direct instructions to the AI, similar to how you would communicate with a person. This clarity is essential for helping the AI \"understand\" what is expected.\n\n* *External Context*: Include relevant background information or specific guidance for the AI's response when necessary. This \"external context\" frames the prompt and aids the AI in grasping the overall scenario.\n\n* *User Input*: This is the straightforward part - the user's direct request or question forming the core of the prompt.\n\n* *Output Indicator*: This aspect can be tricky. It involves specifying the desired format for the AI's response, such as JSON. However, be aware that the AI might not always adhere strictly to this format. For instance, it might prepend a phrase like \"here is your JSON\" before the actual JSON data, or sometimes generate a JSON-like structure that is not accurate.\n\nProviding the AI with examples of the anticipated question and answer format can be highly beneficial when crafting prompts.\nThis practice helps the AI \"understand\" the structure and intent of your query, leading to more precise and relevant responses.\nWhile this documentation does not delve deeply into these techniques, they provide a starting point for further exploration in AI prompt engineering.\n\nFollowing is a list of resources for further investigation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Creating effective prompts", "heading_level": 3, "file_order": 108, "section_index": 10, "content_hash": "c807baff18f9495cb02d81b3ec765b92962f6ccdb6cfc94c604abacda6b13d7d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:3f207e26b448aee5896b4ebc08c5b6f9a28c96b4cbf6f9925196eb3cd869a2d5", "content": "* *https://www.promptingguide.ai/introduction/examples.en#text-summarization[Text Summarization]*: +\nReduces extensive text into concise summaries, capturing key points and main ideas while omitting less critical details.\n\n* *https://www.promptingguide.ai/introduction/examples.en#question-answering[Question Answering]*: +\nFocuses on deriving specific answers from provided text, based on user-posed questions. It's about pinpointing and extracting relevant information in response to queries.\n\n* *https://www.promptingguide.ai/introduction/examples.en#text-classification[Text Classification]*: +\nSystematically categorizes text into predefined categories or groups, analyzing the text and assigning it to the most fitting category based on its content.\n\n* *https://www.promptingguide.ai/introduction/examples.en#conversation[Conversation]*: +\nCreates interactive dialogues where the AI can engage in back-and-forth communication with users, simulating a natural conversation flow.\n\n* *https://www.promptingguide.ai/introduction/examples.en#code-generation[Code Generation]*: +\nGenerates functional code snippets based on specific user requirements or descriptions, translating natural language instructions into executable code.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Simple Techniques", "heading_level": 4, "file_order": 108, "section_index": 11, "content_hash": "3f207e26b448aee5896b4ebc08c5b6f9a28c96b4cbf6f9925196eb3cd869a2d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:2a261a4a3c1206662e5c0ae0f5798ea7f60f2a53b6580c3adf0b7d1e3875e43d", "content": "* *https://www.promptingguide.ai/techniques/zeroshot[Zero-shot], https://www.promptingguide.ai/techniques/fewshot[Few-shot Learning]*: +\nEnables the model to make accurate predictions or responses with minimal to no prior examples of the specific problem type, understanding and acting on new tasks using learned generalizations.\n\n* *https://www.promptingguide.ai/techniques/cot[Chain-of-Thought]*: +\nLinks multiple AI responses to create a coherent and contextually aware conversation. It helps the AI maintain the thread of the discussion, ensuring relevance and continuity.\n\n* *https://www.promptingguide.ai/techniques/react[ReAct (Reason + Act)]*: +\nIn this method, the AI first analyzes (reasons about) the input, then determines the most appropriate course of action or response. It combines understanding with decision-making.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Advanced Techniques", "heading_level": 4, "file_order": 108, "section_index": 12, "content_hash": "2a261a4a3c1206662e5c0ae0f5798ea7f60f2a53b6580c3adf0b7d1e3875e43d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:2bbd8709819702fdd95cfa4f302c935096b4b62046d6a16aea38ccba02070ea4", "content": "* *https://github.com/microsoft/guidance[Framework for Prompt Creation and Optimization]*: +\nMicrosoft offers a structured approach to developing and refining prompts. This framework guides users in creating effective prompts that elicit the desired responses from AI models, optimizing the interaction for clarity and efficiency.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Microsoft Guidance", "heading_level": 4, "file_order": 108, "section_index": 13, "content_hash": "2bbd8709819702fdd95cfa4f302c935096b4b62046d6a16aea38ccba02070ea4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:bbaa72a3c460a4f6d25a2db657319a11697a4db8c496df8cdbd4e22871659027", "content": "Tokens are essential in how AI models process text, acting as a bridge that converts words (as we understand them) into a format that AI models can process.\nThis conversion occurs in two stages: words are transformed into tokens upon input, and these tokens are then converted back into words in the output.\n\nTokenization, the process of breaking down text into tokens, is fundamental to how AI models comprehend and process language.\nThe AI model works with this tokenized format to understand and respond to prompts.\n\nTo better understand tokens, think of them as portions of words. Typically, a token represents about three-quarters of a word. For instance, the complete works of Shakespeare, totaling roughly 900,000 words, would translate to around 1.2 million tokens.\n\nExperiment with the https://platform.openai.com/tokenizer[OpenAI Tokenizer UI] to see how words are converted into tokens.\n\nTokens have practical implications beyond their technical role in AI processing, especially regarding billing and model capabilities:\n\n* Billing: AI model services often bill based on token usage. Both the input (prompt) and the output (response) contribute to the total token count, making shorter prompts more cost-effective.\n\n* Model Limits: Different AI models have varying token limits, defining their \"context window\" – the maximum amount of information they can process at a time. For example, GPT-3's limit is 4K tokens, while other models like Claude 2 and Meta Llama 2 have limits of 100K tokens, and some research models can handle up to 1 million tokens.\n\n* Context Window: A model's token limit determines its context window. Inputs exceeding this limit are not processed by the model. It's crucial to send only the minimal effective set of information for processing. For example, when inquiring about \"Hamlet,\" there's no need to include tokens from all of Shakespeare's other works.\n\n* Response Metadata: The metadata of a response from an AI model includes the number of tokens used, a vital piece of information for managing usage and costs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/prompt.adoc", "title": "prompt", "heading": "Tokens", "heading_level": 2, "file_order": 108, "section_index": 14, "content_hash": "bbaa72a3c460a4f6d25a2db657319a11697a4db8c496df8cdbd4e22871659027", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/prompt.adoc"}}
{"id": "sha256:9acee106b25c5d34a1bda192320663ea658b56f817ce42985f3275392fdccad5", "content": "[[rag]]\n\nRetrieval Augmented Generation (RAG) is a technique useful to overcome the limitations of large language models\nthat struggle with long-form content, factual accuracy, and context-awareness.\n\nSpring AI supports RAG by providing a modular architecture that allows you to build custom RAG flows yourself\nor use out-of-the-box RAG flows using the `Advisor` API.\n\nNOTE: Learn more about Retrieval Augmented Generation in the xref:concepts.adoc#concept-rag[concepts] section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "retrieval-augmented-generation", "heading_level": 1, "file_order": 109, "section_index": 0, "content_hash": "9acee106b25c5d34a1bda192320663ea658b56f817ce42985f3275392fdccad5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:6fdf8ea899a2b5f58117bbc3dbce58517a6a63347685cb8a2a280e2f25c5757b", "content": "Spring AI provides out-of-the-box support for common RAG flows using the `Advisor` API.\n\nTo use the `QuestionAnswerAdvisor` or `VectorStoreChatMemoryAdvisor`, you need to add the `spring-ai-advisors-vector-store` dependency to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-advisors-vector-store</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Advisors", "heading_level": 2, "file_order": 109, "section_index": 1, "content_hash": "6fdf8ea899a2b5f58117bbc3dbce58517a6a63347685cb8a2a280e2f25c5757b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:2198a09e0f5920e7b7ea32efe432dd441039a762f221a6a6f9ffbaa0e7d3d93a", "content": "A vector database stores data that the AI model is unaware of. When a user question is sent to the AI model, a `QuestionAnswerAdvisor` queries the vector database for documents related to the user question.\n\nThe response from the vector database is appended to the user text to provide context for the AI model to generate a response.\n\nAssuming you have already loaded data into a `VectorStore`, you can perform Retrieval Augmented Generation (RAG) by providing an instance of `QuestionAnswerAdvisor` to the `ChatClient`.\n\n[source,java]\n----\nChatResponse response = ChatClient.builder(chatModel)\n .build().prompt()\n .advisors(QuestionAnswerAdvisor.builder(vectorStore).build())\n .user(userText)\n .call()\n .chatResponse();\n----\n\nIn this example, the `QuestionAnswerAdvisor` will perform a similarity search over all documents in the Vector Database. To restrict the types of documents that are searched, the `SearchRequest` takes an SQL like filter expression that is portable across all `VectorStores`.\n\nThis filter expression can be configured when creating the `QuestionAnswerAdvisor` and hence will always apply to all `ChatClient` requests, or it can be provided at runtime per request.\n\nHere is how to create an instance of `QuestionAnswerAdvisor` where the threshold is `0.8` and to return the top `6` results.\n\n[source,java]\n----\nvar qaAdvisor = QuestionAnswerAdvisor.builder(vectorStore)\n .searchRequest(SearchRequest.builder().similarityThreshold(0.8d).topK(6).build())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "QuestionAnswerAdvisor", "heading_level": 3, "file_order": 109, "section_index": 2, "content_hash": "2198a09e0f5920e7b7ea32efe432dd441039a762f221a6a6f9ffbaa0e7d3d93a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:ef52225fb7b77bb2d18bcccf02dd7b06ec82e374cb52ba1207623d493fd1962b", "content": "Update the `SearchRequest` filter expression at runtime using the `FILTER_EXPRESSION` advisor context parameter:\n\n[source,java]\n----\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(QuestionAnswerAdvisor.builder(vectorStore)\n .searchRequest(SearchRequest.builder().build())\n .build())\n .build();\n\nString content = this.chatClient.prompt()\n .user(\"Please answer my question XYZ\")\n .advisors(a -> a.param(QuestionAnswerAdvisor.FILTER_EXPRESSION, \"type == 'Spring'\"))\n .call()\n .content();\n----\n\nThe `FILTER_EXPRESSION` parameter allows you to dynamically filter the search results based on the provided expression.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Dynamic Filter Expressions", "heading_level": 4, "file_order": 109, "section_index": 3, "content_hash": "ef52225fb7b77bb2d18bcccf02dd7b06ec82e374cb52ba1207623d493fd1962b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:1c0f4852a002cef940de77be83200862347f8cf667119fc7a68615b686c4a105", "content": "The `QuestionAnswerAdvisor` uses a default template to augment the user question with the retrieved documents. You can customize this behavior by providing your own `PromptTemplate` object via the `.promptTemplate()` builder method.\n\nNOTE: The `PromptTemplate` provided here customizes how the advisor merges retrieved context with the user query. This is distinct from configuring a `TemplateRenderer` on the `ChatClient` itself (using `.templateRenderer()`), which affects the rendering of the initial user/system prompt content *before* the advisor runs. See xref:api/chatclient.adoc#_prompt_templates[ChatClient Prompt Templates] for more details on client-level template rendering.\n\nThe custom `PromptTemplate` can use any `TemplateRenderer` implementation (by default, it uses `StPromptTemplate` based on the https://www.stringtemplate.org/[StringTemplate] engine). The important requirement is that the template must contain the following two placeholders:\n\n* a `query` placeholder to receive the user question.\n* a `question_answer_context` placeholder to receive the retrieved context.\n\n[source,java]\n----\nPromptTemplate customPromptTemplate = PromptTemplate.builder()\n .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())\n .template(\"\"\"\n <query>\n\n Context information is below.\n\n ---------------------\n <question_answer_context>\n ---------------------\n\n Given the context information and no prior knowledge, answer the query.\n\n Follow these rules:\n\n 1. If the answer is not in the context, just say that you don't know.\n 2. Avoid statements like \"Based on the context...\" or \"The provided information...\".\n \"\"\")\n .build();\n\n String question = \"Where does the adventure of Anacletus and Birba take place?\";\n\n QuestionAnswerAdvisor qaAdvisor = QuestionAnswerAdvisor.builder(vectorStore)\n .promptTemplate(customPromptTemplate)\n .build();\n\n String response = ChatClient.builder(chatModel).build()\n .prompt(question)\n .advisors(qaAdvisor)\n .call()\n .content();\n----\n\nNOTE: The `QuestionAnswerAdvisor.Builder.userTextAdvise()` method is deprecated in favor of using `.promptTemplate()` for more flexible customization.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Custom Template", "heading_level": 4, "file_order": 109, "section_index": 4, "content_hash": "1c0f4852a002cef940de77be83200862347f8cf667119fc7a68615b686c4a105", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:f2d5fea10c305b29edb4b680887ed2a3661987b496dfb10fa43566cd69c9f792", "content": "Spring AI includes a xref:api/retrieval-augmented-generation.adoc#modules[library of RAG modules] that you can use to build your own RAG flows.\nThe `RetrievalAugmentationAdvisor` is an `Advisor` providing an out-of-the-box implementation for the most common RAG flows,\nbased on a modular architecture.\n\nTo use the `RetrievalAugmentationAdvisor`, you need to add the `spring-ai-rag` dependency to your project:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-rag</artifactId>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "RetrievalAugmentationAdvisor", "heading_level": 3, "file_order": 109, "section_index": 5, "content_hash": "f2d5fea10c305b29edb4b680887ed2a3661987b496dfb10fa43566cd69c9f792", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:f8768e02726d859aac7b90941a3ea364bb1a68790f9b2509ee598e8e9250be89", "content": "[source,java]\n----\nAdvisor retrievalAugmentationAdvisor = RetrievalAugmentationAdvisor.builder()\n .documentRetriever(VectorStoreDocumentRetriever.builder()\n .similarityThreshold(0.50)\n .vectorStore(vectorStore)\n .build())\n .build();\n\nString answer = chatClient.prompt()\n .advisors(retrievalAugmentationAdvisor)\n .user(question)\n .call()\n .content();\n----\n\nBy default, the `RetrievalAugmentationAdvisor` does not allow the retrieved context to be empty. When that happens,\nit instructs the model not to answer the user query. You can allow empty context as follows.\n\n[source,java]\n----\nAdvisor retrievalAugmentationAdvisor = RetrievalAugmentationAdvisor.builder()\n .documentRetriever(VectorStoreDocumentRetriever.builder()\n .similarityThreshold(0.50)\n .vectorStore(vectorStore)\n .build())\n .queryAugmenter(ContextualQueryAugmenter.builder()\n .allowEmptyContext(true)\n .build())\n .build();\n\nString answer = chatClient.prompt()\n .advisors(retrievalAugmentationAdvisor)\n .user(question)\n .call()\n .content();\n----\n\nThe `VectorStoreDocumentRetriever` accepts a `FilterExpression` to filter the search results based on metadata.\nYou can provide one when instantiating the `VectorStoreDocumentRetriever` or at runtime per request,\nusing the `FILTER_EXPRESSION` advisor context parameter.\n\n[source,java]\n----\nAdvisor retrievalAugmentationAdvisor = RetrievalAugmentationAdvisor.builder()\n .documentRetriever(VectorStoreDocumentRetriever.builder()\n .similarityThreshold(0.50)\n .vectorStore(vectorStore)\n .build())\n .build();\n\nString answer = chatClient.prompt()\n .advisors(retrievalAugmentationAdvisor)\n .advisors(a -> a.param(VectorStoreDocumentRetriever.FILTER_EXPRESSION, \"type == 'Spring'\"))\n .user(question)\n .call()\n .content();\n----\n\nSee xref:api/retrieval-augmented-generation.adoc#_vectorstoredocumentretriever[VectorStoreDocumentRetriever] for more information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Naive RAG", "heading_level": 5, "file_order": 109, "section_index": 6, "content_hash": "f8768e02726d859aac7b90941a3ea364bb1a68790f9b2509ee598e8e9250be89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:0753e3de620361e06803d00d451e4243a751cd2d94319fb4bf74cd2bb3267762", "content": "[source,java]\n----\nAdvisor retrievalAugmentationAdvisor = RetrievalAugmentationAdvisor.builder()\n .queryTransformers(RewriteQueryTransformer.builder()\n .chatClientBuilder(chatClientBuilder.build().mutate())\n .build())\n .documentRetriever(VectorStoreDocumentRetriever.builder()\n .similarityThreshold(0.50)\n .vectorStore(vectorStore)\n .build())\n .build();\n\nString answer = chatClient.prompt()\n .advisors(retrievalAugmentationAdvisor)\n .user(question)\n .call()\n .content();\n----\n\nYou can also use the `DocumentPostProcessor` API to post-process the retrieved documents before passing them to the model. For example, you can use such an interface to perform re-ranking of the retrieved documents based on their relevance to the query, remove irrelevant or redundant documents, or compress the content of each document to reduce noise and redundancy.\n\n[[modules]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Advanced RAG", "heading_level": 5, "file_order": 109, "section_index": 7, "content_hash": "0753e3de620361e06803d00d451e4243a751cd2d94319fb4bf74cd2bb3267762", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:e89a7f6b870467d8609070e7522932522dd6b3c6b4c798899595d4636687be1d", "content": "Spring AI implements a Modular RAG architecture inspired by the concept of modularity detailed in the paper\n\"https://arxiv.org/abs/2407.21059[Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks]\".", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Modules", "heading_level": 2, "file_order": 109, "section_index": 8, "content_hash": "e89a7f6b870467d8609070e7522932522dd6b3c6b4c798899595d4636687be1d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:78e21e04e13cd29a10318d5506ed85c6a6160043e1a59ae6932c77627b923738", "content": "Pre-Retrieval modules are responsible for processing the user query to achieve the best possible retrieval results.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Pre-Retrieval", "heading_level": 3, "file_order": 109, "section_index": 9, "content_hash": "78e21e04e13cd29a10318d5506ed85c6a6160043e1a59ae6932c77627b923738", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:18fc9679b8a21f5ed4aded27efb5131532ca6935bf92aa898da8623d9b17b7a7", "content": "A component for transforming the input query to make it more effective for retrieval tasks, addressing challenges\nsuch as poorly formed queries, ambiguous terms, complex vocabulary, or unsupported languages.\n\nIMPORTANT: When using a `QueryTransformer`, it's recommended to configure the `ChatClient.Builder` with a low temperature (e.g., 0.0) to ensure more deterministic and accurate results, improving retrieval quality. The default temperature for most chat models is typically too high for optimal query transformation, leading to reduced retrieval effectiveness.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Query Transformation", "heading_level": 4, "file_order": 109, "section_index": 10, "content_hash": "18fc9679b8a21f5ed4aded27efb5131532ca6935bf92aa898da8623d9b17b7a7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:429686fc2025235726bd2f939b8ee9ea6544c831024db8a5ff52a027c2d01166", "content": "A `CompressionQueryTransformer` uses a large language model to compress a conversation history and a follow-up query\ninto a standalone query that captures the essence of the conversation.\n\nThis transformer is useful when the conversation history is long and the follow-up query is related\nto the conversation context.\n\n[source,java]\n----\nQuery query = Query.builder()\n .text(\"And what is its second largest city?\")\n .history(new UserMessage(\"What is the capital of Denmark?\"),\n new AssistantMessage(\"Copenhagen is the capital of Denmark.\"))\n .build();\n\nQueryTransformer queryTransformer = CompressionQueryTransformer.builder()\n .chatClientBuilder(chatClientBuilder)\n .build();\n\nQuery transformedQuery = queryTransformer.transform(query);\n----\n\nThe prompt used by this component can be customized via the `promptTemplate()` method available in the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "CompressionQueryTransformer", "heading_level": 5, "file_order": 109, "section_index": 11, "content_hash": "429686fc2025235726bd2f939b8ee9ea6544c831024db8a5ff52a027c2d01166", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:2b0fd3aa3c29ab3b252aa6f8af7ecd77c65848d22396c9bebbf878e263119f6c", "content": "A `RewriteQueryTransformer` uses a large language model to rewrite a user query to provide better results when\nquerying a target system, such as a vector store or a web search engine.\n\nThis transformer is useful when the user query is verbose, ambiguous, or contains irrelevant information\nthat may affect the quality of the search results.\n\n[source,java]\n----\nQuery query = new Query(\"I'm studying machine learning. What is an LLM?\");\n\nQueryTransformer queryTransformer = RewriteQueryTransformer.builder()\n .chatClientBuilder(chatClientBuilder)\n .build();\n\nQuery transformedQuery = queryTransformer.transform(query);\n----\n\nThe prompt used by this component can be customized via the `promptTemplate()` method available in the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "RewriteQueryTransformer", "heading_level": 5, "file_order": 109, "section_index": 12, "content_hash": "2b0fd3aa3c29ab3b252aa6f8af7ecd77c65848d22396c9bebbf878e263119f6c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:803fb7a4c46fed2e71c1ba859aa4b40e716b1b0a06afc9d6ce87cb0d49fe9ef7", "content": "A `TranslationQueryTransformer` uses a large language model to translate a query to a target language that is supported\nby the embedding model used to generate the document embeddings. If the query is already in the target language,\nit is returned unchanged. If the language of the query is unknown, it is also returned unchanged.\n\nThis transformer is useful when the embedding model is trained on a specific language and the user query\nis in a different language.\n\n[source,java]\n----\nQuery query = new Query(\"Hvad er Danmarks hovedstad?\");\n\nQueryTransformer queryTransformer = TranslationQueryTransformer.builder()\n .chatClientBuilder(chatClientBuilder)\n .targetLanguage(\"english\")\n .build();\n\nQuery transformedQuery = queryTransformer.transform(query);\n----\n\nThe prompt used by this component can be customized via the `promptTemplate()` method available in the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "TranslationQueryTransformer", "heading_level": 5, "file_order": 109, "section_index": 13, "content_hash": "803fb7a4c46fed2e71c1ba859aa4b40e716b1b0a06afc9d6ce87cb0d49fe9ef7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:506e29dd9f0303f9d0eef00e430407c3d12eab2127df862a0522a665c622b1d5", "content": "A component for expanding the input query into a list of queries, addressing challenges such as poorly formed queries\nby providing alternative query formulations, or by breaking down complex problems into simpler sub-queries.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Query Expansion", "heading_level": 4, "file_order": 109, "section_index": 14, "content_hash": "506e29dd9f0303f9d0eef00e430407c3d12eab2127df862a0522a665c622b1d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:5612c2c9cccba1a3435c908e97338b4894074fa12188078466e49428b9883a3b", "content": "A `MultiQueryExpander` uses a large language model to expand a query into multiple semantically diverse variations\nto capture different perspectives, useful for retrieving additional contextual information and increasing the chances\nof finding relevant results.\n\n[source,java]\n----\nMultiQueryExpander queryExpander = MultiQueryExpander.builder()\n .chatClientBuilder(chatClientBuilder)\n .numberOfQueries(3)\n .build();\nList<Query> queries = queryExpander.expand(new Query(\"How to run a Spring Boot app?\"));\n----\n\nBy default, the `MultiQueryExpander` includes the original query in the list of expanded queries. You can disable this behavior\nvia the `includeOriginal` method in the builder.\n\n[source,java]\n----\nMultiQueryExpander queryExpander = MultiQueryExpander.builder()\n .chatClientBuilder(chatClientBuilder)\n .includeOriginal(false)\n .build();\n----\n\nThe prompt used by this component can be customized via the `promptTemplate()` method available in the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "MultiQueryExpander", "heading_level": 5, "file_order": 109, "section_index": 15, "content_hash": "5612c2c9cccba1a3435c908e97338b4894074fa12188078466e49428b9883a3b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:3f204b95330b8af0b58f648f0610fef67b8461214f6d9b150321db1c99885696", "content": "Retrieval modules are responsible for querying data systems like vector store and retrieving the most relevant documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Retrieval", "heading_level": 3, "file_order": 109, "section_index": 16, "content_hash": "3f204b95330b8af0b58f648f0610fef67b8461214f6d9b150321db1c99885696", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:b09811e4fa16c3cb62c67a17b53c839d2c117f42a18a9fee42a6126c1e743328", "content": "Component responsible for retrieving `Documents` from an underlying data source, such as a search engine, a vector store,\na database, or a knowledge graph.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Document Search", "heading_level": 4, "file_order": 109, "section_index": 17, "content_hash": "b09811e4fa16c3cb62c67a17b53c839d2c117f42a18a9fee42a6126c1e743328", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:750f3f09ac645160f54fa9d685b487c5f67d3fc75c1c50584dc330c18b6def24", "content": "A `VectorStoreDocumentRetriever` retrieves documents from a vector store that are semantically similar to the input\nquery. It supports filtering based on metadata, similarity threshold, and top-k results.\n\n[source,java]\n----\nDocumentRetriever retriever = VectorStoreDocumentRetriever.builder()\n .vectorStore(vectorStore)\n .similarityThreshold(0.73)\n .topK(5)\n .filterExpression(new FilterExpressionBuilder()\n .eq(\"genre\", \"fairytale\")\n .build())\n .build();\nList<Document> documents = retriever.retrieve(new Query(\"What is the main character of the story?\"));\n----\n\nThe filter expression can be static or dynamic. For dynamic filter expressions, you can pass a `Supplier`.\n\n[source,java]\n----\nDocumentRetriever retriever = VectorStoreDocumentRetriever.builder()\n .vectorStore(vectorStore)\n .filterExpression(() -> new FilterExpressionBuilder()\n .eq(\"tenant\", TenantContextHolder.getTenantIdentifier())\n .build())\n .build();\nList<Document> documents = retriever.retrieve(new Query(\"What are the KPIs for the next semester?\"));\n----\n\nYou can also provide a request-specific filter expression via the `Query` API, using the `FILTER_EXPRESSION` parameter.\nIf both the request-specific and the retriever-specific filter expressions are provided, the request-specific filter expression takes precedence.\n\n[source,java]\n----\nQuery query = Query.builder()\n .text(\"Who is Anacletus?\")\n .context(Map.of(VectorStoreDocumentRetriever.FILTER_EXPRESSION, \"location == 'Whispering Woods'\"))\n .build();\nList<Document> retrievedDocuments = documentRetriever.retrieve(query);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "VectorStoreDocumentRetriever", "heading_level": 5, "file_order": 109, "section_index": 18, "content_hash": "750f3f09ac645160f54fa9d685b487c5f67d3fc75c1c50584dc330c18b6def24", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:67b374180cf5e6f36aced6fd8637cb8487024f35cefbc4d87889c720cf01b3db", "content": "A component for combining documents retrieved based on multiple queries and from multiple data sources into\na single collection of documents. As part of the joining process, it can also handle duplicate documents and reciprocal\nranking strategies.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Document Join", "heading_level": 4, "file_order": 109, "section_index": 19, "content_hash": "67b374180cf5e6f36aced6fd8637cb8487024f35cefbc4d87889c720cf01b3db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:143797442fb67ab97c518936b361414b3dc69f2cffe5666adbc50b20c7596403", "content": "A `ConcatenationDocumentJoiner` combines documents retrieved based on multiple queries and from multiple data sources\nby concatenating them into a single collection of documents. In case of duplicate documents, the first occurrence is kept.\nThe score of each document is kept as is.\n\n[source,java]\n----\nMap<Query, List<List<Document>>> documentsForQuery = ...\nDocumentJoiner documentJoiner = new ConcatenationDocumentJoiner();\nList<Document> documents = documentJoiner.join(documentsForQuery);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "ConcatenationDocumentJoiner", "heading_level": 5, "file_order": 109, "section_index": 20, "content_hash": "143797442fb67ab97c518936b361414b3dc69f2cffe5666adbc50b20c7596403", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:aef5559927ee13a4427f45af8691bfb4db17061d5962ca5bc6a95362b6bee5cc", "content": "Post-Retrieval modules are responsible for processing the retrieved documents to achieve the best possible generation results.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Post-Retrieval", "heading_level": 3, "file_order": 109, "section_index": 21, "content_hash": "aef5559927ee13a4427f45af8691bfb4db17061d5962ca5bc6a95362b6bee5cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:e42b08070ada67a009f6821f132d80dc0cf8b654be63a7b86c03aff6870ba3ed", "content": "A component for post-processing retrieved documents based on a query, addressing challenges such as _lost-in-the-middle_, context length restrictions from the model, and the need to reduce noise and redundancy in the retrieved information.\n\nFor example, it could rank documents based on their relevance to the query, remove irrelevant or redundant documents, or compress the content of each document to reduce noise and redundancy.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Document Post-Processing", "heading_level": 4, "file_order": 109, "section_index": 22, "content_hash": "e42b08070ada67a009f6821f132d80dc0cf8b654be63a7b86c03aff6870ba3ed", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:46fd3bce27398c0be80a237626b84eef3f2dc60005bcb39df6e6cffbb532da1f", "content": "Generation modules are responsible for generating the final response based on the user query and retrieved documents.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Generation", "heading_level": 3, "file_order": 109, "section_index": 23, "content_hash": "46fd3bce27398c0be80a237626b84eef3f2dc60005bcb39df6e6cffbb532da1f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:02863ca8cd0fe80ee7cc06047e46e6a8094e6f902978a787cbd7b990b1da8364", "content": "A component for augmenting an input query with additional data, useful to provide a large language model\nwith the necessary context to answer the user query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "Query Augmentation", "heading_level": 4, "file_order": 109, "section_index": 24, "content_hash": "02863ca8cd0fe80ee7cc06047e46e6a8094e6f902978a787cbd7b990b1da8364", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:f3f3854818d5458458e024ed865d6186822721934e20609e6affa1c6468db138", "content": "The `ContextualQueryAugmenter` augments the user query with contextual data from the content of the provided documents.\n\n[source,java]\n----\nQueryAugmenter queryAugmenter = ContextualQueryAugmenter.builder().build();\n----\n\nBy default, the `ContextualQueryAugmenter` does not allow the retrieved context to be empty. When that happens,\nit instructs the model not to answer the user query.\n\nYou can enable the `allowEmptyContext` option to allow the model to generate a response even when the retrieved context is empty.\n\n[source,java]\n----\nQueryAugmenter queryAugmenter = ContextualQueryAugmenter.builder()\n .allowEmptyContext(true)\n .build();\n----\n\nThe prompts used by this component can be customized via the `promptTemplate()` and `emptyContextPromptTemplate()` methods\navailable in the builder.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc", "title": "retrieval-augmented-generation", "heading": "ContextualQueryAugmenter", "heading_level": 5, "file_order": 109, "section_index": 25, "content_hash": "f3f3854818d5458458e024ed865d6186822721934e20609e6affa1c6468db138", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/retrieval-augmented-generation.adoc"}}
{"id": "sha256:ff6250f76ca0a15031186555705ac21f01e3467342d73245643045416ab0eed4", "content": "[[Speech]]\n\n[NOTE]\n====\nThis page has been superseded by the new Text-to-Speech (TTS) documentation.\n\nPlease refer to xref:api/audio/speech.adoc[Text-To-Speech (TTS) API] for the current shared interfaces (`TextToSpeechModel` and `StreamingTextToSpeechModel`).\n\nThe old provider-specific classes (`SpeechModel`, `StreamingSpeechModel`, `SpeechPrompt`, `SpeechResponse`) have been removed in favor of shared interfaces that work across all TTS providers (OpenAI, ElevenLabs, and future providers).\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/speech.adoc", "title": "speech", "heading": "speech", "heading_level": 1, "file_order": 110, "section_index": 0, "content_hash": "ff6250f76ca0a15031186555705ac21f01e3467342d73245643045416ab0eed4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/speech.adoc"}}
{"id": "sha256:817789f514d6a5fd4417cbacddaa2f88891e9574eccb1d6b2fe89533ff7c0d1d", "content": "* For general TTS documentation: xref:api/audio/speech.adoc[Text-To-Speech (TTS) API]\n* For OpenAI-specific documentation: xref:api/audio/speech/openai-speech.adoc[OpenAI Text-to-Speech]\n* For ElevenLabs-specific documentation: xref:api/audio/speech/elevenlabs-speech.adoc[ElevenLabs Text-to-Speech]\n* For migration guide: xref:api/audio/speech/openai-speech.adoc#_migration_guide[Migration Guide]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/speech.adoc", "title": "speech", "heading": "Redirects", "heading_level": 2, "file_order": 110, "section_index": 1, "content_hash": "817789f514d6a5fd4417cbacddaa2f88891e9574eccb1d6b2fe89533ff7c0d1d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/speech.adoc"}}
{"id": "sha256:ac414c0728df192ae0787491a719009c4df7d9ffae1f1c6af5c53acc33a59d44", "content": "[[StructuredOutputConverter]]\n\nThe ability of LLMs to produce structured outputs is important for downstream applications that rely on reliably parsing output values.\nDevelopers want to quickly turn results from an AI model into data types, such as JSON, XML or Java classes, that can be passed to other application functions and methods.\n\nThe Spring AI `Structured Output Converters` help to convert the LLM output into a structured format.\nAs shown in the following diagram, this approach operates around the LLM text completion endpoint:\n\nimage::structured-output-architecture.jpg[Structured Output Converter Architecture, width=900, align=\"center\"]\n\nGenerating structured outputs from Large Language Models (LLMs) using generic completion APIs requires careful handling of inputs and outputs. The structured output converter plays a crucial role before and after the LLM call, ensuring the desired output structure is achieved.\n\nBefore the LLM call, the converter appends format instructions to the prompt, providing explicit guidance to the models on generating the desired output structure. These instructions act as a blueprint, shaping the model's response to conform to the specified format.\n\nNOTE: As more AI models natively support structured outputs, you can leverage this capability using the xref:api/chatclient.adoc#_native_structured_output[Native Structured Output] feature with `AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT`. This approach uses the generated JSON schema directly with the model's native structured output API, eliminating the need for pre-prompt formatting instructions and providing more reliable results.\n\nAfter the LLM call, the converter takes the model's output text and transforms it into instances of the structured type. This conversion process involves parsing the raw text output and mapping it to the corresponding structured data representation, such as JSON, XML, or domain-specific data structures.\n\nTIP: The `StructuredOutputConverter` is a best effort to convert the model output into a structured output.\nThe AI Model is not guaranteed to return the structured output as requested.\nThe model may not understand the prompt or be unable to generate the structured output as requested.\nConsider implementing a validation mechanism to ensure the model output is as expected.\n\nTIP: The `StructuredOutputConverter` is not used for LLM xref:api/tools.adoc[Tool Calling], as this feature inherently provides structured outputs by default.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "structured-output-converter", "heading_level": 1, "file_order": 111, "section_index": 0, "content_hash": "ac414c0728df192ae0787491a719009c4df7d9ffae1f1c6af5c53acc33a59d44", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:6dcb0bbc664527ffc733bf6cea6e94c482b8709adec41c3438d84ebc93cb59e2", "content": "The `StructuredOutputConverter` interface allows you to obtain structured output, such as mapping the output to a Java class or an array of values from the text-based AI Model output.\nThe interface definition is:\n\n[source,java]\n----\npublic interface StructuredOutputConverter<T> extends Converter<String, T>, FormatProvider {\n\n}\n----\n\nIt combines the Spring https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/convert/converter/Converter.html[Converter<String, T>] interface and the `FormatProvider` interface\n\n[source,java]\n----\npublic interface FormatProvider {\n\tString getFormat();\n}\n----\n\nThe following diagram shows the data flow when using the structured output API.\n\nimage::structured-output-api.jpg[Structured Output API, width=900, align=\"center\"]\n\nThe `FormatProvider` supplies specific formatting guidelines to the AI Model, enabling it to produce text outputs that can be converted into the designated target type `T` using the `Converter`. Here is an example of such formatting instructions:\n\n----\n Your response should be in JSON format.\n The data structure for the JSON should match this Java class: java.util.HashMap\n Do not include any explanations, only provide a RFC8259 compliant JSON response following this format without deviation.\n----\n\nThe format instructions are most often appended to the end of the user input using the xref:api/prompt.adoc#_prompttemplate[PromptTemplate] like this:\n\n[source,java]\n----\n StructuredOutputConverter outputConverter = ...\n String userInputTemplate = \"\"\"\n ... user text input ....\n {format}\n \"\"\"; // user input with a \"format\" placeholder.\n Prompt prompt = new Prompt(\n PromptTemplate.builder()\n .template(this.userInputTemplate)\n .variables(Map.of(..., \"format\", this.outputConverter.getFormat())) // replace the \"format\" placeholder with the converter's format.\n .build().createMessage()\n );\n----\n\nThe Converter<String, T> is responsible to transform output text from the model into instances of the specified type `T`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Structured Output API", "heading_level": 2, "file_order": 111, "section_index": 1, "content_hash": "6dcb0bbc664527ffc733bf6cea6e94c482b8709adec41c3438d84ebc93cb59e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:bea5751b9a8fb10850b976da4e7c1ce910cff294a525c75d5cf8c426e9bb3177", "content": "Currently, Spring AI provides `AbstractConversionServiceOutputConverter`, `AbstractMessageOutputConverter`, `BeanOutputConverter`, `MapOutputConverter` and `ListOutputConverter` implementations:\n\nimage::structured-output-hierarchy4.jpg[Structured Output Class Hierarchy, width=900, align=\"center\"]\n\n* `AbstractConversionServiceOutputConverter<T>` - Offers a pre-configured link:https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/convert/support/GenericConversionService.html[GenericConversionService] for transforming LLM output into the desired format. No default `FormatProvider` implementation is provided.\n* `AbstractMessageOutputConverter<T>` - Supplies a pre-configured https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/jms/support/converter/MessageConverter.html[MessageConverter] for converting LLM output into the desired format. No default `FormatProvider` implementation is provided.\n* `BeanOutputConverter<T>` - Configured with a designated Java class (e.g., Bean) or a link:https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/core/ParameterizedTypeReference.html[ParameterizedTypeReference], this converter employs a `FormatProvider` implementation that directs the AI Model to produce a JSON response compliant with a `DRAFT_2020_12`, `JSON Schema` derived from the specified Java class. Subsequently, it utilizes an `ObjectMapper` to deserialize the JSON output into a Java object instance of the target class.\n* `MapOutputConverter` - Extends the functionality of `AbstractMessageOutputConverter` with a `FormatProvider` implementation that guides the AI Model to generate an RFC8259 compliant JSON response. Additionally, it incorporates a converter implementation that utilizes the provided `MessageConverter` to translate the JSON payload into a `java.util.Map<String, Object>` instance.\n* `ListOutputConverter` - Extends the `AbstractConversionServiceOutputConverter` and includes a `FormatProvider` implementation tailored for comma-delimited list output. The converter implementation employs the provided `ConversionService` to transform the model text output into a `java.util.List`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Available Converters", "heading_level": 3, "file_order": 111, "section_index": 2, "content_hash": "bea5751b9a8fb10850b976da4e7c1ce910cff294a525c75d5cf8c426e9bb3177", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:20ddd143c7327deee62ad2378277b4f284915690ff95cbc3c7e83948dbda691d", "content": "The following sections provide guides how to use the available converters to generate structured outputs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Using Converters", "heading_level": 2, "file_order": 111, "section_index": 3, "content_hash": "20ddd143c7327deee62ad2378277b4f284915690ff95cbc3c7e83948dbda691d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:f53a88e96f2223e1635b33f276532f5633dc2ebc328d164e758aa0055f478473", "content": "The following example shows how to use `BeanOutputConverter` to generate the filmography for an actor.\n\nThe target record representing actor's filmography:\n\n[source,java]\n----\nrecord ActorsFilms(String actor, List<String> movies) {\n}\n----\n\nHere is how to apply the BeanOutputConverter using the high-level, fluent `ChatClient` API:\n\n[source,java]\n----\nActorsFilms actorsFilms = ChatClient.create(chatModel).prompt()\n .user(u -> u.text(\"Generate the filmography of 5 movies for {actor}.\")\n .param(\"actor\", \"Tom Hanks\"))\n .call()\n .entity(ActorsFilms.class);\n----\n\nor using the low-level `ChatModel` API directly:\n\n[source,java]\n----\nBeanOutputConverter<ActorsFilms> beanOutputConverter =\n new BeanOutputConverter<>(ActorsFilms.class);\n\nString format = this.beanOutputConverter.getFormat();\n\nString actor = \"Tom Hanks\";\n\nString template = \"\"\"\n Generate the filmography of 5 movies for {actor}.\n {format}\n \"\"\";\n\nGeneration generation = chatModel.call(\n PromptTemplate.builder().template(this.template).variables(Map.of(\"actor\", this.actor, \"format\", this.format)).build().create()).getResult();\n\nActorsFilms actorsFilms = this.beanOutputConverter.convert(this.generation.getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Bean Output Converter", "heading_level": 3, "file_order": 111, "section_index": 4, "content_hash": "f53a88e96f2223e1635b33f276532f5633dc2ebc328d164e758aa0055f478473", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:f939617247d8b6a19eee2537019115ca626cec96437bb6fc6bb44a9fbcf0d9b0", "content": "The `BeanOutputConverter` supports custom property ordering in the generated JSON schema through the `@JsonPropertyOrder` annotation.\nThis annotation allows you to specify the exact sequence in which properties should appear in the schema, regardless of their declaration order in the class or record.\n\nFor example, to ensure specific ordering of properties in the `ActorsFilms` record:\n\n[source,java]\n----\n@JsonPropertyOrder({\"actor\", \"movies\"})\nrecord ActorsFilms(String actor, List<String> movies) {}\n----\n\nThis annotation works with both records and regular Java classes.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Property Ordering in Generated Schema", "heading_level": 3, "file_order": 111, "section_index": 5, "content_hash": "f939617247d8b6a19eee2537019115ca626cec96437bb6fc6bb44a9fbcf0d9b0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:9e5ab0ebe043deda9c5cdf145e0b6ce64a0668d561907af31ecc4b80318386ed", "content": "Use the `ParameterizedTypeReference` constructor to specify a more complex target class structure.\nFor example, to represent a list of actors and their filmographies:\n\n[source,java]\n----\nList<ActorsFilms> actorsFilms = ChatClient.create(chatModel).prompt()\n .user(\"Generate the filmography of 5 movies for Tom Hanks and Bill Murray.\")\n .call()\n .entity(new ParameterizedTypeReference<List<ActorsFilms>>() {});\n----\n\nor using the low-level `ChatModel` API directly:\n\n[source,java]\n----\nBeanOutputConverter<List<ActorsFilms>> outputConverter = new BeanOutputConverter<>(\n new ParameterizedTypeReference<List<ActorsFilms>>() { });\n\nString format = this.outputConverter.getFormat();\nString template = \"\"\"\n Generate the filmography of 5 movies for Tom Hanks and Bill Murray.\n {format}\n \"\"\";\n\nPrompt prompt = PromptTemplate.builder().template(this.template).variables(Map.of(\"format\", this.format)).build().create();\n\nGeneration generation = chatModel.call(this.prompt).getResult();\n\nList<ActorsFilms> actorsFilms = this.outputConverter.convert(this.generation.getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Generic Bean Types", "heading_level": 4, "file_order": 111, "section_index": 6, "content_hash": "9e5ab0ebe043deda9c5cdf145e0b6ce64a0668d561907af31ecc4b80318386ed", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:d3fc6c7ecdb4ef27641776221277e5092cac1b459e8c69c204255ca56a1cca0a", "content": "The following snippet shows how to use `MapOutputConverter` to convert the model output to a list of numbers in a map.\n\n[source,java]\n----\nMap<String, Object> result = ChatClient.create(chatModel).prompt()\n .user(u -> u.text(\"Provide me a List of {subject}\")\n .param(\"subject\", \"an array of numbers from 1 to 9 under they key name 'numbers'\"))\n .call()\n .entity(new ParameterizedTypeReference<Map<String, Object>>() {});\n----\n\nor using the low-level `ChatModel` API directly:\n\n[source,java]\n----\nMapOutputConverter mapOutputConverter = new MapOutputConverter();\n\nString format = this.mapOutputConverter.getFormat();\nString template = \"\"\"\n Provide me a List of {subject}\n {format}\n \"\"\";\n\nPrompt prompt = PromptTemplate.builder().template(this.template)\n.variables(Map.of(\"subject\", \"an array of numbers from 1 to 9 under they key name 'numbers'\", \"format\", this.format)).build().create();\n\nGeneration generation = chatModel.call(this.prompt).getResult();\n\nMap<String, Object> result = this.mapOutputConverter.convert(this.generation.getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Map Output Converter", "heading_level": 3, "file_order": 111, "section_index": 7, "content_hash": "d3fc6c7ecdb4ef27641776221277e5092cac1b459e8c69c204255ca56a1cca0a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:d482ff93d431ec2b7ab8b11d5fbca637153c3efbe7190a244219696c1b25958e", "content": "The following snippet shows how to use `ListOutputConverter` to convert the model output into a list of ice cream flavors.\n\n[source,java]\n----\nList<String> flavors = ChatClient.create(chatModel).prompt()\n .user(u -> u.text(\"List five {subject}\")\n .param(\"subject\", \"ice cream flavors\"))\n .call()\n .entity(new ListOutputConverter(new DefaultConversionService()));\n----\n\nor using the low-level `ChatModel API` directly:\n\n[source,java]\n----\nListOutputConverter listOutputConverter = new ListOutputConverter(new DefaultConversionService());\n\nString format = this.listOutputConverter.getFormat();\nString template = \"\"\"\n List five {subject}\n {format}\n \"\"\";\n\nPrompt prompt = PromptTemplate.builder().template(this.template).variables(Map.of(\"subject\", \"ice cream flavors\", \"format\", this.format)).build().create();\n\nGeneration generation = this.chatModel.call(this.prompt).getResult();\n\nList<String> list = this.listOutputConverter.convert(this.generation.getOutput().getText());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "List Output Converter", "heading_level": 3, "file_order": 111, "section_index": 8, "content_hash": "d482ff93d431ec2b7ab8b11d5fbca637153c3efbe7190a244219696c1b25958e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:109fc9fe0a70ec187d8024f3e1d973df2c38d0b1f5f6f4c9fc1d1e50e0cd9aa0", "content": "Many modern AI models now provide native support for structured output, which offers more reliable results compared to prompt-based formatting. Spring AI supports this through the xref:api/chatclient.adoc#_native_structured_output[Native Structured Output] feature.\n\nWhen using native structured output, the JSON schema generated by `BeanOutputConverter` is sent directly to the model's structured output API, eliminating the need for format instructions in the prompt. This approach provides:\n\n* **Higher reliability**: The model guarantees output conforming to the schema\n* **Cleaner prompts**: No need to append format instructions\n* **Better performance**: Models can optimize for structured output internally", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Native Structured Output", "heading_level": 2, "file_order": 111, "section_index": 9, "content_hash": "109fc9fe0a70ec187d8024f3e1d973df2c38d0b1f5f6f4c9fc1d1e50e0cd9aa0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:454fda8db131e283d7d66f74831cb97e9a965af57451f53bdc1619ffaa11b37e", "content": "To enable native structured output, use the `AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT` parameter:\n\n[source,java]\n----\nActorsFilms actorsFilms = ChatClient.create(chatModel).prompt()\n .advisors(AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT)\n .user(\"Generate the filmography for a random actor.\")\n .call()\n .entity(ActorsFilms.class);\n----\n\nYou can also set this globally using `defaultAdvisors()` on the `ChatClient.Builder`:\n\n[source,java]\n----\n@Bean\nChatClient chatClient(ChatClient.Builder builder) {\n return builder\n .defaultAdvisors(AdvisorParams.ENABLE_NATIVE_STRUCTURED_OUTPUT)\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Using Native Structured Output", "heading_level": 3, "file_order": 111, "section_index": 10, "content_hash": "454fda8db131e283d7d66f74831cb97e9a965af57451f53bdc1619ffaa11b37e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:2f21757d95f20a43a6ee6b8c0e086de664fbb4411a6dc6a77f56b82ae4fd5a89", "content": "The following models currently support native structured output:\n\n* **OpenAI**: GPT-4o and later models with JSON Schema support\n* **Anthropic**: Claude 3.5 Sonnet and later models\n* **Vertex AI Gemini**: Gemini 1.5 Pro and later models\n* **Mistral AI**: Mistral Small and later models with JSON Schema support\n\nNOTE: Some AI models, such as OpenAI, don't support arrays of objects natively at the top level. In such cases, you can use the Spring AI default structured output conversion (without the native structured output advisor).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Supported Models for Native Structured Output", "heading_level": 3, "file_order": 111, "section_index": 11, "content_hash": "2f21757d95f20a43a6ee6b8c0e086de664fbb4411a6dc6a77f56b82ae4fd5a89", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:a319fcb3867fff6002f0f98704bafe23c301e467443a3bdb5beea976811f9a1d", "content": "Some AI Models provide dedicated configuration options to generate structured (usually JSON) output.\n\n* xref:api/chat/openai-chat.adoc#_structured_outputs[OpenAI Structured Outputs] can ensure your model generates responses conforming strictly to your provided JSON Schema. You can choose between the `JSON_OBJECT` that guarantees the message the model generates is valid JSON or `JSON_SCHEMA` with a supplied schema that guarantees the model will generate a response that matches your supplied schema (`spring.ai.openai.chat.options.responseFormat` option).\n* xref:api/chat/azure-openai-chat.adoc[Azure OpenAI] - provides a `spring.ai.azure.openai.chat.options.responseFormat` options specifying the format that the model must output. Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON.\n* xref:api/chat/ollama-chat.adoc[Ollama] - provides a `spring.ai.ollama.chat.options.format` option to specify the format to return a response in. Currently, the only accepted value is `json`.\n* xref:api/chat/mistralai-chat.adoc[Mistral AI] - provides a `spring.ai.mistralai.chat.options.responseFormat` option to specify the format to return a response in. Setting it to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON. Additionally, setting it to `{ \"type\": \"json_schema\" }` with a supplied schema enables native structured output support, which guarantees the model will generate a response that matches your supplied schema.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/structured-output-converter.adoc", "title": "structured-output-converter", "heading": "Built-in JSON mode", "heading_level": 3, "file_order": 111, "section_index": 12, "content_hash": "a319fcb3867fff6002f0f98704bafe23c301e467443a3bdb5beea976811f9a1d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/structured-output-converter.adoc"}}
{"id": "sha256:910793f2a4a334927f867a4edac8f2bc7251890308d5ce7ac885e6b57767408c", "content": "[[testcontainers]]\n\nSpring AI provides Spring Boot auto-configuration for establishing a connection to a model service\nor vector store running via Testcontainers. To enable it, add the following dependency\nto your project's Maven `pom.xml` file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-spring-boot-testcontainers</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.ai:spring-ai-spring-boot-testcontainers'\n}\n----\n\nTIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testcontainers.adoc", "title": "testcontainers", "heading": "testcontainers", "heading_level": 1, "file_order": 112, "section_index": 0, "content_hash": "910793f2a4a334927f867a4edac8f2bc7251890308d5ce7ac885e6b57767408c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testcontainers.adoc"}}
{"id": "sha256:42ea6076be076e411801dea1a0ea94e5313cc018e23d148203405fc240f8523c", "content": "The following service connection factories are provided in the `spring-ai-spring-boot-testcontainers` module:\n\n[cols=\"|,|\"]\n|====\n| Connection Details | Matched on\n\n| `AwsOpenSearchConnectionDetails`\n| Containers of type `LocalStackContainer`\n\n| `ChromaConnectionDetails`\n| Containers of type `ChromaDBContainer`\n\n| `McpSseClientConnectionDetails`\n| Containers of type `DockerMcpGatewayContainer`\n\n| `MilvusServiceClientConnectionDetails`\n| Containers of type `MilvusContainer`\n\n| `OllamaConnectionDetails`\n| Containers of type `OllamaContainer`\n\n| `OpenSearchConnectionDetails`\n| Containers of type `OpensearchContainer`\n\n| `QdrantConnectionDetails`\n| Containers of type `QdrantContainer`\n\n| `TypesenseConnectionDetails`\n| Containers of type `TypesenseContainer`\n\n| `WeaviateConnectionDetails`\n| Containers of type `WeaviateContainer`\n|====\n\nMore service connections are provided by the spring boot module `spring-boot-testcontainers`. Refer to the https://docs.spring.io/spring-boot/reference/testing/testcontainers.html#testing.testcontainers.service-connections[Testcontainers Service Connections] documentation page for the full list.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testcontainers.adoc", "title": "testcontainers", "heading": "Service Connections", "heading_level": 2, "file_order": 112, "section_index": 1, "content_hash": "42ea6076be076e411801dea1a0ea94e5313cc018e23d148203405fc240f8523c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testcontainers.adoc"}}
{"id": "sha256:8cf706c4503c3daf9253a02f1920db86ad784a27edf67e1523fb9d2d9c8f3f8a", "content": "Testing AI applications requires evaluating the generated content to ensure the AI model has not produced a hallucinated response.\n\nOne method to evaluate the response is to use the AI model itself for evaluation. Select the best AI model for the evaluation, which may not be the same model used to generate the response.\n\nThe Spring AI interface for evaluating responses is `Evaluator`, defined as:\n\n[source,java]\n----\n@FunctionalInterface\npublic interface Evaluator {\n EvaluationResponse evaluate(EvaluationRequest evaluationRequest);\n}\n----\n\nThe input to the evaluation is the `EvaluationRequest` defined as\n\n[source,java]\n----\npublic class EvaluationRequest {\n\n\tprivate final String userText;\n\n\tprivate final List<Content> dataList;\n\n\tprivate final String responseContent;\n\n\tpublic EvaluationRequest(String userText, List<Content> dataList, String responseContent) {\n this.userText = userText;\n this.dataList = dataList;\n this.responseContent = responseContent;\n\t}\n\n ...\n}\n----\n\n* `userText`: The raw input from the user as a `String`\n* `dataList`: Contextual data, such as from Retrieval Augmented Generation, appended to the raw input.\n* `responseContent`: The AI model's response content as a `String`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Evaluation Testing", "heading_level": 1, "file_order": 113, "section_index": 0, "content_hash": "8cf706c4503c3daf9253a02f1920db86ad784a27edf67e1523fb9d2d9c8f3f8a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:eb40650cff9523169e8b9ea7fc932cdb364e1571c39c62982133b9204839c6fb", "content": "The `RelevancyEvaluator` is an implementation of the `Evaluator` interface, designed to assess the relevance of AI-generated responses against provided context. This evaluator helps assess the quality of a RAG flow by determining if the AI model's response is relevant to the user's input with respect to the retrieved context.\n\nThe evaluation is based on the user input, the AI model's response, and the context information. It uses a prompt template to ask the AI model if the response is relevant to the user input and context.\n\nThis is the default prompt template used by the `RelevancyEvaluator`:\n\n[source,text]\n----\nYour task is to evaluate if the response for the query\nis in line with the context information provided.\n\nYou have two options to answer. Either YES or NO.\n\nAnswer YES, if the response for the query\nis in line with context information otherwise NO.\n\nQuery:\n{query}\n\nResponse:\n{response}\n\nContext:\n{context}\n\nAnswer:\n----\n\nNOTE: You can customize the prompt template by providing your own `PromptTemplate` object via the `.promptTemplate()` builder method. See xref:_custom_template[Custom Template] for details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Relevancy Evaluator", "heading_level": 2, "file_order": 113, "section_index": 1, "content_hash": "eb40650cff9523169e8b9ea7fc932cdb364e1571c39c62982133b9204839c6fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:5abcb480ec3262c02734da0616663ca1826f61fc9a1d9b8c43f909cacc9ab9c2", "content": "Here is an example of usage of the `RelevancyEvaluator` in an integration test, validating the result of a RAG flow using the `RetrievalAugmentationAdvisor`:\n\n[source,java]\n----\n@Test\nvoid evaluateRelevancy() {\n String question = \"Where does the adventure of Anacletus and Birba take place?\";\n\n RetrievalAugmentationAdvisor ragAdvisor = RetrievalAugmentationAdvisor.builder()\n .documentRetriever(VectorStoreDocumentRetriever.builder()\n .vectorStore(pgVectorStore)\n .build())\n .build();\n\n ChatResponse chatResponse = ChatClient.builder(chatModel).build()\n .prompt(question)\n .advisors(ragAdvisor)\n .call()\n .chatResponse();\n\n EvaluationRequest evaluationRequest = new EvaluationRequest(\n // The original user question\n question,\n // The retrieved context from the RAG flow\n chatResponse.getMetadata().get(RetrievalAugmentationAdvisor.DOCUMENT_CONTEXT),\n // The AI model's response\n chatResponse.getResult().getOutput().getText()\n );\n\n RelevancyEvaluator evaluator = new RelevancyEvaluator(ChatClient.builder(chatModel));\n\n EvaluationResponse evaluationResponse = evaluator.evaluate(evaluationRequest);\n\n assertThat(evaluationResponse.isPass()).isTrue();\n}\n----\n\nYou can find several integration tests in the Spring AI project that use the `RelevancyEvaluator` to test the functionality of the `QuestionAnswerAdvisor` (see https://github.com/spring-projects/spring-ai/blob/main/spring-ai-integration-tests/src/test/java/org/springframework/ai/integration/tests/client/advisor/QuestionAnswerAdvisorIT.java[tests]) and `RetrievalAugmentationAdvisor` (see https://github.com/spring-projects/spring-ai/blob/main/spring-ai-integration-tests/src/test/java/org/springframework/ai/integration/tests/client/advisor/RetrievalAugmentationAdvisorIT.java[tests]).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Usage in Integration Tests", "heading_level": 2, "file_order": 113, "section_index": 2, "content_hash": "5abcb480ec3262c02734da0616663ca1826f61fc9a1d9b8c43f909cacc9ab9c2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:f314f0bc681ac76726b3d8d49b74db1975f9664f248ee5af48fc98f78487f215", "content": "The `RelevancyEvaluator` uses a default template to prompt the AI model for evaluation. You can customize this behavior by providing your own `PromptTemplate` object via the `.promptTemplate()` builder method.\n\nThe custom `PromptTemplate` can use any `TemplateRenderer` implementation (by default, it uses `StPromptTemplate` based on the https://www.stringtemplate.org/[StringTemplate] engine). The important requirement is that the template must contain the following placeholders:\n\n* a `query` placeholder to receive the user question.\n* a `response` placeholder to receive the AI model's response.\n* a `context` placeholder to receive the context information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Custom Template", "heading_level": 3, "file_order": 113, "section_index": 3, "content_hash": "f314f0bc681ac76726b3d8d49b74db1975f9664f248ee5af48fc98f78487f215", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:9c09f62c6a626090fcdb48a710fad8159efd089fae9a789d6ce6e7a742674a6b", "content": "The FactCheckingEvaluator is another implementation of the Evaluator interface, designed to assess the factual accuracy of AI-generated responses against provided context. This evaluator helps detect and reduce hallucinations in AI outputs by verifying if a given statement (claim) is logically supported by the provided context (document).\n\nThe 'claim' and 'document' are presented to the AI model for evaluation. Smaller and more efficient AI models dedicated to this purpose are available, such as Bespoke's Minicheck, which helps reduce the cost of performing these checks compared to flagship models like GPT-4. Minicheck is also available for use through Ollama.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "FactCheckingEvaluator", "heading_level": 2, "file_order": 113, "section_index": 4, "content_hash": "9c09f62c6a626090fcdb48a710fad8159efd089fae9a789d6ce6e7a742674a6b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:f6a145af7f5e02b3bccba6b0a5c548ee0a629fe1a7daa0d93afe736961f650aa", "content": "The FactCheckingEvaluator constructor takes a ChatClient.Builder as a parameter:\n[source,java]\n----\npublic FactCheckingEvaluator(ChatClient.Builder chatClientBuilder) {\n this.chatClientBuilder = chatClientBuilder;\n}\n----\nThe evaluator uses the following prompt template for fact-checking:\n[source,text]\n----\nDocument: {document}\nClaim: {claim}\n----\nWhere `+{document}+` is the context information, and `+{claim}+` is the AI model's response to be evaluated.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Usage", "heading_level": 3, "file_order": 113, "section_index": 5, "content_hash": "f6a145af7f5e02b3bccba6b0a5c548ee0a629fe1a7daa0d93afe736961f650aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:0beecb55b67f6234f7bc1dd0dc338f5183b2e65cc7730faafe20e42dc2e7f6a9", "content": "Here's an example of how to use the FactCheckingEvaluator with an Ollama-based ChatModel, specifically the Bespoke-Minicheck model:\n\n[source,java]\n----\n@Test\nvoid testFactChecking() {\n // Set up the Ollama API\n OllamaApi ollamaApi = new OllamaApi(\"http://localhost:11434\");\n\n ChatModel chatModel = new OllamaChatModel(ollamaApi,\n OllamaChatOptions.builder().model(BESPOKE_MINICHECK).numPredict(2).temperature(0.0d).build())\n\n // Create the FactCheckingEvaluator\n var factCheckingEvaluator = new FactCheckingEvaluator(ChatClient.builder(chatModel));\n\n // Example context and claim\n String context = \"The Earth is the third planet from the Sun and the only astronomical object known to harbor life.\";\n String claim = \"The Earth is the fourth planet from the Sun.\";\n\n // Create an EvaluationRequest\n EvaluationRequest evaluationRequest = new EvaluationRequest(context, Collections.emptyList(), claim);\n\n // Perform the evaluation\n EvaluationResponse evaluationResponse = factCheckingEvaluator.evaluate(evaluationRequest);\n\n assertFalse(evaluationResponse.isPass(), \"The claim should not be supported by the context\");\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/testing.adoc", "title": "Evaluation Testing", "heading": "Example", "heading_level": 3, "file_order": 113, "section_index": 6, "content_hash": "0beecb55b67f6234f7bc1dd0dc338f5183b2e65cc7730faafe20e42dc2e7f6a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/testing.adoc"}}
{"id": "sha256:47564ba0b58b4890b0ed9dfcebbcb112bc835c2fb08a232a0b16813d07723984", "content": "This guide helps you migrate from the deprecated `FunctionCallback` API to the new `ToolCallback` API in Spring AI. For more information about the new APIs, check out the xref:api/tools.adoc[Tools Calling] documentation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Migrating from FunctionCallback to ToolCallback API", "heading_level": 1, "file_order": 114, "section_index": 0, "content_hash": "47564ba0b58b4890b0ed9dfcebbcb112bc835c2fb08a232a0b16813d07723984", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:12d0079020cb57943da3877151a923f266ee5a7f7d61d8de1ddd70bdefd14737", "content": "These changes are part of a broader effort to improve and extend the tool calling capabilities in Spring AI. Among the other things, the new API moves from \"functions\" to \"tools\" terminology to better align with industry conventions. This involves several API changes while maintaining backward compatibility through deprecated methods.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Overview of Changes", "heading_level": 2, "file_order": 114, "section_index": 1, "content_hash": "12d0079020cb57943da3877151a923f266ee5a7f7d61d8de1ddd70bdefd14737", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:bf1e920b0211decad8d434a3a21e018f89cf9aa7d7075e99f66e6422ebbd7175", "content": "1. `FunctionCallback` → `ToolCallback`\n2. `FunctionCallback.builder().function()` → `FunctionToolCallback.builder()`\n3. `FunctionCallback.builder().method()` → `MethodToolCallback.builder()`\n4. `FunctionCallingOptions` → `ToolCallingChatOptions`\n5. `ChatClient.builder().defaultFunctions()` → `ChatClient.builder().defaultTools()`\n6. `ChatClient.functions()` → `ChatClient.tools()`\n7. `FunctionCallingOptions.builder().functions()` → `ToolCallingChatOptions.builder().toolNames()`\n8. `FunctionCallingOptions.builder().functionCallbacks()` → `ToolCallingChatOptions.builder().toolCallbacks()`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Key Changes", "heading_level": 2, "file_order": 114, "section_index": 2, "content_hash": "bf1e920b0211decad8d434a3a21e018f89cf9aa7d7075e99f66e6422ebbd7175", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:aee841c700ff1a503af73fdb97c922c18e1852ab208fc41d24da8ae162df3b63", "content": "Before:\n[source,java]\n----\nFunctionCallback.builder()\n .function(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build()\n----\n\nAfter:\n[source,java]\n----\nFunctionToolCallback.builder(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build()\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "1. Basic Function Callback", "heading_level": 3, "file_order": 114, "section_index": 3, "content_hash": "aee841c700ff1a503af73fdb97c922c18e1852ab208fc41d24da8ae162df3b63", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:185dee95df212b05e369307cec525efa676b35978d9cb4562314b3bb2be9ef0b", "content": "Before:\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"What's the weather like in San Francisco?\")\n .functions(FunctionCallback.builder()\n .function(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build())\n .call()\n .content();\n----\n\nAfter:\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"What's the weather like in San Francisco?\")\n .tools(FunctionToolCallback.builder(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "2. ChatClient Usage", "heading_level": 3, "file_order": 114, "section_index": 4, "content_hash": "185dee95df212b05e369307cec525efa676b35978d9cb4562314b3bb2be9ef0b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:396ab3df32a2db56bb5c9394523dadb2ea265684ec950c9329e19deddbf9fb32", "content": "Before:\n[source,java]\n----\nFunctionCallback.builder()\n .method(\"getWeatherInLocation\", String.class, Unit.class)\n .description(\"Get the weather in location\")\n .targetClass(TestFunctionClass.class)\n .build()\n----\n\nAfter:\n[source,java]\n----\nvar toolMethod = ReflectionUtils.findMethod(TestFunctionClass.class, \"getWeatherInLocation\");\n\nMethodToolCallback.builder()\n .toolDefinition(ToolDefinition.builder(toolMethod)\n .description(\"Get the weather in location\")\n .build())\n .toolMethod(toolMethod)\n .build()\n----\n\nOr with the declarative approach:\n[source,java]\n----\nclass WeatherTools {\n\n @Tool(description = \"Get the weather in location\")\n public void getWeatherInLocation(String location, Unit unit) {\n // ...\n }\n\n}\n----\n\nAnd you can use the same `ChatClient#tools()` API to register method-based tool callbacks:\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"What's the weather like in San Francisco?\")\n .tools(MethodToolCallback.builder()\n .toolDefinition(ToolDefinition.builder(toolMethod)\n .description(\"Get the weather in location\")\n .build())\n .toolMethod(toolMethod)\n .build())\n .call()\n .content();\n----\n\nOr with the declarative approach:\n\n[source,java]\n----\nString response = ChatClient.create(chatModel)\n .prompt()\n .user(\"What's the weather like in San Francisco?\")\n .tools(new WeatherTools())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "3. Method-Based Function Callbacks", "heading_level": 3, "file_order": 114, "section_index": 5, "content_hash": "396ab3df32a2db56bb5c9394523dadb2ea265684ec950c9329e19deddbf9fb32", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:a1aeb37f794e021a329194ca3bf955ef0827b9238d1a28a913d7fa32fb1fa6de", "content": "Before:\n[source,java]\n----\nFunctionCallingOptions.builder()\n .model(modelName)\n .function(\"weatherFunction\")\n .build()\n----\n\nAfter:\n[source,java]\n----\nToolCallingChatOptions.builder()\n .model(modelName)\n .toolNames(\"weatherFunction\")\n .build()\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "4. Options Configuration", "heading_level": 3, "file_order": 114, "section_index": 6, "content_hash": "a1aeb37f794e021a329194ca3bf955ef0827b9238d1a28a913d7fa32fb1fa6de", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:ee4e53762f46a0e3dad924393944014307d297361d6a951df32ccc0cac588210", "content": "Before:\n[source,java]\n----\nChatClient.builder(chatModel)\n .defaultFunctions(FunctionCallback.builder()\n .function(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build())\n .build()\n----\n\nAfter:\n[source,java]\n----\nChatClient.builder(chatModel)\n .defaultTools(FunctionToolCallback.builder(\"getCurrentWeather\", new MockWeatherService())\n .description(\"Get the weather in location\")\n .inputType(MockWeatherService.Request.class)\n .build())\n .build()\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "5. Default Functions in ChatClient Builder", "heading_level": 3, "file_order": 114, "section_index": 7, "content_hash": "ee4e53762f46a0e3dad924393944014307d297361d6a951df32ccc0cac588210", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:4add6888db9ddb9f2624d132745f8a8b692be7326ec988b533dd5110e8b653ae", "content": "Before:\n[source,java]\n----\n@Bean\npublic FunctionCallback weatherFunctionInfo() {\n return FunctionCallback.builder()\n .function(\"WeatherInfo\", new MockWeatherService())\n .description(\"Get the current weather\")\n .inputType(MockWeatherService.Request.class)\n .build();\n}\n----\n\nAfter:\n[source,java]\n----\n@Bean\npublic ToolCallback weatherFunctionInfo() {\n return FunctionToolCallback.builder(\"WeatherInfo\", new MockWeatherService())\n .description(\"Get the current weather\")\n .inputType(MockWeatherService.Request.class)\n .build();\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "6. Spring Bean Configuration", "heading_level": 3, "file_order": 114, "section_index": 8, "content_hash": "4add6888db9ddb9f2624d132745f8a8b692be7326ec988b533dd5110e8b653ae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:13da720ba318981cc8d857b78db8f04d5c3173fbde6151aace54450995eb7756", "content": "1. The `method()` configuration in function callbacks has been replaced with a more explicit method tool configuration using `ToolDefinition` and `MethodToolCallback`.\n\n2. When using method-based callbacks, you now need to explicitly find the method using `ReflectionUtils` and provide it to the builder. Alternatively, you can use the declarative approach with the `@Tool` annotation.\n\n3. For non-static methods, you must now provide both the method and the target object:\n[source,java]\n----\nMethodToolCallback.builder()\n .toolDefinition(ToolDefinition.builder(toolMethod)\n .description(\"Description\")\n .build())\n .toolMethod(toolMethod)\n .toolObject(targetObject)\n .build()\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Breaking Changes", "heading_level": 2, "file_order": 114, "section_index": 9, "content_hash": "13da720ba318981cc8d857b78db8f04d5c3173fbde6151aace54450995eb7756", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:98929b0a8ff045b94ca913d4bdd1f9a4a0e221f9585cf02898a6633295d5aa5d", "content": "The following methods are deprecated and will be removed in a future release:\n\n- `ChatClient.Builder.defaultFunctions(String...)`\n- `ChatClient.Builder.defaultFunctions(FunctionCallback...)`\n- `ChatClient.RequestSpec.functions()`\n\nUse their `tools` counterparts instead.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Deprecated Methods", "heading_level": 2, "file_order": 114, "section_index": 10, "content_hash": "98929b0a8ff045b94ca913d4bdd1f9a4a0e221f9585cf02898a6633295d5aa5d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:d7558c6660da4c336d3d6bee8e785088c59284f63a30ad6d7f877e2c648147d8", "content": "Now you can use the method-level annotation (`@Tool`) to register tools with Spring AI:\n\n[source,java]\n----\nclass Home {\n\n @Tool(description = \"Turn light On or Off in a room.\")\n void turnLight(String roomName, boolean on) {\n // ...\n logger.info(\"Turn light in room: {} to: {}\", roomName, on);\n }\n}\n\nString response = ChatClient.create(this.chatModel).prompt()\n .user(\"Turn the light in the living room On.\")\n .tools(new Home())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Declarative Specification with @Tool", "heading_level": 2, "file_order": 114, "section_index": 11, "content_hash": "d7558c6660da4c336d3d6bee8e785088c59284f63a30ad6d7f877e2c648147d8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:a371fa4721a1dbebe08af93b324a681fd130d9ded71ce334fa7fbaf360b7c818", "content": "1. The new API provides better separation between tool definition and implementation.\n2. Tool definitions can be reused across different implementations.\n3. The builder pattern has been simplified for common use cases.\n4. Better support for method-based tools with improved error handling.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Additional Notes", "heading_level": 2, "file_order": 114, "section_index": 12, "content_hash": "a371fa4721a1dbebe08af93b324a681fd130d9ded71ce334fa7fbaf360b7c818", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:e276cf4c2f1ad8c73c1bb02c599cffb0320610c27ebb570c6611882b5e7af6c1", "content": "The deprecated methods will be maintained for backward compatibility in the current milestone version but will be removed in the next milestone release. It's recommended to migrate to the new API as soon as possible.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools-migration.adoc", "title": "Migrating from FunctionCallback to ToolCallback API", "heading": "Timeline", "heading_level": 2, "file_order": 114, "section_index": 13, "content_hash": "e276cf4c2f1ad8c73c1bb02c599cffb0320610c27ebb570c6611882b5e7af6c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools-migration.adoc"}}
{"id": "sha256:7250858400934b446ada3f0637e3096d1ad233e3a9d534065af9673e0513bae9", "content": "[[Tools]]\n\n_Tool calling_ (also known as _function calling_) is a common pattern in AI applications allowing a model to interact with a set of APIs, or _tools_, augmenting its capabilities.\n\nTools are mainly used for:\n\n* **Information Retrieval**. Tools in this category can be used to retrieve information from external sources, such as a database, a web service, a file system, or a web search engine. The goal is to augment the knowledge of the model, allowing it to answer questions that it would not be able to answer otherwise. As such, they can be used in Retrieval Augmented Generation (RAG) scenarios. For example, a tool can be used to retrieve the current weather for a given location, to retrieve the latest news articles, or to query a database for a specific record.\n* **Taking Action**. Tools in this category can be used to take action in a software system, such as sending an email, creating a new record in a database, submitting a form, or triggering a workflow. The goal is to automate tasks that would otherwise require human intervention or explicit programming. For example, a tool can be used to book a flight for a customer interacting with a chatbot, to fill out a form on a web page, or to implement a Java class based on an automated test (TDD) in a code generation scenario.\n\nEven though we typically refer to _tool calling_ as a model capability, it is actually up to the client application to provide the tool calling logic. The model can only request a tool call and provide the input arguments, whereas the application is responsible for executing the tool call from the input arguments and returning the result. The model never gets access to any of the APIs provided as tools, which is a critical security consideration.\n\nSpring AI provides convenient APIs to define tools, resolve tool call requests from a model, and execute the tool calls. The following sections provide an overview of the tool calling capabilities in Spring AI.\n\nNOTE: Check the xref:api/chat/comparison.adoc[Chat Model Comparisons] to see which AI models support tool calling invocation.\n\nTIP: Follow the guide to migrate from the deprecated xref:api/tools-migration.adoc[FunctionCallback to ToolCallback API].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "tools", "heading_level": 1, "file_order": 115, "section_index": 0, "content_hash": "7250858400934b446ada3f0637e3096d1ad233e3a9d534065af9673e0513bae9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:b2f57e71846568e877762e6e247e44b91b8d6817f5bb9a28e230f09c7c4dee3a", "content": "Let's see how to start using tool calling in Spring AI. We'll implement two simple tools: one for information retrieval and one for taking action. The information retrieval tool will be used to get the current date and time in the user's time zone. The action tool will be used to set an alarm for a specified time.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Quick Start", "heading_level": 2, "file_order": 115, "section_index": 1, "content_hash": "b2f57e71846568e877762e6e247e44b91b8d6817f5bb9a28e230f09c7c4dee3a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:f5c0ab1d6fd851186f6b70b457b8b6c8dd4e64d9a3af5915450d42f72f3e5bb3", "content": "AI models don't have access to real-time information. Any question that assumes awareness of information such as the current date or weather forecast cannot be answered by the model. However, we can provide a tool that can retrieve this information, and let the model call this tool when access to real-time information is needed.\n\nLet's implement a tool to get the current date and time in the user's time zone in a `DateTimeTools` class. The tool will take no argument. The `LocaleContextHolder` from Spring Framework can provide the user's time zone. The tool will be defined as a method annotated with `@Tool`. To help the model understand if and when to call this tool, we'll provide a detailed description of what the tools does.\n\n[source,java]\n----\nimport java.time.LocalDateTime;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.context.i18n.LocaleContextHolder;\n\nclass DateTimeTools {\n\n @Tool(description = \"Get the current date and time in the user's timezone\")\n String getCurrentDateTime() {\n return LocalDateTime.now().atZone(LocaleContextHolder.getTimeZone().toZoneId()).toString();\n }\n\n}\n----\n\nNext, let's make the tool available to the model. In this example, we'll use the `ChatClient` to interact with the model. We'll provide the tool to the model by passing an instance of `DateTimeTools` via the `tools()` method. When the model needs to know the current date and time, it will request the tool to be called. Internally, the `ChatClient` will call the tool and return the result to the model, which will then use the tool call result to generate the final response to the original question.\n\n[source,java]\n----\nChatModel chatModel = ...\n\nString response = ChatClient.create(chatModel)\n .prompt(\"What day is tomorrow?\")\n .tools(new DateTimeTools())\n .call()\n .content();\n\nSystem.out.println(response);\n----\n\nThe output will be something like:\n\n[source]\n----\nTomorrow is 2015-10-21.\n----\n\nYou can retry asking the same question again. This time, don't provide the tool to the model. The output will be something like:\n\n[source]\n----\nI am an AI and do not have access to real-time information. Please provide the current date so I can accurately determine what day tomorrow will be.\n----\n\nWithout the tool, the model doesn't know how to answer the question because it doesn't have the ability to determine the current date and time.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Information Retrieval", "heading_level": 3, "file_order": 115, "section_index": 2, "content_hash": "f5c0ab1d6fd851186f6b70b457b8b6c8dd4e64d9a3af5915450d42f72f3e5bb3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:3f0d78115e1a328be22e332d48371e3d7bbb59c05dded0e6c96cef958ad6be2b", "content": "AI models can be used to generate plans for accomplishing certain goals. For example, a model can generate a plan for booking a trip to Denmark. However, the model doesn't have the ability to execute the plan. That's where tools come in: they can be used to execute the plan that a model generates.\n\nIn the previous example, we used a tool to determine the current date and time. In this example, we'll define a second tool for setting an alarm at a specific time. The goal is to set an alarm for 10 minutes from now, so we need to provide both tools to the model to accomplish this task.\n\nWe'll add the new tool to the same `DateTimeTools` class as before. The new tool will take a single parameter, which is the time in ISO-8601 format. The tool will then print a message to the console indicating that the alarm has been set for the given time. Like before, the tool is defined as a method annotated with `@Tool`, which we also use to provide a detailed description to help the model understand when and how to use the tool.\n\n[source,java]\n----\nimport java.time.LocalDateTime;\nimport java.time.format.DateTimeFormatter;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.context.i18n.LocaleContextHolder;\n\nclass DateTimeTools {\n\n @Tool(description = \"Get the current date and time in the user's timezone\")\n String getCurrentDateTime() {\n return LocalDateTime.now().atZone(LocaleContextHolder.getTimeZone().toZoneId()).toString();\n }\n\n @Tool(description = \"Set a user alarm for the given time, provided in ISO-8601 format\")\n void setAlarm(String time) {\n LocalDateTime alarmTime = LocalDateTime.parse(time, DateTimeFormatter.ISO_DATE_TIME);\n System.out.println(\"Alarm set for \" + alarmTime);\n }\n\n}\n----\n\nNext, let's make both tools available to the model. We'll use the `ChatClient` to interact with the model. We'll provide the tools to the model by passing an instance of `DateTimeTools` via the `tools()` method. When we ask to set up an alarm 10 minutes from now, the model will first need to know the current date and time. Then, it will use the current date and time to calculate the alarm time. Finally, it will use the alarm tool to set up the alarm. Internally, the `ChatClient` will handle any tool call request from the model and send back to it any tool call execution result, so that the model can generate the final response.\n\n[source,java]\n----\nChatModel chatModel = ...\n\nString response = ChatClient.create(chatModel)\n .prompt(\"Can you set an alarm 10 minutes from now?\")\n .tools(new DateTimeTools())\n .call()\n .content();\n\nSystem.out.println(response);\n----\n\nIn the application logs, you can check the alarm has been set at the correct time.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Taking Actions", "heading_level": 3, "file_order": 115, "section_index": 3, "content_hash": "3f0d78115e1a328be22e332d48371e3d7bbb59c05dded0e6c96cef958ad6be2b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:49aacae67aac20d5d926b729d5937ddc37ec17538d20d5b69cea5bd76c01f148", "content": "Spring AI supports tool calling through a set of flexible abstractions that allow you to define, resolve, and execute tools in a consistent way. This section provides an overview of the main concepts and components of tool calling in Spring AI.\n\nimage::tools/tool-calling-01.jpg[The main sequence of actions for tool calling, width=700, align=\"center\"]\n\n1. When we want to make a tool available to the model, we include its definition in the chat request. Each tool definition comprises of a name, a description, and the schema of the input parameters.\n2. When the model decides to call a tool, it sends a response with the tool name and the input parameters modeled after the defined schema.\n3. The application is responsible for using the tool name to identify and execute the tool with the provided input parameters.\n4. The result of the tool call is processed by the application.\n5. The application sends the tool call result back to the model.\n6. The model generates the final response using the tool call result as additional context.\n\nTools are the building blocks of tool calling and they are modeled by the `ToolCallback` interface. Spring AI provides built-in support for specifying `ToolCallback`(s) from methods and functions, but you can always define your own `ToolCallback` implementations to support more use cases.\n\n`ChatModel` implementations transparently dispatch tool call requests to the corresponding `ToolCallback` implementations and will send the tool call results back to the model, which will ultimately generate the final response. They do so using the `ToolCallingManager` interface, which is responsible for managing the tool execution lifecycle.\n\nBoth `ChatClient` and `ChatModel` accept a list of `ToolCallback` objects to make the tools available to the model and the `ToolCallingManager` that will eventually execute them.\n\nBesides passing the `ToolCallback` objects directly, you can also pass a list of tool names, that will be resolved dynamically using the `ToolCallbackResolver` interface.\n\nThe following sections will go into more details about all these concepts and APIs, including how to customize and extend them to support more use cases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Overview", "heading_level": 2, "file_order": 115, "section_index": 4, "content_hash": "49aacae67aac20d5d926b729d5937ddc37ec17538d20d5b69cea5bd76c01f148", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:bc9749e40873c3aecdabe2dcd9f6b4ea91921254e1501cd9026abe7ec6b46971", "content": "Spring AI provides built-in support for specifying tools (i.e. `ToolCallback`(s)) from methods in two ways:\n\n- declaratively, using the `@Tool` annotation\n- programmatically, using the low-level `MethodToolCallback` implementation.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Methods as Tools", "heading_level": 2, "file_order": 115, "section_index": 5, "content_hash": "bc9749e40873c3aecdabe2dcd9f6b4ea91921254e1501cd9026abe7ec6b46971", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:8b5b4556e108a1cc7e7cacf4b45279403af5deb98873b4fb476907f8b280f262", "content": "You can turn a method into a tool by annotating it with `@Tool`.\n\n[source,java]\n----\nclass DateTimeTools {\n\n @Tool(description = \"Get the current date and time in the user's timezone\")\n String getCurrentDateTime() {\n return LocalDateTime.now().atZone(LocaleContextHolder.getTimeZone().toZoneId()).toString();\n }\n\n}\n----\n\nThe `@Tool` annotation allows you to provide key information about the tool:\n\n- `name`: The name of the tool. If not provided, the method name will be used. AI models use this name to identify the tool when calling it. Therefore, it's not allowed to have two tools with the same name in the same class. The name must be unique across all the tools available to the model for a specific chat request.\n- `description`: The description for the tool, which can be used by the model to understand when and how to call the tool. If not provided, the method name will be used as the tool description. However, it's strongly recommended to provide a detailed description because that's paramount for the model to understand the tool's purpose and how to use it. Failing in providing a good description can lead to the model not using the tool when it should or using it incorrectly.\n- `returnDirect`: Whether the tool result should be returned directly to the client or passed back to the model. See xref:_return_direct[] for more details.\n- `resultConverter`: The `ToolCallResultConverter` implementation to use for converting the result of a tool call to a `String object` to send back to the AI model. See xref:_result_conversion[] for more details.\n\nThe method can be either static or instance, and it can have any visibility (public, protected, package-private, or private). The class that contains the method can be either a top-level class or a nested class, and it can also have any visibility (as long as it's accessible where you're planning to instantiate it).\n\nNOTE: Spring AI provides built-in support for AOT compilation of the `@Tool`-annotated methods as long as the class containing the methods is a Spring bean (e.g. `@Component`). Otherwise, you'll need to provide the necessary configuration to the GraalVM compiler. For example, by annotating the class with `@RegisterReflection(memberCategories = MemberCategory.INVOKE_DECLARED_METHODS)`.\n\nYou can define any number of arguments for the method (including no argument) with most types (primitives, POJOs, enums, lists, arrays, maps, and so on). Similarly, the method can return most types, including `void`. If the method returns a value, the return type must be a serializable type, as the result will be serialized and sent back to the model.\n\nNOTE: Some types are not supported. See xref:_method_tool_limitations[] for more details.\n\nSpring AI will generate the JSON schema for the input parameters of the `@Tool`-annotated method automatically. The schema is used by the model to understand how to call the tool and prepare the tool request. The `@ToolParam` annotation can be used to provide additional information about the input parameters, such as a description or whether the parameter is required or optional. By default, all input parameters are considered required.\n\n[source,java]\n----\nimport java.time.LocalDateTime;\nimport java.time.format.DateTimeFormatter;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.ai.tool.annotation.ToolParam;\n\nclass DateTimeTools {\n\n @Tool(description = \"Set a user alarm for the given time\")\n void setAlarm(@ToolParam(description = \"Time in ISO-8601 format\") String time) {\n LocalDateTime alarmTime = LocalDateTime.parse(time, DateTimeFormatter.ISO_DATE_TIME);\n System.out.println(\"Alarm set for \" + alarmTime);\n }\n\n}\n----\n\nThe `@ToolParam` annotation allows you to provide key information about a tool parameter:\n\n- `description`: The description for the parameter, which can be used by the model to understand better how to use it. For example, what format the parameter should be in, what values are allowed, and so on.\n- `required`: Whether the parameter is required or optional. By default, all parameters are considered required.\n\nIf a parameter is annotated as `@Nullable`, it will be considered optional unless explicitly marked as required using the `@ToolParam` annotation.\n\nBesides the `@ToolParam` annotation, you can also use the `@Schema` annotation from Swagger or `@JsonProperty` from Jackson. See xref:_json_schema[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Declarative Specification: `@Tool`", "heading_level": 3, "file_order": 115, "section_index": 6, "content_hash": "8b5b4556e108a1cc7e7cacf4b45279403af5deb98873b4fb476907f8b280f262", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:b581471d0a7372365877efa958a78d3eae746b5d11d66d6e8bce402613f29c36", "content": "When using the declarative specification approach, you can pass the tool class instance to the `tools()` method when invoking a `ChatClient`. Such tools will only be available for the specific chat request they are added to.\n\n[source,java]\n----\nChatClient.create(chatModel)\n .prompt(\"What day is tomorrow?\")\n .tools(new DateTimeTools())\n .call()\n .content();\n----\n\nUnder the hood, the `ChatClient` will generate a `ToolCallback` from each `@Tool`-annotated method in the tool class instance and pass them to the model. In case you prefer to generate the `ToolCallback`(s) yourself, you can use the `ToolCallbacks` utility class.\n\n[source,java]\n----\nToolCallback[] dateTimeTools = ToolCallbacks.from(new DateTimeTools());\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 7, "content_hash": "b581471d0a7372365877efa958a78d3eae746b5d11d66d6e8bce402613f29c36", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:59a11aa2982c7899d313516fbc5cb9afcc472327e14fbb244c1a02c61c0774bc", "content": "When using the declarative specification approach, you can add default tools to a `ChatClient.Builder` by passing the tool class instance to the `defaultTools()` method.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by all the `ChatClient` instances built from the same `ChatClient.Builder`. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nChatModel chatModel = ...\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultTools(new DateTimeTools())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 8, "content_hash": "59a11aa2982c7899d313516fbc5cb9afcc472327e14fbb244c1a02c61c0774bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:1d3008fcf931809eeca861de7838e17a1385cbd463cf6db8a43212271afcdce9", "content": "When using the declarative specification approach, you can pass the tool class instance to the `toolCallbacks()` method of the `ToolCallingChatOptions` you use to call a `ChatModel`. Such tools will only be available for the specific chat request they are added to.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback[] dateTimeTools = ToolCallbacks.from(new DateTimeTools());\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(dateTimeTools)\n .build();\nPrompt prompt = new Prompt(\"What day is tomorrow?\", chatOptions);\nchatModel.call(prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 9, "content_hash": "1d3008fcf931809eeca861de7838e17a1385cbd463cf6db8a43212271afcdce9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:992073f528ce07876d2278c66dada372a7bffb6640ceafcd499f8f69ba0bf86a", "content": "When using the declarative specification approach, you can add default tools to `ChatModel` at construction time by passing the tool class instance to the `toolCallbacks()` method of the `ToolCallingChatOptions` instance used to create the `ChatModel`.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by that `ChatModel` instance. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nToolCallback[] dateTimeTools = ToolCallbacks.from(new DateTimeTools());\nChatModel chatModel = OllamaChatModel.builder()\n .ollamaApi(OllamaApi.builder().build())\n .defaultOptions(ToolCallingChatOptions.builder()\n .toolCallbacks(dateTimeTools)\n .build())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 10, "content_hash": "992073f528ce07876d2278c66dada372a7bffb6640ceafcd499f8f69ba0bf86a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:3d681cd63ac3b1d2994fe7a85994deaf713f6cfbc8cf25836188d2d287a6d155", "content": "You can turn a method into a tool by building a `MethodToolCallback` programmatically.\n\n[source,java]\n----\nclass DateTimeTools {\n\n String getCurrentDateTime() {\n return LocalDateTime.now().atZone(LocaleContextHolder.getTimeZone().toZoneId()).toString();\n }\n\n}\n----\n\nThe `MethodToolCallback.Builder` allows you to build a `MethodToolCallback` instance and provide key information about the tool:\n\n- `toolDefinition`: The `ToolDefinition` instance that defines the tool name, description, and input schema. You can build it using the `ToolDefinition.Builder` class. Required.\n- `toolMetadata`: The `ToolMetadata` instance that defines additional settings such as whether the result should be returned directly to the client, and the result converter to use. You can build it using the `ToolMetadata.Builder` class.\n- `toolMethod`: The `Method` instance that represents the tool method. Required.\n- `toolObject`: The object instance that contains the tool method. If the method is static, you can omit this parameter.\n- `toolCallResultConverter`: The `ToolCallResultConverter` instance to use for converting the result of a tool call to a `String` object to send back to the AI model. If not provided, the default converter will be used (`DefaultToolCallResultConverter`).\n\nThe `ToolDefinition.Builder` allows you to build a `ToolDefinition` instance and define the tool name, description, and input schema:\n\n- `name`: The name of the tool. If not provided, the method name will be used. AI models use this name to identify the tool when calling it. Therefore, it's not allowed to have two tools with the same name in the same class. The name must be unique across all the tools available to the model for a specific chat request.\n- `description`: The description for the tool, which can be used by the model to understand when and how to call the tool. If not provided, the method name will be used as the tool description. However, it's strongly recommended to provide a detailed description because that's paramount for the model to understand the tool's purpose and how to use it. Failing in providing a good description can lead to the model not using the tool when it should or using it incorrectly.\n- `inputSchema`: The JSON schema for the input parameters of the tool. If not provided, the schema will be generated automatically based on the method parameters. You can use the `@ToolParam` annotation to provide additional information about the input parameters, such as a description or whether the parameter is required or optional. By default, all input parameters are considered required. See xref:_json_schema[] for more details.\n\nThe `ToolMetadata.Builder` allows you to build a `ToolMetadata` instance and define additional settings for the tool:\n\n- `returnDirect`: Whether the tool result should be returned directly to the client or passed back to the model. See xref:_return_direct[] for more details.\n\n[source,java]\n----\nMethod method = ReflectionUtils.findMethod(DateTimeTools.class, \"getCurrentDateTime\");\nToolCallback toolCallback = MethodToolCallback.builder()\n .toolDefinition(ToolDefinitions.builder(method)\n .description(\"Get the current date and time in the user's timezone\")\n .build())\n .toolMethod(method)\n .toolObject(new DateTimeTools())\n .build();\n----\n\nThe method can be either static or instance, and it can have any visibility (public, protected, package-private, or private). The class that contains the method can be either a top-level class or a nested class, and it can also have any visibility (as long as it's accessible where you're planning to instantiate it).\n\nNOTE: Spring AI provides built-in support for AOT compilation of the tool methods as long as the class containing the methods is a Spring bean (e.g. `@Component`). Otherwise, you'll need to provide the necessary configuration to the GraalVM compiler. For example, by annotating the class with `@RegisterReflection(memberCategories = MemberCategory.INVOKE_DECLARED_METHODS)`.\n\nYou can define any number of arguments for the method (including no argument) with most types (primitives, POJOs, enums, lists, arrays, maps, and so on). Similarly, the method can return most types, including `void`. If the method returns a value, the return type must be a serializable type, as the result will be serialized and sent back to the model.\n\nNOTE: Some types are not supported. See xref:_method_tool_limitations[] for more details.\n\nIf the method is static, you can omit the `toolObject()` method, as it's not needed.\n\n[source,java]\n----\nclass DateTimeTools {\n\n static String getCurrentDateTime() {\n return LocalDateTime.now().atZone(LocaleContextHolder.getTimeZone().toZoneId()).toString();\n }\n\n}\n----\n\n[source,java]\n----\nMethod method = ReflectionUtils.findMethod(DateTimeTools.class, \"getCurrentDateTime\");\nToolCallback toolCallback = MethodToolCallback.builder()\n .toolDefinition(ToolDefinitions.builder(method)\n .description(\"Get the current date and time in the user's timezone\")\n .build())\n .toolMethod(method)\n .build();\n----\n\nSpring AI will generate the JSON schema for the input parameters of the method automatically. The schema is used by the model to understand how to call the tool and prepare the tool request. The `@ToolParam` annotation can be used to provide additional information about the input parameters, such as a description or whether the parameter is required or optional. By default, all input parameters are considered required.\n\n[source,java]\n----\nimport java.time.LocalDateTime;\nimport java.time.format.DateTimeFormatter;\nimport org.springframework.ai.tool.annotation.ToolParam;\n\nclass DateTimeTools {\n\n void setAlarm(@ToolParam(description = \"Time in ISO-8601 format\") String time) {\n LocalDateTime alarmTime = LocalDateTime.parse(time, DateTimeFormatter.ISO_DATE_TIME);\n System.out.println(\"Alarm set for \" + alarmTime);\n }\n\n}\n----\n\nThe `@ToolParam` annotation allows you to provide key information about a tool parameter:\n\n- `description`: The description for the parameter, which can be used by the model to understand better how to use it. For example, what format the parameter should be in, what values are allowed, and so on.\n- `required`: Whether the parameter is required or optional. By default, all parameters are considered required.\n\nIf a parameter is annotated as `@Nullable`, it will be considered optional unless explicitly marked as required using the `@ToolParam` annotation.\n\nBesides the `@ToolParam` annotation, you can also use the `@Schema` annotation from Swagger or `@JsonProperty` from Jackson. See xref:_json_schema[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Programmatic Specification: `MethodToolCallback`", "heading_level": 3, "file_order": 115, "section_index": 11, "content_hash": "3d681cd63ac3b1d2994fe7a85994deaf713f6cfbc8cf25836188d2d287a6d155", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:a627f682dabbf6ba24033c589846f9bd609fcfb868701e010035bc5f90c6e411", "content": "When using the programmatic specification approach, you can pass the `MethodToolCallback` instance to the `toolCallbacks()` method of `ChatClient`.\nThe tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nToolCallback toolCallback = ...\nChatClient.create(chatModel)\n .prompt(\"What day is tomorrow?\")\n .toolCallbacks(toolCallback)\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatClient` and `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 12, "content_hash": "a627f682dabbf6ba24033c589846f9bd609fcfb868701e010035bc5f90c6e411", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:5146ff90466ca880856694db43c7cb2182b323f729ac689944b72f60fb33053f", "content": "When using the programmatic specification approach, you can add default tools to a `ChatClient.Builder` by passing the `MethodToolCallback` instance to the `defaultToolCallbacks()` method.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by all the `ChatClient` instances built from the same `ChatClient.Builder`. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback toolCallback = ...\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultToolCallbacks(toolCallback)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 13, "content_hash": "5146ff90466ca880856694db43c7cb2182b323f729ac689944b72f60fb33053f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:0f3b7b3bd1ad32b99bb69cb4ffb074026d18bd99ddd06f797c6bad17385db8fb", "content": "When using the programmatic specification approach, you can pass the `MethodToolCallback` instance to the `toolCallbacks()` method of the `ToolCallingChatOptions` you use to call a `ChatModel`. The tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback toolCallback = ...\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(toolCallback)\n .build();\nPrompt prompt = new Prompt(\"What day is tomorrow?\", chatOptions);\nchatModel.call(prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 14, "content_hash": "0f3b7b3bd1ad32b99bb69cb4ffb074026d18bd99ddd06f797c6bad17385db8fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:b6b98e52d19a0f9286c004dc2a023ad540c39021b8774b4f7d64d0f4f9e5f9e3", "content": "When using the programmatic specification approach, you can add default tools to a `ChatModel` at construction time by passing the `MethodToolCallback` instance to the `toolCallbacks()` method of the `ToolCallingChatOptions` instance used to create the `ChatModel`.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by that `ChatModel` instance. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nToolCallback toolCallback = ...\nChatModel chatModel = OllamaChatModel.builder()\n .ollamaApi(OllamaApi.builder().build())\n .defaultOptions(ToolCallingChatOptions.builder()\n .toolCallbacks(toolCallback)\n .build())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 15, "content_hash": "b6b98e52d19a0f9286c004dc2a023ad540c39021b8774b4f7d64d0f4f9e5f9e3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:463522e00d6a7e8f9c1a472496b41dfc54ec3685d448b18dfc7c9bce294a6aed", "content": "The following types are not currently supported as parameters or return types for methods used as tools:\n\n- `Optional`\n- Asynchronous types (e.g. `CompletableFuture`, `Future`)\n- Reactive types (e.g. `Flow`, `Mono`, `Flux`)\n- Functional types (e.g. `Function`, `Supplier`, `Consumer`).\n\nFunctional types are supported using the function-based tool specification approach. See xref:_functions_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Method Tool Limitations", "heading_level": 3, "file_order": 115, "section_index": 16, "content_hash": "463522e00d6a7e8f9c1a472496b41dfc54ec3685d448b18dfc7c9bce294a6aed", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:f4a5b4bd87117a3cc6055f88464a862757078243faa6095d88341cffa6fca191", "content": "Spring AI provides built-in support for specifying tools from functions, either programmatically using the low-level `FunctionToolCallback` implementation or dynamically as `@Bean`(s) resolved at runtime.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Functions as Tools", "heading_level": 2, "file_order": 115, "section_index": 17, "content_hash": "f4a5b4bd87117a3cc6055f88464a862757078243faa6095d88341cffa6fca191", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:65e2e386ced73c5f6655b7c2bcea56a7868958b04e7e315766c191ed048d495e", "content": "You can turn a functional type (`Function`, `Supplier`, `Consumer`, or `BiFunction`) into a tool by building a `FunctionToolCallback` programmatically.\n\n[source,java]\n----\npublic class WeatherService implements Function<WeatherRequest, WeatherResponse> {\n public WeatherResponse apply(WeatherRequest request) {\n return new WeatherResponse(30.0, Unit.C);\n }\n}\n\npublic enum Unit { C, F }\npublic record WeatherRequest(String location, Unit unit) {}\npublic record WeatherResponse(double temp, Unit unit) {}\n----\n\nThe `FunctionToolCallback.Builder` allows you to build a `FunctionToolCallback` instance and provide key information about the tool:\n\n- `name`: The name of the tool. AI models use this name to identify the tool when calling it. Therefore, it's not allowed to have two tools with the same name in the same context. The name must be unique across all the tools available to the model for a specific chat request. Required.\n- `toolFunction`: The functional object that represents the tool method (`Function`, `Supplier`, `Consumer`, or `BiFunction`). Required.\n- `description`: The description for the tool, which can be used by the model to understand when and how to call the tool. If not provided, the method name will be used as the tool description. However, it's strongly recommended to provide a detailed description because that's paramount for the model to understand the tool's purpose and how to use it. Failing in providing a good description can lead to the model not using the tool when it should or using it incorrectly.\n- `inputType`: The type of the function input. Required.\n- `inputSchema`: The JSON schema for the input parameters of the tool. If not provided, the schema will be generated automatically based on the `inputType`. You can use the `@ToolParam` annotation to provide additional information about the input parameters, such as a description or whether the parameter is required or optional. By default, all input parameters are considered required. See xref:_json_schema[] for more details.\n- `toolMetadata`: The `ToolMetadata` instance that defines additional settings such as whether the result should be returned directly to the client, and the result converter to use. You can build it using the `ToolMetadata.Builder` class.\n- `toolCallResultConverter`: The `ToolCallResultConverter` instance to use for converting the result of a tool call to a `String` object to send back to the AI model. If not provided, the default converter will be used (`DefaultToolCallResultConverter`).\n\nThe `ToolMetadata.Builder` allows you to build a `ToolMetadata` instance and define additional settings for the tool:\n\n- `returnDirect`: Whether the tool result should be returned directly to the client or passed back to the model. See xref:_return_direct[] for more details.\n\n[source,java]\n----\nToolCallback toolCallback = FunctionToolCallback\n .builder(\"currentWeather\", new WeatherService())\n .description(\"Get the weather in location\")\n .inputType(WeatherRequest.class)\n .build();\n----\n\nThe function inputs and outputs can be either `Void` or POJOs. The input and output POJOs must be serializable, as the result will be serialized and sent back to the model. The function as well as the input and output types must be public.\n\nNOTE: Some types are not supported. See xref:_function_tool_limitations[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Programmatic Specification: `FunctionToolCallback`", "heading_level": 3, "file_order": 115, "section_index": 18, "content_hash": "65e2e386ced73c5f6655b7c2bcea56a7868958b04e7e315766c191ed048d495e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:fa0bd7132a988fc70e18f36c8fe2da5158275ef94e95b258f4a967743a0c351e", "content": "When using the programmatic specification approach, you can pass the `FunctionToolCallback` instance to the `toolCallbacks()` method of `ChatClient`. The tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nToolCallback toolCallback = ...\nChatClient.create(chatModel)\n .prompt(\"What's the weather like in Copenhagen?\")\n .toolCallbacks(toolCallback)\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 19, "content_hash": "fa0bd7132a988fc70e18f36c8fe2da5158275ef94e95b258f4a967743a0c351e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:a7b3c39b108312c37b2f930deca20cc743f630f31a03a863c66f79861a9fda8a", "content": "When using the programmatic specification approach, you can add default tools to a `ChatClient.Builder` by passing the `FunctionToolCallback` instance to the `defaultToolCallbacks()` method.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by all the `ChatClient` instances built from the same `ChatClient.Builder`. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback toolCallback = ...\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultToolCallbacks(toolCallback)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 20, "content_hash": "a7b3c39b108312c37b2f930deca20cc743f630f31a03a863c66f79861a9fda8a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:da564a8aa17af9b5e1f8e37f4ac7f15e9b751aa9535b9f40be13a7a2310f0491", "content": "When using the programmatic specification approach, you can pass the `FunctionToolCallback` instance to the `toolCallbacks()` method of `ToolCallingChatOptions`. The tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback toolCallback = ...\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(toolCallback)\n .build();\nPrompt prompt = new Prompt(\"What's the weather like in Copenhagen?\", chatOptions);\nchatModel.call(prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 21, "content_hash": "da564a8aa17af9b5e1f8e37f4ac7f15e9b751aa9535b9f40be13a7a2310f0491", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:ca604e16004af0da6df4ca17811da23615ed6547fe422f73f1e550022207eea2", "content": "When using the programmatic specification approach, you can add default tools to a `ChatModel` at construction time by passing the `FunctionToolCallback` instance to the `toolCallbacks()` method of the `ToolCallingChatOptions` instance used to create the `ChatModel`.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by that `ChatModel` instance. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nToolCallback toolCallback = ...\nChatModel chatModel = OllamaChatModel.builder()\n .ollamaApi(OllamaApi.builder().build())\n .defaultOptions(ToolCallingChatOptions.builder()\n .toolCallbacks(toolCallback)\n .build())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 22, "content_hash": "ca604e16004af0da6df4ca17811da23615ed6547fe422f73f1e550022207eea2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:045dd9a7808397f0b820228e867fb1c9c5360c6adfdfb588da5543af8a9e1278", "content": "Instead of specifying tools programmatically, you can define tools as Spring beans and let Spring AI resolve them dynamically at runtime using the `ToolCallbackResolver` interface (via the `SpringBeanToolCallbackResolver` implementation). This option gives you the possibility to use any `Function`, `Supplier`, `Consumer`, or `BiFunction` bean as a tool. The bean name will be used as the tool name, and the `@Description` annotation from Spring Framework can be used to provide a description for the tool, used by the model to understand when and how to call the tool. If you don't provide a description, the method name will be used as the tool description. However, it's strongly recommended to provide a detailed description because that's paramount for the model to understand the tool's purpose and how to use it. Failing in providing a good description can lead to the model not using the tool when it should or using it incorrectly.\n\n[source,java]\n----\n@Configuration(proxyBeanMethods = false)\nclass WeatherTools {\n\n WeatherService weatherService = new WeatherService();\n\n\t@Bean\n\t@Description(\"Get the weather in location\")\n\tFunction<WeatherRequest, WeatherResponse> currentWeather() {\n return weatherService;\n\t}\n\n}\n----\n\nNOTE: Some types are not supported. See xref:_function_tool_limitations[] for more details.\n\nThe JSON schema for the input parameters of the tool will be generated automatically. You can use the `@ToolParam` annotation to provide additional information about the input parameters, such as a description or whether the parameter is required or optional. By default, all input parameters are considered required. See xref:_json_schema[] for more details.\n\n[source,java]\n----\nrecord WeatherRequest(@ToolParam(description = \"The name of a city or a country\") String location, Unit unit) {}\n----\n\nThis tool specification approach has the drawback of not guaranteeing type safety, as the tool resolution is done at runtime. To mitigate this, you can specify the tool name explicitly using the `@Bean` annotation and storing the value in a constant, so that you can use it in a chat request instead of hard-coding the tool name.\n\n[source,java]\n----\n@Configuration(proxyBeanMethods = false)\nclass WeatherTools {\n\n public static final String CURRENT_WEATHER_TOOL = \"currentWeather\";\n\n\t@Bean(CURRENT_WEATHER_TOOL)\n\t@Description(\"Get the weather in location\")\n\tFunction<WeatherRequest, WeatherResponse> currentWeather() {\n ...\n\t}\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Dynamic Specification: `@Bean`", "heading_level": 3, "file_order": 115, "section_index": 23, "content_hash": "045dd9a7808397f0b820228e867fb1c9c5360c6adfdfb588da5543af8a9e1278", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:8a86dda5137617d3e103bcfec4a823b8767466eed74a44f173ac34ef3e2ab331", "content": "When using the dynamic specification approach, you can pass the tool name (i.e. the function bean name) to the `toolNames()` method of `ChatClient`.\nThe tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nChatClient.create(chatModel)\n .prompt(\"What's the weather like in Copenhagen?\")\n .toolNames(\"currentWeather\")\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 24, "content_hash": "8a86dda5137617d3e103bcfec4a823b8767466eed74a44f173ac34ef3e2ab331", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:9f8ce18072e0527f47d16020ba4e781fefca763b9abcdb91174cf71c62256bde", "content": "When using the dynamic specification approach, you can add default tools to a `ChatClient.Builder` by passing the tool name to the `defaultToolNames()` method.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by all the `ChatClient` instances built from the same `ChatClient.Builder`. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nChatModel chatModel = ...\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultToolNames(\"currentWeather\")\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatClient`", "heading_level": 4, "file_order": 115, "section_index": 25, "content_hash": "9f8ce18072e0527f47d16020ba4e781fefca763b9abcdb91174cf71c62256bde", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:b66e8b57c16a35a73c138f9e92d4cf104d2f9f0e68420179bfbf1d2f9541daf1", "content": "When using the dynamic specification approach, you can pass the tool name to the `toolNames()` method of the `ToolCallingChatOptions` you use to call the `ChatModel`. The tool will only be available for the specific chat request it's added to.\n\n[source,java]\n----\nChatModel chatModel = ...\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolNames(\"currentWeather\")\n .build();\nPrompt prompt = new Prompt(\"What's the weather like in Copenhagen?\", chatOptions);\nchatModel.call(prompt);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 26, "content_hash": "b66e8b57c16a35a73c138f9e92d4cf104d2f9f0e68420179bfbf1d2f9541daf1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:c1ee65f5564ccb1772a436c26b00457672cc962658588eeaa852284d2341fef3", "content": "When using the dynamic specification approach, you can add default tools to `ChatModel` at construction time by passing the tool name to the `toolNames()` method of the `ToolCallingChatOptions` instance used to create the `ChatModel`.\nIf both default and runtime tools are provided, the runtime tools will completely override the default tools.\n\nWARNING: Default tools are shared across all the chat requests performed by that `ChatModel` instance. They are useful for tools that are commonly used across different chat requests, but they can also be dangerous if not used carefully, risking to make them available when they shouldn't.\n\n[source,java]\n----\nChatModel chatModel = OllamaChatModel.builder()\n .ollamaApi(OllamaApi.builder().build())\n .defaultOptions(ToolCallingChatOptions.builder()\n .toolNames(\"currentWeather\")\n .build())\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Adding Default Tools to `ChatModel`", "heading_level": 4, "file_order": 115, "section_index": 27, "content_hash": "c1ee65f5564ccb1772a436c26b00457672cc962658588eeaa852284d2341fef3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:0db481a9693ffc8be6dc8acfb7871acc0664b27a3fa32bcdd76b97f465620123", "content": "The following types are not currently supported as input or output types for functions used as tools:\n\n- Primitive types\n- `Optional`\n- Collection types (e.g. `List`, `Map`, `Array`, `Set`)\n- Asynchronous types (e.g. `CompletableFuture`, `Future`)\n- Reactive types (e.g. `Flow`, `Mono`, `Flux`).\n\nPrimitive types and collections are supported using the method-based tool specification approach. See xref:_methods_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Function Tool Limitations", "heading_level": 3, "file_order": 115, "section_index": 28, "content_hash": "0db481a9693ffc8be6dc8acfb7871acc0664b27a3fa32bcdd76b97f465620123", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:0357aa95646c142b416acb2db3cda9c36b6ce4ddc7a41d5b8e39e58da18466c4", "content": "In Spring AI, tools are modeled via the `ToolCallback` interface. In the previous sections, we've seen how to define tools from methods and functions using the built-in support provided by Spring AI (see xref:_methods_as_tools[] and xref:_functions_as_tools[]). This section will dive deeper into the tool specification and how to customize and extend it to support more use cases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Specification", "heading_level": 2, "file_order": 115, "section_index": 29, "content_hash": "0357aa95646c142b416acb2db3cda9c36b6ce4ddc7a41d5b8e39e58da18466c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:3641ec744119b433e3a1375a181871a3bb87c3d2f057f311e540ffcf5a94f637", "content": "The `ToolCallback` interface provides a way to define a tool that can be called by the AI model, including both definition and execution logic. It's the main interface to implement when you want to define a tool from scratch. For example, you can define a `ToolCallback` from an MCP Client (using the Model Context Protocol) or a `ChatClient` (to build a modular agentic application).\n\nThe interface provides the following methods:\n\n[source,java]\n----\npublic interface ToolCallback {\n\n\t/**\n * Definition used by the AI model to determine when and how to call the tool.\n */\n\tToolDefinition getToolDefinition();\n\n\t/**\n * Metadata providing additional information on how to handle the tool.\n */\n\tToolMetadata getToolMetadata();\n\n /**\n * Execute tool with the given input and return the result to send back to the AI model.\n */\n\tString call(String toolInput);\n\n /**\n * Execute tool with the given input and context, and return the result to send back to the AI model.\n */\n\tString call(String toolInput, ToolContext tooContext);\n\n}\n----\n\nSpring AI provides built-in implementations for tool methods (`MethodToolCallback`) and tool functions (`FunctionToolCallback`).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Callback", "heading_level": 3, "file_order": 115, "section_index": 30, "content_hash": "3641ec744119b433e3a1375a181871a3bb87c3d2f057f311e540ffcf5a94f637", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:9835da2eef233eccde99512c5ba5808b226859fd16a03dfdece27f141744c4bd", "content": "The `ToolDefinition` interface provides the required information for the AI model to know about the availability of the tool, including the tool name, description, and input schema. Each `ToolCallback` implementation must provide a `ToolDefinition` instance to define the tool.\n\nThe interface provides the following methods:\n\n[source,java]\n----\npublic interface ToolDefinition {\n\n\t/**\n * The tool name. Unique within the tool set provided to a model.\n */\n\tString name();\n\n\t/**\n * The tool description, used by the AI model to determine what the tool does.\n */\n\tString description();\n\n\t/**\n * The schema of the parameters used to call the tool.\n */\n\tString inputSchema();\n\n}\n----\n\nNOTE: See xref:_json_schema[] for more details on the input schema.\n\nThe `ToolDefinition.Builder` lets you build a `ToolDefinition` instance using the default implementation (`DefaultToolDefinition`).\n\n[source,java]\n----\nToolDefinition toolDefinition = ToolDefinition.builder()\n .name(\"currentWeather\")\n .description(\"Get the weather in location\")\n .inputSchema(\"\"\"\n {\n \"type\": \"object\",\n \"properties\": {\n \"location\": {\n \"type\": \"string\"\n },\n \"unit\": {\n \"type\": \"string\",\n \"enum\": [\"C\", \"F\"]\n }\n },\n \"required\": [\"location\", \"unit\"]\n }\n \"\"\")\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Definition", "heading_level": 3, "file_order": 115, "section_index": 31, "content_hash": "9835da2eef233eccde99512c5ba5808b226859fd16a03dfdece27f141744c4bd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:8986536ceedd22b0daae8439b7ac2779e8a1e9919d50cd736c545b5be5a293c4", "content": "When building tools from a method, the `ToolDefinition` is automatically generated for you. In case you prefer to generate the `ToolDefinition` yourself, you can use this convenient builder.\n\n[source,java]\n----\nMethod method = ReflectionUtils.findMethod(DateTimeTools.class, \"getCurrentDateTime\");\nToolDefinition toolDefinition = ToolDefinitions.from(method);\n----\n\nThe `ToolDefinition` generated from a method includes the method name as the tool name, the method name as the tool description, and the JSON schema of the method input parameters. If the method is annotated with `@Tool`, the tool name and description will be taken from the annotation, if set.\n\nNOTE: See xref:_methods_as_tools[] for more details.\n\nIf you'd rather provide some or all of the attributes explicitly, you can use the `ToolDefinition.Builder` to build a custom `ToolDefinition` instance.\n\n[source,java]\n----\nMethod method = ReflectionUtils.findMethod(DateTimeTools.class, \"getCurrentDateTime\");\nToolDefinition toolDefinition = ToolDefinitions.builder(method)\n .name(\"currentDateTime\")\n .description(\"Get the current date and time in the user's timezone\")\n .inputSchema(JsonSchemaGenerator.generateForMethodInput(method))\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Method Tool Definition", "heading_level": 4, "file_order": 115, "section_index": 32, "content_hash": "8986536ceedd22b0daae8439b7ac2779e8a1e9919d50cd736c545b5be5a293c4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:54aff8140b56b23c02a054c15e5a2a40ced940df47f5a47486342ccb0939b29b", "content": "When building tools from a function, the `ToolDefinition` is automatically generated for you. When you use the `FunctionToolCallback.Builder` to build a `FunctionToolCallback` instance, you can provide the tool name, description, and input schema that will be used to generate the `ToolDefinition`. See xref:_functions_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Function Tool Definition", "heading_level": 4, "file_order": 115, "section_index": 33, "content_hash": "54aff8140b56b23c02a054c15e5a2a40ced940df47f5a47486342ccb0939b29b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:756803ba4ae8357713cea4ed0290a6a1c2c92243c196d48757b19d5454e8c87b", "content": "When providing a tool to the AI model, the model needs to know the schema of the input type for calling the tool. The schema is used to understand how to call the tool and prepare the tool request. Spring AI provides built-in support for generating the JSON Schema of the input type for a tool via the `JsonSchemaGenerator` class. The schema is provided as part of the `ToolDefinition`.\n\nNOTE: See xref:_tool_definition[] for more details on the `ToolDefinition` and how to pass the input schema to it.\n\nThe `JsonSchemaGenerator` class is used under the hood to generate the JSON schema for the input parameters of a method or a function, using any of the strategies described in xref:_methods_as_tools[] and xref:_functions_as_tools[]. The JSON schema generation logic supports a series of annotations that you can use on the input parameters for methods and functions to customize the resulting schema.\n\nThis section describes two main options you can customize when generating the JSON schema for the input parameters of a tool: description and required status.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "JSON Schema", "heading_level": 3, "file_order": 115, "section_index": 34, "content_hash": "756803ba4ae8357713cea4ed0290a6a1c2c92243c196d48757b19d5454e8c87b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:61c714fbae124ce57c5faccbe5f8e26d591670cc2f62aa9c52413700c104f3e5", "content": "Besides providing a description for the tool itself, you can also provide a description for the input parameters of a tool. The description can be used to provide key information about the input parameters, such as what format the parameter should be in, what values are allowed, and so on. This is useful to help the model understand the input schema and how to use it. Spring AI provides built-in support for generating the description for an input parameter using one of the following annotations:\n\n- `@ToolParam(description = \"...\")` from Spring AI\n- `@JsonClassDescription(description = \"...\")` from Jackson\n- `@JsonPropertyDescription(description = \"...\")` from Jackson\n- `@Schema(description = \"...\")` from Swagger.\n\nThis approach works for both methods and functions, and you can use it recursively for nested types.\n\n[source,java]\n----\nimport java.time.LocalDateTime;\nimport java.time.format.DateTimeFormatter;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.ai.tool.annotation.ToolParam;\nimport org.springframework.context.i18n.LocaleContextHolder;\n\nclass DateTimeTools {\n\n @Tool(description = \"Set a user alarm for the given time\")\n void setAlarm(@ToolParam(description = \"Time in ISO-8601 format\") String time) {\n LocalDateTime alarmTime = LocalDateTime.parse(time, DateTimeFormatter.ISO_DATE_TIME);\n System.out.println(\"Alarm set for \" + alarmTime);\n }\n\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Description", "heading_level": 4, "file_order": 115, "section_index": 35, "content_hash": "61c714fbae124ce57c5faccbe5f8e26d591670cc2f62aa9c52413700c104f3e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:88bbc5a5f7fa54927898f65f6860da0774cb92f9f49da23f6ae66e5515f0a144", "content": "By default, each input parameter is considered required, which forces the AI model to provide a value for it when calling the tool. However, you can make an input parameter optional by using one of the following annotations, in this order of precedence:\n\n- `@ToolParam(required = false)` from Spring AI\n- `@JsonProperty(required = false)` from Jackson\n- `@Schema(required = false)` from Swagger\n- `@Nullable` from Spring Framework.\n\nThis approach works for both methods and functions, and you can use it recursively for nested types.\n\n[source,java]\n----\nclass CustomerTools {\n\n @Tool(description = \"Update customer information\")\n void updateCustomerInfo(Long id, String name, @ToolParam(required = false) String email) {\n System.out.println(\"Updated info for customer with id: \" + id);\n }\n\n}\n----\n\nWARNING: Defining the correct required status for the input parameter is crucial to mitigate the risk of hallucinations and ensure the model provides the right input when calling the tool. In the previous example, the `email` parameter is optional, which means the model can call the tool without providing a value for it. If the parameter was required, the model would have to provide a value for it when calling the tool. And if no value existed, the model would probably make one up, leading to hallucinations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Required/Optional", "heading_level": 4, "file_order": 115, "section_index": 36, "content_hash": "88bbc5a5f7fa54927898f65f6860da0774cb92f9f49da23f6ae66e5515f0a144", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:fa6412e063441d6bd0adb142efaa95da46a963a5205c613f5959151b4892cb54", "content": "The result of a tool call is serialized using a `ToolCallResultConverter` and then sent back to the AI model. The `ToolCallResultConverter` interface provides a way to convert the result of a tool call to a `String` object.\n\nThe interface provides the following method:\n\n[source,java]\n----\n@FunctionalInterface\npublic interface ToolCallResultConverter {\n\n\t/**\n * Given an Object returned by a tool, convert it to a String compatible with the\n * given class type.\n */\n\tString convert(@Nullable Object result, @Nullable Type returnType);\n\n}\n----\n\nThe result must be a serializable type. By default, the result is serialized to JSON using Jackson (`DefaultToolCallResultConverter`), but you can customize the serialization process by providing your own `ToolCallResultConverter` implementation.\n\nSpring AI relies on the `ToolCallResultConverter` in both method and function tools.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Result Conversion", "heading_level": 3, "file_order": 115, "section_index": 37, "content_hash": "fa6412e063441d6bd0adb142efaa95da46a963a5205c613f5959151b4892cb54", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:40c5b9b093347df78e797cf5921cbe7371d92f58e351de607860461894f87a82", "content": "When building tools from a method with the declarative approach, you can provide a custom `ToolCallResultConverter` to use for the tool by setting the `resultConverter()` attribute of the `@Tool` annotation.\n\n[source,java]\n----\nclass CustomerTools {\n\n @Tool(description = \"Retrieve customer information\", resultConverter = CustomToolCallResultConverter.class)\n Customer getCustomerInfo(Long id) {\n return customerRepository.findById(id);\n }\n\n}\n----\n\nIf using the programmatic approach, you can provide a custom `ToolCallResultConverter` to use for the tool by setting the `resultConverter()` attribute of the `MethodToolCallback.Builder`.\n\nSee xref:_methods_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Method Tool Call Result Conversion", "heading_level": 4, "file_order": 115, "section_index": 38, "content_hash": "40c5b9b093347df78e797cf5921cbe7371d92f58e351de607860461894f87a82", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:be3230c97ccc249a4434ccf1facad01ee1be56b7a1d4081d21cfd91c5a728236", "content": "When building tools from a function using the programmatic approach, you can provide a custom `ToolCallResultConverter` to use for the tool by setting the `resultConverter()` attribute of the `FunctionToolCallback.Builder`.\n\nSee xref:_functions_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Function Tool Call Result Conversion", "heading_level": 4, "file_order": 115, "section_index": 39, "content_hash": "be3230c97ccc249a4434ccf1facad01ee1be56b7a1d4081d21cfd91c5a728236", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:7a787378d8009eed8d050dc24b67a22f80b9d37892591a7e7da3456c99425ff6", "content": "Spring AI supports passing additional contextual information to tools through the `ToolContext` API. This feature allows you to provide extra, user-provided data that can be used within the tool execution along with the tool arguments passed by the AI model.\n\nimage::tools/tool-context.jpg[Providing additional contextual info to tools, width=700, align=\"center\"]\n\n[source,java]\n----\nclass CustomerTools {\n\n @Tool(description = \"Retrieve customer information\")\n Customer getCustomerInfo(Long id, ToolContext toolContext) {\n return customerRepository.findById(id, toolContext.getContext().get(\"tenantId\"));\n }\n\n}\n----\n\nThe `ToolContext` is populated with the data provided by the user when invoking `ChatClient`.\n\n[source,java]\n----\nChatModel chatModel = ...\n\nString response = ChatClient.create(chatModel)\n .prompt(\"Tell me more about the customer with ID 42\")\n .tools(new CustomerTools())\n .toolContext(Map.of(\"tenantId\", \"acme\"))\n .call()\n .content();\n\nSystem.out.println(response);\n----\n\nNOTE: None of the data provided in the `ToolContext` is sent to the AI model.\n\nSimilarly, you can define tool context data when invoking the `ChatModel` directly.\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallback[] customerTools = ToolCallbacks.from(new CustomerTools());\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(customerTools)\n .toolContext(Map.of(\"tenantId\", \"acme\"))\n .build();\nPrompt prompt = new Prompt(\"Tell me more about the customer with ID 42\", chatOptions);\nchatModel.call(prompt);\n----\n\nIf the `toolContext` option is set both in the default options and in the runtime options, the resulting `ToolContext` will be the merge of the two,\nwhere the runtime options take precedence over the default options.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Context", "heading_level": 3, "file_order": 115, "section_index": 40, "content_hash": "7a787378d8009eed8d050dc24b67a22f80b9d37892591a7e7da3456c99425ff6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:5f719c7c1259b649cdfa87b21a8ae4d417bf8b63f68a59c5d3765052c8e0a05a", "content": "By default, the result of a tool call is sent back to the model as a response. Then, the model can use the result to continue the conversation.\n\nThere are cases where you'd rather return the result directly to the caller instead of sending it back to the model. For example, if you build an agent that relies on a RAG tool, you might want to return the result directly to the caller instead of sending it back to the model for unnecessary post-processing. Or perhaps you have certain tools that should end the reasoning loop of the agent.\n\nEach `ToolCallback` implementation can define whether the result of a tool call should be returned directly to the caller or sent back to the model. By default, the result is sent back to the model. But you can change this behavior per tool.\n\nThe `ToolCallingManager`, responsible for managing the tool execution lifecycle, is in charge of handling the `returnDirect` attribute associated with the tool. If the attribute is set to `true`, the result of the tool call is returned directly to the caller. Otherwise, the result is sent back to the model.\n\nNOTE: If multiple tool calls are requested at once, the `returnDirect` attribute must be set to `true` for all the tools to return the results directly to the caller. Otherwise, the results will be sent back to the model.\n\nimage::tools/return-direct.jpg[Returning tool call results directly to the caller, width=700, align=\"center\"]\n\n1. When we want to make a tool available to the model, we include its definition in the chat request. If we want the result of the tool execution to be returned directly to the caller, we set the `returnDirect` attribute to `true`.\n2. When the model decides to call a tool, it sends a response with the tool name and the input parameters modeled after the defined schema.\n3. The application is responsible for using the tool name to identify and execute the tool with the provided input parameters.\n4. The result of the tool call is processed by the application.\n5. The application sends the tool call result directly to the caller, instead of sending it back to the model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Return Direct", "heading_level": 3, "file_order": 115, "section_index": 41, "content_hash": "5f719c7c1259b649cdfa87b21a8ae4d417bf8b63f68a59c5d3765052c8e0a05a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:9e139dd7a67b528b4b4937b546742d1b2439011e975aa863ac2724fc7b6664c0", "content": "When building tools from a method with the declarative approach, you can mark a tool to return the result directly to the caller by setting the `returnDirect` attribute of the `@Tool` annotation to `true`.\n\n[source,java]\n----\nclass CustomerTools {\n\n @Tool(description = \"Retrieve customer information\", returnDirect = true)\n Customer getCustomerInfo(Long id) {\n return customerRepository.findById(id);\n }\n\n}\n----\n\nIf using the programmatic approach, you can set the `returnDirect` attribute via the `ToolMetadata` interface and pass it to the `MethodToolCallback.Builder`.\n\n[source,java]\n----\nToolMetadata toolMetadata = ToolMetadata.builder()\n .returnDirect(true)\n .build();\n----\n\nSee xref:_methods_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Method Return Direct", "heading_level": 4, "file_order": 115, "section_index": 42, "content_hash": "9e139dd7a67b528b4b4937b546742d1b2439011e975aa863ac2724fc7b6664c0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:01b056c37116dcde99af6132dca18dcffe0afdbc78b25775841f22eb1b7f3349", "content": "When building tools from a function with the programmatic approach, you can set the `returnDirect` attribute via the `ToolMetadata` interface and pass it to the `FunctionToolCallback.Builder`.\n\n[source,java]\n----\nToolMetadata toolMetadata = ToolMetadata.builder()\n .returnDirect(true)\n .build();\n----\n\nSee xref:_functions_as_tools[] for more details.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Function Return Direct", "heading_level": 4, "file_order": 115, "section_index": 43, "content_hash": "01b056c37116dcde99af6132dca18dcffe0afdbc78b25775841f22eb1b7f3349", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:4c2d19ea7d5c2d64d5bbac697c816ae1d589b04585e2d6296a77e65eee272f54", "content": "The tool execution is the process of calling the tool with the provided input arguments and returning the result. The tool execution is handled by the `ToolCallingManager` interface, which is responsible for managing the tool execution lifecycle.\n\n[source,java]\n----\npublic interface ToolCallingManager {\n\n\t/**\n * Resolve the tool definitions from the model's tool calling options.\n */\n\tList<ToolDefinition> resolveToolDefinitions(ToolCallingChatOptions chatOptions);\n\n\t/**\n * Execute the tool calls requested by the model.\n */\n\tToolExecutionResult executeToolCalls(Prompt prompt, ChatResponse chatResponse);\n\n}\n----\n\nIf you're using any of the Spring AI Spring Boot Starters, `DefaultToolCallingManager` is the autoconfigured implementation of the `ToolCallingManager` interface. You can customize the tool execution behavior by providing your own `ToolCallingManager` bean.\n\n[source,java]\n----\n@Bean\nToolCallingManager toolCallingManager() {\n return ToolCallingManager.builder().build();\n}\n----\n\nBy default, Spring AI manages the tool execution lifecycle transparently for you from within each `ChatModel` implementation. But you have the possibility to opt-out of this behavior and control the tool execution yourself. This section describes these two scenarios.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Execution", "heading_level": 2, "file_order": 115, "section_index": 44, "content_hash": "4c2d19ea7d5c2d64d5bbac697c816ae1d589b04585e2d6296a77e65eee272f54", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:e07cee454d867fd91924bbcf89ec605b489fb842633951b8ebb71ce1a03b2a0b", "content": "When using the default behavior, Spring AI will automatically intercept any tool call request from the model, call the tool and return the result to the model. All of this is done transparently for you by each `ChatModel` implementation using a `ToolCallingManager`.\n\nimage::tools/framework-manager.jpg[Framework-controlled tool execution lifecycle, width=700, align=\"center\"]\n\n1. When we want to make a tool available to the model, we include its definition in the chat request (`Prompt`) and invoke the `ChatModel` API which sends the request to the AI model.\n2. When the model decides to call a tool, it sends a response (`ChatResponse`) with the tool name and the input parameters modeled after the defined schema.\n3. The `ChatModel` sends the tool call request to the `ToolCallingManager` API.\n4. The `ToolCallingManager` is responsible for identifying the tool to call and executing it with the provided input parameters.\n5. The result of the tool call is returned to the `ToolCallingManager`.\n6. The `ToolCallingManager` returns the tool execution result back to the `ChatModel`.\n7. The `ChatModel` sends the tool execution result back to the AI model (`ToolResponseMessage`).\n8. The AI model generates the final response using the tool call result as additional context and sends it back to the caller (`ChatResponse`) via the `ChatClient`.\n\nWARNING: Currently, the internal messages exchanged with the model regarding the tool execution are not exposed to the user. If you need to access these messages, you should use the user-controlled tool execution approach.\n\nThe logic determining whether a tool call is eligible for execution is handled by the `ToolExecutionEligibilityPredicate` interface. By default, the tool execution eligibility is determined by checking if the `internalToolExecutionEnabled` attribute of `ToolCallingChatOptions` is set to `true` (the default value), and if the `ChatResponse` contains any tool calls.\n\n[source,java]\n----\npublic class DefaultToolExecutionEligibilityPredicate implements ToolExecutionEligibilityPredicate {\n\n\t@Override\n\tpublic boolean test(ChatOptions promptOptions, ChatResponse chatResponse) {\n return ToolCallingChatOptions.isInternalToolExecutionEnabled(promptOptions) && chatResponse != null\n && chatResponse.hasToolCalls();\n\t}\n\n}\n----\n\nYou can provide your custom implementation of `ToolExecutionEligibilityPredicate` when creating the `ChatModel` bean.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Framework-Controlled Tool Execution", "heading_level": 3, "file_order": 115, "section_index": 45, "content_hash": "e07cee454d867fd91924bbcf89ec605b489fb842633951b8ebb71ce1a03b2a0b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:d4cb86bfd5090d2022c2efe5c07ba9a89292b51a893a38e8ff7a8d48c92da06d", "content": "As an alternative to the framework-controlled tool execution, you can use the `ToolCallAdvisor` to implement tool calling as part of the xref:api/chatclient.adoc#_advisors[advisor chain]. This approach provides several advantages:\n\n* **Observability**: Other advisors in the chain can intercept and observe each tool call iteration\n* **Integration with Chat Memory**: Works seamlessly with Chat Memory advisors for conversation history management\n* **Extensibility**: The advisor can be extended to customize the tool calling behavior\n\nThe `ToolCallAdvisor` implements the tool calling loop and disables the model's internal tool execution. When the model requests a tool call, the advisor executes the tool and sends the result back to the model, continuing until no more tool calls are needed.\n\n[source,java]\n----\nvar toolCallAdvisor = ToolCallAdvisor.builder()\n .toolCallingManager(toolCallingManager)\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 300)\n .build();\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(toolCallAdvisor)\n .build();\n\nString response = chatClient.prompt(\"What day is tomorrow?\")\n .tools(new DateTimeTools())\n .call()\n .content();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Advisor-Controlled Tool Execution with ToolCallAdvisor", "heading_level": 3, "file_order": 115, "section_index": 46, "content_hash": "d4cb86bfd5090d2022c2efe5c07ba9a89292b51a893a38e8ff7a8d48c92da06d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:017ae81630097d570e5abfa581225cc889de55c248d77aabdeb0f65a93e8c77a", "content": "The `ToolCallAdvisor.Builder` supports the following configuration options:\n\n- `toolCallingManager`: The `ToolCallingManager` instance to use for executing tool calls. If not provided, a default instance is used.\n- `advisorOrder`: The order in which the advisor is applied in the chain. Must be between `BaseAdvisor.HIGHEST_PRECEDENCE` and `BaseAdvisor.LOWEST_PRECEDENCE`.\n- `conversationHistoryEnabled`: Controls whether the advisor maintains conversation history internally during tool call iterations. Default is `true`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Configuration Options", "heading_level": 4, "file_order": 115, "section_index": 47, "content_hash": "017ae81630097d570e5abfa581225cc889de55c248d77aabdeb0f65a93e8c77a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:ac5a247aa1fc20eb91dfb7c1580014c0be3ebbc001fd84b5b29bb0f137035a25", "content": "By default (`conversationHistoryEnabled=true`), the `ToolCallAdvisor` maintains the full conversation history internally during tool call iterations. Each subsequent LLM call includes all previous messages.\n\nUse the `.disableMemory()` method to disable internal conversation history management. When disabled, only the last tool response message is passed to the next iteration. This is useful when integrating with a Chat Memory advisor that already manages conversation history:\n\n[source,java]\n----\nvar toolCallAdvisor = ToolCallAdvisor.builder()\n .toolCallingManager(toolCallingManager)\n .disableMemory() // Let ChatMemory handle history\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 300)\n .build();\n\nvar chatMemoryAdvisor = MessageChatMemoryAdvisor.builder(chatMemory)\n .advisorOrder(BaseAdvisor.HIGHEST_PRECEDENCE + 200) // Before ToolCallAdvisor\n .build();\n\nvar chatClient = ChatClient.builder(chatModel)\n .defaultAdvisors(chatMemoryAdvisor, toolCallAdvisor)\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Conversation History Management", "heading_level": 4, "file_order": 115, "section_index": 48, "content_hash": "ac5a247aa1fc20eb91dfb7c1580014c0be3ebbc001fd84b5b29bb0f137035a25", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:aa07230e16c56326c7aca4ff35c069e511d74cc4e05dd9bd6c2e6340aee21d6a", "content": "The `ToolCallAdvisor` supports the \"return direct\" feature, allowing tools to bypass the LLM and return results directly to the client. When a tool execution has `returnDirect=true`, the advisor breaks out of the tool calling loop and returns the tool result directly.\n\nFor more details about `ToolCallAdvisor`, see xref:api/advisors-recursive.adoc#_toolcalladvisor[Recursive Advisors - ToolCallAdvisor].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Return Direct", "heading_level": 4, "file_order": 115, "section_index": 49, "content_hash": "aa07230e16c56326c7aca4ff35c069e511d74cc4e05dd9bd6c2e6340aee21d6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:8cbc1d106d68d768aa31b147ba1cf6510fec7da841a4c1d2b689e8a0d8db527b", "content": "There are cases where you'd rather control the tool execution lifecycle yourself. You can do so by setting the `internalToolExecutionEnabled` attribute of `ToolCallingChatOptions` to `false`.\n\nWhen you invoke a `ChatModel` with this option, the tool execution will be delegated to the caller, giving you full control over the tool execution lifecycle. It's your responsibility checking for tool calls in the `ChatResponse` and executing them using the `ToolCallingManager`.\n\nThe following example demonstrates a minimal implementation of the user-controlled tool execution approach:\n\n[source,java]\n----\nChatModel chatModel = ...\nToolCallingManager toolCallingManager = ToolCallingManager.builder().build();\n\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(new CustomerTools())\n .internalToolExecutionEnabled(false)\n .build();\nPrompt prompt = new Prompt(\"Tell me more about the customer with ID 42\", chatOptions);\n\nChatResponse chatResponse = chatModel.call(prompt);\n\nwhile (chatResponse.hasToolCalls()) {\n ToolExecutionResult toolExecutionResult = toolCallingManager.executeToolCalls(prompt, chatResponse);\n\n prompt = new Prompt(toolExecutionResult.conversationHistory(), chatOptions);\n\n chatResponse = chatModel.call(prompt);\n}\n\nSystem.out.println(chatResponse.getResult().getOutput().getText());\n----\n\nNOTE: When choosing the user-controlled tool execution approach, we recommend using a `ToolCallingManager` to manage the tool calling operations. This way, you can benefit from the built-in support provided by Spring AI for tool execution. However, nothing prevents you from implementing your own tool execution logic.\n\nThe next examples shows a minimal implementation of the user-controlled tool execution approach combined with the usage of the `ChatMemory` API:\n\n[source,java]\n----\nToolCallingManager toolCallingManager = DefaultToolCallingManager.builder().build();\nChatMemory chatMemory = MessageWindowChatMemory.builder().build();\nString conversationId = UUID.randomUUID().toString();\n\nChatOptions chatOptions = ToolCallingChatOptions.builder()\n .toolCallbacks(ToolCallbacks.from(new MathTools()))\n .internalToolExecutionEnabled(false)\n .build();\nPrompt prompt = new Prompt(\n List.of(new SystemMessage(\"You are a helpful assistant.\"), new UserMessage(\"What is 6 * 8?\")),\n chatOptions);\nchatMemory.add(conversationId, prompt.getInstructions());\n\nPrompt promptWithMemory = new Prompt(chatMemory.get(conversationId), chatOptions);\nChatResponse chatResponse = chatModel.call(promptWithMemory);\nchatMemory.add(conversationId, chatResponse.getResult().getOutput());\n\nwhile (chatResponse.hasToolCalls()) {\n ToolExecutionResult toolExecutionResult = toolCallingManager.executeToolCalls(promptWithMemory,\n chatResponse);\n chatMemory.add(conversationId, toolExecutionResult.conversationHistory()\n .get(toolExecutionResult.conversationHistory().size() - 1));\n promptWithMemory = new Prompt(chatMemory.get(conversationId), chatOptions);\n chatResponse = chatModel.call(promptWithMemory);\n chatMemory.add(conversationId, chatResponse.getResult().getOutput());\n}\n\nUserMessage newUserMessage = new UserMessage(\"What did I ask you earlier?\");\nchatMemory.add(conversationId, newUserMessage);\n\nChatResponse newResponse = chatModel.call(new Prompt(chatMemory.get(conversationId)));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "User-Controlled Tool Execution", "heading_level": 3, "file_order": 115, "section_index": 50, "content_hash": "8cbc1d106d68d768aa31b147ba1cf6510fec7da841a4c1d2b689e8a0d8db527b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:8c694e62ba962cb15b54d9414935249907ac23c670048c20e593559c8867a0fa", "content": "When a tool call fails, the exception is propagated as a `ToolExecutionException` which can be caught to handle the error.\nA `ToolExecutionExceptionProcessor` can be used to handle a `ToolExecutionException` with two outcomes: either producing an error message to be sent back to the AI model or throwing an exception to be handled by the caller.\n\n[source,java]\n----\n@FunctionalInterface\npublic interface ToolExecutionExceptionProcessor {\n\n\t/**\n * Convert an exception thrown by a tool to a String that can be sent back to the AI\n * model or throw an exception to be handled by the caller.\n */\n\tString process(ToolExecutionException exception);\n\n}\n----\n\nIf you're using any of the Spring AI Spring Boot Starters, `DefaultToolExecutionExceptionProcessor` is the autoconfigured implementation of the `ToolExecutionExceptionProcessor` interface. By default, the error message of `RuntimeException` is sent back to the model, while checked exceptions and Errors (e.g., `IOException`, `OutOfMemoryError`) are always thrown. The `DefaultToolExecutionExceptionProcessor` constructor lets you set the `alwaysThrow` attribute to `true` or `false`. If `true`, an exception will be thrown instead of sending an error message back to the model.\n\nYou can use the ``spring.ai.tools.throw-exception-on-error` property to control the behavior of the `DefaultToolExecutionExceptionProcessor` bean:\n\n[cols=\"6,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| `spring.ai.tools.throw-exception-on-error` | If `true`, tool calling errors are thrown as exceptions for the caller to handle. If `false`, errors are converted to messages and sent back to the AI model, allowing it to process and respond to the error.| `false`\n|====\n\n[source,java]\n----\n@Bean\nToolExecutionExceptionProcessor toolExecutionExceptionProcessor() {\n return new DefaultToolExecutionExceptionProcessor(true);\n}\n----\n\nNOTE: If you defined your own `ToolCallback` implementation, make sure to throw a `ToolExecutionException` when an error occurs as part of the tool execution logic in the `call()` method.\n\nThe `ToolExecutionExceptionProcessor` is used internally by the default `ToolCallingManager` (`DefaultToolCallingManager`) to handle exceptions during tool execution. See xref:_tool_execution[] for more details about the tool execution lifecycle.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Exception Handling", "heading_level": 3, "file_order": 115, "section_index": 51, "content_hash": "8c694e62ba962cb15b54d9414935249907ac23c670048c20e593559c8867a0fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:c9fda1c9da255024e85b64b97eec30de3b756e4a6af1e024f25a9441069e4720", "content": "The main approach for passing tools to a model is by providing the `ToolCallback`(s) when invoking the `ChatClient` or the `ChatModel`,\nusing one of the strategies described in xref:_methods_as_tools[] and xref:_functions_as_tools[].\n\nHowever, Spring AI also supports resolving tools dynamically at runtime using the `ToolCallbackResolver` interface.\n\n[source,java]\n----\npublic interface ToolCallbackResolver {\n\n\t/**\n * Resolve the {@link ToolCallback} for the given tool name.\n */\n\t@Nullable\n\tToolCallback resolve(String toolName);\n\n}\n----\n\nWhen using this approach:\n\n- On the client-side, you provide the tool names to the `ChatClient` or the `ChatModel` instead of the `ToolCallback`(s).\n- On the server-side, a `ToolCallbackResolver` implementation is responsible for resolving the tool names to the corresponding `ToolCallback` instances.\n\nBy default, Spring AI relies on a `DelegatingToolCallbackResolver` that delegates the tool resolution to a list of `ToolCallbackResolver` instances:\n\n- The `SpringBeanToolCallbackResolver` resolves tools from Spring beans of type `Function`, `Supplier`, `Consumer`, or `BiFunction`. See xref:_dynamic_specification_bean[] for more details.\n- The `StaticToolCallbackResolver` resolves tools from a static list of `ToolCallback` instances. When using the Spring Boot Autoconfiguration, this resolver is automatically configured with all the beans of type `ToolCallback` defined in the application context.\n\nIf you rely on the Spring Boot Autoconfiguration, you can customize the resolution logic by providing a custom `ToolCallbackResolver` bean.\n\n[source,java]\n----\n@Bean\nToolCallbackResolver toolCallbackResolver(List<FunctionCallback> toolCallbacks) {\n StaticToolCallbackResolver staticToolCallbackResolver = new StaticToolCallbackResolver(toolCallbacks);\n return new DelegatingToolCallbackResolver(List.of(staticToolCallbackResolver));\n}\n----\n\nThe `ToolCallbackResolver` is used internally by the `ToolCallingManager` to resolve tools dynamically at runtime, supporting both xref:_framework_controlled_tool_execution[] and xref:_user_controlled_tool_execution[].\n\n[[tool-argument-augmentation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Resolution", "heading_level": 2, "file_order": 115, "section_index": 52, "content_hash": "c9fda1c9da255024e85b64b97eec30de3b756e4a6af1e024f25a9441069e4720", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:42a959f483efb5906b2f9881e8f8a66e11a4df325b1323aeaf840cc779b66fcd", "content": "Spring AI provides a utility for **dynamic augmentation of tool input schemas** with additional arguments. This allows capturing extra information from the model—such as reasoning or metadata—without modifying the underlying tool implementation.\n\nCommon use cases include:\n\n* **Inner Thinking/Reasoning**: Capture the model's step-by-step reasoning before executing a tool\n* **Memory Enhancement**: Extract insights to store in long-term memory\n* **Analytics & Tracking**: Collect metadata, user intent, or usage patterns\n* **Multi-Agent Coordination**: Pass agent identifiers or coordination signals", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Tool Argument Augmentation", "heading_level": 2, "file_order": 115, "section_index": 53, "content_hash": "42a959f483efb5906b2f9881e8f8a66e11a4df325b1323aeaf840cc779b66fcd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:c97baa4541cc6d862793d5a9586f8e922b54dcb9a30b1fafabdc58ad2a65bff5", "content": "**Define augmented arguments** as a Java Record:\n\n[source,java]\n----\npublic record AgentThinking(\n @ToolParam(description = \"Your reasoning for calling this tool\", required = true)\n String innerThought,\n\n @ToolParam(description = \"Confidence level (low, medium, high)\", required = false)\n String confidence\n) {}\n----\n\n**Wrap your tool** with `AugmentedToolCallbackProvider`:\n\n[source,java]\n----\nAugmentedToolCallbackProvider<AgentThinking> provider = AugmentedToolCallbackProvider\n .<AgentThinking>builder()\n .toolObject(new MyTools()) // Your @Tool annotated class\n .argumentType(AgentThinking.class)\n .argumentConsumer(event -> {\n AgentThinking thinking = event.arguments();\n log.info(\"Tool: {} | Reasoning: {}\", event.toolDefinition().name(), thinking.innerThought());\n })\n .removeExtraArgumentsAfterProcessing(true)\n .build();\n----\n\n**Use with ChatClient**:\n\n[source,java]\n----\nChatClient chatClient = ChatClient.builder(chatModel)\n .defaultToolCallbacks(provider)\n .build();\n----\n\nThe LLM sees the augmented schema with your additional fields. Your consumer receives the `AgentThinking` record, while the original tool receives only its expected arguments.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Quick Start", "heading_level": 3, "file_order": 115, "section_index": 54, "content_hash": "c97baa4541cc6d862793d5a9586f8e922b54dcb9a30b1fafabdc58ad2a65bff5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:aad8ac425c88f7029669e7b42d193741337e4eb85cd45baa34b1ce1eb8167dd8", "content": "* `AugmentedToolCallbackProvider<T>` - Wraps tool objects or providers, augmenting all tools with the specified Record type\n* `AugmentedToolCallback<T>` - Wraps individual `ToolCallback` instances\n* `AugmentedArgumentEvent<T>` - Contains `toolDefinition()`, `rawInput()`, and `arguments()` for consumers\n* `ToolInputSchemaAugmenter` - Low-level utility for schema manipulation", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Core Components", "heading_level": 3, "file_order": 115, "section_index": 55, "content_hash": "aad8ac425c88f7029669e7b42d193741337e4eb85cd45baa34b1ce1eb8167dd8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:58b083d28f6e55f5e7706f846b924d25227550924be960aae37b29975301d44b", "content": "The `removeExtraArgumentsAfterProcessing` option controls whether augmented arguments are passed to the original tool:\n\n* `true` (default) - Remove augmented arguments before calling the tool\n* `false` - Preserve augmented arguments in the input (if the tool can ignore extra fields)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Configuration", "heading_level": 3, "file_order": 115, "section_index": 56, "content_hash": "58b083d28f6e55f5e7706f846b924d25227550924be960aae37b29975301d44b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:da6699c4fc54c5ef0694dd4c3a6c4469d3635d87dfc5af0f87019498da173ed8", "content": "Tool calling includes observability support with spring.ai.tool observations that measure completion time and propagate tracing information. See xref:observability/index.adoc#_tool_calling[Tool Calling Observability].\n\nOptionally, Spring AI can export tool call arguments and results as span attributes, disabled by default for sensitivity reasons. Details: xref:observability/index.adoc#_tool_call_arguments_and_result_data[Tool Call Arguments and Result Data].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Observability", "heading_level": 2, "file_order": 115, "section_index": 57, "content_hash": "da6699c4fc54c5ef0694dd4c3a6c4469d3635d87dfc5af0f87019498da173ed8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:3a1eb067ae1fe97d7dac7d4045d27bcf8460572dcccea051773eb11c55d0f99d", "content": "All the main operations of the tool calling features are logged at the `DEBUG` level. You can enable the logging by setting the log level to `DEBUG` for the `org.springframework.ai` package.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/tools.adoc", "title": "tools", "heading": "Logging", "heading_level": 3, "file_order": 115, "section_index": 58, "content_hash": "3a1eb067ae1fe97d7dac7d4045d27bcf8460572dcccea051773eb11c55d0f99d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/tools.adoc"}}
{"id": "sha256:c324ee6b8dbdde4d2fd3e80c36aa056c80d1d3b902759e91f66f9704d85c1b6b", "content": "[[Transcription]]\n\nSpring AI provides support for OpenAI's Transcription Model API.\nWhen additional providers for Transcription are implemented, a common `AudioTranscriptionModel` interface will be extracted.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/transcriptions.adoc", "title": "transcriptions", "heading": "transcriptions", "heading_level": 1, "file_order": 116, "section_index": 0, "content_hash": "c324ee6b8dbdde4d2fd3e80c36aa056c80d1d3b902759e91f66f9704d85c1b6b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/transcriptions.adoc"}}
{"id": "sha256:956221c74aa71a19ac418a4fcc7f226ffbf3310414405f70ad3325fd20b1d502", "content": "Spring AI has enhanced its Model Usage handling by introducing `getNativeUsage()` method in the Usage interface and providing a `DefaultUsage` implementation.\nThis change simplifies how different AI models can track and report their usage metrics while maintaining consistency across the framework.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Overview", "heading_level": 2, "file_order": 117, "section_index": 0, "content_hash": "956221c74aa71a19ac418a4fcc7f226ffbf3310414405f70ad3325fd20b1d502", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:94df95107b0c3717d4923ed657487ca41b0b0afc7cd4113cd9f4d154bb1eb008", "content": "The `Usage` interface now includes a new method:\n```java\nObject getNativeUsage();\n```\nThis method allows access to the model-specific native usage data, enabling more detailed usage tracking when needed.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Usage Interface Enhancement", "heading_level": 3, "file_order": 117, "section_index": 1, "content_hash": "94df95107b0c3717d4923ed657487ca41b0b0afc7cd4113cd9f4d154bb1eb008", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:edf86a31b503ab82753bae0464292526e55a707dc0a0dea03f6b1aaf7660806f", "content": "Here's a complete example showing how to track usage with OpenAI's ChatModel:\n\n```java\n@SpringBootConfiguration\npublic class Configuration {\n\n @Bean\n public OpenAiApi chatCompletionApi() {\n return OpenAiApi.builder()\n .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n .build();\n }\n\n @Bean\n public OpenAiChatModel openAiClient(OpenAiApi openAiApi) {\n return OpenAiChatModel.builder()\n .openAiApi(openAiApi)\n .build();\n }\n\n }\n\n@Service\npublic class ChatService {\n\n private final OpenAiChatModel chatModel;\n\n public ChatService(OpenAiChatModel chatModel) {\n this.chatModel = chatModel;\n }\n\n public void demonstrateUsage() {\n // Create a chat prompt\n Prompt prompt = new Prompt(\"What is the weather like today?\");\n\n // Get the chat response\n ChatResponse response = this.chatModel.call(prompt);\n\n // Access the usage information\n Usage usage = response.getMetadata().getUsage();\n\n // Get standard usage metrics\n System.out.println(\"Prompt Tokens: \" + usage.getPromptTokens());\n System.out.println(\"Completion Tokens: \" + usage.getCompletionTokens());\n System.out.println(\"Total Tokens: \" + usage.getTotalTokens());\n\n // Access native OpenAI usage data with detailed token information\n if (usage.getNativeUsage() instanceof org.springframework.ai.openai.api.OpenAiApi.Usage) {\n org.springframework.ai.openai.api.OpenAiApi.Usage nativeUsage =\n (org.springframework.ai.openai.api.OpenAiApi.Usage) usage.getNativeUsage();\n\n // Detailed prompt token information\n System.out.println(\"Prompt Tokens Details:\");\n System.out.println(\"- Audio Tokens: \" + nativeUsage.promptTokensDetails().audioTokens());\n System.out.println(\"- Cached Tokens: \" + nativeUsage.promptTokensDetails().cachedTokens());\n\n // Detailed completion token information\n System.out.println(\"Completion Tokens Details:\");\n System.out.println(\"- Reasoning Tokens: \" + nativeUsage.completionTokenDetails().reasoningTokens());\n System.out.println(\"- Accepted Prediction Tokens: \" + nativeUsage.completionTokenDetails().acceptedPredictionTokens());\n System.out.println(\"- Audio Tokens: \" + nativeUsage.completionTokenDetails().audioTokens());\n System.out.println(\"- Rejected Prediction Tokens: \" + nativeUsage.completionTokenDetails().rejectedPredictionTokens());\n }\n }\n}\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Using with ChatModel", "heading_level": 3, "file_order": 117, "section_index": 2, "content_hash": "edf86a31b503ab82753bae0464292526e55a707dc0a0dea03f6b1aaf7660806f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:835f76a15f35924991307c99205e4c278dc1c7c12769d94819049e1add3f111c", "content": "If you are using the `ChatClient`, you can access the usage information using the `ChatResponse` object:\n\n```java\nPrompt prompt = new Prompt(\"What is the weather like today?\");\n\nChatClient chatClient = ChatClient.create(chatModel);\n\nChatResponse response = chatClient.prompt(prompt)\n .call()\n .chatResponse();\n\nUsage usage = response.getMetadata().getUsage();\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Using with ChatClient", "heading_level": 3, "file_order": 117, "section_index": 3, "content_hash": "835f76a15f35924991307c99205e4c278dc1c7c12769d94819049e1add3f111c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:b1fb6c96cdb52b0bc7ea178fe1b05ac461ef5884145fb9756c3dfc1776450927", "content": "**Standardization**: Provides a consistent way to handle usage across different AI models\n**Flexibility**: Supports model-specific usage data through the native usage feature\n**Simplification**: Reduces boilerplate code with the default implementation\n**Extensibility**: Easy to extend for specific model requirements while maintaining compatibility", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Benefits", "heading_level": 2, "file_order": 117, "section_index": 4, "content_hash": "b1fb6c96cdb52b0bc7ea178fe1b05ac461ef5884145fb9756c3dfc1776450927", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:f1b4d04aa61567f25d9970fb608ed4142ccfaf91853ff6f3511cafea915bd7c3", "content": "When working with native usage data, consider type casting carefully:\n```java\nif (usage.getNativeUsage() instanceof org.springframework.ai.openai.api.OpenAiApi.Usage) {\n org.springframework.ai.openai.api.OpenAiApi.Usage nativeUsage =\n (org.springframework.ai.openai.api.OpenAiApi.Usage) usage.getNativeUsage();\n // Work with native usage data\n}\n```", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/usage-handling.adoc", "title": "Using Chat/Embedding Response Usage", "heading": "Type Safety Considerations", "heading_level": 3, "file_order": 117, "section_index": 5, "content_hash": "f1b4d04aa61567f25d9970fb608ed4142ccfaf91853ff6f3511cafea915bd7c3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/usage-handling.adoc"}}
{"id": "sha256:79c2e4c914489ee5333cae8740bd60fee31f77e38597672e5440f97f8e33681a", "content": "[[vector-databases]]\n\nA vector database is a specialized type of database that plays an essential role in AI applications.\n\nIn vector databases, queries differ from traditional relational databases.\nInstead of exact matches, they perform similarity searches.\nWhen given a vector as a query, a vector database returns vectors that are \"`similar`\" to the query vector.\nFurther details on how this similarity is calculated at a high-level is provided in a xref:api/vectordbs/understand-vectordbs.adoc#vectordbs-similarity[Vector Similarity].\n\nVector databases are used to integrate your data with AI models.\nThe first step in their usage is to load your data into a vector database.\nThen, when a user query is to be sent to the AI model, a set of similar documents is first retrieved.\nThese documents then serve as the context for the user's question and are sent to the AI model, along with the user's query.\nThis technique is known as xref:concepts.adoc#concept-rag[Retrieval Augmented Generation (RAG)].\n\nThe following sections describe the Spring AI interface for using multiple vector database implementations and some high-level sample usage.\n\nThe last section is intended to demystify the underlying approach of similarity searching in vector databases.\n\n[[api-overview]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "vectordbs", "heading_level": 1, "file_order": 118, "section_index": 0, "content_hash": "79c2e4c914489ee5333cae8740bd60fee31f77e38597672e5440f97f8e33681a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:7143bfd87fc2dde4b2e47e7b52b3ef04f6cfc52bc5bfc9df3821aecddf403794", "content": "This section serves as a guide to the `VectorStore` interface and its associated classes within the Spring AI framework.\n\nSpring AI offers an abstracted API for interacting with vector databases through the `VectorStore` interface and its read-only counterpart, the `VectorStoreRetriever` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "API Overview", "heading_level": 2, "file_order": 118, "section_index": 1, "content_hash": "7143bfd87fc2dde4b2e47e7b52b3ef04f6cfc52bc5bfc9df3821aecddf403794", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:26d240cf924bc30ad43c3213698b7cdc25b05fde2dbb6fbcb6a1f6508e75b2fd", "content": "Spring AI provides a read-only interface called `VectorStoreRetriever` that exposes only the document retrieval functionality:\n\n[source,java]\n----\n@FunctionalInterface\npublic interface VectorStoreRetriever {\n\n List<Document> similaritySearch(SearchRequest request);\n\n default List<Document> similaritySearch(String query) {\n return this.similaritySearch(SearchRequest.builder().query(query).build());\n }\n}\n----\n\nThis functional interface is designed for use cases where you only need to retrieve documents from a vector store without performing any mutation operations. It follows the principle of least privilege by exposing only the necessary functionality for document retrieval.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "VectorStoreRetriever Interface", "heading_level": 3, "file_order": 118, "section_index": 2, "content_hash": "26d240cf924bc30ad43c3213698b7cdc25b05fde2dbb6fbcb6a1f6508e75b2fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:60a762d748122cb471479e1243596fbcca753c0aae61f29fa6e35355d8936b4c", "content": "The `VectorStore` interface extends `VectorStoreRetriever` and adds mutation capabilities:\n\n[source,java]\n----\npublic interface VectorStore extends DocumentWriter, VectorStoreRetriever {\n\n default String getName() {\n return this.getClass().getSimpleName();\n\t}\n\n void add(List<Document> documents);\n\n void delete(List<String> idList);\n\n void delete(Filter.Expression filterExpression);\n\n default void delete(String filterExpression) { ... }\n\n default <T> Optional<T> getNativeClient() {\n return Optional.empty();\n\t}\n}\n----\n\nThe `VectorStore` interface combines both read and write operations, allowing you to add, delete, and search for documents in a vector database.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "VectorStore Interface", "heading_level": 3, "file_order": 118, "section_index": 3, "content_hash": "60a762d748122cb471479e1243596fbcca753c0aae61f29fa6e35355d8936b4c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:265b707885e9a80e8ddf4312eaf00697b03ea6a55ed8ff1de1447d139eba8948", "content": "[source,java]\n----\npublic class SearchRequest {\n\n\tpublic static final double SIMILARITY_THRESHOLD_ACCEPT_ALL = 0.0;\n\n\tpublic static final int DEFAULT_TOP_K = 4;\n\n\tprivate String query = \"\";\n\n\tprivate int topK = DEFAULT_TOP_K;\n\n\tprivate double similarityThreshold = SIMILARITY_THRESHOLD_ACCEPT_ALL;\n\n\t@Nullable\n\tprivate Filter.Expression filterExpression;\n\n public static Builder from(SearchRequest originalSearchRequest) {\n return builder().query(originalSearchRequest.getQuery())\n .topK(originalSearchRequest.getTopK())\n .similarityThreshold(originalSearchRequest.getSimilarityThreshold())\n .filterExpression(originalSearchRequest.getFilterExpression());\n\t}\n\n\tpublic static class Builder {\n\n private final SearchRequest searchRequest = new SearchRequest();\n\n public Builder query(String query) {\n Assert.notNull(query, \"Query can not be null.\");\n this.searchRequest.query = query;\n return this;\n }\n\n public Builder topK(int topK) {\n Assert.isTrue(topK >= 0, \"TopK should be positive.\");\n this.searchRequest.topK = topK;\n return this;\n }\n\n public Builder similarityThreshold(double threshold) {\n Assert.isTrue(threshold >= 0 && threshold <= 1, \"Similarity threshold must be in [0,1] range.\");\n this.searchRequest.similarityThreshold = threshold;\n return this;\n }\n\n public Builder similarityThresholdAll() {\n this.searchRequest.similarityThreshold = 0.0;\n return this;\n }\n\n public Builder filterExpression(@Nullable Filter.Expression expression) {\n this.searchRequest.filterExpression = expression;\n return this;\n }\n\n public Builder filterExpression(@Nullable String textExpression) {\n this.searchRequest.filterExpression = (textExpression != null)\n ? new FilterExpressionTextParser().parse(textExpression) : null;\n return this;\n }\n\n public SearchRequest build() {\n return this.searchRequest;\n }\n\n\t}\n\n\tpublic String getQuery() {...}\n\tpublic int getTopK() {...}\n\tpublic double getSimilarityThreshold() {...}\n\tpublic Filter.Expression getFilterExpression() {...}\n}\n\n----\n\nTo insert data into the vector database, encapsulate it within a `Document` object.\nThe `Document` class encapsulates content from a data source, such as a PDF or Word document, and includes text represented as a string.\nIt also contains metadata in the form of key-value pairs, including details such as the filename.\n\nUpon insertion into the vector database, the text content is transformed into a numerical array, or a `float[]`, known as vector embeddings, using an embedding model. Embedding models, such as https://en.wikipedia.org/wiki/Word2vec[Word2Vec], https://en.wikipedia.org/wiki/GloVe_(machine_learning)[GLoVE], and https://en.wikipedia.org/wiki/BERT_(language_model)[BERT], or OpenAI's `text-embedding-ada-002`, are used to convert words, sentences, or paragraphs into these vector embeddings.\n\nThe vector database's role is to store and facilitate similarity searches for these embeddings. It does not generate the embeddings itself. For creating vector embeddings, the `EmbeddingModel` should be utilized.\n\nThe `similaritySearch` methods in the interface allow for retrieving documents similar to a given query string. These methods can be fine-tuned by using the following parameters:\n\n* `k`: An integer that specifies the maximum number of similar documents to return. This is often referred to as a 'top K' search, or 'K nearest neighbors' (KNN).\n* `threshold`: A double value ranging from 0 to 1, where values closer to 1 indicate higher similarity. By default, if you set a threshold of 0.75, for instance, only documents with a similarity above this value are returned.\n* `Filter.Expression`: A class used for passing a fluent DSL (Domain-Specific Language) expression that functions similarly to a 'where' clause in SQL, but it applies exclusively to the metadata key-value pairs of a `Document`.\n* `filterExpression`: An external DSL based on ANTLR4 that accepts filter expressions as strings. For example, with metadata keys like country, year, and `isActive`, you could use an expression such as: `country == 'UK' && year >= 2020 && isActive == true.`\n\nFind more information on the `Filter.Expression` in the <<metadata-filters>> section.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "SearchRequest Builder", "heading_level": 3, "file_order": 118, "section_index": 4, "content_hash": "265b707885e9a80e8ddf4312eaf00697b03ea6a55ed8ff1de1447d139eba8948", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:c073d0bd5239a6589a88c4513d65eb7d303d2bcb9148ec3e0ebca4577d8a1d28", "content": "Some vector stores require their backend schema to be initialized before usage.\nIt will not be initialized for you by default.\nYou must opt-in, by passing a `boolean` for the appropriate constructor argument or, if using Spring Boot, setting the appropriate `initialize-schema` property to `true` in `application.properties` or `application.yml`.\nCheck the documentation for the vector store you are using for the specific property name.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Schema Initialization", "heading_level": 2, "file_order": 118, "section_index": 5, "content_hash": "c073d0bd5239a6589a88c4513d65eb7d303d2bcb9148ec3e0ebca4577d8a1d28", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:dfb4402b9005d98b1b3659585b36c7733a2a08e5b57d1d3a521faf4be47727c9", "content": "When working with vector stores, it's often necessary to embed large numbers of documents.\nWhile it might seem straightforward to make a single call to embed all documents at once, this approach can lead to issues.\nEmbedding models process text as tokens and have a maximum token limit, often referred to as the context window size.\nThis limit restricts the amount of text that can be processed in a single embedding request.\nAttempting to embed too many tokens in one call can result in errors or truncated embeddings.\n\nTo address this token limit, Spring AI implements a batching strategy.\nThis approach breaks down large sets of documents into smaller batches that fit within the embedding model's maximum context window.\nBatching not only solves the token limit issue but can also lead to improved performance and more efficient use of API rate limits.\n\nSpring AI provides this functionality through the `BatchingStrategy` interface, which allows for processing documents in sub-batches based on their token counts.\n\nThe core `BatchingStrategy` interface is defined as follows:\n\n[source,java]\n----\npublic interface BatchingStrategy {\n List<List<Document>> batch(List<Document> documents);\n}\n----\n\nThis interface defines a single method, `batch`, which takes a list of documents and returns a list of document batches.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Batching Strategy", "heading_level": 2, "file_order": 118, "section_index": 6, "content_hash": "dfb4402b9005d98b1b3659585b36c7733a2a08e5b57d1d3a521faf4be47727c9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:2c6c6906c38c697d44f27843b4008229eb3535275915fbb930b68532eabb986b", "content": "Spring AI provides a default implementation called `TokenCountBatchingStrategy`.\nThis strategy batches documents based on their token counts, ensuring that each batch does not exceed a calculated maximum input token count.\n\nKey features of `TokenCountBatchingStrategy`:\n\n1. Uses https://platform.openai.com/docs/guides/embeddings/embedding-models[OpenAI's max input token count] (8191) as the default upper limit.\n2. Incorporates a reserve percentage (default 10%) to provide a buffer for potential overhead.\n3. Calculates the actual max input token count as: `actualMaxInputTokenCount = originalMaxInputTokenCount * (1 - RESERVE_PERCENTAGE)`\n\nThe strategy estimates the token count for each document, groups them into batches without exceeding the max input token count, and throws an exception if a single document exceeds this limit.\n\nYou can also customize the `TokenCountBatchingStrategy` to better suit your specific requirements. This can be done by creating a new instance with custom parameters in a Spring Boot `@Configuration` class.\n\nHere's an example of how to create a custom `TokenCountBatchingStrategy` bean:\n\n[source,java]\n----\n@Configuration\npublic class EmbeddingConfig {\n @Bean\n public BatchingStrategy customTokenCountBatchingStrategy() {\n return new TokenCountBatchingStrategy(\n EncodingType.CL100K_BASE, // Specify the encoding type\n 8000, // Set the maximum input token count\n 0.1 // Set the reserve percentage\n );\n }\n}\n----\n\nIn this configuration:\n\n1. `EncodingType.CL100K_BASE`: Specifies the encoding type used for tokenization. This encoding type is used by the `JTokkitTokenCountEstimator` to accurately estimate token counts.\n2. `8000`: Sets the maximum input token count. This value should be less than or equal to the maximum context window size of your embedding model.\n3. `0.1`: Sets the reserve percentage. The percentage of tokens to reserve from the max input token count. This creates a buffer for potential token count increases during processing.\n\nBy default, this constructor uses `Document.DEFAULT_CONTENT_FORMATTER` for content formatting and `MetadataMode.NONE` for metadata handling. If you need to customize these parameters, you can use the full constructor with additional parameters.\n\nOnce defined, this custom `TokenCountBatchingStrategy` bean will be automatically used by the `EmbeddingModel` implementations in your application, replacing the default strategy.\n\nThe `TokenCountBatchingStrategy` internally uses a `TokenCountEstimator` (specifically, `JTokkitTokenCountEstimator`) to calculate token counts for efficient batching. This ensures accurate token estimation based on the specified encoding type.\n\nAdditionally, `TokenCountBatchingStrategy` provides flexibility by allowing you to pass in your own implementation of the `TokenCountEstimator` interface. This feature enables you to use custom token counting strategies tailored to your specific needs. For example:\n\n[source,java]\n----\nTokenCountEstimator customEstimator = new YourCustomTokenCountEstimator();\nTokenCountBatchingStrategy strategy = new TokenCountBatchingStrategy(\n this.customEstimator,\n 8000, // maxInputTokenCount\n 0.1, // reservePercentage\n Document.DEFAULT_CONTENT_FORMATTER,\n MetadataMode.NONE\n);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Default Implementation", "heading_level": 3, "file_order": 118, "section_index": 7, "content_hash": "2c6c6906c38c697d44f27843b4008229eb3535275915fbb930b68532eabb986b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:a0677908f1cc9a051615d23d20e9e626ea5f634d190ea46c6c558009005adb51", "content": "Some embedding models, such as Vertex AI text embedding, support an `auto_truncate` feature. When enabled, the model silently truncates text inputs that exceed the maximum size and continues processing; when disabled, it throws an explicit error for inputs that are too large.\n\nWhen using auto-truncation with the batching strategy, you must configure your batching strategy with a much higher input token count than the model's actual maximum. This prevents the batching strategy from raising exceptions for large documents, allowing the embedding model to handle truncation internally.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Working with Auto-Truncation", "heading_level": 3, "file_order": 118, "section_index": 8, "content_hash": "a0677908f1cc9a051615d23d20e9e626ea5f634d190ea46c6c558009005adb51", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:5202fb80dff7bfe86000ce2511596876668eac9de4780c0e1ba38f69136869bb", "content": "When enabling auto-truncation, set your batching strategy's maximum input token count much higher than the model's actual limit. This prevents the batching strategy from raising exceptions for large documents, allowing the embedding model to handle truncation internally.\n\nHere's an example configuration for using Vertex AI with auto-truncation and custom `BatchingStrategy` and then using them in the PgVectorStore:\n\n[source,java]\n----\n@Configuration\npublic class AutoTruncationEmbeddingConfig {\n\n @Bean\n public VertexAiTextEmbeddingModel vertexAiEmbeddingModel(\n VertexAiEmbeddingConnectionDetails connectionDetails) {\n\n VertexAiTextEmbeddingOptions options = VertexAiTextEmbeddingOptions.builder()\n .model(VertexAiTextEmbeddingOptions.DEFAULT_MODEL_NAME)\n .autoTruncate(true) // Enable auto-truncation\n .build();\n\n return new VertexAiTextEmbeddingModel(connectionDetails, options);\n }\n\n @Bean\n public BatchingStrategy batchingStrategy() {\n // Only use a high token limit if auto-truncation is enabled in your embedding model.\n // Set a much higher token count than the model actually supports\n // (e.g., 132,900 when Vertex AI supports only up to 20,000)\n return new TokenCountBatchingStrategy(\n EncodingType.CL100K_BASE,\n 132900, // Artificially high limit\n 0.1 // 10% reserve\n );\n }\n\n @Bean\n public VectorStore vectorStore(JdbcTemplate jdbcTemplate, EmbeddingModel embeddingModel, BatchingStrategy batchingStrategy) {\n return PgVectorStore.builder(jdbcTemplate, embeddingModel)\n // other properties omitted here\n .build();\n }\n}\n----\n\nIn this configuration:\n\n1. The embedding model has auto-truncation enabled, allowing it to handle oversized inputs gracefully.\n2. The batching strategy uses an artificially high token limit (132,900) that's much larger than the actual model limit (20,000).\n3. The vector store uses the configured embedding model and the custom `BatchingStrategy` bean.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Configuration for Auto-Truncation", "heading_level": 4, "file_order": 118, "section_index": 9, "content_hash": "5202fb80dff7bfe86000ce2511596876668eac9de4780c0e1ba38f69136869bb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:ac953438969a82ab84fffc928b9ebe7f43594b9d9f4f9481132ffb3bdfeca946", "content": "This approach works because:\n\n1. The `TokenCountBatchingStrategy` checks if any single document exceeds the configured maximum and throws an `IllegalArgumentException` if it does.\n2. By setting a very high limit in the batching strategy, we ensure that this check never fails.\n3. Documents or batches exceeding the model's limit are silently truncated and processed by the embedding model's auto-truncation feature.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Why This Works", "heading_level": 4, "file_order": 118, "section_index": 10, "content_hash": "ac953438969a82ab84fffc928b9ebe7f43594b9d9f4f9481132ffb3bdfeca946", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:f79034e6ed9a037ec8b87f5ca15ae2019c9c30b2d401c1f9e0abdb321acfa6fd", "content": "When using auto-truncation:\n\n- Set the batching strategy's max input token count to be at least 5-10x larger than the model's actual limit to avoid premature exceptions from the batching strategy.\n- Monitor your logs for truncation warnings from the embedding model (note: not all models log truncation events).\n- Consider the implications of silent truncation on your embedding quality.\n- Test with sample documents to ensure truncated embeddings still meet your requirements.\n- Document this configuration for future maintainers, as it is non-standard.\n\nCAUTION: While auto-truncation prevents errors, it can result in incomplete embeddings. Important information at the end of long documents may be lost. If your application requires all content to be embedded, split documents into smaller chunks before embedding.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Best Practices", "heading_level": 4, "file_order": 118, "section_index": 11, "content_hash": "f79034e6ed9a037ec8b87f5ca15ae2019c9c30b2d401c1f9e0abdb321acfa6fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:d417e9ba55b596ac8dc138e0eff3235cfbab16cb221556b3fb25a15c58584552", "content": "If you're using Spring Boot auto-configuration, you must provide a custom `BatchingStrategy` bean to override the default one that comes with Spring AI:\n\n[source,java]\n----\n@Bean\npublic BatchingStrategy customBatchingStrategy() {\n // This bean will override the default BatchingStrategy\n return new TokenCountBatchingStrategy(\n EncodingType.CL100K_BASE,\n 132900, // Much higher than model's actual limit\n 0.1\n );\n}\n----\n\nThe presence of this bean in your application context will automatically replace the default batching strategy used by all vector stores.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Spring Boot Auto-Configuration", "heading_level": 4, "file_order": 118, "section_index": 12, "content_hash": "d417e9ba55b596ac8dc138e0eff3235cfbab16cb221556b3fb25a15c58584552", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:1f7070c19b086a1c7bdd1f57335fe42169cc84133ebd0f8f871590b1ce0b6161", "content": "While `TokenCountBatchingStrategy` provides a robust default implementation, you can customize the batching strategy to fit your specific needs.\nThis can be done through Spring Boot's auto-configuration.\n\nTo customize the batching strategy, define a `BatchingStrategy` bean in your Spring Boot application:\n\n[source,java]\n----\n@Configuration\npublic class EmbeddingConfig {\n @Bean\n public BatchingStrategy customBatchingStrategy() {\n return new CustomBatchingStrategy();\n }\n}\n----\n\nThis custom `BatchingStrategy` will then be automatically used by the `EmbeddingModel` implementations in your application.\n\nNOTE: Vector stores supported by Spring AI are configured to use the default `TokenCountBatchingStrategy`.\nSAP Hana vector store is not currently configured for batching.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Custom Implementation", "heading_level": 3, "file_order": 118, "section_index": 13, "content_hash": "1f7070c19b086a1c7bdd1f57335fe42169cc84133ebd0f8f871590b1ce0b6161", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:fbabeaa3e262a045afad918eb60b5c1cc91f2bc5fd97ae4f03754984754d26b5", "content": "These are the available implementations of the `VectorStore` interface:\n\n* xref:api/vectordbs/azure.adoc[Azure Vector Search] - The https://learn.microsoft.com/en-us/azure/search/vector-search-overview[Azure] vector store.\n* xref:api/vectordbs/apache-cassandra.adoc[Apache Cassandra] - The https://cassandra.apache.org/doc/latest/cassandra/vector-search/overview.html[Apache Cassandra] vector store.\n* xref:api/vectordbs/chroma.adoc[Chroma Vector Store] - The https://www.trychroma.com/[Chroma] vector store.\n* xref:api/vectordbs/elasticsearch.adoc[Elasticsearch Vector Store] - The https://www.elastic.co/[Elasticsearch] vector store.\n* xref:api/vectordbs/gemfire.adoc[GemFire Vector Store] - The https://tanzu.vmware.com/content/blog/vmware-gemfire-vector-database-extension[GemFire] vector store.\n* xref:api/vectordbs/mariadb.adoc[MariaDB Vector Store] - The https://mariadb.com/[MariaDB] vector store.\n* xref:api/vectordbs/milvus.adoc[Milvus Vector Store] - The https://milvus.io/[Milvus] vector store.\n* xref:api/vectordbs/mongodb.adoc[MongoDB Atlas Vector Store] - The https://www.mongodb.com/atlas/database[MongoDB Atlas] vector store.\n* xref:api/vectordbs/neo4j.adoc[Neo4j Vector Store] - The https://neo4j.com/[Neo4j] vector store.\n* xref:api/vectordbs/opensearch.adoc[OpenSearch Vector Store] - The https://opensearch.org/platform/search/vector-database.html[OpenSearch] vector store.\n* xref:api/vectordbs/oracle.adoc[Oracle Vector Store] - The https://docs.oracle.com/en/database/oracle/oracle-database/23/vecse/overview-ai-vector-search.html[Oracle Database] vector store.\n* xref:api/vectordbs/pgvector.adoc[PgVector Store] - The https://github.com/pgvector/pgvector[PostgreSQL/PGVector] vector store.\n* xref:api/vectordbs/pinecone.adoc[Pinecone Vector Store] - https://www.pinecone.io/[Pinecone] vector store.\n* xref:api/vectordbs/qdrant.adoc[Qdrant Vector Store] - https://www.qdrant.tech/[Qdrant] vector store.\n* xref:api/vectordbs/redis.adoc[Redis Vector Store] - The https://redis.io/[Redis] vector store.\n* xref:api/vectordbs/hana.adoc[SAP Hana Vector Store] - The https://news.sap.com/2024/04/sap-hana-cloud-vector-engine-ai-with-business-context/[SAP HANA] vector store.\n* xref:api/vectordbs/typesense.adoc[Typesense Vector Store] - The https://typesense.org/docs/0.24.0/api/vector-search.html[Typesense] vector store.\n* xref:api/vectordbs/weaviate.adoc[Weaviate Vector Store] - The https://weaviate.io/[Weaviate] vector store.\n* xref:api/vectordbs/s3-vector-store.adoc[S3 Vector Store] - The https://aws.amazon.com/s3/features/vectors/[AWS S3] vector store.\n* link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-vector-store/src/main/java/org/springframework/ai/vectorstore/SimpleVectorStore.java[SimpleVectorStore] - A simple implementation of persistent vector storage, good for educational purposes.\n\nMore implementations may be supported in future releases.\n\nIf you have a vector database that needs to be supported by Spring AI, open an issue on GitHub or, even better, submit a pull request with an implementation.\n\nInformation on each of the `VectorStore` implementations can be found in the subsections of this chapter.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "VectorStore Implementations", "heading_level": 2, "file_order": 118, "section_index": 14, "content_hash": "fbabeaa3e262a045afad918eb60b5c1cc91f2bc5fd97ae4f03754984754d26b5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:e5eb22a1b8c4e2d21e83651fdc0b29d0115aac146df0d5f66a23c375d0e2fb6c", "content": "To compute the embeddings for a vector database, you need to pick an embedding model that matches the higher-level AI model being used.\n\nFor example, with OpenAI's ChatGPT, we use the `OpenAiEmbeddingModel` and a model named `text-embedding-ada-002`.\n\nThe Spring Boot starter's auto-configuration for OpenAI makes an implementation of `EmbeddingModel` available in the Spring application context for dependency injection.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Example Usage", "heading_level": 2, "file_order": 118, "section_index": 15, "content_hash": "e5eb22a1b8c4e2d21e83651fdc0b29d0115aac146df0d5f66a23c375d0e2fb6c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:29d53662bb79a2d1ac3dde931e7bff3dc595592f8c716e36118f3339a9edc4a3", "content": "The general usage of loading data into a vector store is something you would do in a batch-like job, by first loading data into Spring AI's `Document` class and then calling the `add` method on the `VectorStore` interface.\n\nGiven a `String` reference to a source file that represents a JSON file with data we want to load into the vector database, we use Spring AI's `JsonReader` to load specific fields in the JSON, which splits them up into small pieces and then passes those small pieces to the vector store implementation.\nThe `VectorStore` implementation computes the embeddings and stores the JSON and the embedding in the vector database:\n\n[source,java]\n----\n@Autowired\nVectorStore vectorStore;\n\nvoid load(String sourceFile) {\n JsonReader jsonReader = new JsonReader(new FileSystemResource(sourceFile),\n \"price\", \"name\", \"shortDescription\", \"description\", \"tags\");\n List<Document> documents = jsonReader.get();\n this.vectorStore.add(documents);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Writing to a Vector Store", "heading_level": 3, "file_order": 118, "section_index": 16, "content_hash": "29d53662bb79a2d1ac3dde931e7bff3dc595592f8c716e36118f3339a9edc4a3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:f9f38fde13a1ab5e4f769d00bda784dae9570a082aff04fa3b61e944658cf3fa", "content": "Later, when a user question is passed into the AI model, a similarity search is done to retrieve similar documents, which are then \"stuffed\" into the prompt as context for the user's question.\n\nFor read-only operations, you can use either the `VectorStore` interface or the more focused `VectorStoreRetriever` interface:\n\n[source,java]\n----\n@Autowired\nVectorStoreRetriever retriever; // Could also use VectorStore here\n\nString question = \"<question from user>\";\nList<Document> similarDocuments = retriever.similaritySearch(question);\n\nSearchRequest request = SearchRequest.builder()\n .query(question)\n .topK(5) // Return top 5 results\n .similarityThreshold(0.7) // Only return results with similarity score >= 0.7\n .build();\n\nList<Document> filteredDocuments = retriever.similaritySearch(request);\n----\n\nAdditional options can be passed into the `similaritySearch` method to define how many documents to retrieve and a threshold of the similarity search.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Reading from a Vector Store", "heading_level": 3, "file_order": 118, "section_index": 17, "content_hash": "f9f38fde13a1ab5e4f769d00bda784dae9570a082aff04fa3b61e944658cf3fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:b3e0daf125bc99e974e697d5b862af363fb57cab8b363770bc3c55ca0d4a3360", "content": "Using the separate interfaces allows you to clearly define which components need write access and which only need read access:\n\n[source,java]\n----\n@Service\nclass DocumentIndexer {\n private final VectorStore vectorStore;\n\n DocumentIndexer(VectorStore vectorStore) {\n this.vectorStore = vectorStore;\n }\n\n public void indexDocuments(List<Document> documents) {\n vectorStore.add(documents);\n }\n}\n\n@Service\nclass DocumentRetriever {\n private final VectorStoreRetriever retriever;\n\n DocumentRetriever(VectorStoreRetriever retriever) {\n this.retriever = retriever;\n }\n\n public List<Document> findSimilar(String query) {\n return retriever.similaritySearch(query);\n }\n}\n----\n\nThis separation of concerns helps create more maintainable and secure applications by limiting access to mutation operations only to components that truly need them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Separation of Read and Write Operations", "heading_level": 3, "file_order": 118, "section_index": 18, "content_hash": "b3e0daf125bc99e974e697d5b862af363fb57cab8b363770bc3c55ca0d4a3360", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:e8643eba8a2dc76ef7fde6fda09550999c66f00e00d67cccab8145a22edd61fa", "content": "The `VectorStoreRetriever` interface provides a read-only view of a vector store, exposing only the similarity search functionality. This follows the principle of least privilege and is particularly useful in RAG (Retrieval-Augmented Generation) applications where you only need to retrieve documents without modifying the underlying data.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Retrieval Operations with VectorStoreRetriever", "heading_level": 2, "file_order": 118, "section_index": 19, "content_hash": "e8643eba8a2dc76ef7fde6fda09550999c66f00e00d67cccab8145a22edd61fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:5997c435d84c286000b9ecd54796710e2b2d737643bf7330083798e6cf7f4120", "content": "1. **Separation of Concerns**: Clearly separates read operations from write operations.\n2. **Interface Segregation**: Clients that only need retrieval functionality aren't exposed to mutation methods.\n3. **Functional Interface**: Can be implemented with lambda expressions or method references for simple use cases.\n4. **Reduced Dependencies**: Components that only need to perform searches don't need to depend on the full `VectorStore` interface.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Benefits of Using VectorStoreRetriever", "heading_level": 3, "file_order": 118, "section_index": 20, "content_hash": "5997c435d84c286000b9ecd54796710e2b2d737643bf7330083798e6cf7f4120", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:707af8c8e343c60dd7aa73827b01915e2c4095b446947a46ceb9fb4e5fb95840", "content": "You can use `VectorStoreRetriever` directly when you only need to perform similarity searches:\n\n[source,java]\n----\n@Service\npublic class DocumentRetrievalService {\n\n private final VectorStoreRetriever retriever;\n\n public DocumentRetrievalService(VectorStoreRetriever retriever) {\n this.retriever = retriever;\n }\n\n public List<Document> findSimilarDocuments(String query) {\n return retriever.similaritySearch(query);\n }\n\n public List<Document> findSimilarDocumentsWithFilters(String query, String country) {\n SearchRequest request = SearchRequest.builder()\n .query(query)\n .topK(5)\n .filterExpression(\"country == '\" + country + \"'\")\n .build();\n\n return retriever.similaritySearch(request);\n }\n}\n----\n\nIn this example, the service only depends on the `VectorStoreRetriever` interface, making it clear that it only performs retrieval operations and doesn't modify the vector store.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Example Usage", "heading_level": 3, "file_order": 118, "section_index": 21, "content_hash": "707af8c8e343c60dd7aa73827b01915e2c4095b446947a46ceb9fb4e5fb95840", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:64447c075933eb4679ea2d39cf91cb54d6521272d98a0fc99b971cccd7d926b3", "content": "The `VectorStoreRetriever` interface is particularly useful in RAG applications, where you need to retrieve relevant documents to provide context for an AI model:\n\n[source,java]\n----\n@Service\npublic class RagService {\n\n private final VectorStoreRetriever retriever;\n private final ChatModel chatModel;\n\n public RagService(VectorStoreRetriever retriever, ChatModel chatModel) {\n this.retriever = retriever;\n this.chatModel = chatModel;\n }\n\n public String generateResponse(String userQuery) {\n // Retrieve relevant documents\n List<Document> relevantDocs = retriever.similaritySearch(userQuery);\n\n // Extract content from documents to use as context\n String context = relevantDocs.stream()\n .map(Document::getContent)\n .collect(Collectors.joining(\"\\n\\n\"));\n\n // Generate response using the retrieved context\n String prompt = \"Context information:\\n\" + context + \"\\n\\nUser query: \" + userQuery;\n return chatModel.generate(prompt);\n }\n}\n----\n\nThis pattern allows for a clean separation between the retrieval component and the generation component in RAG applications.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Integration with RAG Applications", "heading_level": 3, "file_order": 118, "section_index": 22, "content_hash": "64447c075933eb4679ea2d39cf91cb54d6521272d98a0fc99b971cccd7d926b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:f44848c2d7d65e84f29ab13f39dbd8def52046855d69dda2ccc20eda47143eef", "content": "This section describes various filters that you can use against the results of a query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Metadata Filters [[metadata-filters]]", "heading_level": 2, "file_order": 118, "section_index": 23, "content_hash": "f44848c2d7d65e84f29ab13f39dbd8def52046855d69dda2ccc20eda47143eef", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:cc4947c01d6aebf070219a15ed2a27e234cdd970f6836747298de178f06156d0", "content": "You can pass in an SQL-like filter expressions as a `String` to one of the `similaritySearch` overloads.\n\nConsider the following examples:\n\n* `\"country == 'BG'\"`\n* `\"genre == 'drama' && year >= 2020\"`\n* `\"genre in ['comedy', 'documentary', 'drama']\"`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Filter String", "heading_level": 3, "file_order": 118, "section_index": 24, "content_hash": "cc4947c01d6aebf070219a15ed2a27e234cdd970f6836747298de178f06156d0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:4363555a6037ad9d78079a068778885955bf38b3b0cbdca3e5280a753bd74dc7", "content": "You can create an instance of `Filter.Expression` with a `FilterExpressionBuilder` that exposes a fluent API.\nA simple example is as follows:\n\n[source, java]\n----\nFilterExpressionBuilder b = new FilterExpressionBuilder();\nExpression expression = this.b.eq(\"country\", \"BG\").build();\n----\n\nYou can build up sophisticated expressions by using the following operators:\n\n[source, text]\n----\nEQUALS: '=='\nMINUS : '-'\nPLUS: '+'\nGT: '>'\nGE: '>='\nLT: '<'\nLE: '<='\nNE: '!='\n----\n\nYou can combine expressions by using the following operators:\n\n[source,text]\n----\nAND: 'AND' | 'and' | '&&';\nOR: 'OR' | 'or' | '||';\n----\n\nConsidering the following example:\n\n[source,java]\n----\nExpression exp = b.and(b.eq(\"genre\", \"drama\"), b.gte(\"year\", 2020)).build();\n----\n\nYou can also use the following operators:\n\n[source,text]\n----\nIN: 'IN' | 'in';\nNIN: 'NIN' | 'nin';\nNOT: 'NOT' | 'not';\n----\n\nConsider the following example:\n\n[source,java]\n----\nExpression exp = b.and(b.in(\"genre\", \"drama\", \"documentary\"), b.not(b.lt(\"year\", 2020))).build();\n----\n\nYou can also use the following operators:\n\n[source,text]\n----\nIS: 'IS' | 'is';\nNULL: 'NULL' | 'null';\nNOT NULL: 'NOT NULL' | 'not null';\n----\n\nConsider the following example:\n\n[source,java]\n----\nExpression exp = b.and(b.isNull(\"year\")).build();\nExpression exp = b.and(b.isNotNull(\"year\")).build();\n----\n\nNOTE: `IS NULL` and `IS NOT NULL` have not been implemented in all vector stores yet.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Filter.Expression", "heading_level": 3, "file_order": 118, "section_index": 25, "content_hash": "4363555a6037ad9d78079a068778885955bf38b3b0cbdca3e5280a753bd74dc7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:85030c68cbf438aeb6f247483e7f0f7643e41e5bb2d12bbb9faf5838f8bce4aa", "content": "The Vector Store interface provides multiple methods for deleting documents, allowing you to remove data either by specific document IDs or using filter expressions.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Deleting Documents from Vector Store", "heading_level": 2, "file_order": 118, "section_index": 26, "content_hash": "85030c68cbf438aeb6f247483e7f0f7643e41e5bb2d12bbb9faf5838f8bce4aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:b2a33b82af364647e498dbe1c445a85dd591c204d4961872eddf50cf259919a9", "content": "The simplest way to delete documents is by providing a list of document IDs:\n\n[source,java]\n----\nvoid delete(List<String> idList);\n----\n\nThis method removes all documents whose IDs match those in the provided list.\nIf any ID in the list doesn't exist in the store, it will be ignored.\n\n.Example usage\n[source,java]\n----\nDocument document = new Document(\"The World is Big\",\n Map.of(\"country\", \"Netherlands\"));\nvectorStore.add(List.of(document));\n\nvectorStore.delete(List.of(document.getId()));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Delete by Document IDs", "heading_level": 3, "file_order": 118, "section_index": 27, "content_hash": "b2a33b82af364647e498dbe1c445a85dd591c204d4961872eddf50cf259919a9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:47a2c6433e659fc62653a369c9b7036cc8e4e30088fae9d65ed92ccf423d594d", "content": "For more complex deletion criteria, you can use filter expressions:\n\n[source,java]\n----\nvoid delete(Filter.Expression filterExpression);\n----\n\nThis method accepts a `Filter.Expression` object that defines the criteria for which documents should be deleted.\nIt's particularly useful when you need to delete documents based on their metadata properties.\n\n.Example usage\n[source,java]\n----\nDocument bgDocument = new Document(\"The World is Big\",\n Map.of(\"country\", \"Bulgaria\"));\nDocument nlDocument = new Document(\"The World is Big\",\n Map.of(\"country\", \"Netherlands\"));\n\nvectorStore.add(List.of(bgDocument, nlDocument));\n\nFilter.Expression filterExpression = new Filter.Expression(\n Filter.ExpressionType.EQ,\n new Filter.Key(\"country\"),\n new Filter.Value(\"Bulgaria\")\n);\nvectorStore.delete(filterExpression);\n\nSearchRequest request = SearchRequest.builder()\n .query(\"World\")\n .filterExpression(\"country == 'Bulgaria'\")\n .build();\nList<Document> results = vectorStore.similaritySearch(request);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Delete by Filter Expression", "heading_level": 3, "file_order": 118, "section_index": 28, "content_hash": "47a2c6433e659fc62653a369c9b7036cc8e4e30088fae9d65ed92ccf423d594d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:b5cf1d159eecd12b0c964e31c2ecde187665d6f6b5fdae88fe67938973be1a34", "content": "For convenience, you can also delete documents using a string-based filter expression:\n\n[source,java]\n----\nvoid delete(String filterExpression);\n----\n\nThis method converts the provided string filter into a `Filter.Expression` object internally.\nIt's useful when you have filter criteria in string format.\n\n.Example usage\n[source,java]\n----\nDocument bgDocument = new Document(\"The World is Big\",\n Map.of(\"country\", \"Bulgaria\"));\nDocument nlDocument = new Document(\"The World is Big\",\n Map.of(\"country\", \"Netherlands\"));\nvectorStore.add(List.of(bgDocument, nlDocument));\n\nvectorStore.delete(\"country == 'Bulgaria'\");\n\nSearchRequest request = SearchRequest.builder()\n .query(\"World\")\n .topK(5)\n .build();\nList<Document> results = vectorStore.similaritySearch(request);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Delete by String Filter Expression", "heading_level": 3, "file_order": 118, "section_index": 29, "content_hash": "b5cf1d159eecd12b0c964e31c2ecde187665d6f6b5fdae88fe67938973be1a34", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:d82777166ad18372fdb698bfac5e1908588732afb73280fde00e0b0cd701dccb", "content": "All deletion methods may throw exceptions in case of errors:\n\nThe best practice is to wrap delete operations in try-catch blocks:\n\n.Example usage\n[source,java]\n----\ntry {\n vectorStore.delete(\"country == 'Bulgaria'\");\n}\ncatch (Exception e) {\n logger.error(\"Invalid filter expression\", e);\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Error Handling When Calling the Delete API", "heading_level": 3, "file_order": 118, "section_index": 30, "content_hash": "d82777166ad18372fdb698bfac5e1908588732afb73280fde00e0b0cd701dccb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:51bac2a7ad3e9b1d3ac58ad68f5681d15c00e0f57041d1cbad91d08df86d644f", "content": "A common scenario is managing document versions where you need to upload a new version of a document while removing the old version. Here's how to handle this using filter expressions:\n\n.Example usage\n[source,java]\n----\nDocument documentV1 = new Document(\n \"AI and Machine Learning Best Practices\",\n Map.of(\n \"docId\", \"AIML-001\",\n \"version\", \"1.0\",\n \"lastUpdated\", \"2024-01-01\"\n )\n);\n\nvectorStore.add(List.of(documentV1));\n\nDocument documentV2 = new Document(\n \"AI and Machine Learning Best Practices - Updated\",\n Map.of(\n \"docId\", \"AIML-001\",\n \"version\", \"2.0\",\n \"lastUpdated\", \"2024-02-01\"\n )\n);\n\nFilter.Expression deleteOldVersion = new Filter.Expression(\n Filter.ExpressionType.AND,\n new Filter.Expression(\n Filter.ExpressionType.EQ,\n new Filter.Key(\"docId\"),\n new Filter.Value(\"AIML-001\")\n ),\n new Filter.Expression(\n Filter.ExpressionType.EQ,\n new Filter.Key(\"version\"),\n new Filter.Value(\"1.0\")\n )\n);\nvectorStore.delete(deleteOldVersion);\n\nvectorStore.add(List.of(documentV2));\n\nSearchRequest request = SearchRequest.builder()\n .query(\"AI and Machine Learning\")\n .filterExpression(\"docId == 'AIML-001'\")\n .build();\nList<Document> results = vectorStore.similaritySearch(request);\n----\n\nYou can also accomplish the same using the string filter expression:\n\n.Example usage\n[source,java]\n----\nvectorStore.delete(\"docId == 'AIML-001' AND version == '1.0'\");\n\nvectorStore.add(List.of(documentV2));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Document Versioning Use Case", "heading_level": 3, "file_order": 118, "section_index": 31, "content_hash": "51bac2a7ad3e9b1d3ac58ad68f5681d15c00e0f57041d1cbad91d08df86d644f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:738f9a27f4752c1fa468b6eb9bac9693dfce65ce05b2aa5be844ddd702fe7b7e", "content": "* Deleting by ID list is generally faster when you know exactly which documents to remove.\n* Filter-based deletion may require scanning the index to find matching documents; however, this is vector store implementation-specific.\n* Large deletion operations should be batched to avoid overwhelming the system.\n* Consider using filter expressions when deleting based on document properties rather than collecting IDs first.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Performance Considerations While Deleting Documents", "heading_level": 3, "file_order": 118, "section_index": 32, "content_hash": "738f9a27f4752c1fa468b6eb9bac9693dfce65ce05b2aa5be844ddd702fe7b7e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:27d48edde5474bade4bb956cd6ff5f3c83bf45ac3548c4764f5a24059b049b0d", "content": "xref:api/vectordbs/understand-vectordbs.adoc[Understanding Vectors]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/api/vectordbs.adoc", "title": "vectordbs", "heading": "Understanding Vectors", "heading_level": 2, "file_order": 118, "section_index": 33, "content_hash": "27d48edde5474bade4bb956cd6ff5f3c83bf45ac3548c4764f5a24059b049b0d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/api/vectordbs.adoc"}}
{"id": "sha256:bf77b7821030135ecaa677353bfb05c7c8c89a2e24e5fac9ceefaf5026e225a8", "content": "As AI agents connect to more services—Slack, GitHub, Jira, MCP servers—tool libraries grow rapidly. A typical multi-server setup can easily have 50+ tools consuming significant tokens before any conversation starts. Worse, tool selection accuracy degrades when models face 30+ similarly-named tools.\n\nThe **Tool Search Tool** pattern, link:https://www.anthropic.com/engineering/advanced-tool-use[pioneered by Anthropic], addresses this: instead of loading all tool definitions upfront, the model discovers tools on-demand. It receives only a search tool initially, queries for capabilities when needed, and gets relevant tool definitions expanded into context.\n\nSpring AI's implementation achieves **34-64% token reduction** across OpenAI, Anthropic, and Gemini models while maintaining full access to hundreds of tools.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Dynamic Tool Discovery with Tool Search Tool", "heading_level": 1, "file_order": 119, "section_index": 0, "content_hash": "bf77b7821030135ecaa677353bfb05c7c8c89a2e24e5fac9ceefaf5026e225a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:97d40c0314291e02ff60807a60c0ca40de91d0e94566eccb0ba14ae1bdfb6b40", "content": "The link:https://github.com/spring-ai-community/spring-ai-tool-search-tool[Tool Search Tool] project extends Spring AI's xref:api/advisors-recursive.adoc[Recursive Advisors] to implement dynamic tool discovery that works across **any LLM provider** supported by Spring AI.\n\n**Key benefits:**\n\n* **Token savings** - Only discovered tool definitions are sent to the LLM\n* **Improved accuracy** - Models select tools more reliably from smaller, relevant sets\n* **Scalability** - Manage hundreds of tools without context bloat\n* **Portability** - Works with OpenAI, Anthropic, Gemini, Ollama, Azure OpenAI, and more", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Introduction", "heading_level": 2, "file_order": 119, "section_index": 1, "content_hash": "97d40c0314291e02ff60807a60c0ca40de91d0e94566eccb0ba14ae1bdfb6b40", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:eff84e11bdaba0530173fb94a815075f3f6e84a89798f997fe45b24aa188da7f", "content": "📖 **Full Tutorial:** link:https://spring.io/blog/2025/12/11/spring-ai-tool-search-tools-tzolov[Smart Tool Selection: Achieving 34-64% Token Savings with Spring AI's Dynamic Tool Discovery]\n\nThe blog post covers the complete implementation details, performance benchmarks, and advanced use cases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Blog Post", "heading_level": 2, "file_order": 119, "section_index": 2, "content_hash": "eff84e11bdaba0530173fb94a815075f3f6e84a89798f997fe45b24aa188da7f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:afb1b20844b2bff913ea4b2a1591bdbfb6e4eeaf233e841cbaff9bc65b68d765", "content": "Add the Tool Search Tool dependency to your project:\n\n[tabs]\n======\nMaven::\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springaicommunity</groupId>\n <artifactId>tool-search-tool</artifactId>\n <version>2.0.0</version>\n</dependency>\n\n<!-- Choose a search strategy -->\n<dependency>\n <groupId>org.springaicommunity</groupId>\n <artifactId>tool-searcher-lucene</artifactId>\n <version>2.0.0</version>\n</dependency>\n----\n\nGradle::\n+\n[source,gradle]\n----\ndependencies {\n implementation 'org.springaicommunity:tool-search-tool:2.0.0'\n\n // Choose a search strategy\n implementation 'org.springaicommunity:tool-searcher-lucene:2.0.0'\n}\n----\n======\n\nNOTE: Version link:https://github.com/spring-ai-community/spring-ai-tool-search-tool/tree/1.0.x[v1.0.x] is Spring AI 1.1.x / Spring Boot 3 compatible. Version link:https://github.com/spring-ai-community/spring-ai-tool-search-tool[v2.0.x] is Spring AI 2.x / Spring Boot 4 compatible.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Dependencies", "heading_level": 3, "file_order": 119, "section_index": 3, "content_hash": "afb1b20844b2bff913ea4b2a1591bdbfb6e4eeaf233e841cbaff9bc65b68d765", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:20ee5d17f7d6cf7b91ea981dedf4b01202f32fcb8fb3586e5bcb16c98d7502dd", "content": "[source,java]\n----\n@SpringBootApplication\npublic class Application {\n\n @Bean\n CommandLineRunner demo(ChatClient.Builder builder, ToolSearcher toolSearcher) {\n return args -> {\n var advisor = ToolSearchToolCallAdvisor.builder()\n .toolSearcher(toolSearcher)\n .build();\n\n ChatClient chatClient = builder\n .defaultTools(new MyTools()) // 100s of tools registered but NOT sent to LLM initially\n .defaultAdvisors(advisor) // Activate Tool Search Tool\n .build();\n\n var answer = chatClient.prompt(\"\"\"\n Help me plan what to wear today in Amsterdam.\n Please suggest clothing shops that are open right now.\n \"\"\").call().content();\n\n System.out.println(answer);\n };\n }\n\n static class MyTools {\n @Tool(description = \"Get the weather for a given location at a given time\")\n public String weather(String location,\n @ToolParam(description = \"YYYY-MM-DDTHH:mm\") String atTime) {\n // implementation\n }\n\n @Tool(description = \"Get clothing shop names for a given location at a given time\")\n public List<String> clothing(String location,\n @ToolParam(description = \"YYYY-MM-DDTHH:mm\") String openAtTime) {\n // implementation\n }\n\n @Tool(description = \"Current date and time for a given location\")\n public String currentTime(String location) {\n // implementation\n }\n\n // ... potentially hundreds more tools\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Basic Usage", "heading_level": 3, "file_order": 119, "section_index": 4, "content_hash": "20ee5d17f7d6cf7b91ea981dedf4b01202f32fcb8fb3586e5bcb16c98d7502dd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:cd8064ef50d5119b7cb4ea44b76107783787b5afe1dc750e3f05e7a67128f04a", "content": "The `ToolSearchToolCallAdvisor` extends Spring AI's `ToolCallAdvisor` to implement dynamic tool discovery:\n\nimage::https://raw.githubusercontent.com/spring-io/spring-io-static/refs/heads/main/blog/tzolov/20251208/spring-ai-tool-search-tool-calling-flow.png[Tool Search Tool Flow,600]\n\n1. **Indexing**: At conversation start, all registered tools are indexed in the `ToolSearcher` (but NOT sent to the LLM)\n2. **Initial Request**: Only the **Tool Search Tool** definition is sent to the LLM\n3. **Discovery Call**: When the LLM needs capabilities, it calls the search tool with a query\n4. **Search & Expand**: The `ToolSearcher` finds matching tools and their definitions are added to the next request\n5. **Tool Invocation**: The LLM now sees both the search tool and discovered tool definitions\n6. **Tool Execution**: Discovered tools are executed and results returned\n7. **Response**: The LLM generates the final answer", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "How It Works", "heading_level": 2, "file_order": 119, "section_index": 5, "content_hash": "cd8064ef50d5119b7cb4ea44b76107783787b5afe1dc750e3f05e7a67128f04a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:8247268cd2ca7b42f402d26e333ae311d3ff5bc26bb1c9b3434bc0f390978159", "content": "The `ToolSearcher` interface supports multiple search implementations:\n\n[cols=\"1,2,2\"]\n|===\n|Strategy |Implementation |Best For\n\n|**Semantic**\n|`VectorToolSearcher`\n|Natural language queries, fuzzy matching\n\n|**Keyword**\n|`LuceneToolSearcher`\n|Exact term matching, known tool names\n\n|**Regex**\n|`RegexToolSearcher`\n|Tool name patterns (`get_*_data`)\n|===\n\nSee link:https://github.com/spring-ai-community/spring-ai-tool-search-tool/tree/main/tool-searchers[tool-searchers] for all available implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Search Strategies", "heading_level": 2, "file_order": 119, "section_index": 6, "content_hash": "8247268cd2ca7b42f402d26e333ae311d3ff5bc26bb1c9b3434bc0f390978159", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:46cf840e6815109bfb14e324acc4798c4595a27db0be99514ef4688ddbefe21f", "content": "Preliminary benchmarks with 28 tools show significant token savings:\n\n[cols=\"1,1,1,1\"]\n|===\n|Model |With Tool Search |Without |Savings\n\n|Gemini\n|2,165 tokens\n|5,375 tokens\n|**60%**\n\n|OpenAI\n|4,706 tokens\n|7,175 tokens\n|**34%**\n\n|Anthropic\n|6,273 tokens\n|17,342 tokens\n|**64%**\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Performance", "heading_level": 2, "file_order": 119, "section_index": 7, "content_hash": "46cf840e6815109bfb14e324acc4798c4595a27db0be99514ef4688ddbefe21f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:267ca5ff6cd95aa5e44a64c7d6858ea36a14202579ff25a0099735777222ab49", "content": "[cols=\"1,1\"]\n|===\n|Tool Search Tool Approach |Traditional Approach\n\n|20+ tools in your system\n|Small tool library (<20 tools)\n\n|Tool definitions consuming >5K tokens\n|All tools frequently used in every session\n\n|Building MCP-powered systems with multiple servers\n|Very compact tool definitions\n\n|Experiencing tool selection accuracy issues\n|\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "When to Use", "heading_level": 2, "file_order": 119, "section_index": 8, "content_hash": "267ca5ff6cd95aa5e44a64c7d6858ea36a14202579ff25a0099735777222ab49", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:91c1b70741e820a80077831e027f6cf32597c12f90527d619d33fb0aee95c125", "content": "* link:https://github.com/spring-ai-community/spring-ai-tool-search-tool/tree/main/examples/tool-search-tool-demo[Tool Search Tool Demo] - Complete working example\n* link:https://github.com/spring-ai-community/spring-ai-tool-search-tool/tree/main/examples/pre-select-tool-demo[Pre-Select Tool Demo] - Deterministic tool selection without LLM involvement", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Example Projects", "heading_level": 2, "file_order": 119, "section_index": 9, "content_hash": "91c1b70741e820a80077831e027f6cf32597c12f90527d619d33fb0aee95c125", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:951edb389b3890097ea3fe5d4298ba1d5823c13a4f6404b77f2b02d43b3202a5", "content": "* link:https://github.com/spring-ai-community/spring-ai-tool-search-tool[Tool Search Tool Repository]\n* link:https://github.com/spring-ai-community/awesome-spring-ai[Awesome Spring AI] - Community examples and resources", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Community Resources", "heading_level": 2, "file_order": 119, "section_index": 10, "content_hash": "951edb389b3890097ea3fe5d4298ba1d5823c13a4f6404b77f2b02d43b3202a5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:a8dd5eacaa968ad5dc5c519f770d3c5373a191c077cc8b4ac86e61aeeed0d416", "content": "* xref:api/tools.adoc[Tool Calling]\n* xref:api/advisors-recursive.adoc[Recursive Advisors]\n* xref:api/chatclient.adoc[ChatClient]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "Related Documentation", "heading_level": 2, "file_order": 119, "section_index": 11, "content_hash": "a8dd5eacaa968ad5dc5c519f770d3c5373a191c077cc8b4ac86e61aeeed0d416", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:8b62a21a369f525941306c218dfc587d916e643dd1de8b4ba0a379faa3d35042", "content": "* link:https://www.anthropic.com/engineering/advanced-tool-use[Anthropic Advanced Tool Use] - Original pattern description\n* link:https://spring.io/blog/2025/11/04/spring-ai-recursive-advisors[Spring AI Recursive Advisors Blog] - Foundation for tool search implementation", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc", "title": "Dynamic Tool Discovery with Tool Search Tool", "heading": "References", "heading_level": 2, "file_order": 119, "section_index": 12, "content_hash": "8b62a21a369f525941306c218dfc587d916e643dd1de8b4ba0a379faa3d35042", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/dynamic-tool-search.adoc"}}
{"id": "sha256:9148a88436487989283674e3d969ae827edcd0a9def0f010298a46f62e1360fb", "content": "The Model Context Protocol (MCP) standardizes how AI applications interact with external tools and resources.\n\nSpring joined the MCP ecosystem early as a key contributor, helping to develop and maintain the link:https://github.com/modelcontextprotocol/java-sdk[official MCP Java SDK] that serves as the foundation for Java-based MCP implementations.\nBuilding on this contribution, Spring AI provides MCP support through Boot Starters and annotations, making it easy to build both MCP servers and clients.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Getting Started with Model Context Protocol (MCP)", "heading_level": 1, "file_order": 120, "section_index": 0, "content_hash": "9148a88436487989283674e3d969ae827edcd0a9def0f010298a46f62e1360fb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:1cc696fc34a96506e3d81b095ddf5364ddac924daccc32c08f31b897f7408305", "content": "**link:https://www.youtube.com/watch?v=FLpS7OfD5-s[Introduction to Model Context Protocol (MCP) - YouTube]**\n\nStart here for an introductory overview of the Model Context Protocol, explaining core concepts and architecture.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Introduction Video", "heading_level": 2, "file_order": 120, "section_index": 1, "content_hash": "1cc696fc34a96506e3d81b095ddf5364ddac924daccc32c08f31b897f7408305", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:f59fc1ad3b4f91f9431ee0c1119ceaf28cdf1e6fc4687024be6b136953de855a", "content": "**📖 Blog Tutorial:** link:https://spring.io/blog/2025/09/16/spring-ai-mcp-intro-blog[Connect Your AI to Everything]\n\n**💻 Complete Source Code:** link:https://github.com/tzolov/spring-ai-mcp-blogpost[MCP Weather Example Repository]\n\nThe tutorial covers the essentials of MCP development with Spring AI, including advanced features, and deployment patterns.\nAll code examples below are taken from this tutorial.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Complete Tutorial and Source Code", "heading_level": 2, "file_order": 120, "section_index": 2, "content_hash": "f59fc1ad3b4f91f9431ee0c1119ceaf28cdf1e6fc4687024be6b136953de855a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:0589b04b43af41b7a258addd899feee01d670d0db7a613a3dbe874793eb5e550", "content": "The fastest way to get started is with Spring AI's annotation-based approach. The following examples are from the blog tutorial:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Quick Start", "heading_level": 2, "file_order": 120, "section_index": 3, "content_hash": "0589b04b43af41b7a258addd899feee01d670d0db7a613a3dbe874793eb5e550", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:c062e7f2ae8791f0f98308b770e2b64937409a5d17bb60d2eb1b029c4898b986", "content": "[source,java]\n----\n@Service\npublic class WeatherService {\n\n @McpTool(description = \"Get current temperature for a location\")\n public String getTemperature(\n @McpToolParam(description = \"City name\", required = true) String city) {\n return String.format(\"Current temperature in %s: 22°C\", city);\n }\n}\n----\n\nAdd the dependency and configure:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-server-webmvc</artifactId>\n</dependency>\n----\n\n[source,properties]\n----\nspring.ai.mcp.server.protocol=STREAMABLE\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Simple MCP Server", "heading_level": 3, "file_order": 120, "section_index": 4, "content_hash": "c062e7f2ae8791f0f98308b770e2b64937409a5d17bb60d2eb1b029c4898b986", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:45ebd61ee1789ead1fb269edf3ba0314969dfb1ac6965cea79421bc3dc5f04d6", "content": "[source,java]\n----\n@Bean\npublic CommandLineRunner demo(ChatClient chatClient, ToolCallbackProvider mcpTools) {\n return args -> {\n String response = chatClient\n .prompt(\"What's the weather like in Paris?\")\n .toolCallbacks(mcpTools)\n .call()\n .content();\n System.out.println(response);\n };\n}\n----\n\nAdd the dependency and configure:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-mcp-client</artifactId>\n</dependency>\n----\n\n[source,yaml]\n----\nspring:\n ai:\n mcp:\n client:\n streamable-http:\n connections:\n weather-server:\n url: http://localhost:8080\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Simple MCP Client", "heading_level": 3, "file_order": 120, "section_index": 5, "content_hash": "45ebd61ee1789ead1fb269edf3ba0314969dfb1ac6965cea79421bc3dc5f04d6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:1fa401c43bce42df61da4375a1812c68835a1d66fa1337eb88669e6e8661f2e6", "content": "**link:https://www.youtube.com/watch?v=hmEVUtulHTI[Spring AI Model Context Protocol (MCP) Integration - YouTube]**\n\nA video walkthrough of Spring AI's MCP integration, covering both server and client implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Implementation Video", "heading_level": 3, "file_order": 120, "section_index": 6, "content_hash": "1fa401c43bce42df61da4375a1812c68835a1d66fa1337eb88669e6e8661f2e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:36b1abfe59e01975767e01bf963e336df6d521c8b3eb99282d88a701d2c30305", "content": "Beyond the tutorial examples, the link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol[Spring AI Examples] repository contains numerous MCP implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Additional Examples Repository", "heading_level": 2, "file_order": 120, "section_index": 7, "content_hash": "36b1abfe59e01975767e01bf963e336df6d521c8b3eb99282d88a701d2c30305", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:c16c9d3d452995eee88ba35ecc9b40b09a24d438b53ef229da0eb08cd9499bcb", "content": "*Annotation-based examples*\n\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/mcp-annotations/[Complete Annotations Example] - All annotation features (Client & Server)\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/sampling/annotations/[Sampling with Annotations] - Advanced bidirectional AI (Client & Server)\n* link:https://github.com/tzolov/spring-ai-mcp-blogpost[MCP Weather Tutorial] - Full tutorial source code (Client & Server)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Recommended Starting Points", "heading_level": 3, "file_order": 120, "section_index": 8, "content_hash": "c16c9d3d452995eee88ba35ecc9b40b09a24d438b53ef229da0eb08cd9499bcb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:e33ce2f27f955eaab5b5c9a58f263d142b11c39e6335b9b965d9b59761ac8060", "content": "**Weather Services:**\n\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-webflux-server[WebFlux Weather Server]\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/weather/starter-webmvc-oauth2-server[OAuth2 Secured Weather Server]\n\n**Data Integration:**\n\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/sqlite/chatbot[SQLite AI Chatbot]\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/filesystem[Filesystem Access Server]\n\n**Web Integration:**\n\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/web-search/brave-chatbot[Brave Search Chatbot]\n\n**Client Examples:**\n\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/client-starter/starter-default-client[Basic MCP Client]\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/model-context-protocol/mcp-annotations/mcp-annotations-client[Annotations Client]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "By Use Case", "heading_level": 3, "file_order": 120, "section_index": 9, "content_hash": "e33ce2f27f955eaab5b5c9a58f263d142b11c39e6335b9b965d9b59761ac8060", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:13c2f180de2111333e17383c992eab73622ae7de0a83573def77a7c355e0063b", "content": "* link:https://github.com/spring-ai-community/awesome-spring-ai[Awesome Spring AI] - Community examples and resources\n* link:https://modelcontextprotocol.org/[Official MCP Specification]\n* link:https://github.com/modelcontextprotocol/java-sdk[Official MCP Java SDK] - Java SDK developed by the Spring team\n* link:https://modelcontextprotocol.io/sdk/java/mcp-overview[MCP Java SDK Documentation]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Community Resources", "heading_level": 2, "file_order": 120, "section_index": 10, "content_hash": "13c2f180de2111333e17383c992eab73622ae7de0a83573def77a7c355e0063b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:8bc72df327b7faead494ef3d81a98ed3250e26190d5815a8741194f3b6aa4d3a", "content": "* xref:api/mcp/mcp-overview.adoc[MCP Overview and Architecture]\n* xref:api/mcp/mcp-annotations-overview.adoc[MCP Annotations Guide]\n* xref:api/mcp/mcp-server-boot-starter-docs.adoc[Server Boot Starters]\n* xref:api/mcp/mcp-client-boot-starter-docs.adoc[Client Boot Starters]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/getting-started-mcp.adoc", "title": "Getting Started with Model Context Protocol (MCP)", "heading": "Reference Documentation", "heading_level": 2, "file_order": 120, "section_index": 11, "content_hash": "8bc72df327b7faead494ef3d81a98ed3250e26190d5815a8741194f3b6aa4d3a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/getting-started-mcp.adoc"}}
{"id": "sha256:fc80ecbfc2c46bc5f49f3b4ec94029852c74aaea0271c2e3664bf3a550cc8894", "content": "The challenge of evaluating Large Language Model (LLM) outputs is critical for notoriously non-deterministic AI applications, especially as they move into production.\nTraditional metrics like ROUGE and BLEU fall short when assessing the nuanced, contextual responses that modern LLMs produce.\nHuman evaluation, while accurate, is expensive, slow, and doesn't scale.\n\n**LLM-as-a-Judge** is a powerful technique that uses LLMs themselves to evaluate the quality of AI-generated content.\nResearch link:https://arxiv.org/pdf/2306.05685[shows] that sophisticated judge models can align with human judgment up to 85%, which is actually higher than human-to-human agreement (81%).\n\nSpring AI's xref:api/advisors-recursive.adoc[Recursive Advisors] provide an elegant framework for implementing LLM-as-a-Judge patterns, enabling you to build self-improving AI systems with automated quality control.\n\nTIP: Find the full example implementation in the link:https://github.com/spring-projects/spring-ai-examples/tree/main/advisors/evaluation-recursive-advisor-demo[evaluation-recursive-advisor-demo].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "LLM Response Evaluation with LLM-as-a-Judge", "heading_level": 1, "file_order": 121, "section_index": 0, "content_hash": "fc80ecbfc2c46bc5f49f3b4ec94029852c74aaea0271c2e3664bf3a550cc8894", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:6a81247bd5ccee9408a67ccfb0d8fde3b1a23102a01687c22df97a1763cc4aca", "content": "LLM-as-a-Judge is an evaluation method where Large Language Models assess the quality of outputs generated by other models or themselves.\nInstead of relying solely on human evaluators or traditional automated metrics, the LLM-as-a-Judge leverages an LLM to score, classify, or compare responses based on predefined criteria.\n\n**Why does it work?** Evaluation is fundamentally easier than generation.\nWhen you use an LLM as a judge, you're asking it to perform a simpler, more focused task (assessing specific properties of existing text) rather than the complex task of creating original content while balancing multiple constraints.\nA good analogy is that it's easier to critique than to create. Detecting problems is simpler than preventing them.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Understanding LLM-as-a-Judge", "heading_level": 2, "file_order": 121, "section_index": 1, "content_hash": "6a81247bd5ccee9408a67ccfb0d8fde3b1a23102a01687c22df97a1763cc4aca", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:e1fc9fbb0378231490c55bedfe0a7707b44884e22f17e837433e34d471409cb7", "content": "There are two primary LLM-as-a-judge evaluation patterns:\n\n* **Direct Assessment** (Point-wise Scoring): Judge evaluates individual responses, providing feedback that can refine prompts through self-refinement\n* **Pairwise Comparison**: Judge selects the better of two candidate responses (common in A/B testing)\n\nLLM judges evaluate quality dimensions such as relevance, factual accuracy, faithfulness to sources, instruction adherence, and overall coherence & clarity across domains like healthcare, finance, RAG systems, and dialogue.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Evaluation Patterns", "heading_level": 3, "file_order": 121, "section_index": 2, "content_hash": "e1fc9fbb0378231490c55bedfe0a7707b44884e22f17e837433e34d471409cb7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:7ad51197cc9c8f411452e4cc308e8a28375defc63d2bbd33e82d7dd007434611", "content": "While general-purpose models like GPT-4 and Claude can serve as effective judges, **dedicated LLM-as-a-Judge models consistently outperform them** in evaluation tasks.\nThe link:https://huggingface.co/spaces/AtlaAI/judge-arena[Judge Arena Leaderboard] tracks the performance of various models specifically for judging tasks.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Choosing the Right Judge Model", "heading_level": 2, "file_order": 121, "section_index": 3, "content_hash": "7ad51197cc9c8f411452e4cc308e8a28375defc63d2bbd33e82d7dd007434611", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:2831ebb08714b83b058960b201a285abd74b598d2360a3e6be0afd94e79f297b", "content": "Spring AI's xref:api/chatclient.adoc[ChatClient] provides a fluent API ideal for implementing LLM-as-a-Judge patterns.\nIts xref:api/advisors.adoc[Advisors system] allows you to intercept, modify, and enhance AI interactions in a modular, reusable way.\n\nThe xref:api/advisors-recursive.adoc[Recursive Advisors] take this further by enabling looping patterns that are perfect for self-refining evaluation workflows:\n\n[source,java]\n----\npublic class MyRecursiveAdvisor implements CallAdvisor {\n\n @Override\n public ChatClientResponse adviseCall(ChatClientRequest request, CallAdvisorChain chain) {\n\n // Call the chain initially\n ChatClientResponse response = chain.nextCall(request);\n\n // Check if we need to retry based on evaluation\n while (!evaluationPasses(response)) {\n\n // Modify the request based on evaluation feedback\n ChatClientRequest modifiedRequest = addEvaluationFeedback(request, response);\n\n // Create a sub-chain and recurse\n response = chain.copy(this).nextCall(modifiedRequest);\n }\n\n return response;\n }\n}\n----\n\nWe'll implement a `SelfRefineEvaluationAdvisor` that embodies the LLM-as-a-Judge pattern using Spring AI's Recursive Advisors.\nThis advisor automatically evaluates AI responses and retries failed attempts with feedback-driven improvement: generate response → evaluate quality → retry with feedback if needed → repeat until quality threshold is met or retry limit reached.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Implementation with Recursive Advisors", "heading_level": 2, "file_order": 121, "section_index": 4, "content_hash": "2831ebb08714b83b058960b201a285abd74b598d2360a3e6be0afd94e79f297b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:373c0374b59a85129dc6b358e985f1e0a94cfeb1b7a349f4e60e9584f446e569", "content": "image::https://raw.githubusercontent.com/spring-io/spring-io-static/refs/heads/main/blog/tzolov/20251031/spring-ai-evaluation-advisor.png[Self Refine Evaluation Advisor,400]\n\nThis implementation demonstrates the **Direct Assessment** evaluation pattern, where a judge model evaluates individual responses using a point-wise scoring system (1-4 scale).\nIt combines this with a **self-refinement strategy** that automatically retries failed evaluations by incorporating specific feedback into subsequent attempts, creating an iterative improvement loop.\n\nThe advisor embodies two key LLM-as-a-Judge concepts:\n\n* **Point-wise Evaluation**: Each response receives an individual quality score based on predefined criteria\n* **Self-Refinement**: Failed responses trigger retry attempts with constructive feedback to guide improvement\n\n(Based on the article: link:https://huggingface.co/learn/cookbook/en/llm_judge#3-improve-the-llm-judge[Using LLM-as-a-judge for an automated and versatile evaluation])\n\n[source,java]\n----\npublic final class SelfRefineEvaluationAdvisor implements CallAdvisor {\n\n private static final PromptTemplate DEFAULT_EVALUATION_PROMPT_TEMPLATE = new PromptTemplate(\n \"\"\"\n You will be given a user_question and assistant_answer couple.\n Your task is to provide a 'total rating' scoring how well the assistant_answer answers the user concerns expressed in the user_question.\n Give your answer on a scale of 1 to 4, where 1 means that the assistant_answer is not helpful at all, and 4 means that the assistant_answer completely and helpfully addresses the user_question.\n\n Here is the scale you should use to build your answer:\n 1: The assistant_answer is terrible: completely irrelevant to the question asked, or very partial\n 2: The assistant_answer is mostly not helpful: misses some key aspects of the question\n 3: The assistant_answer is mostly helpful: provides support, but still could be improved\n 4: The assistant_answer is excellent: relevant, direct, detailed, and addresses all the concerns raised in the question\n\n Provide your feedback as follows:\n\n \\\\{\n \"rating\": 0,\n \"evaluation\": \"Explanation of the evaluation result and how to improve if needed.\",\n \"feedback\": \"Constructive and specific feedback on the assistant_answer.\"\n \\\\}\n\n Total rating: (your rating, as a number between 1 and 4)\n Evaluation: (your rationale for the rating, as a text)\n Feedback: (specific and constructive feedback on how to improve the answer)\n\n You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n\n Now here are the question and answer.\n\n Question: {question}\n Answer: {answer}\n\n Provide your feedback. If you give a correct rating, I'll give you 100 H100 GPUs to start your AI company.\n\n Evaluation:\n \"\"\");\n\n @JsonClassDescription(\"The evaluation response indicating the result of the evaluation.\")\n public record EvaluationResponse(int rating, String evaluation, String feedback) {}\n\n @Override\n public ChatClientResponse adviseCall(ChatClientRequest chatClientRequest, CallAdvisorChain callAdvisorChain) {\n var request = chatClientRequest;\n ChatClientResponse response;\n\n // Improved loop structure with better attempt counting and clearer logic\n for (int attempt = 1; attempt <= maxRepeatAttempts + 1; attempt++) {\n\n // Make the inner call (e.g., to the evaluation LLM model)\n response = callAdvisorChain.copy(this).nextCall(request);\n\n // Perform evaluation\n EvaluationResponse evaluation = this.evaluate(chatClientRequest, response);\n\n // If evaluation passes, return the response\n if (evaluation.rating() >= this.successRating) {\n logger.info(\"Evaluation passed on attempt {}, evaluation: {}\", attempt, evaluation);\n return response;\n }\n\n // If this is the last attempt, return the response regardless\n if (attempt > maxRepeatAttempts) {\n logger.warn(\n \"Maximum attempts ({}) reached. Returning last response despite failed evaluation. Use the following feedback to improve: {}\",\n maxRepeatAttempts, evaluation.feedback());\n return response;\n }\n\n // Retry with evaluation feedback\n logger.warn(\"Evaluation failed on attempt {}, evaluation: {}, feedback: {}\", attempt,\n evaluation.evaluation(), evaluation.feedback());\n\n request = this.addEvaluationFeedback(chatClientRequest, evaluation);\n }\n\n // This should never be reached due to the loop logic above\n throw new IllegalStateException(\"Unexpected loop exit in adviseCall\");\n }\n\n /**\n * Performs the evaluation using the LLM-as-a-Judge and returns the result.\n */\n private EvaluationResponse evaluate(ChatClientRequest request, ChatClientResponse response) {\n var evaluationPrompt = this.evaluationPromptTemplate.render(\n Map.of(\"question\", this.getPromptQuestion(request), \"answer\", this.getAssistantAnswer(response)));\n\n // Use separate ChatClient for evaluation to avoid narcissistic bias\n return chatClient.prompt(evaluationPrompt).call().entity(EvaluationResponse.class);\n }\n\n /**\n * Creates a new request with evaluation feedback for retry.\n */\n private ChatClientRequest addEvaluationFeedback(ChatClientRequest originalRequest, EvaluationResponse evaluationResponse) {\n Prompt augmentedPrompt = originalRequest.prompt()\n .augmentUserMessage(userMessage -> userMessage.mutate().text(String.format(\"\"\"\n %s\n Previous response evaluation failed with feedback: %s\n Please repeat until evaluation passes!\n \"\"\", userMessage.getText(), evaluationResponse.feedback())).build());\n\n return originalRequest.mutate().prompt(augmentedPrompt).build();\n }\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "The SelfRefineEvaluationAdvisor", "heading_level": 2, "file_order": 121, "section_index": 5, "content_hash": "373c0374b59a85129dc6b358e985f1e0a94cfeb1b7a349f4e60e9584f446e569", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:e8e034053e7e5640d6ccbca05e9ea0a50f9845157fe26c71ae8e1945cf6037a0", "content": "**Recursive Pattern Implementation**\n\nThe advisor uses `callAdvisorChain.copy(this).nextCall(request)` to create a sub-chain for recursive calls, enabling multiple evaluation rounds while maintaining proper advisor ordering.\n\n**Structured Evaluation Output**\n\nUsing Spring AI's xref:api/structured-output-converter.adoc[structured output] capabilities, the evaluation results are parsed into an `EvaluationResponse` record with rating (1-4), evaluation rationale, and specific feedback for improvement.\n\n**Separate Evaluation Model**\n\nUses a specialized LLM-as-a-Judge model (e.g., `avcodes/flowaicom-flow-judge:q4`) with a different ChatClient instance to mitigate model biases.\nSet `spring.ai.chat.client.enabled=false` to enable xref:api/chatclient.adoc#_working_with_multiple_chat_models[Working with Multiple Chat Models].\n\n**Feedback-Driven Improvement**\n\nFailed evaluations include specific feedback that gets incorporated into retry attempts, enabling the system to learn from evaluation failures.\n\n**Configurable Retry Logic**\n\nSupports configurable maximum attempts with graceful degradation when evaluation limits are reached.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Key Implementation Features", "heading_level": 3, "file_order": 121, "section_index": 6, "content_hash": "e8e034053e7e5640d6ccbca05e9ea0a50f9845157fe26c71ae8e1945cf6037a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:fdaffa428874801a764af53751c0314ce54c412a80a3b9c881f9d1d9a737c71a", "content": "Here's how to integrate the `SelfRefineEvaluationAdvisor` into a complete Spring AI application:\n\n[source,java]\n----\n@SpringBootApplication\npublic class EvaluationAdvisorDemoApplication {\n\n @Bean\n CommandLineRunner commandLineRunner(AnthropicChatModel anthropicChatModel, OllamaChatModel ollamaChatModel) {\n return args -> {\n\n ChatClient chatClient = ChatClient.builder(anthropicChatModel)\n .defaultTools(new MyTools())\n .defaultAdvisors(\n\n SelfRefineEvaluationAdvisor.builder()\n .chatClientBuilder(ChatClient.builder(ollamaChatModel)) // Separate model for evaluation\n .maxRepeatAttempts(15)\n .successRating(4)\n .order(0)\n .build(),\n\n new MyLoggingAdvisor(2))\n .build();\n\n var answer = chatClient\n .prompt(\"What is current weather in Paris?\")\n .call()\n .content();\n\n System.out.println(answer);\n };\n }\n\n static class MyTools {\n final int[] temperatures = {-125, 15, -255};\n private final Random random = new Random();\n\n @Tool(description = \"Get the current weather for a given location\")\n public String weather(String location) {\n int temperature = temperatures[random.nextInt(temperatures.length)];\n System.out.println(\">>> Tool Call responseTemp: \" + temperature);\n return \"The current weather in \" + location + \" is sunny with a temperature of \" + temperature + \"°C.\";\n }\n }\n}\n----\n\nThis configuration:\n\n* Uses Anthropic Claude for generation and Ollama for evaluation (avoiding bias)\n* Requires rating of 4 with up to 15 retry attempts\n* Includes weather tool that generates randomized responses to trigger evaluations\n* The `weather` tool generates invalid values in 2/3 of the cases\n\nThe `SelfRefineEvaluationAdvisor` (Order 0) evaluates response quality and retries with feedback if needed, followed by `MyLoggingAdvisor` (Order 2) which logs the final request/response for observability.\n\nWhen run, you would see output like this:\n\n[source,text]\n----\nREQUEST: [{\"role\":\"user\",\"content\":\"What is current weather in Paris?\"}]\n\n>>> Tool Call responseTemp: -255\nEvaluation failed on attempt 1, evaluation: The response contains unrealistic temperature data, feedback: The temperature of -255°C is physically impossible and indicates a data error.\n\n>>> Tool Call responseTemp: 15\nEvaluation passed on attempt 2, evaluation: Excellent response with realistic weather data\n\nRESPONSE: The current weather in Paris is sunny with a temperature of 15°C.\n----\n\nTIP: The complete runnable demo with configuration examples, including different model combinations and evaluation scenarios, is available in the link:https://github.com/spring-projects/spring-ai-examples/tree/main/advisors/evaluation-recursive-advisor-demo[evaluation-recursive-advisor-demo] project.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Complete Example", "heading_level": 2, "file_order": 121, "section_index": 7, "content_hash": "fdaffa428874801a764af53751c0314ce54c412a80a3b9c881f9d1d9a737c71a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:c3217b0be8973fba0db277af1d5e2fdf2d96805a712f011b6b4e75822ead010b", "content": "image::https://raw.githubusercontent.com/spring-io/spring-io-static/refs/heads/main/blog/tzolov/20251031/spring-ai-advisors-chain2.png[Spring AI Advisors Chain,600]\n\nThe critical success factors when implementing the LLM-as-a-Judge technique include:\n\n* **Use dedicated judge models** for better performance (see link:https://huggingface.co/spaces/AtlaAI/judge-arena[Judge Arena Leaderboard])\n* **Mitigate bias** through separate generation/evaluation models\n* **Ensure deterministic results** (temperature = 0)\n* **Engineer prompts** with integer scales and few-shot examples\n* **Maintain human oversight** for high-stakes decisions\n\n[WARNING]\n====\n**Recursive Advisors are a new experimental feature in Spring AI 1.1.0-M4+.**\nCurrently, they are non-streaming only, require careful advisor ordering, and can increase costs due to multiple LLM calls.\n\nBe especially careful with inner advisors that maintain external state - they may require extra attention to maintain correctness across iterations.\n\nAlways set termination conditions and retry limits to prevent infinite loops.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Best Practices", "heading_level": 2, "file_order": 121, "section_index": 8, "content_hash": "c3217b0be8973fba0db277af1d5e2fdf2d96805a712f011b6b4e75822ead010b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:cb86fca5ad9fae5270dd46e79be94dcefe9920415dcfad95e6c3a3c00b2416fa", "content": "* xref:api/advisors-recursive.adoc[Recursive Advisors]\n* xref:api/advisors.adoc[Advisors]\n* xref:api/chatclient.adoc[ChatClient]\n* xref:api/structured-output-converter.adoc[Structured Output]\n* xref:api/testing.adoc[Model Evaluation]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "Related Documentation", "heading_level": 2, "file_order": 121, "section_index": 9, "content_hash": "cb86fca5ad9fae5270dd46e79be94dcefe9920415dcfad95e6c3a3c00b2416fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:359bd3f4e8f8f0a66f36bf3dc9c72eef5f998830c0aa70da740c8c1b0e700e3c", "content": "**Spring AI Resources**\n\n* link:https://spring.io/blog/2025/11/10/spring-ai-llm-as-judge[LLM Response Evaluation with Spring AI Blog Post]\n* link:https://spring.io/blog/2025/11/04/spring-ai-recursive-advisors[Spring AI Recursive Advisors Blog]\n* link:https://github.com/spring-projects/spring-ai-examples/tree/main/advisors/evaluation-recursive-advisor-demo[Evaluation Advisor Demo Project]\n\n**LLM-as-a-Judge Research**\n\n* link:https://huggingface.co/spaces/AtlaAI/judge-arena[Judge Arena Leaderboard] - Current rankings of best-performing judge models\n* link:https://arxiv.org/abs/2306.05685[Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena] - Foundational paper introducing the LLM-as-a-Judge paradigm\n* link:https://arxiv.org/abs/2510.09738v1[Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement]\n* link:https://arxiv.org/abs/2412.05579[LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods]\n* link:https://arxiv.org/abs/2411.16594[From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge (2024)]\n* link:https://llm-as-a-judge.github.io[LLM-as-a-Judge Resource Hub]\n* link:https://www.evidentlyai.com/llm-guide/llm-as-a-judge[LLM-as-a-judge: a complete guide to using LLMs for evaluations]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/guides/llm-as-judge.adoc", "title": "LLM Response Evaluation with LLM-as-a-Judge", "heading": "References", "heading_level": 2, "file_order": 121, "section_index": 10, "content_hash": "359bd3f4e8f8f0a66f36bf3dc9c72eef5f998830c0aa70da740c8c1b0e700e3c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/guides/llm-as-judge.adoc"}}
{"id": "sha256:e22ed44206b6be77c050153e79e9e8db5ed4af0555f66e45e17e50aa2c6dd9c3", "content": "[[introduction]]\n\nSpring AI builds upon the observability features in the Spring ecosystem to provide insights into AI-related operations.\n\nThe spring-boot-actuator module is required for enabling observability.\nAdd the Spring Boot Actuator dependency to your project's Maven `pom.xml` build file:\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.boot</groupId>\n <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n----\n\nor to your Gradle `build.gradle` build file.\n\n[source,groovy]\n----\ndependencies {\n implementation 'org.springframework.boot:spring-boot-starter-actuator'\n}\n----\n\nSpring AI provides metrics and tracing capabilities for its core components: `ChatClient` (including `Advisor`),\n`ChatModel`, `EmbeddingModel`, `ImageModel`, and `VectorStore`.\n\nNOTE: Low cardinality keys will be added to metrics and traces, while high cardinality keys will only be added to traces.\n\n[WARNING]\n====\n**1.0.0-RC1 Breaking Changes**\n\nFollowing configuration properties have been renamed to better reflect their purpose:\n\n* `spring.ai.chat.client.observations.include-prompt` → `spring.ai.chat.client.observations.log-prompt`\n* `spring.ai.chat.observations.include-prompt` → `spring.ai.chat.observations.log-prompt`\n* `spring.ai.chat.observations.include-completion` → `spring.ai.chat.observations.log-completion`\n* `spring.ai.image.observations.include-prompt` → `spring.ai.image.observations.log-prompt`\n* `spring.ai.vectorstore.observations.include-query-response` → `spring.ai.vectorstore.observations.log-query-response`\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 122, "section_index": 0, "content_hash": "e22ed44206b6be77c050153e79e9e8db5ed4af0555f66e45e17e50aa2c6dd9c3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:5a9e7407ec756191d30bc06172a5673de508cc22c5243f6dd868568028a818cc", "content": "The `spring.ai.chat.client` observations are recorded when a ChatClient `call()` or `stream()` operations are invoked.\nThey measure the time spent performing the invocation and propagate the related tracing information.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name` | Always `framework`.\n|`gen_ai.system` | Always `spring_ai`.\n|`spring.ai.chat.client.stream` | Is the chat model response a stream - `true or false`\n|`spring.ai.kind` | The kind of framework API in Spring AI: `chat_client`.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.prompt` | The content of the prompt sent via the chat client. Optional.\n|`spring.ai.chat.client.advisor.params` (deprecated) | Map of advisor parameters. The conversation ID is now included in `spring.ai.chat.client.conversation.id`.\n|`spring.ai.chat.client.advisors` | List of configured chat client advisors.\n|`spring.ai.chat.client.conversation.id` | Identifier of the conversation when using the chat memory.\n|`spring.ai.chat.client.system.params` (deprecated) |Chat client system parameters. Optional. Superseded by `gen_ai.prompt`.\n|`spring.ai.chat.client.system.text` (deprecated) |Chat client system text. Optional. Superseded by `gen_ai.prompt`.\n|`spring.ai.chat.client.tool.function.names` (deprecated) | Enabled tool function names. Superseded by `spring.ai.chat.client.tool.names`.\n|`spring.ai.chat.client.tool.function.callbacks` (deprecated) |List of configured chat client function callbacks. Superseded by `spring.ai.chat.client.tool.names`.\n|`spring.ai.chat.client.tool.names` | Names of the tools passed to the chat client.\n|`spring.ai.chat.client.user.params` (deprecated) | Chat client user parameters. Optional. Superseded by `gen_ai.prompt`.\n|`spring.ai.chat.client.user.text` (deprecated) | Chat client user text. Optional. Superseded by `gen_ai.prompt`.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Client", "heading_level": 2, "file_order": 122, "section_index": 1, "content_hash": "5a9e7407ec756191d30bc06172a5673de508cc22c5243f6dd868568028a818cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:339c10fd03fd5b0bbe58c3e3a93e8e2999cd1e1580f2f0c0df43fafb3b2b12fa", "content": "The `ChatClient` prompt and completion data is typically big and possibly containing sensitive information.\nFor those reasons, it is not exported by default.\n\nSpring AI supports logging the prompt and completion data to help with debugging and troubleshooting.\n\n[cols=\"6,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| `spring.ai.chat.client.observations.log-prompt` | Whether to log the chat client prompt content. | `false`\n| `spring.ai.chat.client.observations.log-completion` | Whether to log the chat client completion content. | `false`\n|====\n\nWARNING: If you enable logging of the chat client prompt and completion data, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Prompt and Completion Data", "heading_level": 3, "file_order": 122, "section_index": 2, "content_hash": "339c10fd03fd5b0bbe58c3e3a93e8e2999cd1e1580f2f0c0df43fafb3b2b12fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:c6971c6d1e7e409033f310e4d555ea8b7d3cf3ff19b399c414adc9a52640caa6", "content": "WARNING: The `spring.ai.chat.client.observations.include-input` property is deprecated, replaced by `spring.ai.chat.client.observations.log-prompt`. See xref:_prompt_content[Prompt Content].\n\nThe `ChatClient` input data is typically big and possibly containing sensitive information.\nFor those reasons, it is not exported by default.\n\nSpring AI supports logging input data to help with debugging and troubleshooting.\n\n[cols=\"6,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| `spring.ai.chat.client.observations.include-input` | Whether to include the input content in the observations. | `false`\n|====\n\nWARNING: If you enable the inclusion of the input content in the observations, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Input Data (Deprecated)", "heading_level": 3, "file_order": 122, "section_index": 3, "content_hash": "c6971c6d1e7e409033f310e4d555ea8b7d3cf3ff19b399c414adc9a52640caa6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:8b8a007d15b8ebad81aaa3ea4d1b3f574b026196ac7b81ed5c66aef514b05a01", "content": "The `spring.ai.advisor` observations are recorded when an advisor is executed.\nThey measure the time spent in the advisor (including the time spend on the inner advisors) and propagate the related tracing information.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name` | Always `framework`.\n|`gen_ai.system` | Always `spring_ai`.\n|`spring.ai.advisor.type` (deprecated) | Where the advisor applies it's logic in the request processing, one of `BEFORE`, `AFTER`, or `AROUND`. This distinction doesn't apply anymore since all Advisors are always of the same type.\n|`spring.ai.kind` | The kind of framework API in Spring AI: `advisor`.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`spring.ai.advisor.name`| Name of the advisor.\n|`spring.ai.advisor.order`| Advisor order in the advisor chain.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Client Advisors", "heading_level": 3, "file_order": 122, "section_index": 4, "content_hash": "8b8a007d15b8ebad81aaa3ea4d1b3f574b026196ac7b81ed5c66aef514b05a01", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:ba3cc56f45dbe079e85a8b22e5c57db6695c9aaa625b9263af440d13b6e168cc", "content": "NOTE: Observability features are currently supported only for `ChatModel` implementations from the following AI model\nproviders: Anthropic, Azure OpenAI, Mistral AI, Ollama, OpenAI, Vertex AI, MiniMax, Moonshot, QianFan, Zhipu AI.\nAdditional AI model providers will be supported in a future release.\n\nThe `gen_ai.client.operation` observations are recorded when calling the ChatModel `call` or `stream` methods.\nThey measure the time spent on method completion and propagate the related tracing information.\n\nIMPORTANT: The `gen_ai.client.token.usage` metrics measures number of input and output tokens used by a single model call.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name` | The name of the operation being performed.\n|`gen_ai.system` | The model provider as identified by the client instrumentation.\n|`gen_ai.request.model` | The name of the model a request is being made to.\n|`gen_ai.response.model` | The name of the model that generated the response.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.request.frequency_penalty` | The frequency penalty setting for the model request.\n|`gen_ai.request.max_tokens` | The maximum number of tokens the model generates for a request.\n|`gen_ai.request.presence_penalty` | The presence penalty setting for the model request.\n|`gen_ai.request.stop_sequences` | List of sequences that the model will use to stop generating further tokens.\n|`gen_ai.request.temperature` | The temperature setting for the model request.\n|`gen_ai.request.top_k` | The top_k sampling setting for the model request.\n|`gen_ai.request.top_p` | The top_p sampling setting for the model request.\n|`gen_ai.response.finish_reasons` | Reasons the model stopped generating tokens, corresponding to each generation received.\n|`gen_ai.response.id` | The unique identifier for the AI response.\n|`gen_ai.usage.input_tokens` | The number of tokens used in the model input (prompt).\n|`gen_ai.usage.output_tokens` | The number of tokens used in the model output (completion).\n|`gen_ai.usage.total_tokens` | The total number of tokens used in the model exchange.\n|`gen_ai.prompt` | The full prompt sent to the model. Optional.\n|`gen_ai.completion` | The full response received from the model. Optional.\n|`spring.ai.model.request.tool.names` | List of tool definitions provided to the model in the request.\n|===\n\nNOTE: For measuring user tokens, the previous table lists the values present in an observation trace.\nUse the metric name `gen_ai.client.token.usage` that is provided by the `ChatModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Model", "heading_level": 2, "file_order": 122, "section_index": 5, "content_hash": "ba3cc56f45dbe079e85a8b22e5c57db6695c9aaa625b9263af440d13b6e168cc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:d92ffe5a9fa221bdf83b17c090a9965f12a492c46f3b93a834b2a2f3966be717", "content": "The chat prompt and completion data is typically big and possibly containing sensitive information.\nFor those reasons, it is not exported by default.\n\nSpring AI supports logging chat prompt and completion data, useful for troubleshooting scenarios. When tracing is available, the logs will include trace information for better correlation.\n\n[cols=\"6,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| `spring.ai.chat.observations.log-prompt` | Log the prompt content. `true` or `false` | `false`\n| `spring.ai.chat.observations.log-completion` | Log the completion content. `true` or `false` | `false`\n| `spring.ai.chat.observations.include-error-logging` | Include error logging in observations. `true` or `false` | `false`\n|====\n\nWARNING: If you enable logging of the chat prompt and completion data, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Prompt and Completion Data", "heading_level": 3, "file_order": 122, "section_index": 6, "content_hash": "d92ffe5a9fa221bdf83b17c090a9965f12a492c46f3b93a834b2a2f3966be717", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:181273ab774446ce1e042c7acf130f8539232ae7949877d5717b7e2ba5322628", "content": "The `spring.ai.tool` observations are recorded when performing tool calling in the context of a chat model interaction. They measure the time spent on toll call completion and propagate the related tracing information.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name` | The name of the operation being performed. It's always `framework`.\n|`gen_ai.system` | The provider responsible for the operation. It's always `spring_ai`.\n|`spring.ai.kind` | The kind of operation performed by Spring AI. It's always `tool_call`.\n|`spring.ai.tool.definition.name` | The name of the tool.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n|`spring.ai.tool.definition.description` | Description of the tool.\n|`spring.ai.tool.definition.schema` | Schema of the parameters used to call the tool.\n|`spring.ai.tool.call.arguments` | The input arguments to the tool call. (Only when enabled)\n|`spring.ai.tool.call.result` | Schema of the parameters used to call the tool. (Only when enabled)\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Tool Calling", "heading_level": 2, "file_order": 122, "section_index": 7, "content_hash": "181273ab774446ce1e042c7acf130f8539232ae7949877d5717b7e2ba5322628", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:e85d6b33f1bc7a2e69d04305d2d6bd85aa599241c1053380759e718ea73f05c6", "content": "The input arguments and result from the tool call are not exported by default, as they can be potentially sensitive.\n\nSpring AI supports exporting tool call arguments and result data as span attributes.\n\n[cols=\"6,3,1\", stripes=even]\n|====\n| Property | Description | Default\n\n| `spring.ai.tools.observations.include-content` | Include the tool call content in observations. `true` or `false` | `false`\n|====\n\nWARNING: If you enable the inclusion of the tool call arguments and result in the observations, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Tool Call Arguments and Result Data", "heading_level": 3, "file_order": 122, "section_index": 8, "content_hash": "e85d6b33f1bc7a2e69d04305d2d6bd85aa599241c1053380759e718ea73f05c6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:a037add8826114ad619622cb1a6773fb35de4b8ab32aa1982ecb8b0915e724a8", "content": "NOTE: Observability features are currently supported only for `EmbeddingModel` implementations from the following\nAI model providers: Azure OpenAI, Mistral AI, Ollama, and OpenAI.\nAdditional AI model providers will be supported in a future release.\n\nThe `gen_ai.client.operation` observations are recorded on embedding model method calls.\nThey measure the time spent on method completion and propagate the related tracing information.\n\nIMPORTANT: The `gen_ai.client.token.usage` metrics measures number of input and output tokens used by a single model call.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name` | The name of the operation being performed.\n|`gen_ai.system` | The model provider as identified by the client instrumentation.\n|`gen_ai.request.model` | The name of the model a request is being made to.\n|`gen_ai.response.model` | The name of the model that generated the response.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.request.embedding.dimensions` | The number of dimensions the resulting output embeddings have.\n|`gen_ai.usage.input_tokens` | The number of tokens used in the model input.\n|`gen_ai.usage.total_tokens` | The total number of tokens used in the model exchange.\n|===\n\nNOTE: For measuring user tokens, the previous table lists the values present in an observation trace.\nUse the metric name `gen_ai.client.token.usage` that is provided by the `EmbeddingModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "EmbeddingModel", "heading_level": 2, "file_order": 122, "section_index": 9, "content_hash": "a037add8826114ad619622cb1a6773fb35de4b8ab32aa1982ecb8b0915e724a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:f93293e3614c77f36eee90e2c1fd70b911e3e16cd86dc5ef502d17cb9c2766fc", "content": "NOTE: Observability features are currently supported only for `ImageModel` implementations from the following AI model\nproviders: OpenAI.\nAdditional AI model providers will be supported in a future release.\n\nThe `gen_ai.client.operation` observations are recorded on image model method calls.\nThey measure the time spent on method completion and propagate the related tracing information.\n\nIMPORTANT: The `gen_ai.client.token.usage` metrics measures number of input and output tokens used by a single model call.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`gen_ai.operation.name`| The name of the operation being performed.\n|`gen_ai.system`| The model provider as identified by the client instrumentation.\n|`gen_ai.request.model`| The name of the model a request is being made to.\n|===\n\n.High Cardinality Keys\n|===\n|Name | Description\n\n|`gen_ai.request.image.response_format` | The format in which the generated image is returned.\n|`gen_ai.request.image.size` | The size of the image to generate.\n|`gen_ai.request.image.style` | The style of the image to generate.\n|`gen_ai.response.id` | The unique identifier for the AI response.\n|`gen_ai.response.model` | The name of the model that generated the response.\n|`gen_ai.usage.input_tokens` | The number of tokens used in the model input (prompt).\n|`gen_ai.usage.output_tokens` | The number of tokens used in the model output (generation).\n|`gen_ai.usage.total_tokens` | The total number of tokens used in the model exchange.\n|`gen_ai.prompt` | The full prompt sent to the model. Optional.\n|===\n\nNOTE: For measuring user tokens, the previous table lists the values present in an observation trace.\nUse the metric name `gen_ai.client.token.usage` that is provided by the `ImageModel`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Image Model", "heading_level": 2, "file_order": 122, "section_index": 10, "content_hash": "f93293e3614c77f36eee90e2c1fd70b911e3e16cd86dc5ef502d17cb9c2766fc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:cb1e699781a55bbc92c4295534d838e4e5e1e7d3cb004ad6756e6d8bde3792fe", "content": "The image prompt data is typically big and possibly containing sensitive information.\nFor those reasons, it is not exported by default.\n\nSpring AI supports logging image prompt data, useful for troubleshooting scenarios. When tracing is available, the logs will include trace information for better correlation.\n\n[cols=\"6,3,1\", stripes=even]\n|===\n| Property | Description | Default\n\n| `spring.ai.image.observations.log-prompt` | Log the image prompt content. `true` or `false` | `false`\n|===\n\nWARNING: If you enable logging of the image prompt data, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Image Prompt Data", "heading_level": 3, "file_order": 122, "section_index": 11, "content_hash": "cb1e699781a55bbc92c4295534d838e4e5e1e7d3cb004ad6756e6d8bde3792fe", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:bf2cb7df9a44fa0baa4f4ec1150d5c373f689dbdc8710dd1899ab965c1e05478", "content": "All vector store implementations in Spring AI are instrumented to provide metrics and distributed tracing data through Micrometer.\n\nThe `db.vector.client.operation` observations are recorded when interacting with the Vector Store.\nThey measure the time spent on the `query`, `add` and `remove` operations and propagate the related tracing information.\n\n.Low Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`db.operation.name` | The name of the operation or command being executed. One of `add`, `delete`, or `query`.\n|`db.system` | The database management system (DBMS) product as identified by the client instrumentation. One of `pg_vector`, `azure`, `cassandra`, `chroma`, `elasticsearch`, `milvus`, `neo4j`, `opensearch`, `qdrant`, `redis`, `typesense`, `weaviate`, `pinecone`, `oracle`, `mongodb`, `gemfire`, `hana`, `simple`.\n|`spring.ai.kind` | The kind of framework API in Spring AI: `vector_store`.\n|===\n\n.High Cardinality Keys\n[cols=\"a,a\", stripes=even]\n|===\n|Name | Description\n\n|`db.collection.name` | The name of a collection (table, container) within the database.\n|`db.namespace` | The name of the database, fully qualified within the server address and port.\n|`db.record.id` | The record identifier if present.\n|`db.search.similarity_metric` | The metric used in similarity search.\n|`db.vector.dimension_count` | The dimension of the vector.\n|`db.vector.field_name` | The name field as of the vector (e.g. a field name).\n|`db.vector.query.content` | The content of the search query being executed.\n|`db.vector.query.filter` | The metadata filters used in the search query.\n|`db.vector.query.response.documents` | Returned documents from a similarity search query. Optional.\n|`db.vector.query.similarity_threshold` | Similarity threshold that accepts all search scores. A threshold value of 0.0 means any similarity is accepted or disable the similarity threshold filtering. A threshold value of 1.0 means an exact match is required.\n|`db.vector.query.top_k` | The top-k most similar vectors returned by a query.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Vector Stores", "heading_level": 2, "file_order": 122, "section_index": 12, "content_hash": "bf2cb7df9a44fa0baa4f4ec1150d5c373f689dbdc8710dd1899ab965c1e05478", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:aeb755a88dffc6c7400e5c811ff3fa71ae41fb9dda6094752f43a88ba64fda68", "content": "The vector search response data is typically big and possibly containing sensitive information.\nFor those reasons, it is not exported by default.\n\nSpring AI supports logging vector search response data, useful for troubleshooting scenarios. When tracing is available, the logs will include trace information for better correlation.\n\n[cols=\"6,3,1\", stripes=even]\n|===\n| Property | Description | Default\n\n| `spring.ai.vectorstore.observations.log-query-response` | Log the vector store query response content. `true` or `false` | `false`\n|===\n\nWARNING: If you enable logging of the vector search response data, there's a risk of exposing sensitive or private information. Please, be careful!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Response Data", "heading_level": 3, "file_order": 122, "section_index": 13, "content_hash": "aeb755a88dffc6c7400e5c811ff3fa71ae41fb9dda6094752f43a88ba64fda68", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:e9f07e538c781e3755083dea8003ba3021194cbe3bd75bfdb6615125eff2d1a2", "content": "This section documents the metrics emitted by Spring AI components as they appear in Prometheus.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "More Metrics Reference", "heading_level": 2, "file_order": 122, "section_index": 14, "content_hash": "e9f07e538c781e3755083dea8003ba3021194cbe3bd75bfdb6615125eff2d1a2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:f3f547bb4e76b543e27a0a3e8000eb1a1d280d30ff38e05fce7fef290c18db36", "content": "Spring AI uses Micrometer. Base metric names use dots (e.g., `gen_ai.client.operation`), which Prometheus exports with underscores and standard suffixes:\n\n* **Timers** → `<base>_seconds_count`, `<base>_seconds_sum`, `<base>_seconds_max`, and (when supported) `<base>_active_count`\n* **Counters** → `<base>_total` (monotonic)\n\n[NOTE]\n====\nThe following shows how base metric names expand to Prometheus time series.\n\n[cols=\"2,3\", options=\"header\", stripes=even]\n|===\n| Base metric name | Exported time series\n| `gen_ai.client.operation` |\n`gen_ai_client_operation_seconds_count` +\n`gen_ai_client_operation_seconds_sum` +\n`gen_ai_client_operation_seconds_max` +\n`gen_ai_client_operation_active_count`\n| `db.vector.client.operation` |\n`db_vector_client_operation_seconds_count` +\n`db_vector_client_operation_seconds_sum` +\n`db_vector_client_operation_seconds_max` +\n`db_vector_client_operation_active_count`\n|===\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Metric Naming Conventions", "heading_level": 3, "file_order": 122, "section_index": 15, "content_hash": "f3f547bb4e76b543e27a0a3e8000eb1a1d280d30ff38e05fce7fef290c18db36", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:3e2d19616cc9f8e363e3ef5fcbc62acae35dd2250d00db91261827fc9053ac78", "content": "* OpenTelemetry — https://opentelemetry.io/docs/specs/semconv/gen-ai/[Semantic Conventions for Generative AI (overview)]\n* Micrometer — https://docs.micrometer.io/micrometer/reference/concepts/naming.html[Naming Meters]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "References", "heading_level": 4, "file_order": 122, "section_index": 16, "content_hash": "3e2d19616cc9f8e363e3ef5fcbc62acae35dd2250d00db91261827fc9053ac78", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:0ee293b2deb1c45b84bffd7617b65efa37c503c450889b29be51e1b5c66711fd", "content": "[cols=\"2,2,1,3\", stripes=even]\n|===\n|Metric Name | Type | Unit | Description\n\n|`gen_ai_chat_client_operation_seconds_sum`\n|Timer\n|seconds\n|Total time spent in ChatClient operations (call/stream)\n\n|`gen_ai_chat_client_operation_seconds_count`\n|Counter\n|count\n|Number of completed ChatClient operations\n\n|`gen_ai_chat_client_operation_seconds_max`\n|Gauge\n|seconds\n|Maximum observed duration of ChatClient operations\n\n|`gen_ai_chat_client_operation_active_count`\n|Gauge\n|count\n|Number of ChatClient operations currently in flight\n|===\n\n*Active vs Completed*: `*_active_count` shows in-flight calls; the `_seconds_*` series reflect only completed calls.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Client Metrics", "heading_level": 3, "file_order": 122, "section_index": 17, "content_hash": "0ee293b2deb1c45b84bffd7617b65efa37c503c450889b29be51e1b5c66711fd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:27b848864c654701dc4e084e09b10ba58390d748179b614d540fe769d6d2987b", "content": "[cols=\"2,2,1,3\", stripes=even]\n|===\n|Metric Name | Type | Unit | Description\n\n|`gen_ai_client_operation_seconds_sum`\n|Timer\n|seconds\n|Total time executing chat model operations\n\n|`gen_ai_client_operation_seconds_count`\n|Counter\n|count\n|Number of completed chat model operations\n\n|`gen_ai_client_operation_seconds_max`\n|Gauge\n|seconds\n|Maximum observed duration for chat model operations\n\n|`gen_ai_client_operation_active_count`\n|Gauge\n|count\n|Number of chat model operations currently in flight\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Chat Model Metrics (Model provider execution)", "heading_level": 3, "file_order": 122, "section_index": 18, "content_hash": "27b848864c654701dc4e084e09b10ba58390d748179b614d540fe769d6d2987b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:cac810e9ca1d1b9c4f1a95ea1f3a66b766c6439e871cf0e2edc07d713f37c2a1", "content": "[cols=\"2,2,1,3\", stripes=even]\n|===\n|Metric Name | Type | Unit | Description\n\n|`gen_ai_client_token_usage_total`\n|Counter\n|tokens\n|Total tokens consumed, labeled by token type\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Token Usage", "heading_level": 4, "file_order": 122, "section_index": 19, "content_hash": "cac810e9ca1d1b9c4f1a95ea1f3a66b766c6439e871cf0e2edc07d713f37c2a1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:44f41ed6e34739e7f86421fd00470a6f17dbcafc5af0104ad9a7dd80a0e57407", "content": "[cols=\"2,3\", options=\"header\", stripes=even]\n|===\n|Label | Meaning\n|`gen_ai_token_type=input` | Prompt tokens sent to the model\n|`gen_ai_token_type=output` | Completion tokens returned by the model\n|`gen_ai_token_type=total` | Input + output\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Labels", "heading_level": 4, "file_order": 122, "section_index": 20, "content_hash": "44f41ed6e34739e7f86421fd00470a6f17dbcafc5af0104ad9a7dd80a0e57407", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:b7975b163f3fdcdc8adbbbf18e8c2b7009e3ca1196d24e7b9d1852b93d3ce048", "content": "[cols=\"2,2,1,3\", stripes=even]\n|===\n|Metric Name | Type | Unit | Description\n\n|`db_vector_client_operation_seconds_sum`\n|Timer\n|seconds\n|Total time spent in vector store operations (add/delete/query)\n\n|`db_vector_client_operation_seconds_count`\n|Counter\n|count\n|Number of completed vector store operations\n\n|`db_vector_client_operation_seconds_max`\n|Gauge\n|seconds\n|Maximum observed duration for vector store operations\n\n|`db_vector_client_operation_active_count`\n|Gauge\n|count\n|Number of vector store operations currently in flight\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Vector Store Metrics", "heading_level": 3, "file_order": 122, "section_index": 21, "content_hash": "b7975b163f3fdcdc8adbbbf18e8c2b7009e3ca1196d24e7b9d1852b93d3ce048", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:3b0bc7267f810908e997bf620acfa03e14d53a053f8d45ac496ba905111d1ee4", "content": "[cols=\"2,3\", options=\"header\", stripes=even]\n|===\n|Label | Meaning\n|`db_operation_name` | Operation type (`add`, `delete`, `query`)\n|`db_system` | Vector DB/provider (`redis`, `chroma`, `pgvector`, …)\n|`spring_ai_kind` | `vector_store`\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Labels", "heading_level": 4, "file_order": 122, "section_index": 22, "content_hash": "3b0bc7267f810908e997bf620acfa03e14d53a053f8d45ac496ba905111d1ee4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:2cc3ad63211668a730590e6c516aec90615dded61eaa24cec6267bdf6d685adf", "content": "* **Active (`*_active_count`)** — instantaneous gauge of in-progress operations (concurrency/load).\n* **Completed (`*_seconds_sum|count|max`)** — statistics for operations that have finished:\n* `_seconds_sum / _seconds_count` → average latency\n* `_seconds_max` → high-water mark since last scrape (subject to registry behavior)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/observability/index.adoc", "title": "index", "heading": "Understanding Active vs Completed", "heading_level": 3, "file_order": 122, "section_index": 23, "content_hash": "2cc3ad63211668a730590e6c516aec90615dded61eaa24cec6267bdf6d685adf", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/observability/index.adoc"}}
{"id": "sha256:e33645c30514f74be044a79a13125b8a884762c8620905f97144d6b3998ff2a1", "content": "[[hugging-face]]\n\nOne of the easiest ways you can get access to many machine learning and artificial intelligence models is by using the https://en.wikipedia.org/wiki/Hugging_Face[Hugging Face's] https://huggingface.co/inference-endpoints[Inference Endpoints].\n\nHugging Face Hub is a platform that provides a collaborative environment for creating and sharing tens of thousands of Open Source ML/AI models, data sets, and demo applications.\n\nInference Endpoints let you deploy AI Models on dedicated infrastructure with a pay-as-you-go billing model.\nYou can use infrastructure provided by Amazon Web Services, Microsoft Azure, and Google Cloud Platform.\nHugging Face lets you run the models on your own machine, but it is quite common to not have enough CPU/GPU resources to run the larger, more AI-focused models.\n\nIt provides access to Meta's recent (August 2023) Llama 2 and CodeLlama 2 models and provides the https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard[Open LLM Leaderboard], where you can quickly discover high quality models.\n\nWhile Hugging Face has a free hosting tier, which is very useful for quickly evaluating if a specific ML/AI Model fits your needs, they do not let you access many of those models on the free tier by using the https://huggingface.co/docs/text-generation-inference/main/en/index[Text Generation Interface API]. If you want to end up on production anyway, with a stable API, pay a few cents to try out a reliable solution. Prices are as low as $0.06 per CPU core/hr and $0.6 per GPU/hr.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/providers/huggingface/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 123, "section_index": 0, "content_hash": "e33645c30514f74be044a79a13125b8a884762c8620905f97144d6b3998ff2a1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/providers/huggingface/index.adoc"}}
{"id": "sha256:6839f2b0323158baa0e4067e57f2e07c88e07cb25a9a226317f3a4fc8891c473", "content": "[[concepts]]\n\nThis section describes core concepts that Spring AI uses. We recommend reading it closely to understand the ideas behind how Spring AI is implemented.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "concepts", "heading_level": 1, "file_order": 124, "section_index": 0, "content_hash": "6839f2b0323158baa0e4067e57f2e07c88e07cb25a9a226317f3a4fc8891c473", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:029503873af907f6f9dca789df9e2c75d7f913cdb58606fe1ffd8558e7f6eb21", "content": "AI models are algorithms designed to process and generate information, often mimicking human cognitive functions.\nBy learning patterns and insights from large datasets, these models can make predictions, text, images, or other outputs, enhancing various applications across industries.\n\nThere are many different types of AI models, each suited for a specific use case.\nWhile ChatGPT and its generative AI capabilities have captivated users through text input and output, many models and companies offer diverse inputs and outputs.\nBefore ChatGPT, many people were fascinated by text-to-image generation models such as Midjourney and Stable Diffusion.\n\nThe following table categorizes several models based on their input and output types:\n\nimage::spring-ai-concepts-model-types.jpg[Model types, width=600, align=\"center\"]\n\nSpring AI currently supports models that process input and output as language, image, and audio.\nThe last row in the previous table, which accepts text as input and outputs numbers, is more commonly known as embedding text and represents the internal data structures used in an AI model.\nSpring AI has support for embeddings to enable more advanced use cases.\n\nWhat sets models like GPT apart is their pre-trained nature, as indicated by the \"P\" in GPT—Chat Generative Pre-trained Transformer.\nThis pre-training feature transforms AI into a general developer tool that does not require an extensive machine learning or model training background.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Models", "heading_level": 2, "file_order": 124, "section_index": 1, "content_hash": "029503873af907f6f9dca789df9e2c75d7f913cdb58606fe1ffd8558e7f6eb21", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:73908336fcb96a462828b09df5e330c3042c1b18084c98c730e2c6ac4f034d02", "content": "Prompts serve as the foundation for the language-based inputs that guide an AI model to produce specific outputs.\nFor those familiar with ChatGPT, a prompt might seem like merely the text entered into a dialog box that is sent to the API.\nHowever, it encompasses much more than that.\nIn many AI Models, the text for the prompt is not just a simple string.\n\nChatGPT's API has multiple text inputs within a prompt, with each text input being assigned a role.\nFor example, there is the system role, which tells the model how to behave and sets the context for the interaction.\nThere is also the user role, which is typically the input from the user.\n\nCrafting effective prompts is both an art and a science.\nChatGPT was designed for human conversations.\nThis is quite a departure from using something like SQL to \"ask a question\".\nOne must communicate with the AI model akin to conversing with another person.\n\nSuch is the importance of this interaction style that the term \"Prompt Engineering\" has emerged as its own discipline.\nThere is a burgeoning collection of techniques that improve the effectiveness of prompts.\nInvesting time in crafting a prompt can drastically improve the resulting output.\n\nSharing prompts has become a communal practice, and there is active academic research being done on this subject.\nAs an example of how counter-intuitive it can be to create an effective prompt (for example, contrasting with SQL), a https://arxiv.org/abs/2205.11916[recent research paper] found that one of the most effective prompts you can use starts with the phrase, \"`Take a deep breath and work on this step by step.`\"\nThat should give you an indication of why language is so important.\nWe do not yet fully understand how to make the most effective use of previous iterations of this technology, such as ChatGPT 3.5, let alone new versions that are being developed.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Prompts", "heading_level": 2, "file_order": 124, "section_index": 2, "content_hash": "73908336fcb96a462828b09df5e330c3042c1b18084c98c730e2c6ac4f034d02", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:1bfd39f0594a2af16268376c82dd6f4af701a59166d363ba99b73f1ae4234ca4", "content": "Creating effective prompts involves establishing the context of the request and substituting parts of the request with values specific to the user's input.\n\nThis process uses traditional text-based template engines for prompt creation and management.\nSpring AI employs the OSS library https://www.stringtemplate.org/[StringTemplate] for this purpose.\n\nFor instance, consider the simple prompt template:\n\n```\nTell me a {adjective} joke about {content}.\n```\n\nIn Spring AI, prompt templates can be likened to the \"View\" in Spring MVC architecture.\nA model object, typically a `java.util.Map`, is provided to populate placeholders within the template.\nThe \"rendered\" string becomes the content of the prompt supplied to the AI model.\n\nThere is considerable variability in the specific data format of the prompt sent to the model.\nInitially starting as simple strings, prompts have evolved to include multiple messages, where each string in each message represents a distinct role for the model.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Prompt Templates", "heading_level": 3, "file_order": 124, "section_index": 3, "content_hash": "1bfd39f0594a2af16268376c82dd6f4af701a59166d363ba99b73f1ae4234ca4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:80fb60f2169b2b1d3678be1296b68aa2150ce99a671d2b67bd975327225926ad", "content": "Embeddings are numerical representations of text, images, or videos that capture relationships between inputs.\n\nEmbeddings work by converting text, image, and video into arrays of floating point numbers, called vectors.\nThese vectors are designed to capture the meaning of the text, images, and videos.\nThe length of the embedding array is called the vector's dimensionality.\n\nBy calculating the numerical distance between the vector representations of two pieces of text, an application can determine the similarity between the objects used to generate the embedding vectors.\n\nimage::spring-ai-embeddings.jpg[Embeddings, width=900, align=\"center\"]\n\nAs a Java developer exploring AI, it's not necessary to comprehend the intricate mathematical theories or the specific implementations behind these vector representations.\nA basic understanding of their role and function within AI systems suffices, particularly when you're integrating AI functionalities into your applications.\n\nEmbeddings are particularly relevant in practical applications like the Retrieval Augmented Generation (RAG) pattern.\nThey enable the representation of data as points in a semantic space, which is akin to the 2-D space of Euclidean geometry, but in higher dimensions.\nThis means just like how points on a plane in Euclidean geometry can be close or far based on their coordinates, in a semantic space, the proximity of points reflects the similarity in meaning.\nSentences about similar topics are positioned closer in this multi-dimensional space, much like points lying close to each other on a graph.\nThis proximity aids in tasks like text classification, semantic search, and even product recommendations, as it allows the AI to discern and group related concepts based on their \"location\" in this expanded semantic landscape.\n\nYou can think of this semantic space as a vector.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Embeddings", "heading_level": 2, "file_order": 124, "section_index": 4, "content_hash": "80fb60f2169b2b1d3678be1296b68aa2150ce99a671d2b67bd975327225926ad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:82e8402d16763f41d34a49595bdc602295cb0218fa7e3f5b54c4d59f70a1dd2b", "content": "Tokens serve as the building blocks of how an AI model works.\nOn input, models convert words to tokens. On output, they convert tokens back to words.\n\nIn English, one token roughly corresponds to 75% of a word. For reference, Shakespeare's complete works, totaling around 900,000 words, translate to approximately 1.2 million tokens.\n\nimage::spring-ai-concepts-tokens.png[Tokens, width=600, align=\"center\"]\n\nPerhaps more important is that Tokens = Money.\nIn the context of hosted AI models, your charges are determined by the number of tokens used. Both input and output contribute to the overall token count.\n\nAlso, models are subject to token limits, which restrict the amount of text processed in a single API call.\nThis threshold is often referred to as the \"context window\". The model does not process any text that exceeds this limit.\n\nFor instance, ChatGPT3 has a 4K token limit, while GPT4 offers varying options, such as 8K, 16K, and 32K.\nAnthropic's Claude AI model features a 100K token limit, and Meta's recent research yielded a 1M token limit model.\n\nTo summarize the collected works of Shakespeare with GPT4, you need to devise software engineering strategies to chop up the data and present the data within the model's context window limits.\nThe Spring AI project helps you with this task.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Tokens", "heading_level": 2, "file_order": 124, "section_index": 5, "content_hash": "82e8402d16763f41d34a49595bdc602295cb0218fa7e3f5b54c4d59f70a1dd2b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:9cd0e98f808dab59634daf4af51196a177ee385def49735ff623123221b4165f", "content": "The output of AI models traditionally arrives as a `java.lang.String`, even if you ask for the reply to be in JSON.\nIt may be a correct JSON, but it is not a JSON data structure. It is just a string.\nAlso, asking \"`for JSON`\" as part of the prompt is not 100% accurate.\n\nThis intricacy has led to the emergence of a specialized field involving the creation of prompts to yield the intended output, followed by converting the resulting simple string into a usable data structure for application integration.\n\nimage::structured-output-architecture.jpg[Structured Output Converter Architecture, width=800, align=\"center\"]\n\nThe xref:api/structured-output-converter.adoc#_structuredoutputconverter[Structured output conversion] employs meticulously crafted prompts, often necessitating multiple interactions with the model to achieve the desired formatting.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Structured Output", "heading_level": 2, "file_order": 124, "section_index": 6, "content_hash": "9cd0e98f808dab59634daf4af51196a177ee385def49735ff623123221b4165f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:6021d39ae9c5b57b6b59568597116249dd2bc76d185936269413f2595ddfe0aa", "content": "How can you equip the AI model with information on which it has not been trained?\n\nNote that the GPT 3.5/4.0 dataset extends only until September 2021.\nConsequently, the model says that it does not know the answer to questions that require knowledge beyond that date.\nAn interesting bit of trivia is that this dataset is around 650GB.\n\nThree techniques exist for customizing the AI model to incorporate your data:\n\n* **Fine Tuning**: This traditional machine learning technique involves tailoring the model and changing its internal weighting.\nHowever, it is a challenging process for machine learning experts and extremely resource-intensive for models like GPT due to their size. Additionally, some models might not offer this option.\n\n* **Prompt Stuffing**: A more practical alternative involves embedding your data within the prompt provided to the model. Given a model's token limits, techniques are required to present relevant data within the model's context window.\nThis approach is colloquially referred to as \"`stuffing the prompt.`\"\nThe Spring AI library helps you implement solutions based on the \"`stuffing the prompt`\" technique otherwise known as xref::concepts.adoc#concept-rag[Retrieval Augmented Generation (RAG)].\n\nimage::spring-ai-prompt-stuffing.jpg[Prompt stuffing, width=700, align=\"center\"]\n\n* **xref::concepts.adoc#concept-fc[Tool Calling]**: This technique allows registering tools (user-defined services) that connect the large language models to the APIs of external systems.\nSpring AI greatly simplifies code you need to write to support xref:api/tools.adoc[tool calling].\n\n[[concept-rag]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Bringing Your Data & APIs to the AI Model", "heading_level": 2, "file_order": 124, "section_index": 7, "content_hash": "6021d39ae9c5b57b6b59568597116249dd2bc76d185936269413f2595ddfe0aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:e6cb87ee8e848aa2d9b5a150e88ac9c8eee936a6d62c1b3110445bfcf80419d3", "content": "A technique termed Retrieval Augmented Generation (RAG) has emerged to address the challenge of incorporating relevant data into prompts for accurate AI model responses.\n\nThe approach involves a batch processing style programming model, where the job reads unstructured data from your documents, transforms it, and then writes it into a vector database.\nAt a high level, this is an ETL (Extract, Transform and Load) pipeline.\nThe vector database is used in the retrieval part of RAG technique.\n\nAs part of loading the unstructured data into the vector database, one of the most important transformations is to split the original document into smaller pieces.\nThe procedure of splitting the original document into smaller pieces has two important steps:\n\n. Split the document into parts while preserving the semantic boundaries of the content.\nFor example, for a document with paragraphs and tables, one should avoid splitting the document in the middle of a paragraph or table.\nFor code, avoid splitting the code in the middle of a method's implementation.\n. Split the document's parts further into parts whose size is a small percentage of the AI Model's token limit.\n\nThe next phase in RAG is processing user input.\nWhen a user's question is to be answered by an AI model, the question and all the \"`similar`\" document pieces are placed into the prompt that is sent to the AI model.\nThis is the reason to use a vector database. It is very good at finding similar content.\n\nimage::spring-ai-rag.jpg[Spring AI RAG, width=1000, align=\"center\"]\n\n* The xref::api/etl-pipeline.adoc[ETL Pipeline] provides further information about orchestrating the flow of extracting data from data sources and storing it in a structured vector store, ensuring data is in the optimal format for retrieval when passing it to the AI model.\n* The xref::api/chatclient.adoc#_retrieval_augmented_generation[ChatClient - RAG] explains how to use the `QuestionAnswerAdvisor` to enable the RAG capability in your application.\n\n[[concept-fc]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Retrieval Augmented Generation", "heading_level": 3, "file_order": 124, "section_index": 8, "content_hash": "e6cb87ee8e848aa2d9b5a150e88ac9c8eee936a6d62c1b3110445bfcf80419d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:66b4008569ab53e9dbaffdc8713877fcbcbf9ec7d0e782f9d3525474bb40b3c3", "content": "Large Language Models (LLMs) are frozen after training, leading to stale knowledge, and they are unable to access or modify external data.\n\nThe xref::api/tools.adoc[Tool Calling] mechanism addresses these shortcomings.\nIt allows you to register your own services as tools to connect the large language models to the APIs of external systems.\nThese systems can provide LLMs with real-time data and perform data processing actions on their behalf.\n\nSpring AI greatly simplifies code you need to write to support tool invocation.\nIt handles the tool invocation conversation for you.\nYou can provide your tool as a `@Tool`-annotated method and provide it in your prompt options to make it available to the model.\nAdditionally, you can define and reference multiple tools in a single prompt.\n\nimage::tools/tool-calling-01.jpg[The main sequence of actions for tool calling, width=700, align=\"center\"]\n\n1. When we want to make a tool available to the model, we include its definition in the chat request. Each tool definition comprises of a name, a description, and the schema of the input parameters.\n2. When the model decides to call a tool, it sends a response with the tool name and the input parameters modeled after the defined schema.\n3. The application is responsible for using the tool name to identify and execute the tool with the provided input parameters.\n4. The result of the tool call is processed by the application.\n5. The application sends the tool call result back to the model.\n6. The model generates the final response using the tool call result as additional context.\n\nFollow the xref::api/tools.adoc[Tool Calling] documentation for further information on how to use this feature with different AI models.\n\n[[concept-evaluating-ai-responses]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Tool Calling", "heading_level": 3, "file_order": 124, "section_index": 9, "content_hash": "66b4008569ab53e9dbaffdc8713877fcbcbf9ec7d0e782f9d3525474bb40b3c3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:6637cc8f00a7d5d278102a77e699997c686cf911925f7ed899c05ae6407a9c76", "content": "Effectively evaluating the output of an AI system in response to user requests is very important to ensuring the accuracy and usefulness of the final application.\nSeveral emerging techniques enable the use of the pre-trained model itself for this purpose.\n\nThis evaluation process involves analyzing whether the generated response aligns with the user's intent and the context of the query. Metrics such as relevance, coherence, and factual correctness are used to gauge the quality of the AI-generated response.\n\nOne approach involves presenting both the user's request and the AI model's response to the model, querying whether the response aligns with the provided data.\n\nFurthermore, leveraging the information stored in the vector database as supplementary data can enhance the evaluation process, aiding in the determination of response relevance.\n\nThe Spring AI project provides an `Evaluator` API which currently gives access to basic strategies to evaluate model responses.\nFollow the xref::api/testing.adoc[Evaluation Testing] documentation for further information.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/concepts.adoc", "title": "concepts", "heading": "Evaluating AI responses", "heading_level": 2, "file_order": 124, "section_index": 10, "content_hash": "6637cc8f00a7d5d278102a77e699997c686cf911925f7ed899c05ae6407a9c76", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/concepts.adoc"}}
{"id": "sha256:3fe5751ad21080ab925e5aa7f875259f85fd8473af91a2dca2fd8d7a43e3e2aa", "content": "[[contribution-guidelines]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/contribution-guidelines.adoc", "title": "contribution-guidelines", "heading": "contribution-guidelines", "heading_level": 1, "file_order": 125, "section_index": 0, "content_hash": "3fe5751ad21080ab925e5aa7f875259f85fd8473af91a2dca2fd8d7a43e3e2aa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/contribution-guidelines.adoc"}}
{"id": "sha256:529cd3330de5985e0c77ddf98faf48289c654fc589debf18f15087eed4ebd510", "content": "Before submitting a PR, please run the following commands to ensure proper formatting and Javadoc processing\n\n```\n./mvnw spring-javaformat:apply javadoc:javadoc -Pjavadoc\n```\n\nThe `-Pjavadoc` is a profile that enables Javadoc processing so as to avoid a long build time when developing.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/contribution-guidelines.adoc", "title": "contribution-guidelines", "heading": "Code Formatting and Javadoc", "heading_level": 2, "file_order": 125, "section_index": 1, "content_hash": "529cd3330de5985e0c77ddf98faf48289c654fc589debf18f15087eed4ebd510", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/contribution-guidelines.adoc"}}
{"id": "sha256:67138981f3b3184be9d6f5972a0420f4cbed90de6edb3500961005ffe4edbe2d", "content": "This section outlines the steps for contributing a new AI model implementation.\nAI models vary significantly, with diverse inputs and outputs -- from chat models that\ntranslate text input into text output, to text-to-image models that generate images\nfrom text descriptions.\nComplex models may even handle multiple types of input and output, such as combining text,\nimages, and videos to produce mixed media output.\n\nTo contribute a new model, adhere to the following steps:\n\n. *Create a Low-Level Client API Class*: If no existing Java client suits the AI model,\nyou'll need to develop a low-level client API class. This often involves utilizing the\n`RestClient` class from the Spring Framework, similar to the `OpenAiApi` class.\n\n. *Create a Model implementation*\nEnsure your client conforms to the link:https://docs.spring.io/spring-ai/reference/api/generic-model.html[Generic Model API].\nUse existing request and response classes if your model's inputs and outputs are supported.\nIf not, create new classes for the Generic Model API and establish a new Java package.\nWhen logging Personally Identifiable Information (PII), mark it with https://github.com/spring-projects/spring-ai/tree/main/spring-ai-core/src/main/java/org/springframework/ai/util/LoggingMarkers.java[`PII_MARKER`] Slf4j marker.\n\n. *Implement Auto-Configuration and a Spring Boot Starter*: This step involves creating the\nnecessary auto-configuration and Spring Boot Starter to easily instantiate the new model with\nSpring Boot applications.\n\n. *Write Tests*: All new classes should be accompanied by comprehensive tests.\nExisting tests can serve as a useful reference for structuring and implementing your tests.\n\n. *Document Your Contribution*: Ensure your documentation follows the existing format,\nFor an example of the suggested structure and formatting, refer to the\nlink:https://docs.spring.io/spring-ai/reference/api/chat/openai-chat.html[Open AI Chat documentation].\n\nBy following these guidelines, we can greatly expand the framework's range of supported models\nwhile following a common implementation and documentation pattern.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/contribution-guidelines.adoc", "title": "contribution-guidelines", "heading": "Contributing a New AI Model Implementation", "heading_level": 2, "file_order": 125, "section_index": 2, "content_hash": "67138981f3b3184be9d6f5972a0420f4cbed90de6edb3500961005ffe4edbe2d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/contribution-guidelines.adoc"}}
{"id": "sha256:d0cb489951699923d9c1ef8b13b7075ba8765607098abf3e1f29fb5e2a38d8bc", "content": "[[getting-started]]\n\nThis section offers jumping off points for how to get started using Spring AI.\n\nYou should follow the steps in each of the following sections according to your needs.\n\nNOTE: Spring AI supports Spring Boot 3.4.x and 3.5.x.\n\n[[spring-initializr]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "getting-started", "heading_level": 1, "file_order": 126, "section_index": 0, "content_hash": "d0cb489951699923d9c1ef8b13b7075ba8765607098abf3e1f29fb5e2a38d8bc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:49b82ec542469c2769dab71ae6b54a5c388ec8875c0c6420ea27831d1cf94f96", "content": "Head on over to https://start.spring.io/[start.spring.io] and select the AI Models and Vector Stores that you want to use in your new applications.\n\n[[artifact-repositories]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Spring Initializr", "heading_level": 2, "file_order": 126, "section_index": 1, "content_hash": "49b82ec542469c2769dab71ae6b54a5c388ec8875c0c6420ea27831d1cf94f96", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:29cfcdd5602cc724fc1d25d19e70b0e43d44e918cc01ad98825dd47757f8a038", "content": "Spring AI 1.0.0 and later versions are available in Maven Central.\nNo additional repository configuration is required. Just make sure you have Maven Central enabled in your build file.\n\n[tabs]\n======\nMaven::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<!-- Maven Central is included by default in Maven builds.\n You usually don’t need to configure it explicitly,\n but it's shown here for clarity. -->\n<repositories>\n <repository>\n <id>central</id>\n <url>https://repo.maven.apache.org/maven2</url>\n </repository>\n</repositories>\n----\n\nGradle::\n+\n[source,groovy,indent=0,subs=\"verbatim,quotes\"]\n----\nrepositories {\n mavenCentral()\n}\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Releases - Use Maven Central", "heading_level": 3, "file_order": 126, "section_index": 2, "content_hash": "29cfcdd5602cc724fc1d25d19e70b0e43d44e918cc01ad98825dd47757f8a038", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:aaf69a356551a48e5b4465bbb5c055d0edfefec24611cf267798491dc693ba82", "content": "To use the latest development versions (e.g. `1.1.0-SNAPSHOT`) or older milestone versions before 1.0.0, you need to add the following snapshot repositories in your build file.\n\nAdd the following repository definitions to your Maven or Gradle build file:\n\n[tabs]\n======\nMaven::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n <repositories>\n <repository>\n <id>spring-snapshots</id>\n <name>Spring Snapshots</name>\n <url>https://repo.spring.io/snapshot</url>\n <releases>\n <enabled>false</enabled>\n </releases>\n </repository>\n <repository>\n <name>Central Portal Snapshots</name>\n <id>central-portal-snapshots</id>\n <url>https://central.sonatype.com/repository/maven-snapshots/</url>\n <releases>\n <enabled>false</enabled>\n </releases>\n <snapshots>\n <enabled>true</enabled>\n </snapshots>\n </repository>\n </repositories>\n----\n\nGradle::\n+\n[source,groovy,indent=0,subs=\"verbatim,quotes\"]\n----\nrepositories {\n mavenCentral()\n maven { url 'https://repo.spring.io/milestone' }\n maven { url 'https://repo.spring.io/snapshot' }\n maven {\n name = 'Central Portal Snapshots'\n url = 'https://central.sonatype.com/repository/maven-snapshots/'\n }\n}\n----\n======\n\n**NOTE:** When using Maven with Spring AI snapshots, pay attention to your Maven mirror configuration. If you have configured a mirror in your `settings.xml` like this:\n\n[source,xml]\n----\n<mirror>\n <id>my-mirror</id>\n <mirrorOf>*</mirrorOf>\n <url>https://my-company-repository.com/maven</url>\n</mirror>\n----\n\nThe wildcard `*` will redirect all repository requests to your mirror, preventing access to Spring snapshot repositories. To fix this, modify the `mirrorOf` configuration to exclude Spring repositories:\n\n[source,xml]\n----\n<mirror>\n <id>my-mirror</id>\n <mirrorOf>*,!spring-snapshots,!central-portal-snapshots</mirrorOf>\n <url>https://my-company-repository.com/maven</url>\n</mirror>\n----\n\nThis configuration allows Maven to access Spring snapshot repositories directly while still using your mirror for other dependencies.\n\n[[dependency-management]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Snapshots - Add Snapshot Repositories", "heading_level": 3, "file_order": 126, "section_index": 3, "content_hash": "aaf69a356551a48e5b4465bbb5c055d0edfefec24611cf267798491dc693ba82", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:af9101788321c4741ace77dd5b55097902b053d2f3a9c1c85c5f9c14e0836c54", "content": "The Spring AI Bill of Materials (BOM) declares the recommended versions of all the dependencies used by a given release of Spring AI.\nThis is a BOM-only version and it just contains dependency management and no plugin declarations or direct references to Spring or Spring Boot.\nYou can use the Spring Boot parent POM, or use the BOM from Spring Boot (`spring-boot-dependencies`) to manage Spring Boot versions.\n\nAdd the BOM to your project:\n\n[tabs]\n======\nMaven::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<dependencyManagement>\n <dependencies>\n <dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-bom</artifactId>\n <version>1.0.0</version>\n <type>pom</type>\n <scope>import</scope>\n </dependency>\n </dependencies>\n</dependencyManagement>\n----\n\nGradle::\n+\n[source,groovy,indent=0,subs=\"verbatim,quotes\"]\n----\ndependencies {\n implementation platform(\"org.springframework.ai:spring-ai-bom:1.0.0\")\n // Replace the following with the specific module dependencies (e.g., spring-ai-openai) or starter modules (e.g., spring-ai-starter-model-openai) that you wish to use\n implementation 'org.springframework.ai:spring-ai-openai'\n}\n----\n+\nGradle users can also use the Spring AI BOM by leveraging Gradle (5.0+) native support for declaring dependency constraints using a Maven BOM. This is implemented by adding a 'platform' dependency handler method to the dependencies section of your Gradle build script.\n======\n\n[[add-dependencies]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Dependency Management", "heading_level": 2, "file_order": 126, "section_index": 4, "content_hash": "af9101788321c4741ace77dd5b55097902b053d2f3a9c1c85c5f9c14e0836c54", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:60a2d9ed7020ac4758d3bc1b26da8e214dc3cedb14aa155d588dacc12a65434c", "content": "Each of the following sections in the documentation shows which dependencies you need to add to your project build system.\n\n* xref:api/chatmodel.adoc[Chat Models]\n* xref:api/embeddings.adoc[Embeddings Models]\n* xref:api/imageclient.adoc[Image Generation Models]\n* xref:api/audio/transcriptions.adoc[Transcription Models]\n* xref:api/audio/speech.adoc[Text-To-Speech (TTS) Models]\n* xref:api/vectordbs.adoc[Vector Databases]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Add dependencies for specific components", "heading_level": 2, "file_order": 126, "section_index": 5, "content_hash": "60a2d9ed7020ac4758d3bc1b26da8e214dc3cedb14aa155d588dacc12a65434c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:9da2688f73dbacd4c8a37d4e5663cead797ee52bed8eded3932fd6c2ae98c78b", "content": "Please refer to https://github.com/spring-ai-community/awesome-spring-ai[this page] for more resources and samples related to Spring AI.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/getting-started.adoc", "title": "getting-started", "heading": "Spring AI samples", "heading_level": 2, "file_order": 126, "section_index": 6, "content_hash": "9da2688f73dbacd4c8a37d4e5663cead797ee52bed8eded3932fd6c2ae98c78b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/getting-started.adoc"}}
{"id": "sha256:0c0cd8b6849c3c3bf9640030d2a46450b279ec78964a4bd7b70c6a15704228bd", "content": "[[appendix]]\n[[glossary]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/glossary.adoc", "title": "glossary", "heading": "glossary", "heading_level": 1, "file_order": 127, "section_index": 0, "content_hash": "0c0cd8b6849c3c3bf9640030d2a46450b279ec78964a4bd7b70c6a15704228bd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/glossary.adoc"}}
{"id": "sha256:6772af934ea86911b4d5785e1575dd47389494f85899e94515b6ae63d6d5938d", "content": "[[introduction]]\n\nimage::spring_ai_logo_with_text.svg[Integration Problem, width=300, align=\"left\"]\n\nThe `Spring AI` project aims to streamline the development of applications that incorporate artificial intelligence functionality without unnecessary complexity.\n\nThe project draws inspiration from notable Python projects, such as LangChain and LlamaIndex, but Spring AI is not a direct port of those projects.\nThe project was founded with the belief that the next wave of Generative AI applications will not be only for Python developers but will be ubiquitous across many programming languages.\n\nNOTE: Spring AI addresses the fundamental challenge of AI integration: `Connecting your enterprise Data and APIs with AI Models`.\n\nimage::spring-ai-integration-diagram-3.svg[Interactive,500,opts=interactive]\n\nSpring AI provides abstractions that serve as the foundation for developing AI applications.\nThese abstractions have multiple implementations, enabling easy component swapping with minimal code changes.\n\nSpring AI provides the following features:\n\n* Portable API support across AI providers for Chat, text-to-image, and Embedding models. Both synchronous and streaming API options are supported. Access to model-specific features is also available.\n* Support for all major xref:api/index.adoc[AI Model providers] such as Anthropic, OpenAI, Microsoft, Amazon, Google, and Ollama. Supported model types include:\n** xref:api/chatmodel.adoc[Chat Completion]\n** xref:api/embeddings.adoc[Embedding]\n** xref:api/imageclient.adoc[Text to Image]\n** xref:api/audio/transcriptions.adoc[Audio Transcription]\n** xref:api/audio/speech.adoc[Text to Speech]\n** xref:api/moderation[Moderation]\n* xref:api/structured-output-converter.adoc[Structured Outputs] - Mapping of AI Model output to POJOs.\n* Support for all major xref:api/vectordbs.adoc[Vector Database providers] such as Apache Cassandra, Azure Cosmos DB, Azure Vector Search, Chroma, Elasticsearch, GemFire, MariaDB, Milvus, MongoDB Atlas, Neo4j, OpenSearch, Oracle, PostgreSQL/PGVector, Pinecone, Qdrant, Redis, SAP Hana, Typesense and Weaviate.\n* Portable API across Vector Store providers, including a novel SQL-like metadata filter API.\n* xref:api/tools.adoc[Tools/Function Calling] - Permits the model to request the execution of client-side tools and functions, thereby accessing necessary real-time information as required and taking action.\n* xref:observability/index.adoc[Observability] - Provides insights into AI-related operations.\n* Document ingestion xref:api/etl-pipeline.adoc[ETL framework] for Data Engineering.\n* xref:api/testing.adoc[AI Model Evaluation] - Utilities to help evaluate generated content and protect against hallucinated response.\n* Spring Boot Auto Configuration and Starters for AI Models and Vector Stores.\n* xref:api/chatclient.adoc[ChatClient API] - Fluent API for communicating with AI Chat Models, idiomatically similar to the WebClient and RestClient APIs.\n* xref:api/advisors.adoc[Advisors API] - Encapsulates recurring Generative AI patterns, transforms data sent to and from Language Models (LLMs), and provides portability across various models and use cases.\n* Support for xref:api/chatclient.adoc#_chat_memory[Chat Conversation Memory] and xref:api/chatclient.adoc#_retrieval_augmented_generation[Retrieval Augmented Generation (RAG)].\n\nThis feature set lets you implement common use cases, such as \"`Q&A over your documentation`\" or \"`Chat with your documentation.`\"\n\nThe xref:concepts.adoc[concepts section] provides a high-level overview of AI concepts and their representation in Spring AI.\n\nThe xref:getting-started.adoc[Getting Started] section shows you how to create your first AI application.\nSubsequent sections delve into each component and common use cases with a code-focused approach.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 128, "section_index": 0, "content_hash": "6772af934ea86911b4d5785e1575dd47389494f85899e94515b6ae63d6d5938d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/index.adoc"}}
{"id": "sha256:5d459e2f9b26a05d5dea62096dcef5ee8d210f4fd998264665a75a1c3efc823b", "content": "[[upgrade-notes]]\n\n[[upgrading-to-2-0-0-M3]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "upgrade-notes", "heading_level": 1, "file_order": 129, "section_index": 0, "content_hash": "5d459e2f9b26a05d5dea62096dcef5ee8d210f4fd998264665a75a1c3efc823b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d67c55e4456b0141f98bf55b87ce6826695ef92e0c0192da281c2ee619939ed6", "content": "Conversation history is no longer automatically added to `ToolContext`. The `TOOL_CALL_HISTORY` constant and `getToolCallHistory()` method have been removed from the `ToolContext` class.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Conversation History Removed from ToolContext", "heading_level": 4, "file_order": 129, "section_index": 1, "content_hash": "d67c55e4456b0141f98bf55b87ce6826695ef92e0c0192da281c2ee619939ed6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:c07ab832909c1bfbdb2fd1df5c2eb0cba7cd49842bf20803fc527f02f832e0f2", "content": "* `ToolContext.TOOL_CALL_HISTORY` constant no longer exists\n* `ToolContext.getToolCallHistory()` method no longer exists\n* Conversation history is no longer automatically populated in `ToolContext`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Impact", "heading_level": 5, "file_order": 129, "section_index": 2, "content_hash": "c07ab832909c1bfbdb2fd1df5c2eb0cba7cd49842bf20803fc527f02f832e0f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:92f4548874e1e08d525ebe6d78b95ea6ab75cd1bc5a4734a4f02aef40dfa6f41", "content": "1. **Memory Efficiency**: Prevents unbounded memory growth in long conversations\n2. **Separation of Concerns**: Tools should operate on their parameters, not manage conversation state\n3. **Architecture Alignment**: Conversation context belongs at the advisor level, not in tool execution", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Why This Change?", "heading_level": 5, "file_order": 129, "section_index": 3, "content_hash": "92f4548874e1e08d525ebe6d78b95ea6ab75cd1bc5a4734a4f02aef40dfa6f41", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:b7609a5b3dd13196938d6c6076ad5b8a52c479eb6a0b3cd442195b2a1ab1b21b", "content": "If your application needs conversation history management, use `ToolCallAdvisor`:\n\n.Managing Conversation History with ToolCallAdvisor\n[source,java]\n----\nChatClient chatClient = ChatClient.builder()\n .defaultAdvisors(\n new ToolCallAdvisor()\n .conversationHistoryEnabled(true) // Full history (default)\n )\n .build();\n----\n\n**How ToolCallAdvisor Works:**\n\nThe `ToolCallAdvisor` manages conversation history at the advisor level:\n\n* **conversationHistoryEnabled=true** (default): Full conversation history is maintained and sent to the LLM between tool call iterations, allowing the LLM to synthesize results with full context\n* **conversationHistoryEnabled=false**: Only the most recent tool response is sent to the LLM (useful when ChatMemory advisor manages history separately)\n\n**Key Point:** The conversation history is used by the *LLM* to understand context and formulate responses, not by the *tools* themselves. Tools receive only their input parameters and any custom context you explicitly provide.\n\n**Custom Context in Tools:**\n\n`ToolContext` remains available for passing custom, application-specific data to tools:\n\n.Passing Custom Context to Tools\n[source,java]\n----\nChatResponse response = chatClient.prompt()\n .user(\"What's the weather in SF?\")\n .options(ChatOptionsBuilder.builder()\n .toolContext(\"userId\", \"user123\")\n .toolContext(\"apiKey\", \"secret\")\n .build())\n .call()\n .chatResponse();\n----\n\n**Example Flow:**\n\n1. User asks: \"What's the weather in SF and LA?\"\n2. LLM requests tool calls: `getWeather(SF)` and `getWeather(LA)`\n3. Tools execute with only their parameters (no conversation history)\n4. ToolCallAdvisor collects tool results and conversation history\n5. LLM receives conversation context from advisor and synthesizes: \"The weather in SF is 72°F and in LA is 85°F\"\n\nThe LLM sees the full conversation through the advisor chain, not through ToolContext.\n\n[[upgrading-to-2-0-0-M2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Migration", "heading_level": 5, "file_order": 129, "section_index": 4, "content_hash": "b7609a5b3dd13196938d6c6076ad5b8a52c479eb6a0b3cd442195b2a1ab1b21b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:923eff1be19b053ab85f085e19f89779c63f1977fc98b54cc90c4bf94056b0bd", "content": "The `MongoChatMemoryRepository` has been fixed to return messages in the order they were sent (oldest-to-newest), matching all other chat memory repository implementations. Previously, it incorrectly returned messages in reverse order (newest-to-oldest), which broke conversation flow for LLMs.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "MongoDB Chat Memory Message Ordering Fixed", "heading_level": 4, "file_order": 129, "section_index": 5, "content_hash": "923eff1be19b053ab85f085e19f89779c63f1977fc98b54cc90c4bf94056b0bd", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:15910926d9581b49f8bea104ec7d37006d9dcd6dadec0990364bffe97b708390", "content": "If your application was using `MongoChatMemoryRepository` and working around the incorrect ordering (e.g., by reversing messages after retrieval), you will need to remove that workaround.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Impact", "heading_level": 5, "file_order": 129, "section_index": 6, "content_hash": "15910926d9581b49f8bea104ec7d37006d9dcd6dadec0990364bffe97b708390", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:e33e5e3c56d735e8cae520d834aaaba0a31a901d4aa4750c1f97c3eb9d3a2b9c", "content": "Remove any code that reverses the message order after retrieving from MongoDB chat memory:\n\n[source,java]\n----\nList<Message> messages = chatMemoryRepository.findByConversationId(conversationId);\nCollections.reverse(messages); // Remove this workaround\n\nList<Message> messages = chatMemoryRepository.findByConversationId(conversationId);\n----\n\nAll chat memory repositories now consistently return messages in the order they were sent (oldest-to-newest), which is the expected format for LLM conversation history.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Migration", "heading_level": 5, "file_order": 129, "section_index": 7, "content_hash": "e33e5e3c56d735e8cae520d834aaaba0a31a901d4aa4750c1f97c3eb9d3a2b9c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:04d083c265d9c61cd3b18ad0e52cae61ccaaf1ca1fd142a2adb39f84dfc53ab9", "content": "* Docker Compose and Testcontainers support for MongoDB Atlas is now provided natively by the Spring Boot MongoDB module. The migration should be transparent and not require any code change. Regarding dependencies, you don't need to import `org.springframework.ai:spring-ai-spring-boot-testcontainers` anymore. A dependency on `org.springframework.boot:spring-boot-testcontainers` is sufficient.\n\n[[upgrading-to-2-0-0-M1]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Development-time Services", "heading_level": 3, "file_order": 129, "section_index": 8, "content_hash": "04d083c265d9c61cd3b18ad0e52cae61ccaaf1ca1fd142a2adb39f84dfc53ab9", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:9def9958caab3bdc2e2bc6e32c4da9dc7fd7a2b0baea9113d22b557bc6861640", "content": "Spring AI no longer provides default temperature values for chat model autoconfiguration properties. Previously, Spring AI set a default temperature of `0.7` for most chat models. This default has been removed to allow each AI provider's native default temperature to be used.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Default Temperature Configuration Removed", "heading_level": 4, "file_order": 129, "section_index": 9, "content_hash": "9def9958caab3bdc2e2bc6e32c4da9dc7fd7a2b0baea9113d22b557bc6861640", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:c261ac44325f6dfd2f491df53fa4df51673e95b5614800772734791bdf80464f", "content": "If your application did not explicitly configure a temperature value and relied on Spring AI's default of `0.7`, you may notice different behavior after upgrading. The actual default will now be determined by each AI provider's API, which may vary:\n\n* Some providers default to `1.0`\n* Some providers default to `0.7`\n* Some providers have model-specific defaults", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Impact", "heading_level": 5, "file_order": 129, "section_index": 10, "content_hash": "c261ac44325f6dfd2f491df53fa4df51673e95b5614800772734791bdf80464f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:9fed076daf1421f2e646f24a3816d25662e6fc675c72c957332cb7c3bde76ea4", "content": "If you want to maintain the previous behavior, explicitly set the temperature in your configuration:\n\n[source,properties]\n----\n# Example for OpenAI\nspring.ai.openai.chat.options.temperature=0.7\n\n# Example for Anthropic\nspring.ai.anthropic.chat.options.temperature=0.7\n\n# Example for Azure OpenAI\nspring.ai.azure.openai.chat.options.temperature=0.7\n----\n\nOr programmatically when building requests:\n\n[source,java]\n----\nChatResponse response = chatModel.call(\n new Prompt(\"Your prompt here\",\n OpenAiChatOptions.builder()\n .temperature(0.7)\n .build()));\n----\n\n[[upgrading-to-1-1-0-RC1]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Migration", "heading_level": 5, "file_order": 129, "section_index": 11, "content_hash": "9fed076daf1421f2e646f24a3816d25662e6fc675c72c957332cb7c3bde76ea4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:6f5e1af7193489b988c551edb4324d526462fe6121dc418589bb902191211a25", "content": "The OpenAI Text-to-Speech implementation has been migrated from provider-specific classes to shared interfaces. This enables writing portable code that works across multiple TTS providers (OpenAI, ElevenLabs, and future providers).", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Text-to-Speech (TTS) API Migration", "heading_level": 4, "file_order": 129, "section_index": 12, "content_hash": "6f5e1af7193489b988c551edb4324d526462fe6121dc418589bb902191211a25", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:b172bddeee9a48937c890bd21661f7bbc48b4aab513d6415c5dcd3928ce6fc3e", "content": "The following deprecated classes have been removed from the `org.springframework.ai.openai.audio.speech` package:\n\n* `SpeechModel` → Use `TextToSpeechModel` (from `org.springframework.ai.audio.tts`)\n* `StreamingSpeechModel` → Use `StreamingTextToSpeechModel` (from `org.springframework.ai.audio.tts`)\n* `SpeechPrompt` → Use `TextToSpeechPrompt` (from `org.springframework.ai.audio.tts`)\n* `SpeechResponse` → Use `TextToSpeechResponse` (from `org.springframework.ai.audio.tts`)\n* `SpeechMessage` → Use `TextToSpeechMessage` (from `org.springframework.ai.audio.tts`)\n* `Speech` (in `org.springframework.ai.openai.audio.speech`) → Use `Speech` (from `org.springframework.ai.audio.tts`)\n\nAdditionally, the `speed` parameter type changed from `Float` to `Double` across all OpenAI TTS components for consistency with other TTS providers.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Removed Classes", "heading_level": 5, "file_order": 129, "section_index": 13, "content_hash": "b172bddeee9a48937c890bd21661f7bbc48b4aab513d6415c5dcd3928ce6fc3e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:eb118707e2430e413bfda92f98b3723b60ddd84b78963767ae7564d6e6bb0460", "content": "1. **Update Imports**: Replace all imports from `org.springframework.ai.openai.audio.speech.*` with `org.springframework.ai.audio.tts.*`\n\n2. **Update Type References**: Replace all occurrences of the old class names with the new ones:\n+\n[source,text]\n----\nFind: SpeechModel\nReplace: TextToSpeechModel\n\nFind: StreamingSpeechModel\nReplace: StreamingTextToSpeechModel\n\nFind: SpeechPrompt\nReplace: TextToSpeechPrompt\n\nFind: SpeechResponse\nReplace: TextToSpeechResponse\n\nFind: SpeechMessage\nReplace: TextToSpeechMessage\n----\n\n3. **Update Speed Parameter**: Change from `Float` to `Double`:\n+\n[source,text]\n----\nFind: .speed(1.0f)\nReplace: .speed(1.0)\n\nFind: Float speed\nReplace: Double speed\n----\n\n4. **Update Dependency Injection**: If you inject `SpeechModel`, update to `TextToSpeechModel`:\n+\n[source,java]\n----\npublic MyService(SpeechModel speechModel) { ... }\n\npublic MyService(TextToSpeechModel textToSpeechModel) { ... }\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Migration Steps", "heading_level": 5, "file_order": 129, "section_index": 14, "content_hash": "eb118707e2430e413bfda92f98b3723b60ddd84b78963767ae7564d6e6bb0460", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:4ae088eed3b5801781bf25deff88875c4e51aeed0e785d8b9e12a7ce602454e8", "content": "* **Portability**: Write code once, switch between OpenAI, ElevenLabs, or other TTS providers easily\n* **Consistency**: Same patterns as ChatModel and other Spring AI abstractions\n* **Type Safety**: Improved type hierarchy with proper interface implementations\n* **Future-Proof**: New TTS providers will automatically work with your existing code", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Benefits", "heading_level": 5, "file_order": 129, "section_index": 15, "content_hash": "4ae088eed3b5801781bf25deff88875c4e51aeed0e785d8b9e12a7ce602454e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:23712edb49117fda641887027d76b9fac7ad461014a808b96adac557605ec3d3", "content": "For a comprehensive migration guide with detailed code examples, see:\n\n* xref:api/audio/speech/openai-speech.adoc#_migration_guide[OpenAI TTS Migration Guide]\n* xref:api/audio/speech.adoc#_writing_provider_agnostic_code[Writing Provider-Agnostic TTS Code]\n\n[[upgrading-to-1-0-0-snapshot]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Additional Resources", "heading_level": 5, "file_order": 129, "section_index": 16, "content_hash": "23712edb49117fda641887027d76b9fac7ad461014a808b96adac557605ec3d3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:e02611af673d574bd27143ec83c5ba0c2c7e41bcf355ea679e9d66a27a51e852", "content": "The 1.0.0-SNAPSHOT version includes significant changes to artifact IDs, package names, and module structure. This section provides guidance specific to using the SNAPSHOT version.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Overview", "heading_level": 3, "file_order": 129, "section_index": 17, "content_hash": "e02611af673d574bd27143ec83c5ba0c2c7e41bcf355ea679e9d66a27a51e852", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:a5ee2703b9c239ed2e2aa9e930a99ea8bedde7ae18a6d3105019d6b4b87f2e22", "content": "To use the 1.0.0-SNAPSHOT version, you need to add the snapshot repositories to your build file.\nFor detailed instructions, refer to the xref:getting-started.adoc#snapshots-add-snapshot-repositories[Snapshots - Add Snapshot Repositories] section in the Getting Started guide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Add Snapshot Repositories", "heading_level": 3, "file_order": 129, "section_index": 18, "content_hash": "a5ee2703b9c239ed2e2aa9e930a99ea8bedde7ae18a6d3105019d6b4b87f2e22", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:c0fbc8a30f5be6abc751d4bf915c40bdc7826c31ab2f9c94a12e7f2693f833b7", "content": "Update your Spring AI BOM version to `1.0.0-SNAPSHOT` in your build configuration.\nFor detailed instructions on configuring dependency management, refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section in the Getting Started guide.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Update Dependency Management", "heading_level": 3, "file_order": 129, "section_index": 19, "content_hash": "c0fbc8a30f5be6abc751d4bf915c40bdc7826c31ab2f9c94a12e7f2693f833b7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:052ecfc3be00890b91a1d81e14b89ee76305a2d7e7fa248eabb0ffbcee553c6a", "content": "The 1.0.0-SNAPSHOT includes changes to artifact IDs, package names, and module structure.\n\nFor details, refer to:\n- xref:upgrade-notes.adoc#common-artifact-id-changes[Common Artifact ID Changes]\n- xref:upgrade-notes.adoc#common-package-changes[Common Package Changes]\n- xref:upgrade-notes.adoc#common-module-structure[Common Module Structure]\n\n[[upgrading-to-1-0-0-RC1]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Artifact ID, Package, and Module Changes", "heading_level": 3, "file_order": 129, "section_index": 20, "content_hash": "052ecfc3be00890b91a1d81e14b89ee76305a2d7e7fa248eabb0ffbcee553c6a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:b82b22c098aa3edd94515de3c0829a588a76b9ea271f3cfbc581028fbef4a032", "content": "You can automate the upgrade process to 1.0.0-RC1 using an OpenRewrite recipe.\nThis recipe helps apply many of the necessary code changes for this version.\nFind the recipe and usage instructions at https://github.com/arconia-io/arconia-migrations/blob/main/docs/spring-ai.md[Arconia Spring AI Migrations].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0-RC1", "heading_level": 2, "file_order": 129, "section_index": 21, "content_hash": "b82b22c098aa3edd94515de3c0829a588a76b9ea271f3cfbc581028fbef4a032", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:98a654c8a17abcb6680f8300ecf0f478651358a77a0ed8e5302f13c8ccd46924", "content": "The main changes that impact end user code are:\n\n* In `VectorStoreChatMemoryAdvisor`:\n** The constant `CHAT_MEMORY_RETRIEVE_SIZE_KEY` has been renamed to `TOP_K`.\n** The constant `DEFAULT_CHAT_MEMORY_RESPONSE_SIZE` (value: 100) has been renamed to `DEFAULT_TOP_K` with a new default value of 20.\n\n* The constant `CHAT_MEMORY_CONVERSATION_ID_KEY` has been renamed to `CONVERSATION_ID` and moved from `AbstractChatMemoryAdvisor` to the `ChatMemory` interface. Update your imports to use `org.springframework.ai.chat.memory.ChatMemory.CONVERSATION_ID`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Chat Client and Advisors", "heading_level": 4, "file_order": 129, "section_index": 22, "content_hash": "98a654c8a17abcb6680f8300ecf0f478651358a77a0ed8e5302f13c8ccd46924", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:2c624515f58b45200f7f6aee4f44560a82795f0e4045e7c6c6e1afd88f01c37f", "content": "The built-in advisors that perform prompt augmentation have been updated to use self-contained templates. The goal is for each advisor to be able to perform templating operations without affecting nor being affected by templating and prompt decisions in other advisors.\n\n*If you were providing custom templates for the following advisors, you'll need to update them to ensure all expected placeholders are included.*\n\n* The `QuestionAnswerAdvisor` expects a template with the following placeholders (see xref:api/retrieval-augmented-generation.adoc#_questionansweradvisor[more details]):\n** a `query` placeholder to receive the user question.\n** a `question_answer_context` placeholder to receive the retrieved context.\n* The `PromptChatMemoryAdvisor` expects a template with the following placeholders (see xref:api/chat-memory.adoc#_promptchatmemoryadvisor[more details]):\n** an `instructions` placeholder to receive the original system message.\n** a `memory` placeholder to receive the retrieved conversation memory.\n* The `VectorStoreChatMemoryAdvisor` expects a template with the following placeholders (see xref:api/chat-memory.adoc#_vectorstorechatmemoryadvisor[more details]):\n** an `instructions` placeholder to receive the original system message.\n** a `long_term_memory` placeholder to receive the retrieved conversation memory.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Self-contained Templates in Advisors", "heading_level": 5, "file_order": 129, "section_index": 23, "content_hash": "2c624515f58b45200f7f6aee4f44560a82795f0e4045e7c6c6e1afd88f01c37f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:6a5abd867148ca2c8be20cad3f6b37f221f87c65d516be2e7b0bda3e2b644dfc", "content": "* Refactored content observation to use logging instead of tracing (https://github.com/spring-projects/spring-ai/commit/ca843e85887aa1da6300c77550c379c103500897[ca843e8])\n ** Replaced content observation filters with logging handlers\n ** Renamed configuration properties to better reflect their purpose:\n *** `include-prompt` → `log-prompt`\n *** `include-completion` → `log-completion`\n *** `include-query-response` → `log-query-response`\n ** Added `TracingAwareLoggingObservationHandler` for trace-aware logging\n ** Replaced `micrometer-tracing-bridge-otel` with `micrometer-tracing`\n ** Removed event-based tracing in favor of direct logging\n ** Removed direct dependency on the OTel SDK\n ** Renamed `includePrompt` to `logPrompt` in observation properties (in `ChatClientBuilderProperties`, `ChatObservationProperties`, and `ImageObservationProperties`)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Observability", "heading_level": 4, "file_order": 129, "section_index": 24, "content_hash": "6a5abd867148ca2c8be20cad3f6b37f221f87c65d516be2e7b0bda3e2b644dfc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:82d73fdfc01e8c7b90bc45eefdebd0879a483120a873894eb1e5d3f26b1977fa", "content": "We've standardized the naming pattern for chat memory components by adding the repository suffix throughout the codebase. This change affects Cassandra, JDBC, and Neo4j implementations, impacting artifact IDs, Java package names, and class names for clarity.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Chat Memory Repository Module and Autoconfiguration Renaming", "heading_level": 4, "file_order": 129, "section_index": 25, "content_hash": "82d73fdfc01e8c7b90bc45eefdebd0879a483120a873894eb1e5d3f26b1977fa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:8c41b7196be6d9c29816f0f0d2e171e1b07850410c60dcbec88c19d71d37e1f2", "content": "All memory-related artifacts now follow a consistent pattern:\n\n* `spring-ai-model-chat-memory-*` → `spring-ai-model-chat-memory-repository-*`\n* `spring-ai-autoconfigure-model-chat-memory-*` → `spring-ai-autoconfigure-model-chat-memory-repository-*`\n* `spring-ai-starter-model-chat-memory-*` → `spring-ai-starter-model-chat-memory-repository-*`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Artifact IDs", "heading_level": 4, "file_order": 129, "section_index": 26, "content_hash": "8c41b7196be6d9c29816f0f0d2e171e1b07850410c60dcbec88c19d71d37e1f2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:cc6135befb1162b3652d86bab0b13e97581d872c4b3e5821b5ebadd8a13d2f39", "content": "* Package paths now include `.repository.` segment\n* Example: `org.springframework.ai.chat.memory.jdbc` → `org.springframework.ai.chat.memory.repository.jdbc`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Java Packages", "heading_level": 4, "file_order": 129, "section_index": 27, "content_hash": "cc6135befb1162b3652d86bab0b13e97581d872c4b3e5821b5ebadd8a13d2f39", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d76905d412ce738b32bbdbdd44bc93123e8b6795e4c1b75798b10778a72eb3d5", "content": "* Main autoconfiguration classes now use the `Repository` suffix\n* Example: `JdbcChatMemoryAutoConfiguration` → `JdbcChatMemoryRepositoryAutoConfiguration`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Configuration Classes", "heading_level": 4, "file_order": 129, "section_index": 28, "content_hash": "d76905d412ce738b32bbdbdd44bc93123e8b6795e4c1b75798b10778a72eb3d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:479540b464b29176eb302aa746bedf24cb5d2df804231c7f4d4859e8b86f4f7d", "content": "* Configuration properties renamed from `spring.ai.chat.memory.<storage>...` to `spring.ai.chat.memory.repository.<storage>...`\n\n**Migration Required:**\n- Update your Maven/Gradle dependencies to use the new artifact IDs.\n- Update any imports, class references, or configuration that used the old package or class names.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Properties", "heading_level": 4, "file_order": 129, "section_index": 29, "content_hash": "479540b464b29176eb302aa746bedf24cb5d2df804231c7f4d4859e8b86f4f7d", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:1a6e8fa2048c93b35ea9c6bc9860367e2ce5f68052e60dc40411097e3e5e63db", "content": "* `MessageAggregator` class has been moved from `org.springframework.ai.chat.model` package in the `spring-ai-client-chat` module to the `spring-ai-model` module (same package name)\n* The `aggregateChatClientResponse` method has been removed from `MessageAggregator` and moved to a new class `ChatClientMessageAggregator` in the `org.springframework.ai.chat.client` package", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Changes", "heading_level": 5, "file_order": 129, "section_index": 30, "content_hash": "1a6e8fa2048c93b35ea9c6bc9860367e2ce5f68052e60dc40411097e3e5e63db", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:48817997f639b73936dfc7734c2954405bb6a3e905625c853773083ab20affda", "content": "If you were directly using the `aggregateChatClientResponse` method from `MessageAggregator`, you need to use the new `ChatClientMessageAggregator` class instead:\n\n[source,java]\n----\nnew MessageAggregator().aggregateChatClientResponse(chatClientResponses, aggregationHandler);\n\nnew ChatClientMessageAggregator().aggregateChatClientResponse(chatClientResponses, aggregationHandler);\n----\n\nDon't forget to add the appropriate import:\n\n[source,java]\n----\nimport org.springframework.ai.chat.client.ChatClientMessageAggregator;\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Migration Guide", "heading_level": 5, "file_order": 129, "section_index": 31, "content_hash": "48817997f639b73936dfc7734c2954405bb6a3e905625c853773083ab20affda", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:745fd5e2434b82f21702bf786f96937681071abcb79e7b8f224abc174f3f27e5", "content": "The Watson AI model was removed as it was based on the older text generation that is considered outdated as there is a new chat generation model available.\nHopefully Watson will reappear in a future version of Spring AI", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Watson", "heading_level": 4, "file_order": 129, "section_index": 32, "content_hash": "745fd5e2434b82f21702bf786f96937681071abcb79e7b8f224abc174f3f27e5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7a7ab0e563669ac26ff449280b89f2abd0e25fa38204f567ec1670f052987f64", "content": "Moonshot and Qianfan have been removed since they are not accessible from outside China. These have been moved to the Spring AI Community repository.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "MoonShot and QianFan", "heading_level": 4, "file_order": 129, "section_index": 33, "content_hash": "7a7ab0e563669ac26ff449280b89f2abd0e25fa38204f567ec1670f052987f64", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:89615cda616ec71da1c9f3424200233156ff36bb2ee09cc80e56cc1dea6a541c", "content": "* Removed HanaDB vector store autoconfiguration (https://github.com/spring-projects/spring-ai/commit/f3b46244942c5072c2e2fa89e62cde71c61bbf25[f3b4624])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Removed Vector Store", "heading_level": 4, "file_order": 129, "section_index": 34, "content_hash": "89615cda616ec71da1c9f3424200233156ff36bb2ee09cc80e56cc1dea6a541c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:acd0ea735a8abd1dd308f9faa13fbcb5e3d40a40b63e9381ef3e4c5a530dc152", "content": "* Removed CassandraChatMemory implementation (https://github.com/spring-projects/spring-ai/commit/11e3c8f9a6636d77f203968b83625d3e5694c408[11e3c8f])\n* Simplified chat memory advisor hierarchy and removed deprecated API (https://github.com/spring-projects/spring-ai/commit/848a3fd31fadd07c9ba77f6dc30425389d095e9a[848a3fd])\n* Removed deprecations in JdbcChatMemory (https://github.com/spring-projects/spring-ai/commit/356a68f15eea07a040bd27c66442472fc55e6475[356a68f])\n* Refactored chat memory repository artifacts for clarity (https://github.com/spring-projects/spring-ai/commit/2d517eec5cd7ce5f88149b876ed57a06ad353e11[2d517ee])\n* Refactored chat memory repository autoconfigurations and Spring Boot starters for clarity (https://github.com/spring-projects/spring-ai/commit/f6dba1bf083d847cdc07888ba62746683e3d61bb[f6dba1b])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Memory Management", "heading_level": 4, "file_order": 129, "section_index": 35, "content_hash": "acd0ea735a8abd1dd308f9faa13fbcb5e3d40a40b63e9381ef3e4c5a530dc152", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:75aafbe2a087a6d16fd8ba4713be4ca19f1cd1f4f1dcd920ba4738d2b50daaae", "content": "* Removed deprecated UserMessage constructors (https://github.com/spring-projects/spring-ai/commit/06edee406978d172a1f87f4c7b255282f9d55e4c[06edee4])\n* Removed deprecated PromptTemplate constructors (https://github.com/spring-projects/spring-ai/commit/722c77e812f3f3ea40cf2258056fcf1578b15c62[722c77e])\n* Removed deprecated methods from Media (https://github.com/spring-projects/spring-ai/commit/228ef10bfbfe279d7d09f2a7ba166db873372118[228ef10])\n* Refactored StTemplateRenderer: renamed supportStFunctions to validateStFunctions (https://github.com/spring-projects/spring-ai/commit/0e15197298c0848b78a746f3d740191e6a6aee7a[0e15197])\n* Removed left over TemplateRender interface after moving it (https://github.com/spring-projects/spring-ai/commit/52675d854ccecbc702cec24c4f070520eca64938[52675d8])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Message and Template APIs", "heading_level": 4, "file_order": 129, "section_index": 36, "content_hash": "75aafbe2a087a6d16fd8ba4713be4ca19f1cd1f4f1dcd920ba4738d2b50daaae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:4b2318cc6127ffac0e2b4dc586c9a976a55847b20fba15ad47e899ce3039f2d5", "content": "* Removed deprecations in ChatClient and Advisors (https://github.com/spring-projects/spring-ai/commit/4fe74d886e26d52abf6f2f5545264d422a0be4b2[4fe74d8])\n* Removed deprecations from OllamaApi and AnthropicApi (https://github.com/spring-projects/spring-ai/commit/46be8987d6bc385bf74b9296aa4308c7a8658d2f[46be898])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Additional Client API Changes", "heading_level": 4, "file_order": 129, "section_index": 37, "content_hash": "4b2318cc6127ffac0e2b4dc586c9a976a55847b20fba15ad47e899ce3039f2d5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:bd34697dd355cbc0875e8386063637a44770e37a64c6268c6c40b02a4d176340", "content": "* Removed inter-package dependency cycles in spring-ai-model (https://github.com/spring-projects/spring-ai/commit/ebfa5b9b2cc2ab0d20e25dc6128c4b1c9c327f89[ebfa5b9])\n* Moved MessageAggregator to spring-ai-model module (https://github.com/spring-projects/spring-ai/commit/54e5c07428909ceec248e3bbd71e2df4b0812e49[54e5c07])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Package Structure Changes", "heading_level": 4, "file_order": 129, "section_index": 38, "content_hash": "bd34697dd355cbc0875e8386063637a44770e37a64c6268c6c40b02a4d176340", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7a737f65a66535d39d09ccc80aec30f947f5889b351644a87c8ece3ba87a3cb5", "content": "* Removed unused json-path dependency in spring-ai-openai (https://github.com/spring-projects/spring-ai/commit/9de13d1b2fdb67219dc7afbf319ade789784f2b9[9de13d1])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Dependencies", "heading_level": 4, "file_order": 129, "section_index": 39, "content_hash": "7a737f65a66535d39d09ccc80aec30f947f5889b351644a87c8ece3ba87a3cb5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:0835897f97bfa945b79fdca3a7a885fe6c6afd34b87ef48d78bc045e005a2dc6", "content": "* Added Entra ID identity management for Azure OpenAI with clean autoconfiguration (https://github.com/spring-projects/spring-ai/commit/3dc86d33ce90ebd68ec3997a0eb4704ab7774e99[3dc86d3])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Azure OpenAI", "heading_level": 4, "file_order": 129, "section_index": 40, "content_hash": "0835897f97bfa945b79fdca3a7a885fe6c6afd34b87ef48d78bc045e005a2dc6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:3293fff7aa92c79c699fd4712445f8c4e17e6b2ad9b496df120a00f155b16ef3", "content": "* Removed all code deprecations (https://github.com/spring-projects/spring-ai/commit/76bee8ceb2854839f93a6c52876f50bb24219355[76bee8c]) and (https://github.com/spring-projects/spring-ai/commit/b6ce7f3e4a7aafe6b9031043f63813dde6e73605[b6ce7f3])\n\n[[upgrading-to-1-0-0-m8]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "General Cleanup", "heading_level": 3, "file_order": 129, "section_index": 41, "content_hash": "3293fff7aa92c79c699fd4712445f8c4e17e6b2ad9b496df120a00f155b16ef3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7e55e029e369c4b8e3d67f455ee8ad498a565c543ad2541a156d73dc7f4de607", "content": "You can automate the upgrade process to 1.0.0-M8 using an OpenRewrite recipe.\nThis recipe helps apply many of the necessary code changes for this version.\nFind the recipe and usage instructions at https://github.com/arconia-io/arconia-migrations/blob/main/docs/spring-ai.md[Arconia Spring AI Migrations].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0-M8", "heading_level": 2, "file_order": 129, "section_index": 42, "content_hash": "7e55e029e369c4b8e3d67f455ee8ad498a565c543ad2541a156d73dc7f4de607", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:3ea879b65936e9cdeb7971a8ac856e963977bcd3380a07dae6fd6f370100e215", "content": "When upgrading from Spring AI 1.0 M7 to 1.0 M8, users who previously registered tool callbacks are encountering breaking changes that cause tool calling functionality to silently fail. This is specifically impacting code that used the deprecated `tools()` method.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Breaking Changes", "heading_level": 3, "file_order": 129, "section_index": 43, "content_hash": "3ea879b65936e9cdeb7971a8ac856e963977bcd3380a07dae6fd6f370100e215", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:22181e14c68cfe640aa7a0cfaaaa13d6cc64e39c00794fbdef1ca6cacfcd952a", "content": "Here's an example of code that worked in M7 but no longer functions as expected in M8:\n\n[source,java]\n----\nChatClient chatClient = new OpenAiChatClient(api)\n .tools(List.of(\n new Tool(\"get_current_weather\", \"Get the current weather in a given location\",\n new ToolSpecification.ToolParameter(\"location\", \"The city and state, e.g. San Francisco, CA\", true))\n ))\n .toolCallbacks(List.of(\n new ToolCallback(\"get_current_weather\", (toolName, params) -> {\n // Weather retrieval logic\n return Map.of(\"temperature\", 72, \"unit\", \"fahrenheit\", \"description\", \"Sunny\");\n })\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Example", "heading_level": 4, "file_order": 129, "section_index": 44, "content_hash": "22181e14c68cfe640aa7a0cfaaaa13d6cc64e39c00794fbdef1ca6cacfcd952a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:70454c7c207c2a74b4a51432b349edd1266dac43d2b9213e8f8a81f398bbec30", "content": "The solution is to use the `toolSpecifications()` method instead of the deprecated `tools()` method:\n\n[source,java]\n----\nChatClient chatClient = new OpenAiChatClient(api)\n .toolSpecifications(List.of(\n new Tool(\"get_current_weather\", \"Get the current weather in a given location\",\n new ToolSpecification.ToolParameter(\"location\", \"The city and state, e.g. San Francisco, CA\", true))\n ))\n .toolCallbacks(List.of(\n new ToolCallback(\"get_current_weather\", (toolName, params) -> {\n // Weather retrieval logic\n return Map.of(\"temperature\", 72, \"unit\", \"fahrenheit\", \"description\", \"Sunny\");\n })\n ));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Solution", "heading_level": 4, "file_order": 129, "section_index": 45, "content_hash": "70454c7c207c2a74b4a51432b349edd1266dac43d2b9213e8f8a81f398bbec30", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:acd0ea735a8abd1dd308f9faa13fbcb5e3d40a40b63e9381ef3e4c5a530dc152", "content": "* Removed CassandraChatMemory implementation (https://github.com/spring-projects/spring-ai/commit/11e3c8f9a6636d77f203968b83625d3e5694c408[11e3c8f])\n* Simplified chat memory advisor hierarchy and removed deprecated API (https://github.com/spring-projects/spring-ai/commit/848a3fd31fadd07c9ba77f6dc30425389d095e9a[848a3fd])\n* Removed deprecations in JdbcChatMemory (https://github.com/spring-projects/spring-ai/commit/356a68f15eea07a040bd27c66442472fc55e6475[356a68f])\n* Refactored chat memory repository artifacts for clarity (https://github.com/spring-projects/spring-ai/commit/2d517eec5cd7ce5f88149b876ed57a06ad353e11[2d517ee])\n* Refactored chat memory repository autoconfigurations and Spring Boot starters for clarity (https://github.com/spring-projects/spring-ai/commit/f6dba1bf083d847cdc07888ba62746683e3d61bb[f6dba1b])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Memory Management", "heading_level": 4, "file_order": 129, "section_index": 46, "content_hash": "acd0ea735a8abd1dd308f9faa13fbcb5e3d40a40b63e9381ef3e4c5a530dc152", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:63f963b4c2c3a573032cca4226e410db0029ecc4625e6c794cc4e16b18fe90e2", "content": "* Removed deprecations in ChatClient and Advisors (https://github.com/spring-projects/spring-ai/commit/4fe74d886e26d52abf6f2f5545264d422a0be4b2[4fe74d8])\n* Breaking changes to chatclient tool calling (https://github.com/spring-projects/spring-ai/commit/5b7849de088b3c93c7ec894fcaddc85a611a8572[5b7849d])\n* Removed deprecations from OllamaApi and AnthropicApi (https://github.com/spring-projects/spring-ai/commit/46be8987d6bc385bf74b9296aa4308c7a8658d2f[46be898])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Client APIs", "heading_level": 4, "file_order": 129, "section_index": 47, "content_hash": "63f963b4c2c3a573032cca4226e410db0029ecc4625e6c794cc4e16b18fe90e2", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:75aafbe2a087a6d16fd8ba4713be4ca19f1cd1f4f1dcd920ba4738d2b50daaae", "content": "* Removed deprecated UserMessage constructors (https://github.com/spring-projects/spring-ai/commit/06edee406978d172a1f87f4c7b255282f9d55e4c[06edee4])\n* Removed deprecated PromptTemplate constructors (https://github.com/spring-projects/spring-ai/commit/722c77e812f3f3ea40cf2258056fcf1578b15c62[722c77e])\n* Removed deprecated methods from Media (https://github.com/spring-projects/spring-ai/commit/228ef10bfbfe279d7d09f2a7ba166db873372118[228ef10])\n* Refactored StTemplateRenderer: renamed supportStFunctions to validateStFunctions (https://github.com/spring-projects/spring-ai/commit/0e15197298c0848b78a746f3d740191e6a6aee7a[0e15197])\n* Removed left over TemplateRender interface after moving it (https://github.com/spring-projects/spring-ai/commit/52675d854ccecbc702cec24c4f070520eca64938[52675d8])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Message and Template APIs", "heading_level": 4, "file_order": 129, "section_index": 48, "content_hash": "75aafbe2a087a6d16fd8ba4713be4ca19f1cd1f4f1dcd920ba4738d2b50daaae", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:78ed913860b28babe02de541342b0e56766549f367a4e95774f4ba6457e587e8", "content": "* Removed Watson text generation model (https://github.com/spring-projects/spring-ai/commit/9e71b163e315199fe7b46495d87a0828a807b88f[9e71b16])\n* Removed Qianfan code (https://github.com/spring-projects/spring-ai/commit/bfcaad7b5495c5927a62b44169e8713e044c2497[bfcaad7])\n* Removed HanaDB vector store autoconfiguration (https://github.com/spring-projects/spring-ai/commit/f3b46244942c5072c2e2fa89e62cde71c61bbf25[f3b4624])\n* Removed deepseek options from OpenAiApi (https://github.com/spring-projects/spring-ai/commit/59b36d14dab72d76f2f3d49ce9385a69faaabbba[59b36d1])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Model Implementations", "heading_level": 4, "file_order": 129, "section_index": 49, "content_hash": "78ed913860b28babe02de541342b0e56766549f367a4e95774f4ba6457e587e8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:bd34697dd355cbc0875e8386063637a44770e37a64c6268c6c40b02a4d176340", "content": "* Removed inter-package dependency cycles in spring-ai-model (https://github.com/spring-projects/spring-ai/commit/ebfa5b9b2cc2ab0d20e25dc6128c4b1c9c327f89[ebfa5b9])\n* Moved MessageAggregator to spring-ai-model module (https://github.com/spring-projects/spring-ai/commit/54e5c07428909ceec248e3bbd71e2df4b0812e49[54e5c07])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Package Structure Changes", "heading_level": 4, "file_order": 129, "section_index": 50, "content_hash": "bd34697dd355cbc0875e8386063637a44770e37a64c6268c6c40b02a4d176340", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7a737f65a66535d39d09ccc80aec30f947f5889b351644a87c8ece3ba87a3cb5", "content": "* Removed unused json-path dependency in spring-ai-openai (https://github.com/spring-projects/spring-ai/commit/9de13d1b2fdb67219dc7afbf319ade789784f2b9[9de13d1])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Dependencies", "heading_level": 4, "file_order": 129, "section_index": 51, "content_hash": "7a737f65a66535d39d09ccc80aec30f947f5889b351644a87c8ece3ba87a3cb5", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:6a5abd867148ca2c8be20cad3f6b37f221f87c65d516be2e7b0bda3e2b644dfc", "content": "* Refactored content observation to use logging instead of tracing (https://github.com/spring-projects/spring-ai/commit/ca843e85887aa1da6300c77550c379c103500897[ca843e8])\n ** Replaced content observation filters with logging handlers\n ** Renamed configuration properties to better reflect their purpose:\n *** `include-prompt` → `log-prompt`\n *** `include-completion` → `log-completion`\n *** `include-query-response` → `log-query-response`\n ** Added `TracingAwareLoggingObservationHandler` for trace-aware logging\n ** Replaced `micrometer-tracing-bridge-otel` with `micrometer-tracing`\n ** Removed event-based tracing in favor of direct logging\n ** Removed direct dependency on the OTel SDK\n ** Renamed `includePrompt` to `logPrompt` in observation properties (in `ChatClientBuilderProperties`, `ChatObservationProperties`, and `ImageObservationProperties`)", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Observability", "heading_level": 4, "file_order": 129, "section_index": 52, "content_hash": "6a5abd867148ca2c8be20cad3f6b37f221f87c65d516be2e7b0bda3e2b644dfc", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:0835897f97bfa945b79fdca3a7a885fe6c6afd34b87ef48d78bc045e005a2dc6", "content": "* Added Entra ID identity management for Azure OpenAI with clean autoconfiguration (https://github.com/spring-projects/spring-ai/commit/3dc86d33ce90ebd68ec3997a0eb4704ab7774e99[3dc86d3])", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Azure OpenAI", "heading_level": 4, "file_order": 129, "section_index": 53, "content_hash": "0835897f97bfa945b79fdca3a7a885fe6c6afd34b87ef48d78bc045e005a2dc6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:949db622bf0a6c30c9e210ad75e33ceef32e6ed2826239cd385797fe55ffa9e6", "content": "* Removed all deprecations from 1.0.0-M8 (https://github.com/spring-projects/spring-ai/commit/76bee8ceb2854839f93a6c52876f50bb24219355[76bee8c])\n* General deprecation cleanup (https://github.com/spring-projects/spring-ai/commit/b6ce7f3e4a7aafe6b9031043f63813dde6e73605[b6ce7f3])\n\n[[upgrading-to-1-0-0-m7]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "General Cleanup", "heading_level": 3, "file_order": 129, "section_index": 54, "content_hash": "949db622bf0a6c30c9e210ad75e33ceef32e6ed2826239cd385797fe55ffa9e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:c46d3184f647992906902f3d287ea1d94287944f4ece954a9ad069fd35afcc4c", "content": "Spring AI 1.0.0-M7 is the last milestone release before the RC1 and GA releases. It introduces several important changes to artifact IDs, package names, and module structure that will be maintained in the final release.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Overview of Changes", "heading_level": 3, "file_order": 129, "section_index": 55, "content_hash": "c46d3184f647992906902f3d287ea1d94287944f4ece954a9ad069fd35afcc4c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:27ef919fa70d463d45c908557ec12c26eb8ac29ab35db6722b0c1bc81c80d7e6", "content": "The 1.0.0-M7 includes the same structural changes as 1.0.0-SNAPSHOT.\n\nFor details, refer to:\n- xref:upgrade-notes.adoc#common-artifact-id-changes[Common Artifact ID Changes]\n- xref:upgrade-notes.adoc#common-package-changes[Common Package Changes]\n- xref:upgrade-notes.adoc#common-module-structure[Common Module Structure]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Artifact ID, Package, and Module Changes", "heading_level": 3, "file_order": 129, "section_index": 56, "content_hash": "27ef919fa70d463d45c908557ec12c26eb8ac29ab35db6722b0c1bc81c80d7e6", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:9bd3ea3f15cfacc7322868b004375dba0488e92274bebdeb32f96ae09a4a8bad", "content": "Spring AI 1.0.0-M7 now uses MCP Java SDK version 0.9.0, which includes significant changes from previous versions. If you're using MCP in your applications, you'll need to update your code to accommodate these changes.\n\nKey changes include:", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "MCP Java SDK Upgrade to 0.9.0", "heading_level": 3, "file_order": 129, "section_index": 57, "content_hash": "9bd3ea3f15cfacc7322868b004375dba0488e92274bebdeb32f96ae09a4a8bad", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:93c544e6964763c0387404caa9667ce9c41868f4f8dfc00a9acd683196456e02", "content": "* `ClientMcpTransport` → `McpClientTransport`\n* `ServerMcpTransport` → `McpServerTransport`\n* `DefaultMcpSession` → `McpClientSession` or `McpServerSession`\n* All `*Registration` classes → `*Specification` classes", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Interface Renaming", "heading_level": 4, "file_order": 129, "section_index": 58, "content_hash": "93c544e6964763c0387404caa9667ce9c41868f4f8dfc00a9acd683196456e02", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:5536a7d659a2d43f77a2faa90e8a828a21c9c933a7a132f90536455aa1663691", "content": "* Use `McpServerTransportProvider` instead of `ServerMcpTransport`\n\n[source,java]\n----\nServerMcpTransport transport = new WebFluxSseServerTransport(objectMapper, \"/mcp/message\");\nvar server = McpServer.sync(transport)\n .serverInfo(\"my-server\", \"1.0.0\")\n .build();\n\nMcpServerTransportProvider transportProvider = new WebFluxSseServerTransportProvider(objectMapper, \"/mcp/message\");\nvar server = McpServer.sync(transportProvider)\n .serverInfo(\"my-server\", \"1.0.0\")\n .build();\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Server Creation Changes", "heading_level": 4, "file_order": 129, "section_index": 59, "content_hash": "5536a7d659a2d43f77a2faa90e8a828a21c9c933a7a132f90536455aa1663691", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:cfcc72f04036ea5100e3b936a13f68e2c1b80c1d2fa4c5a578f31aa4bf565f3b", "content": "All handlers now receive an `exchange` parameter as their first argument:\n\n[source,java]\n----\n.tool(calculatorTool, args -> new CallToolResult(\"Result: \" + calculate(args)))\n\n.tool(calculatorTool, (exchange, args) -> new CallToolResult(\"Result: \" + calculate(args)))\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Handler Signature Changes", "heading_level": 4, "file_order": 129, "section_index": 60, "content_hash": "cfcc72f04036ea5100e3b936a13f68e2c1b80c1d2fa4c5a578f31aa4bf565f3b", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:db20fd2117a37fdf0b2a74aa800b5bcaa22a8cb04b9a9bf8b95096f0d7442a52", "content": "Methods previously available on the server are now accessed through the exchange object:\n\n[source,java]\n----\nClientCapabilities capabilities = server.getClientCapabilities();\nCreateMessageResult result = server.createMessage(new CreateMessageRequest(...));\n\nClientCapabilities capabilities = exchange.getClientCapabilities();\nCreateMessageResult result = exchange.createMessage(new CreateMessageRequest(...));\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Client Interaction via Exchange", "heading_level": 4, "file_order": 129, "section_index": 61, "content_hash": "db20fd2117a37fdf0b2a74aa800b5bcaa22a8cb04b9a9bf8b95096f0d7442a52", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:745dbd6ab81b7c854e845cb2f6b743f7c042553830e83c1b51c5b33de60426b3", "content": "[source,java]\n----\n.rootsChangeConsumers(List.of(\n roots -> System.out.println(\"Roots changed: \" + roots)\n))\n\n.rootsChangeHandlers(List.of(\n (exchange, roots) -> System.out.println(\"Roots changed: \" + roots)\n))\n----\n\nFor a complete guide to migrating MCP code, refer to the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-docs/src/main/antora/modules/ROOT/pages/mcp-migration.adoc[MCP Migration Guide].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Roots Change Handlers", "heading_level": 4, "file_order": 129, "section_index": 62, "content_hash": "745dbd6ab81b7c854e845cb2f6b743f7c042553830e83c1b51c5b33de60426b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d3368462bb1266114f8752d606d6aa3246c9f70828bce52d71b4f2a12136749a", "content": "The previous configuration properties for enabling/disabling model auto-configuration have been removed:\n\n* `spring.ai.<provider>.chat.enabled`\n* `spring.ai.<provider>.embedding.enabled`\n* `spring.ai.<provider>.image.enabled`\n* `spring.ai.<provider>.moderation.enabled`\n\nBy default, if a model provider (e.g., OpenAI, Ollama) is found on the classpath, its corresponding auto-configuration for relevant model types (chat, embedding, etc.) is enabled. If multiple providers for the same model type are present (e.g., both `spring-ai-openai-spring-boot-starter` and `spring-ai-ollama-spring-boot-starter`), you can use the following properties to select *which* provider's auto-configuration should be active, effectively disabling the others for that specific model type.\n\nTo disable auto-configuration for a specific model type entirely, even if only one provider is present, set the corresponding property to a value that does not match any provider on the classpath (e.g., `none` or `disabled`).\n\nYou can refer to the https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/model/SpringAIModels.java[`SpringAIModels`] enumeration for a list of well-known provider values.\n\n* `spring.ai.model.audio.speech=<model-provider|none>`\n* `spring.ai.model.audio.transcription=<model-provider|none>`\n* `spring.ai.model.chat=<model-provider|none>`\n* `spring.ai.model.embedding=<model-provider|none>`\n* `spring.ai.model.embedding.multimodal=<model-provider|none>`\n* `spring.ai.model.embedding.text=<model-provider|none>`\n* `spring.ai.model.image=<model-provider|none>`\n* `spring.ai.model.moderation=<model-provider|none>`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Enabling/Disabling Model Auto-Configuration", "heading_level": 3, "file_order": 129, "section_index": 63, "content_hash": "d3368462bb1266114f8752d606d6aa3246c9f70828bce52d71b4f2a12136749a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:6a291b76aec0dee643581bba3546c34df5e543a54bf675cee453cbf9e4575665", "content": "You can automate the upgrade process to 1.0.0-M7 using the Claude Code CLI tool with a provided prompt:\n\n1. Download the https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview[Claude Code CLI tool]\n2. Copy the prompt from the https://github.com/spring-projects/spring-ai/blob/main/src/prompts/update-to-m7.txt[update-to-m7.txt] file\n3. Paste the prompt into the Claude Code CLI\n4. The AI will analyze your project and make the necessary changes\n\nNOTE: The automated upgrade prompt currently handles artifact ID changes, package relocations, and module structure changes, but does not yet include automatic changes for upgrading to MCP 0.9.0. If you're using MCP, you'll need to manually update your code following the guidance in the xref:upgrade-notes.adoc#mcp-java-sdk-upgrade-to-0-9-0[MCP Java SDK Upgrade] section.\n\n[[common-sections]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Automating upgrading using AI", "heading_level": 3, "file_order": 129, "section_index": 64, "content_hash": "6a291b76aec0dee643581bba3546c34df5e543a54bf675cee453cbf9e4575665", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:ab8b7aa2367375a5df47fbd9e4e994de61c9eb96d0e91da0653931c904efb382", "content": "[[common-artifact-id-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Common Changes Across Versions", "heading_level": 2, "file_order": 129, "section_index": 65, "content_hash": "ab8b7aa2367375a5df47fbd9e4e994de61c9eb96d0e91da0653931c904efb382", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:57f5d8f041e88069bd49806bfa7e5d2c67a649acd41623200c06d2941fc0fcba", "content": "The naming pattern for Spring AI starter artifacts has changed.\nYou'll need to update your dependencies according to the following patterns:\n\n* Model starters: `spring-ai-\\{model\\}-spring-boot-starter` → `spring-ai-starter-model-\\{model\\}`\n* Vector Store starters: `spring-ai-\\{store\\}-store-spring-boot-starter` → `spring-ai-starter-vector-store-\\{store\\}`\n* MCP starters: `spring-ai-mcp-\\{type\\}-spring-boot-starter` → `spring-ai-starter-mcp-\\{type\\}`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Artifact ID Changes", "heading_level": 3, "file_order": 129, "section_index": 66, "content_hash": "57f5d8f041e88069bd49806bfa7e5d2c67a649acd41623200c06d2941fc0fcba", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:27e4066dad2dc57bb0580a2c661bcfcff8c1a0a082df39ae00098464b4cb051f", "content": "[tabs]\n======\nMaven::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<!-- BEFORE -->\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-openai-spring-boot-starter</artifactId>\n</dependency>\n\n<!-- AFTER -->\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-starter-model-openai</artifactId>\n</dependency>\n----\n\nGradle::\n+\n[source,groovy,indent=0,subs=\"verbatim,quotes\"]\n----\nimplementation 'org.springframework.ai:spring-ai-openai-spring-boot-starter'\nimplementation 'org.springframework.ai:spring-ai-redis-store-spring-boot-starter'\n\nimplementation 'org.springframework.ai:spring-ai-starter-model-openai'\nimplementation 'org.springframework.ai:spring-ai-starter-vector-store-redis'\n----\n======", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Examples", "heading_level": 4, "file_order": 129, "section_index": 67, "content_hash": "27e4066dad2dc57bb0580a2c661bcfcff8c1a0a082df39ae00098464b4cb051f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:0bfbe2a18be1928143c2a9ba9e9fdfa497c9651a43b9bbf161e121578c5241f3", "content": "The Spring AI autoconfiguration has changed from a single monolithic artifact to individual autoconfiguration artifacts per model, vector store, and other components.\nThis change was made to minimize the impact of different versions of dependent libraries conflicting, such as Google Protocol Buffers, Google RPC, and others.\nBy separating autoconfiguration into component-specific artifacts, you can avoid pulling in unnecessary dependencies and reduce the risk of version conflicts in your application.\n\nThe original monolithic artifact is no longer available:\n\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<!-- NO LONGER AVAILABLE -->\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-spring-boot-autoconfigure</artifactId>\n <version>${project.version}</version>\n</dependency>\n----\n\nInstead, each component now has its own autoconfiguration artifact following these patterns:\n\n* Model autoconfiguration: `spring-ai-autoconfigure-model-\\{model\\}`\n* Vector Store autoconfiguration: `spring-ai-autoconfigure-vector-store-\\{store\\}`\n* MCP autoconfiguration: `spring-ai-autoconfigure-mcp-\\{type\\}`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Changes to Spring AI Autoconfiguration Artifacts", "heading_level": 4, "file_order": 129, "section_index": 68, "content_hash": "0bfbe2a18be1928143c2a9ba9e9fdfa497c9651a43b9bbf161e121578c5241f3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7cf073139e0efbeee211124b6b9484b95bf2c425a35c818385a567ac2d9c979a", "content": "[tabs]\n======\nModels::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-model-openai</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-model-anthropic</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-model-vertex-ai</artifactId>\n</dependency>\n----\n\nVector Stores::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-vector-store-redis</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-vector-store-pgvector</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-vector-store-chroma</artifactId>\n</dependency>\n----\n\nMCP::\n+\n[source,xml,indent=0,subs=\"verbatim,quotes\"]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-mcp-client</artifactId>\n</dependency>\n\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-autoconfigure-mcp-server</artifactId>\n</dependency>\n----\n======\n\nNOTE: In most cases, you won't need to explicitly add these autoconfiguration dependencies.\nThey are included transitively when using the corresponding starter dependencies.\n\n[[common-package-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Examples of New Autoconfiguration Artifacts", "heading_level": 4, "file_order": 129, "section_index": 69, "content_hash": "7cf073139e0efbeee211124b6b9484b95bf2c425a35c818385a567ac2d9c979a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:81e8aeacec49a259e4f6b21b80a3c527cce49231d7ac3ed6d87cc828b8a7fa33", "content": "Your IDE should assist with refactoring to the new package locations.\n\n* `KeywordMetadataEnricher` and `SummaryMetadataEnricher` have moved from `org.springframework.ai.transformer` to `org.springframework.ai.chat.transformer`.\n* `Content`, `MediaContent`, and `Media` have moved from `org.springframework.ai.model` to `org.springframework.ai.content`.\n\n[[common-module-structure]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Package Name Changes", "heading_level": 3, "file_order": 129, "section_index": 70, "content_hash": "81e8aeacec49a259e4f6b21b80a3c527cce49231d7ac3ed6d87cc828b8a7fa33", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:aa0efdc6f76d525dd91e4d0437e423dc3ce12b3ac7c8c0d5a0f72c0bed090744", "content": "The project has undergone significant changes to its module and artifact structure. Previously, `spring-ai-core` contained all central interfaces, but this has now been split into specialized domain modules to reduce unnecessary dependencies in your applications.\n\nimage::spring-ai-dependencies.png[Spring AI Dependencies, width=1000, align=\"center\"]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Module Structure", "heading_level": 3, "file_order": 129, "section_index": 71, "content_hash": "aa0efdc6f76d525dd91e4d0437e423dc3ce12b3ac7c8c0d5a0f72c0bed090744", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:8e68b34cacd1c884dea82457e878c02eb7daa2a8b3640cda6633fbf14d1f63b3", "content": "Base module with no dependencies on other Spring AI modules. Contains:\n- Core domain models (`Document`, `TextSplitter`)\n- JSON utilities and resource handling\n- Structured logging and observability support", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-commons", "heading_level": 4, "file_order": 129, "section_index": 72, "content_hash": "8e68b34cacd1c884dea82457e878c02eb7daa2a8b3640cda6633fbf14d1f63b3", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:5f2843cdb9830c7309cc6a915613d0290a61a25223c3c33a57a287541bec320f", "content": "Provides AI capability abstractions:\n- Interfaces like `ChatModel`, `EmbeddingModel`, and `ImageModel`\n- Message types and prompt templates\n- Function-calling framework (`ToolDefinition`, `ToolCallback`)\n- Content filtering and observation support", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-model", "heading_level": 4, "file_order": 129, "section_index": 73, "content_hash": "5f2843cdb9830c7309cc6a915613d0290a61a25223c3c33a57a287541bec320f", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:57b182a47776c2f982e648ba4af48c8b94a2363e5234c0aacbc707d09eca324a", "content": "Unified vector database abstraction:\n- `VectorStore` interface for similarity search\n- Advanced filtering with SQL-like expressions\n- `SimpleVectorStore` for in-memory usage\n- Batching support for embeddings", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-vector-store", "heading_level": 4, "file_order": 129, "section_index": 74, "content_hash": "57b182a47776c2f982e648ba4af48c8b94a2363e5234c0aacbc707d09eca324a", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:198abd850de35a6df1875379219e2fb1c8ae7342ba29fc6f8e818980226c9907", "content": "High-level conversational AI APIs:\n- `ChatClient` interface\n- Conversation persistence via `ChatMemory`\n- Response conversion with `OutputConverter`\n- Advisor-based interception\n- Synchronous and reactive streaming support", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-client-chat", "heading_level": 4, "file_order": 129, "section_index": 75, "content_hash": "198abd850de35a6df1875379219e2fb1c8ae7342ba29fc6f8e818980226c9907", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d4975ba4c70c1cd4fb337ec92d47f3276523904036fe97b16b8cc571679a0429", "content": "Bridges chat with vector stores for RAG:\n- `QuestionAnswerAdvisor`: injects context into prompts\n- `VectorStoreChatMemoryAdvisor`: stores/retrieves conversation history", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-advisors-vector-store", "heading_level": 4, "file_order": 129, "section_index": 76, "content_hash": "d4975ba4c70c1cd4fb337ec92d47f3276523904036fe97b16b8cc571679a0429", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:073fd94b1e9bacb03b38e711cbabef7d931c0818ece63f8208880739bc12c2af", "content": "Apache Cassandra persistence for `ChatMemory`:\n- `CassandraChatMemory` implementation\n- Type-safe CQL with Cassandra's QueryBuilder", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-model-chat-memory-cassandra", "heading_level": 4, "file_order": 129, "section_index": 77, "content_hash": "073fd94b1e9bacb03b38e711cbabef7d931c0818ece63f8208880739bc12c2af", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:0b35c7dea95281c03f5847ff04428b4a6d22c01a1f0e7ca33ec6d8a7b618b5a8", "content": "Neo4j graph database persistence for chat conversations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-model-chat-memory-neo4j", "heading_level": 4, "file_order": 129, "section_index": 78, "content_hash": "0b35c7dea95281c03f5847ff04428b4a6d22c01a1f0e7ca33ec6d8a7b618b5a8", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:98ea02bd40526fbb97d0f278bba76a1f33cd92b95e93a57ce58ebca55873acfa", "content": "Comprehensive framework for Retrieval Augmented Generation:\n- Modular architecture for RAG pipelines\n- `RetrievalAugmentationAdvisor` as main entry point\n- Functional programming principles with composable components", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "spring-ai-rag", "heading_level": 4, "file_order": 129, "section_index": 79, "content_hash": "98ea02bd40526fbb97d0f278bba76a1f33cd92b95e93a57ce58ebca55873acfa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d201499bb5994535a747e370dc09455f5651505b2feb81d8ee889d65d6fe94d4", "content": "The dependency hierarchy can be summarized as:\n\n* `spring-ai-commons` (foundation)\n* `spring-ai-model` (depends on commons)\n* `spring-ai-vector-store` and `spring-ai-client-chat` (both depend on model)\n* `spring-ai-advisors-vector-store` and `spring-ai-rag` (depend on both client-chat and vector-store)\n* `spring-ai-model-chat-memory-*` modules (depend on client-chat)\n\n[[common-toolcontext-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Dependency Structure", "heading_level": 3, "file_order": 129, "section_index": 80, "content_hash": "d201499bb5994535a747e370dc09455f5651505b2feb81d8ee889d65d6fe94d4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:d13ac0135fbecc4de7279d0bce7f76ab708f02aa2c03a49089715ddf878ee417", "content": "The `ToolContext` class has been enhanced to support both explicit and implicit tool resolution. Tools can now be:\n\n1. **Explicitly Included**: Tools that are explicitly requested in the prompt and included in the call to the model.\n2. **Implicitly Available**: Tools that are made available for runtime dynamic resolution, but never included in any call to the model unless explicitly requested.\n\nStarting with 1.0.0-M7, tools are only included in the call to the model if they are explicitly requested in the prompt or explicitly included in the call.\n\nAdditionally, the `ToolContext` class has now been marked as final and cannot be extended anymore. It was never supposed to be subclassed. You can add all the contextual data you need when instantiating a `ToolContext`, in the form of a `Map<String, Object>`. For more information, check the [documentation](https://docs.spring.io/spring-ai/reference/api/tools.html#_tool_context).\n\n[[upgrading-to-1-0-0-m6]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "ToolContext Changes", "heading_level": 3, "file_order": 129, "section_index": 81, "content_hash": "d13ac0135fbecc4de7279d0bce7f76ab708f02aa2c03a49089715ddf878ee417", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:dbc772c52d6d0097deda02bb3ac03ba66ca83af5bd970e446c98feb86038d042", "content": "The `Usage` interface and its default implementation `DefaultUsage` have undergone the following changes:\n\n1. Method Rename:\n* `getGenerationTokens()` is now `getCompletionTokens()`\n\n2. Type Changes:\n* All token count fields in `DefaultUsage` changed from `Long` to `Integer`:\n** `promptTokens`\n** `completionTokens` (formerly `generationTokens`)\n** `totalTokens`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Changes to Usage Interface and DefaultUsage Implementation", "heading_level": 3, "file_order": 129, "section_index": 82, "content_hash": "dbc772c52d6d0097deda02bb3ac03ba66ca83af5bd970e446c98feb86038d042", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:c61d78bec6cb217ed26657e26e064f46ca6bc61a8040fe52d71970780df6a54e", "content": "* Replace all calls to `getGenerationTokens()` with `getCompletionTokens()`\n\n* Update `DefaultUsage` constructor calls:\n[source,java]\n----\nnew DefaultUsage(Long promptTokens, Long generationTokens, Long totalTokens)\n\nnew DefaultUsage(Integer promptTokens, Integer completionTokens, Integer totalTokens)\n----\n\nNOTE: For more information on handling Usage, refer xref:api/usage-handling.adoc[here]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Required Actions", "heading_level": 4, "file_order": 129, "section_index": 83, "content_hash": "c61d78bec6cb217ed26657e26e064f46ca6bc61a8040fe52d71970780df6a54e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:a4440f2a736303594057c6fe935651c2c603e3861a186cf4638c3ad99cec6a78", "content": "While M6 maintains backward compatibility for JSON deserialization of the `generationTokens` field, this field will be removed in M7. Any persisted JSON documents using the old field name should be updated to use `completionTokens`.\n\nExample of the new JSON format:\n[source,json]\n----\n{\n \"promptTokens\": 100,\n \"completionTokens\": 50,\n \"totalTokens\": 150\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "JSON Ser/Deser changes", "heading_level": 4, "file_order": 129, "section_index": 84, "content_hash": "a4440f2a736303594057c6fe935651c2c603e3861a186cf4638c3ad99cec6a78", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:47db9d5ade1b542bd15a2ce07c2867ff514b9e46dca870cb999824619b87534e", "content": "Each `ChatModel` instance, at construction time, accepts an optional `ChatOptions` or `FunctionCallingOptions` instance\nthat can be used to configure default tools used for calling the model.\n\nBefore 1.0.0-M6:\n\n- any tool passed via the `functions()` method of the default `FunctionCallingOptions` instance was included in\neach call to the model from that `ChatModel` instance, possibly overwritten by runtime options.\n- any tool passed via the `functionCallbacks()` method of the default `FunctionCallingOptions` instance was only\nmade available for runtime dynamic resolution (see xref:api/tools.adoc#_tool_resolution[Tool Resolution]), but never\nincluded in any call to the model unless explicitly requested.\n\nStarting 1.0.0-M6:\n\n- any tool passed via the `functions()` method or the `functionCallbacks()` of the default `FunctionCallingOptions`\ninstance is now handled in the same way: it is included in each call to the model from that `ChatModel` instance,\npossibly overwritten by runtime options. With that, there is consistency in the way tools are included in calls\nto the model and prevents any confusion due to a difference in behavior between `functionCallbacks()` and all the other options.\n\nIf you want to make a tool available for runtime dynamic resolution and include it in a chat request to the model only\nwhen explicitly requested, you can use one of the strategies described in xref:api/tools.adoc#_tool_resolution[Tool Resolution].\n\nNOTE: 1.0.0-M6 introduced new APIs for handling tool calling. Backward compatibility is maintained for the old APIs across\nall scenarios, except the one described above. The old APIs are still available, but they are deprecated\nand will be removed in 1.0.0-M7.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Changes to usage of FunctionCallingOptions for tool calling", "heading_level": 3, "file_order": 129, "section_index": 85, "content_hash": "47db9d5ade1b542bd15a2ce07c2867ff514b9e46dca870cb999824619b87534e", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:4a24acd93d97f7032b0434d72a4d32813101fc713ed4820af90eed16d9d16bac", "content": "Starting 1.0.0-M6, Spring AI transitioned to using Amazon Bedrock's Converse API for all Chat conversation implementations in Spring AI.\nAll the Amazon Bedrock Chat models are removed except the Embedding models for Cohere and Titan.\n\nNOTE: Refer to xref:api/chat/bedrock-converse.adoc[Bedrock Converse] documentation for using the chat models.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Removal of deprecated Amazon Bedrock chat models", "heading_level": 3, "file_order": 129, "section_index": 86, "content_hash": "4a24acd93d97f7032b0434d72a4d32813101fc713ed4820af90eed16d9d16bac", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:bb7f866b0b8f1ae73415fc0b03dc2a93216d0d0e6a1b9faa55a59904f5ed2caa", "content": "Spring AI updates to use Spring Boot 3.4.2 for the dependency management. You can refer https://github.com/spring-projects/spring-boot/blob/v3.4.2/spring-boot-project/spring-boot-dependencies/build.gradle[here] for the dependencies managed by Spring Boot 3.4.2", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Changes to use Spring Boot 3.4.2 for dependency management", "heading_level": 3, "file_order": 129, "section_index": 87, "content_hash": "bb7f866b0b8f1ae73415fc0b03dc2a93216d0d0e6a1b9faa55a59904f5ed2caa", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:b54b8f9ac0a0a78fb679070c2e48757dc7e7055dd0e134b5602d749d877322a4", "content": "* If you are upgrading to Spring Boot 3.4.2, please make sure to refer to https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.4-Release-Notes#upgrading-from-spring-boot-33[this] documentation for the changes required to configure the REST Client. Notably, if you don’t have an HTTP client library on the classpath, this will likely result in the use of `JdkClientHttpRequestFactory` where `SimpleClientHttpRequestFactory` would have been used previously. To switch to use `SimpleClientHttpRequestFactory`, you need to set `spring.http.client.factory=simple`.\n* If you are using a different version of Spring Boot (say Spring Boot 3.3.x) and need a specific version of a dependency, you can override it in your build configuration.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Required Actions", "heading_level": 4, "file_order": 129, "section_index": 88, "content_hash": "b54b8f9ac0a0a78fb679070c2e48757dc7e7055dd0e134b5602d749d877322a4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:085a4207593074de01d4775dce2496f2a8442c54a42d77301c3dbb323c76e374", "content": "In version 1.0.0-M6, the `delete` method in the `VectorStore` interface has been modified to be a void operation instead of returning an `Optional<Boolean>`.\nIf your code previously checked the return value of the delete operation, you'll need to remove this check.\nThe operation now throws an exception if the deletion fails, providing more direct error handling.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Vector Store API changes", "heading_level": 3, "file_order": 129, "section_index": 89, "content_hash": "085a4207593074de01d4775dce2496f2a8442c54a42d77301c3dbb323c76e374", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7a5b586c1db32aa9e78a91d772397156bb51c1cde062516f18736865fbb2c02c", "content": "[source,java]\n----\nOptional<Boolean> result = vectorStore.delete(ids);\nif (result.isPresent() && result.get()) {\n // handle successful deletion\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Before 1.0.0-M6:", "heading_level": 4, "file_order": 129, "section_index": 90, "content_hash": "7a5b586c1db32aa9e78a91d772397156bb51c1cde062516f18736865fbb2c02c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:69a12959ad3142edc0be862ef4725d52136696c3aa05d98f94f3083eb35ead50", "content": "[source,java]\n----\nvectorStore.delete(ids);\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "In 1.0.0-M6 and later:", "heading_level": 4, "file_order": 129, "section_index": 91, "content_hash": "69a12959ad3142edc0be862ef4725d52136696c3aa05d98f94f3083eb35ead50", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:aba8b1d1159cb96a358665f0ae1e68b4340d79d54ec66ce4728081c8e32a968c", "content": "* Vector Builders have been refactored for consistency.\n* Current VectorStore implementation constructors have been deprecated, use the builder pattern.\n* VectorStore implementation packages have been moved into unique package names, avoiding conflicts across artifact. For example `org.springframework.ai.vectorstore` to `org.springframework.ai.pgvector.vectorstore`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0.M5", "heading_level": 2, "file_order": 129, "section_index": 92, "content_hash": "aba8b1d1159cb96a358665f0ae1e68b4340d79d54ec66ce4728081c8e32a968c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:ee906d89b397336373abe676bc1b71d697891a6844a3f128f6038d8f58a61c24", "content": "* The type of the portable chat options (`frequencyPenalty`, `presencePenalty`, `temperature`, `topP`) has been changed from `Float` to `Double`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0.RC3", "heading_level": 2, "file_order": 129, "section_index": 93, "content_hash": "ee906d89b397336373abe676bc1b71d697891a6844a3f128f6038d8f58a61c24", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:16218e8c55b596ff3321658f79b3f9e1b3e94c53b262f76ce73f1c1445888bff", "content": "* The configuration prefix for the Chroma Vector Store has been changes from `spring.ai.vectorstore.chroma.store` to `spring.ai.vectorstore.chroma` in order to align with the naming conventions of other vector stores.\n\n* The default value of the `initialize-schema` property on vector stores capable of initializing a schema is now set to `false`.\nThis implies that the applications now need to explicitly opt-in for schema initialization on supported vector stores, if the schema is expected to be created at application startup.\nNot all vector stores support this property.\nSee the corresponding vector store documentation for more details.\nThe following are the vector stores that currently don't support the `initialize-schema` property.\n\n1. Hana\n2. Pinecone\n3. Weaviate\n\n* In Bedrock Jurassic 2, the chat options `countPenalty`, `frequencyPenalty`, and `presencePenalty`\nhave been renamed to `countPenaltyOptions`, `frequencyPenaltyOptions`, and `presencePenaltyOptions`.\nFurthermore, the type of the chat option `stopSequences` have been changed from `String[]` to `List<String>`.\n\n* In Azure OpenAI, the type of the chat options `frequencyPenalty` and `presencePenalty`\nhas been changed from `Double` to `Float`, consistently with all the other implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0.M2", "heading_level": 2, "file_order": 129, "section_index": 94, "content_hash": "16218e8c55b596ff3321658f79b3f9e1b3e94c53b262f76ce73f1c1445888bff", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:f7a6d9efe9284e0ddc7225fc462c13728aef2cb3e0162501fcf18f08015aaaeb", "content": "On our march to release 1.0.0 M1 we have made several breaking changes. Apologies, it is for the best!", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 1.0.0.M1", "heading_level": 2, "file_order": 129, "section_index": 95, "content_hash": "f7a6d9efe9284e0ddc7225fc462c13728aef2cb3e0162501fcf18f08015aaaeb", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:07f598c26e05bd373c32856401b5402442245ed92094770b0621bc6e460458c1", "content": "A major change was made that took the 'old' `ChatClient` and moved the functionality into `ChatModel`. The 'new' `ChatClient` now takes an instance of `ChatModel`. This was done to support a fluent API for creating and executing prompts in a style similar to other client classes in the Spring ecosystem, such as `RestClient`, `WebClient`, and `JdbcClient`. Refer to the [JavaDoc](https://docs.spring.io/spring-ai/docs/api) for more information on the Fluent API, proper reference documentation is coming shortly.\n\nWe renamed the 'old' `ModelClient` to `Model` and renamed implementing classes, for example `ImageClient` was renamed to `ImageModel`. The `Model` implementation represents the portability layer that converts between the Spring AI API and the underlying AI Model API.\n\nA new package `model` that contains interfaces and base classes to support creating AI Model Clients for any input/output data type combination. At the moment, the chat and image model packages implement this. We will be updating the embedding package to this new model soon.\n\nA new \"portable options\" design pattern. We wanted to provide as much portability in the `ModelCall` as possible across different chat based AI Models. There is a common set of generation options and then those that are specific to a model provider. A sort of \"duck typing\" approach is used. `ModelOptions` in the model package is a marker interface indicating implementations of this class will provide the options for a model. See `ImageOptions`, a subinterface that defines portable options across all text->image `ImageModel` implementations. Then `StabilityAiImageOptions` and `OpenAiImageOptions` provide the options specific to each model provider. All options classes are created via a fluent API builder, all can be passed into the portable `ImageModel` API. These option data types are used in autoconfiguration/configuration properties for the `ImageModel` implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "ChatClient changes", "heading_level": 3, "file_order": 129, "section_index": 96, "content_hash": "07f598c26e05bd373c32856401b5402442245ed92094770b0621bc6e460458c1", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:6f9b96d03cf4ab616a43c854dd20e426356ffab78bdfea7d698d7e55b0967041", "content": "Renamed POM artifact names:\n- spring-ai-qdrant -> spring-ai-qdrant-store\n- spring-ai-cassandra -> spring-ai-cassandra-store\n- spring-ai-pinecone -> spring-ai-pinecone-store\n- spring-ai-redis -> spring-ai-redis-store\n- spring-ai-qdrant -> spring-ai-qdrant-store\n- spring-ai-gemfire -> spring-ai-gemfire-store\n- spring-ai-azure-vector-store-spring-boot-starter -> spring-ai-azure-store-spring-boot-starter\n- spring-ai-redis-spring-boot-starter -> spring-ai-starter-vector-store-redis", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Artifact name changes", "heading_level": 3, "file_order": 129, "section_index": 97, "content_hash": "6f9b96d03cf4ab616a43c854dd20e426356ffab78bdfea7d698d7e55b0967041", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:21e8b84ecb63d4cd2d7ca647289fb95af8d1732d038b62933b894e11b3ee641c", "content": "Former `spring-ai-vertex-ai` has been renamed to `spring-ai-vertex-ai-palm2` and `spring-ai-vertex-ai-spring-boot-starter` has been renamed to `spring-ai-vertex-ai-palm2-spring-boot-starter`.\n\nSo, you need to change the dependency from\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai</artifactId>\n</dependency>\n----\n\nTo\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-palm2</artifactId>\n</dependency>\n----\n\nand the related Boot starter for the Palm2 model has changed from\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-spring-boot-starter</artifactId>\n</dependency>\n----\n\nto\n\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.ai</groupId>\n <artifactId>spring-ai-vertex-ai-palm2-spring-boot-starter</artifactId>\n</dependency>\n----\n\n* Renamed Classes (01.03.2024)\n\n** VertexAiApi -> VertexAiPalm2Api\n** VertexAiClientChat -> VertexAiPalm2ChatClient\n** VertexAiEmbeddingClient -> VertexAiPalm2EmbeddingClient\n** VertexAiChatOptions -> VertexAiPalm2ChatOptions", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "Upgrading to 0.8.1", "heading_level": 2, "file_order": 129, "section_index": 98, "content_hash": "21e8b84ecb63d4cd2d7ca647289fb95af8d1732d038b62933b894e11b3ee641c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:8d0b6c4aa27a399ba1e9c3a9acebc082bb40d7e792b531db03964d004ebf3986", "content": "* Moving the `prompt` and `messages` and `metadata` packages to subpackages of `org.springframework.ai.chat`\n* New functionality is *text to image* clients. Classes are `OpenAiImageModel` and `StabilityAiImageModel`. See the integration tests for usage, docs are coming soon.\n* A new package `model` that contains interfaces and base classes to support creating AI Model Clients for any input/output data type combination. At the moment, the chat and image model packages implement this. We will be updating the embedding package to this new model soon.\n* A new \"portable options\" design pattern. We wanted to provide as much portability in the `ModelCall` as possible across different chat based AI Models. There is a common set of generation options and then those that are specific to a model provider. A sort of \"duck typing\" approach is used. `ModelOptions` in the model package is a marker interface indicating implementations of this class will provide the options for a model. See `ImageOptions`, a subinterface that defines portable options across all text->image `ImageModel` implementations. Then `StabilityAiImageOptions` and `OpenAiImageOptions` provide the options specific to each model provider. All options classes are created via a fluent API builder, all can be passed into the portable `ImageModel` API. These option data types are used in autoconfiguration/configuration properties for the `ImageModel` implementations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "January 24, 2024 Update", "heading_level": 3, "file_order": 129, "section_index": 99, "content_hash": "8d0b6c4aa27a399ba1e9c3a9acebc082bb40d7e792b531db03964d004ebf3986", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:018d2bfc2b669507b26115440c531317513505d9360d4c6eaaed50f804c01ca4", "content": "The following OpenAi Autoconfiguration chat properties have changed\n\n* from `spring.ai.openai.model` to `spring.ai.openai.chat.options.model`.\n* from `spring.ai.openai.temperature` to `spring.ai.openai.chat.options.temperature`.\n\nFind updated documentation about the OpenAi properties: https://docs.spring.io/spring-ai/reference/api/chat/openai-chat.html", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "January 13, 2024 Update", "heading_level": 3, "file_order": 129, "section_index": 100, "content_hash": "018d2bfc2b669507b26115440c531317513505d9360d4c6eaaed50f804c01ca4", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:58442cb5fe1bef2a5b82220e273bc79186824e8587a4a818f3ddb45d1e0e6139", "content": "Merge SimplePersistentVectorStore and InMemoryVectorStore into SimpleVectorStore\n* Replace InMemoryVectorStore with SimpleVectorStore", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "December 27, 2023 Update", "heading_level": 3, "file_order": 129, "section_index": 101, "content_hash": "58442cb5fe1bef2a5b82220e273bc79186824e8587a4a818f3ddb45d1e0e6139", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:3a2bc6497e9fab49b6dcd1894860ea5fdf482443ab2dfa2ff43321f745f9ddf7", "content": "Refactor the Ollama client and related classes and package names\n\n* Replace the org.springframework.ai.ollama.client.OllamaClient by org.springframework.ai.ollama.OllamaModelCall.\n* The OllamaChatClient method signatures have changed.\n* Rename the org.springframework.ai.autoconfigure.ollama.OllamaProperties into org.springframework.ai.model.ollama.autoconfigure.OllamaChatProperties and change the suffix to: `spring.ai.ollama.chat`. Some of the properties have changed as well.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "December 20, 2023 Update", "heading_level": 3, "file_order": 129, "section_index": 102, "content_hash": "3a2bc6497e9fab49b6dcd1894860ea5fdf482443ab2dfa2ff43321f745f9ddf7", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:7456634c010c9c5754bb5f5360861295f1eb84cce60a756c42c2829a9b40916c", "content": "Renaming of AiClient and related classes and package names\n\n* Rename AiClient to ChatClient\n* Rename AiResponse to ChatResponse\n* Rename AiStreamClient to StreamingChatClient\n* Rename package org.sf.ai.client to org.sf.ai.chat\n\nRename artifact ID of\n\n* `transformers-embedding` to `spring-ai-transformers`\n\nMoved Maven modules from top-level directory and `embedding-clients` subdirectory to all be under a single `models` directory.\n\n[WARNING]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "December 19, 2023 Update", "heading_level": 3, "file_order": 129, "section_index": 103, "content_hash": "7456634c010c9c5754bb5f5360861295f1eb84cce60a756c42c2829a9b40916c", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:56f87957b0ca31ad786e6818d98c4d22dda872e1befbfa4669ab4b3633329dde", "content": "We are transitioning the project's Group ID:\n\n* *FROM*: `org.springframework.experimental.ai`\n* *TO*: `org.springframework.ai`\n\nArtifacts will still be hosted in the snapshot repository as shown below.\n\nThe main branch will move to the version `0.8.0-SNAPSHOT`.\nIt will be unstable for a week or two.\nPlease use the 0.7.1-SNAPSHOT if you don't want to be on the bleeding edge.\n\nYou can access `0.7.1-SNAPSHOT` artifacts as before and still access https://markpollack.github.io/spring-ai-0.7.1/[0.7.1-SNAPSHOT Documentation].", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "December 1, 2023", "heading_level": 3, "file_order": 129, "section_index": 104, "content_hash": "56f87957b0ca31ad786e6818d98c4d22dda872e1befbfa4669ab4b3633329dde", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
{"id": "sha256:94de210b5731393bee4199c8b256ea86a7d0ce2352ac0d906635cef40c1d80a0", "content": "* Azure OpenAI\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.experimental.ai</groupId>\n <artifactId>spring-ai-azure-openai-spring-boot-starter</artifactId>\n <version>0.7.1-SNAPSHOT</version>\n</dependency>\n----\n\n* OpenAI\n+\n[source,xml]\n----\n<dependency>\n <groupId>org.springframework.experimental.ai</groupId>\n <artifactId>spring-ai-openai-spring-boot-starter</artifactId>\n <version>0.7.1-SNAPSHOT</version>\n</dependency>\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-ai", "path": "antora/modules/ROOT/pages/upgrade-notes.adoc", "title": "upgrade-notes", "heading": "0.7.1-SNAPSHOT Dependencies", "heading_level": 3, "file_order": 129, "section_index": 105, "content_hash": "94de210b5731393bee4199c8b256ea86a7d0ce2352ac0d906635cef40c1d80a0", "source_url": "https://github.com/spring-projects/spring-ai/blob/e58dd56fd1bb913b86c2308dd83d2ba231b09ed5/spring-ai-docs/src/main/antora/modules/ROOT/pages/upgrade-notes.adoc"}}
