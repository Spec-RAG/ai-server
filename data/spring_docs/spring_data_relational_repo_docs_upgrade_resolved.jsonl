{"id": "sha256:fee8c208dd3e3bce36224344e61d4831118d713f9f4b6802d90fcb148238721f", "content": "The `Criteria` class provides the following methods, all of which correspond to SQL operators:\n\n* `Criteria` *and* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *or* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *greaterThan* `(Object o)`: Creates a criterion by using the `>` operator.\n* `Criteria` *greaterThanOrEquals* `(Object o)`: Creates a criterion by using the `>=` operator.\n* `Criteria` *in* `(Object... o)`: Creates a criterion by using the `IN` operator for a varargs argument.\n* `Criteria` *in* `(Collection<?> collection)`: Creates a criterion by using the `IN` operator using a collection.\n* `Criteria` *is* `(Object o)`: Creates a criterion by using column matching (`property = value`).\n* `Criteria` *isNull* `()`: Creates a criterion by using the `IS NULL` operator.\n* `Criteria` *isNotNull* `()`: Creates a criterion by using the `IS NOT NULL` operator.\n* `Criteria` *lessThan* `(Object o)`: Creates a criterion by using the `<` operator.\n* `Criteria` *lessThanOrEquals* `(Object o)`: Creates a criterion by using the `<=` operator.\n* `Criteria` *like* `(Object o)`: Creates a criterion by using the `LIKE` operator without escape character processing.\n* `Criteria` *not* `(Object o)`: Creates a criterion by using the `!=` operator.\n* `Criteria` *notIn* `(Object... o)`: Creates a criterion by using the `NOT IN` operator for a varargs argument.\n* `Criteria` *notIn* `(Collection<?> collection)`: Creates a criterion by using the `NOT IN` operator using a collection.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/commons/criteria-methods.adoc", "title": "criteria-methods", "heading": "Methods for the Criteria Class", "heading_level": 3, "file_order": 0, "section_index": 0, "content_hash": "fee8c208dd3e3bce36224344e61d4831118d713f9f4b6802d90fcb148238721f", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/commons/criteria-methods.adoc"}}
{"id": "sha256:56d6c06c684d4b51b78fb624ac7c1d36561aac47013db9bbdf59105ca1d8264e", "content": "include::{commons}@data-commons::page$custom-conversions.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/commons/custom-conversions.adoc", "title": "custom-conversions", "heading": "custom-conversions", "heading_level": 1, "file_order": 1, "section_index": 0, "content_hash": "56d6c06c684d4b51b78fb624ac7c1d36561aac47013db9bbdf59105ca1d8264e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/commons/custom-conversions.adoc"}}
{"id": "sha256:bb57ce3a17a948cd02472db06a1fc16e36f79506b958bd83b44a176a5c5c27e4", "content": "include::{commons}@data-commons::page$entity-callbacks.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/commons/entity-callbacks.adoc", "title": "entity-callbacks", "heading": "entity-callbacks", "heading_level": 1, "file_order": 2, "section_index": 0, "content_hash": "bb57ce3a17a948cd02472db06a1fc16e36f79506b958bd83b44a176a5c5c27e4", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/commons/entity-callbacks.adoc"}}
{"id": "sha256:43cbd2549100ed63938f23081eadc0002eee8b9c544f083a434936d68ae31979", "content": "include::{commons}@data-commons::page$upgrade.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/commons/upgrade.adoc", "title": "upgrade", "heading": "upgrade", "heading_level": 1, "file_order": 3, "section_index": 0, "content_hash": "43cbd2549100ed63938f23081eadc0002eee8b9c544f083a434936d68ae31979", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/commons/upgrade.adoc"}}
{"id": "sha256:9e273f4720cae080949129b01bda0df86f935e0c41f3492761556a71b5469876", "content": "This chapter covers Spring Data's Ahead of Time (AOT) optimizations that build upon {spring-framework-docs}/core/aot.html[Spring's Ahead of Time Optimizations].\n\n[[aot.bestpractices]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Ahead of Time Optimizations", "heading_level": 1, "file_order": 4, "section_index": 0, "content_hash": "9e273f4720cae080949129b01bda0df86f935e0c41f3492761556a71b5469876", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:3cc593cb0bd48d12df513f0568ed87c63c81a8cf393cb98b06f495f375cf26cc", "content": "During application startup, Spring scans the classpath for domain classes for early processing of entities.\nBy annotating your domain types with Spring Data-specific `@Table`, `@Document` or `@Entity` annotations you can aid initial entity scanning and ensure that those types are registered with `ManagedTypes` for Runtime Hints.\nClasspath scanning is not possible in native image arrangements and so Spring has to use `ManagedTypes` for the initial entity set.\n\n[[aot.hints]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Annotate your Domain Types", "heading_level": 3, "file_order": 4, "section_index": 1, "content_hash": "3cc593cb0bd48d12df513f0568ed87c63c81a8cf393cb98b06f495f375cf26cc", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:ea600a9c8441640c14b6a15803c23e92d2d1fe92f7aace31df5b7318b2d64b7b", "content": "Running an application as a native image requires additional information compared to a regular JVM runtime.\nSpring Data contributes {spring-framework-docs}/core/aot.html#aot.hints[Runtime Hints] during AOT processing for native image usage.\nThese are in particular hints for:\n\n* Auditing\n* `ManagedTypes` to capture the outcome of class-path scans\n* Repositories\n** Reflection hints for entities, return types, and Spring Data annotations\n** Repository fragments\n** Querydsl `Q` classes\n** Kotlin Coroutine support\n* Web support (Jackson Hints for `PagedModel`)\n\n[[aot.repositories]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Runtime Hints", "heading_level": 2, "file_order": 4, "section_index": 2, "content_hash": "ea600a9c8441640c14b6a15803c23e92d2d1fe92f7aace31df5b7318b2d64b7b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:4f7c7dca63fa3c462e23fe892d70404f09aec136da2f419b8f58d8d088466dc3", "content": "AOT Repositories are an extension to AOT processing by pre-generating eligible query method implementations.\nQuery methods are opaque to developers regarding their underlying queries being executed in a query method call.\nAOT repositories contribute query method implementations based on derived, annotated, and named queries that are known at build-time.\nThis optimization moves query method processing from runtime to build-time, which can lead to a significant performance improvement as query methods do not need to be analyzed reflectively upon each application start.\n\nThe resulting AOT repository fragment follows the naming scheme of `<Repository FQCN>Impl__Aot` and is placed in the same package as the repository interface.\nYou can find all queries in their String form for generated repository query methods.\n\nNOTE: Consider AOT repository classes an internal optimization.\nDo not use them directly in your code as generation and implementation details may change in future releases.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Ahead of Time Repositories", "heading_level": 2, "file_order": 4, "section_index": 3, "content_hash": "4f7c7dca63fa3c462e23fe892d70404f09aec136da2f419b8f58d8d088466dc3", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:750109da3ff4e7cede94be7baeb4404abe0fde51fc78d228f56b695d629d46f9", "content": "AOT is a mandatory step to transform a Spring application to a native executable, so it is automatically enabled when running in this mode.\nWhen AOT is enabled (either for native compilation or by setting `spring.aot.enabled=true`), AOT repositories are generated as well.\n\nYou can disable AOT repository generation entirely or only disable JDBC AOT repositories:\n\n* Set the `spring.aot.repositories.enabled=false` property to disable generated repositories for all Spring Data modules.\n* Set the `spring.aot.jdbc.repositories.enabled=false` property to disable only JDBC AOT repositories.\n\nAOT repositories contribute configuration changes to the actual repository bean registration to register the generated repository fragment.\n\nNOTE: When AOT optimizations are included, some decisions that have been taken at build-time are hard-coded in the application setup.\nFor instance, profiles that have been enabled at build-time are automatically enabled at runtime as well.\nAlso, the Spring Data module implementing a repository is fixed.\nChanging the implementation requires AOT re-processing.\n\nNOTE: Please provide a `JdbcDialect` to avoid early database access caused by dialect detection.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Running with AOT Repositories", "heading_level": 3, "file_order": 4, "section_index": 4, "content_hash": "750109da3ff4e7cede94be7baeb4404abe0fde51fc78d228f56b695d629d46f9", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:e86ee9966e29a19da72ff0dca1333afeb07dea53250dab288562cdcc652db227", "content": "AOT repositories filter methods that are eligible for AOT processing.\nThese are typically all query methods that are not backed by an xref:repositories/custom-implementations.adoc[implementation fragment].\n\n**Supported Features**\n\n* Derived query methods, `@Query` and named query methods\n* `@Modifying` methods returning `void`, `int`, and `long`\n* Pagination, `Slice`, `Stream`, and `Optional` return types\n* DTO and Interface Projections\n* Value Expressions\n\n**Limitations**\n\n* Methods accepting `ScrollPosition` (e.g. `Keyset` pagination) are not yet supported\n\n**Excluded methods**\n\n* `CrudRepository`, Querydsl, Query by Example, and other base interface methods as their implementation is provided by the base class respective fragments\n* Methods whose implementation would be overly complex\n\n[[aot.repositories.json]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Eligible Methods", "heading_level": 3, "file_order": 4, "section_index": 5, "content_hash": "e86ee9966e29a19da72ff0dca1333afeb07dea53250dab288562cdcc652db227", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:fa8c5d6ee6afed6d97027724cad87d9324b4b7611b56088600398b46b9734c43", "content": "AOT processing introspects query methods and collects metadata about repository queries.\nSpring Data JDBC stores this metadata in JSON files that are named like the repository interface and stored next to it (i.e. within the same package).\nRepository JSON Metadata contains details about queries and fragments.\nAn example for the following repository is shown below:\n\n====\n[source,java]\n----\ninterface UserRepository extends CrudRepository<User, Integer> {\n\n List<User> findUserNoArgumentsBy(); <1>\n\n Page<User> findPageOfUsersByLastnameStartingWith(String lastname, Pageable page); <2>\n\n @Query(\"select * from User u where username = ?1\")\n User findAnnotatedQueryByEmailAddress(String username); <3>\n\n User findByEmailAddress(String emailAddress); <4>\n}\n----\n\n<1> Derived query without arguments.\n<2> Derived query using pagination.\n<3> Annotated query.\n<4> Named query.\nWhile stored procedure methods are included in JSON metadata, their method code blocks are not generated in AOT repositories.\n====\n\n[source,json]\n----\n{\n \"name\": \"com.acme.UserRepository\",\n \"module\": \"JDBC\",\n \"type\": \"IMPERATIVE\",\n \"methods\": [\n {\n \"name\": \"findUserNoArgumentsBy\",\n \"signature\": \"public abstract java.util.List<com.acme.User> com.acme.UserRepository.findUserNoArgumentsBy()\",\n \"query\": {\n \"query\": \"SELECT * FROM User\"\n }\n },\n {\n \"name\": \"findPageOfUsersByLastnameStartingWith\",\n \"signature\": \"public abstract org.springframework.data.domain.Page<com.acme.User> com.acme.UserRepository.findPageOfUsersByLastnameStartingWith(java.lang.String,org.springframework.data.domain.Pageable)\",\n \"query\": {\n \"query\": \"SELECT * FROM User u WHERE lastname LIKE :lastname\",\n \"count-query\": \"SELECT COUNT(*) FROM User WHERE lastname LIKE :lastname\"\n }\n },\n {\n \"name\": \"findAnnotatedQueryByEmailAddress\",\n \"signature\": \"public abstract com.acme.User com.acme.UserRepository.findAnnotatedQueryByEmailAddress(java.lang.String)\",\n \"query\": {\n \"query\": \"select * from User where emailAddress = ?1\"\n }\n },\n {\n \"name\": \"findByEmailAddress\",\n \"signature\": \"public abstract com.acme.User com.acme.UserRepository.findByEmailAddress(java.lang.String)\",\n \"query\": {\n \"name\": \"User.findByEmailAddress\",\n \"query\": \"SELECT * FROM User WHERE emailAddress = ?1\"\n }\n },\n {\n \"name\": \"count\",\n \"signature\": \"public abstract long org.springframework.data.repository.CrudRepository.count()\",\n \"fragment\": {\n \"fragment\": \"org.springframework.data.jdbc.repository.support.SimpleJdbcRepository\"\n }\n }\n ]\n}\n----\n\nQueries may contain the following fields:\n\n* `query`: Query descriptor if the method is a query method.\n** `name`: Name of the named query if the query is a named one.\n** `query` the query used to obtain the query method result from `EntityManager`\n** `count-name`: Name of the named count query if the count query is a named one.\n** `count-query`: The count query used to obtain the count for query methods using pagination.\n* `fragment`: Target fragment if the method call is delegated to a store (repository base class, functional fragment such as Querydsl) or user fragment.\nFragments are either described with just `fragment` if there is no further interface or as `interface` and `fragment` tuple in case there is an interface (such as Querydsl or user-declared fragment interface).\n\n[NOTE]\n.Normalized Query Form\n====\nStatic analysis of queries allows only a limited representation of runtime query behavior.\nQueries are represented in their normalized (pre-parsed and rewritten) form:\n\n* Value Expressions are replaced with bind markers.\n* Query Metadata does not reflect bind-value processing.\n`StartingWith`/`EndingWith` queries prepend/append the wildcard character `%` to the actual bind value.\n* Runtime Sort information cannot be incorporated in the query string itself as that detail is not known at build-time.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/aot.adoc", "title": "Ahead of Time Optimizations", "heading": "Repository Metadata", "heading_level": 2, "file_order": 4, "section_index": 6, "content_hash": "fa8c5d6ee6afed6d97027724cad87d9324b4b7611b56088600398b46b9734c43", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/aot.adoc"}}
{"id": "sha256:2fb0836e4336b011f4defeb97fea3ad425b973f608da543d1765a50b60a8c04e", "content": "[[jdbc.auditing]]\n\nIn order to activate auditing, add `@EnableJdbcAuditing` to your configuration, as the following example shows:\n\n.Activating auditing with Java configuration\n[source,java]\n----\n@Configuration\n@EnableJdbcAuditing\nclass Config {\n\n @Bean\n AuditorAware<AuditableUser> auditorProvider() {\n return new AuditorAwareImpl();\n }\n}\n----\n\nIf you expose a bean of type `AuditorAware` to the `ApplicationContext`, the auditing infrastructure automatically picks it up and uses it to determine the current user to be set on domain types.\nIf you have multiple implementations registered in the `ApplicationContext`, you can select the one to be used by explicitly setting the `auditorAwareRef` attribute of `@EnableJdbcAuditing`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/auditing.adoc", "title": "auditing", "heading": "auditing", "heading_level": 1, "file_order": 5, "section_index": 0, "content_hash": "2fb0836e4336b011f4defeb97fea3ad425b973f608da543d1765a50b60a8c04e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/auditing.adoc"}}
{"id": "sha256:a2e72ccf4d654063720eb6caff30bc395bc71c0f7e7f911e00958355d51f0d8b", "content": "[[jdbc.domain-driven-design]]\n\nAll Spring Data modules are inspired by the concepts of \"`repository`\", \"`aggregate`\", and \"`aggregate root`\" from Domain Driven Design.\nThese are possibly even more important for Spring Data JDBC, because they are, to some extent, contrary to normal practice when working with relational databases.\n\nAn aggregate is a group of entities that is guaranteed to be consistent between atomic changes to it.\nA classic example is an `Order` with `OrderItems`.\nA property on `Order` (for example, `numberOfItems` is consistent with the actual number of `OrderItems`) remains consistent as changes are made.\n\nReferences across aggregates are not guaranteed to be consistent at all times.\nThey are guaranteed to become consistent eventually.\n\nEach aggregate has exactly one aggregate root, which is one of the entities of the aggregate.\nThe aggregate gets manipulated only through methods on that aggregate root.\nThese are the atomic changes mentioned earlier.\n\nA repository is an abstraction over a persistent store that looks like a collection of all the aggregates of a certain type.\nFor Spring Data in general, this means you want to have one `Repository` per aggregate root.\nIn addition, for Spring Data JDBC this means that all entities reachable from an aggregate root are considered to be part of that aggregate root.\nSpring Data JDBC assumes that only the aggregate has a foreign key to a table storing non-root entities of the aggregate and no other entity points toward non-root entities.\n\nWARNING: In the current implementation, entities referenced from an aggregate root are deleted and recreated by Spring Data JDBC.\n\nYou can overwrite the repository methods with implementations that match your style of working and designing your database.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/domain-driven-design.adoc", "title": "domain-driven-design", "heading": "domain-driven-design", "heading_level": 1, "file_order": 6, "section_index": 0, "content_hash": "a2e72ccf4d654063720eb6caff30bc395bc71c0f7e7f911e00958355d51f0d8b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/domain-driven-design.adoc"}}
{"id": "sha256:7ce45871974ab93a123b314526ded0e54fac6ba2a985a016bc6000d60eeb07db", "content": "[[jdbc.entity-persistence]]\n\nSaving an aggregate can be performed with the `CrudRepository.save(…)` method.\nIf the aggregate is new, this results in an insert for the aggregate root, followed by insert statements for all directly or indirectly referenced entities.\n\nIf the aggregate root is not new, all referenced entities get deleted, the aggregate root gets updated, and all referenced entities get inserted again.\nNote that whether an instance is new is part of the instance's state.\n\nNOTE: This approach has some obvious downsides.\nIf only few of the referenced entities have been actually changed, the deletion and insertion is wasteful.\nWhile this process could and probably will be improved, there are certain limitations to what Spring Data JDBC can offer.\nIt does not know the previous state of an aggregate.\nSo any update process always has to take whatever it finds in the database and make sure it converts it to whatever is the state of the entity passed to the save method.\n\nSee also xref:repositories/core-concepts.adoc#is-new-state-detection[Entity State Detection] for further details.\n\n[[jdbc.loading-aggregates]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "entity-persistence", "heading_level": 1, "file_order": 7, "section_index": 0, "content_hash": "7ce45871974ab93a123b314526ded0e54fac6ba2a985a016bc6000d60eeb07db", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:0ce37b678188f8be6bfc7fa3ef989b4d6ac53558fe93fbbf564f30ce988f6977", "content": "Spring Data JDBC offers two ways how it can load aggregates:\n\n. The traditional and before version 3.2 the only way is really simple:\nEach query loads the aggregate roots, independently if the query is based on a `CrudRepository` method, a derived query or an annotated query.\nIf the aggregate root references other entities those are loaded with separate statements.\n\n. Spring Data JDBC 3.2 allows the use of _Single Query Loading_.\nWith this an arbitrary number of aggregates can be fully loaded with a single SQL query.\nThis should be significantly more efficient, especially for complex aggregates, consisting of many entities.\n+\nCurrently, Single Query Loading is restricted in different ways:\n\n1. The aggregate must not have nested collections, this includes `Map`.\nThe plan is to remove this constraint in the future.\n\n2. The aggregate must not use `AggregateReference` or embedded entities.\nThe plan is to remove this constraint in the future.\n\n3. The database dialect must support it. Of the dialects provided by Spring Data JDBC all but H2 and HSQL support this.\nH2 and HSQL don't support analytic functions (aka windowing functions).\n\n4. It only works for the find methods in `CrudRepository`, not for derived queries and not for annotated queries.\nThe plan is to remove this constraint in the future.\n\n5. Single Query Loading needs to be enabled in the `JdbcMappingContext`, by calling `setSingleQueryLoadingEnabled(true)`.\n\nIf any condition is not fulfilled Spring Data JDBC falls back to the default approach of loading aggregates.\n\nNOTE: Single Query Loading is to be considered experimental.\nWe appreciate feedback on how it works for you.\n\nNOTE: While Single Query Loading can be abbreviated as SQL, but we highly discourage doing so since confusion with Structured Query Language is almost guaranteed.\n\n[[entity-persistence.id-generation]]\n== ID Generation\n\nSpring Data uses identifier properties to identify entities.\nThat is, looking these up or creating statements targeting a particular row.\nThe ID of an entity must be annotated with Spring Data's {spring-data-commons-javadoc-base}/org/springframework/data/annotation/Id.html[`@Id`] annotation.\n\nWhen your database has an auto-increment column for the ID column, the generated value gets set in the entity after inserting it into the database.\n\nIf you annotate the identifier property additionally with `@Sequence` a database sequence will be used to obtain values for the id if the underlying `Dialect` supports sequences.\n\nOtherwise, Spring Data does not attempt to insert values of identifier columns when the entity is new and the identifier value defaults to its initial value.\nThat is `0` for primitive types and `null` if the identifier property uses a numeric wrapper type such as `Long`.\n\nxref:repositories/core-concepts.adoc#is-new-state-detection[Entity State Detection] explains in detail the strategies to detect whether an entity is new or whether it is expected to exist in your database.\n\nOne important constraint is that, after saving an entity, the entity must not be new anymore.\nNote that whether an entity is new is part of the entity's state.\nWith auto-increment columns, this happens automatically, because the ID gets set by Spring Data with the value from the ID column.\n\n[[jdbc.template]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Loading Aggregates", "heading_level": 2, "file_order": 7, "section_index": 1, "content_hash": "0ce37b678188f8be6bfc7fa3ef989b4d6ac53558fe93fbbf564f30ce988f6977", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:776a149ccdea4218f621d6de384dd42d4f8b81837ba45e8a3b6264da953a2f57", "content": "As an alternative to repositories Spring Data JDBC offers the javadoc:org.springframework.data.jdbc.core.JdbcAggregateTemplate[] as a more direct means to load and persist entities in a relational database.\nTo a large extent, repositories use `JdbcAggregateTemplate` to implement their features.\n\nThis section highlights only the most interesting parts of the `JdbcAggregateTemplate`.\nFor a more complete overview, see the JavaDoc of `JdbcAggregateTemplate`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Template API", "heading_level": 2, "file_order": 7, "section_index": 2, "content_hash": "776a149ccdea4218f621d6de384dd42d4f8b81837ba45e8a3b6264da953a2f57", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:928019382fbfa1264cecc6db783e5329e1581faf033208cfccf31c25e0e55a2d", "content": "`JdbcAggregateTemplate` is intended to be used as a Spring bean.\nIf you have set up your application to include Spring Data JDBC, you can configure a dependency on `JdbcAggregateTemplate` in any Spring bean, and the Spring Framework injects a properly configured instance.\n\nThis includes fragments you use to implement custom methods for your Spring Data Repositories, letting you to use `JdbcAggregateTemplate` to customize and extend your repositories.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Accessing the JdbcAggregateTemplate", "heading_level": 3, "file_order": 7, "section_index": 3, "content_hash": "928019382fbfa1264cecc6db783e5329e1581faf033208cfccf31c25e0e55a2d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:af6b4803b52a43d3e7bab75b71112375066641449422f4157bb7320f0aefe0e3", "content": "`JdbcAggregateTemplate` offers three types of methods for persisting entities: `save`, `insert`, and `update`.\nEach comes in two flavors:\nOperating on single aggregates, named exactly as mentioned above, and with an `All` suffix operation on an `Iterable`.\n\n`save` does the same as the method of same name in a repository.\n\n`insert` and `update` skip the test if the entity is new and assume a new or existing aggregate as indicated by their names.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Persisting", "heading_level": 3, "file_order": 7, "section_index": 4, "content_hash": "af6b4803b52a43d3e7bab75b71112375066641449422f4157bb7320f0aefe0e3", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:13ea57fde5e3585ff2836b9da95fde2d80d7dbd007cd470a16fa4dac1a26acf8", "content": "`JdbcAggregateTemplate` offers a considerable array of methods for querying aggregates and about collections of aggregates.\nThere is one type of method that requires special attention.\nThat's the methods taking a `Query` as an argument.\nThey allow the execution of programmatically constructed queries, as follows:\n\n[source,java]\n----\ntemplate.findOne(query(where(\"name\").is(\"Gandalf\")), Person.class);\n----\n\nThe javadoc:org.springframework.data.relational.core.query.Query[] returned by the `query` method defines the list of columns to select, a where clause (through a CriteriaDefinition), and specification of limit and offset clauses.\nFor details of the `Query` class, see its JavaDoc.\n\nThe javadoc:org.springframework.data.relational.core.query.Criteria[] class, of which `where` is a static member, provides implementations of org.springframework.data.relational.core.query.CriteriaDefinition[], which represent the where-clause of the query.\n\n[[jdbc.criteria]]\n=== Methods for the Criteria Class\n\nThe `Criteria` class provides the following methods, all of which correspond to SQL operators:\n\n* `Criteria` *and* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *or* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *greaterThan* `(Object o)`: Creates a criterion by using the `>` operator.\n* `Criteria` *greaterThanOrEquals* `(Object o)`: Creates a criterion by using the `>=` operator.\n* `Criteria` *in* `(Object... o)`: Creates a criterion by using the `IN` operator for a varargs argument.\n* `Criteria` *in* `(Collection<?> collection)`: Creates a criterion by using the `IN` operator using a collection.\n* `Criteria` *is* `(Object o)`: Creates a criterion by using column matching (`property = value`).\n* `Criteria` *isNull* `()`: Creates a criterion by using the `IS NULL` operator.\n* `Criteria` *isNotNull* `()`: Creates a criterion by using the `IS NOT NULL` operator.\n* `Criteria` *lessThan* `(Object o)`: Creates a criterion by using the `<` operator.\n* `Criteria` *lessThanOrEquals* `(Object o)`: Creates a criterion by using the `<=` operator.\n* `Criteria` *like* `(Object o)`: Creates a criterion by using the `LIKE` operator without escape character processing.\n* `Criteria` *not* `(Object o)`: Creates a criterion by using the `!=` operator.\n* `Criteria` *notIn* `(Object... o)`: Creates a criterion by using the `NOT IN` operator for a varargs argument.\n* `Criteria` *notIn* `(Collection<?> collection)`: Creates a criterion by using the `NOT IN` operator using a collection.\n\n[[jdbc.entity-persistence.optimistic-locking]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Querying", "heading_level": 3, "file_order": 7, "section_index": 5, "content_hash": "13ea57fde5e3585ff2836b9da95fde2d80d7dbd007cd470a16fa4dac1a26acf8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:33ace854b20e8648a7631c5898b8eaf50bef70575cd8ec8daea35616fb893981", "content": "Spring Data supports optimistic locking by means of a numeric attribute that is annotated with\n{spring-data-commons-javadoc-base}/org/springframework/data/annotation/Version.html[`@Version`] on the aggregate root.\nWhenever Spring Data saves an aggregate with such a version attribute two things happen:\n\n* The update statement for the aggregate root will contain a where clause checking that the version stored in the database is actually unchanged.\n* If this isn't the case an `OptimisticLockingFailureException` will be thrown.\n\nAlso, the version attribute gets increased both in the entity and in the database so a concurrent action will notice the change and throw an `OptimisticLockingFailureException` if applicable as described above.\n\nThis process also applies to inserting new aggregates, where a `null` or `0` version indicates a new instance and the increased instance afterwards marks the instance as not new anymore, making this work rather nicely with cases where the id is generated during object construction for example when UUIDs are used.\n\nDuring deletes the version check also applies but no version is increased.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Optimistic Locking", "heading_level": 2, "file_order": 7, "section_index": 6, "content_hash": "33ace854b20e8648a7631c5898b8eaf50bef70575cd8ec8daea35616fb893981", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/entity-persistence.adoc"}}
{"id": "sha256:b2cccbc10c0145eeec91b3a9633fbc9047f9c029c353c6261c298a7eb9763fb8", "content": "[[jdbc.events]]\n\nSpring Data JDBC publishes lifecycle events to `ApplicationListener` objects, typically beans in the application context.\nEvents are notifications about a certain lifecycle phase.\nIn contrast to entity callbacks, events are intended for notification.\nTransactional listeners will receive events when the transaction completes.\nEvents and callbacks get only triggered for aggregate roots.\nIf you want to process non-root entities, you need to do that through a listener for the containing aggregate root.\n\nEntity lifecycle events can be costly, and you may notice a change in the performance profile when loading large result sets.\nYou can disable lifecycle events on javadoc:org.springframework.data.jdbc.core.JdbcAggregateTemplate#setEntityLifecycleEventsEnabled(boolean)[Template API].\n\nFor example, the following listener gets invoked before an aggregate gets saved:\n\n[source,java]\n----\n@Bean\nApplicationListener<BeforeSaveEvent<Object>> loggingSaves() {\n\n return event -> {\n\n Object entity = event.getEntity();\n LOG.info(\"{} is getting saved.\", entity);\n };\n}\n----\n\nIf you want to handle events only for a specific domain type you may derive your listener from `AbstractRelationalEventListener` and overwrite one or more of the `onXXX` methods, where `XXX` stands for an event type.\nCallback methods will only get invoked for events related to the domain type and their subtypes, therefore you don't require further casting.\n\n[source,java]\n----\nclass PersonLoadListener extends AbstractRelationalEventListener<Person> {\n\n @Override\n protected void onAfterLoad(AfterLoadEvent<Person> personLoad) {\n LOG.info(personLoad.getEntity());\n }\n}\n----\n\nThe following table describes the available events. For more details about the exact relation between process steps see the link:#jdbc.entity-callbacks[description of available callbacks] which map 1:1 to events.\n\n.Available events\n|===\n| Event | When It Is Published\n\n| javadoc:org.springframework.data.relational.core.mapping.event.BeforeDeleteEvent[]\n| Before an aggregate root gets deleted.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterDeleteEvent[]\n| After an aggregate root gets deleted.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.BeforeConvertEvent[]\n| Before an aggregate root gets converted into a plan for executing SQL statements, but after the decision was made if the aggregate is new or not, i.e. if an update or an insert is in order.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.BeforeSaveEvent[]\n| Before an aggregate root gets saved (that is, inserted or updated but after the decision about whether if it gets inserted or updated was made).\n\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterSaveEvent[]\n| After an aggregate root gets saved (that is, inserted or updated).\n\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterConvertEvent[]\n| After an aggregate root gets created from a database `ResultSet` and all its properties get set.\n|===\n\nWARNING: Lifecycle events depend on an `ApplicationEventMulticaster`, which in case of the `SimpleApplicationEventMulticaster` can be configured with a `TaskExecutor`, and therefore gives no guarantees when an Event is processed.\n\n[[jdbc.entity-callbacks]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/events.adoc", "title": "events", "heading": "events", "heading_level": 1, "file_order": 8, "section_index": 0, "content_hash": "b2cccbc10c0145eeec91b3a9633fbc9047f9c029c353c6261c298a7eb9763fb8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/events.adoc"}}
{"id": "sha256:9a958dafaac5e4feb71ba06cde39105e687bcc6e24133cb19292165c923b933e", "content": "Spring Data JDBC uses the xref:commons/entity-callbacks.adoc[`EntityCallback` API] for its auditing support and reacts on the callbacks listed in the following table.\n\n.Process Steps and Callbacks of the Different Processes performed by Spring Data JDBC.\n|===\n| Process | `EntityCallback` / Process Step | Comment\n\n.3+| Delete | javadoc:org.springframework.data.relational.core.mapping.event.BeforeDeleteCallback[]\n| Before the actual deletion.\n\n2+| The aggregate root and all the entities of that aggregate get removed from the database.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterDeleteCallback[]\n| After an aggregate gets deleted.\n\n.6+| Save 2+| Determine if an insert or an update of the aggregate is to be performed dependent on if it is new or not.\n| javadoc:org.springframework.data.relational.core.mapping.event.BeforeConvertCallback[]\n| This is the correct callback if you want to set an id programmatically. In the previous step new aggregates got detected as such and an Id generated in this step would be used in the following step.\n\n2+| Convert the aggregate to an aggregate change, it is a sequence of SQL statements to be executed against the database. In this step the decision is made if an Id is provided by the aggregate or if the Id is still empty and is expected to be generated by the database.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.BeforeSaveCallback[]\n| Changes made to the aggregate root may get considered, but the decision if an id value will be sent to the database is already made in the previous step.\nDo not use this for creating Ids for new aggregates. Use `BeforeConvertCallback` instead.\n\n2+| The SQL statements determined above get executed against the database.\n\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterSaveCallback[]\n| After an aggregate root gets saved (that is, inserted or updated).\n\n.2+| Load 2+| Load the aggregate using 1 or more SQL queries. Construct the aggregate from the resultset.\n| javadoc:org.springframework.data.relational.core.mapping.event.AfterConvertCallback[]\n|\n|===\n\nWe encourage the use of callbacks over events since they support the use of immutable classes and therefore are more powerful and versatile than events.\n\nThe delete and save related callbacks do not get invoked for derived query methods or annotated queries.\nIn general Spring Data JDBC does not have an efficient way to determine what aggregates are affected by these operations and therefore can't provide callbacks or events.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/events.adoc", "title": "events", "heading": "Store-specific EntityCallbacks", "heading_level": 2, "file_order": 8, "section_index": 1, "content_hash": "9a958dafaac5e4feb71ba06cde39105e687bcc6e24133cb19292165c923b933e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/events.adoc"}}
{"id": "sha256:a9d5e94d20c2fbd0beed43d9efe118f6dfef7047ff7f68d6eecd4067d4641b77", "content": "[[jdbc.getting-started]]\n\nAn easy way to bootstrap setting up a working environment is to create a Spring-based project in https://spring.io/tools[Spring Tools] or from https://start.spring.io[Spring Initializr].\n\nFirst, you need to set up a running database server.\nRefer to your vendor documentation on how to configure your database for JDBC access.\n\n[[requirements]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "getting-started", "heading_level": 1, "file_order": 9, "section_index": 0, "content_hash": "a9d5e94d20c2fbd0beed43d9efe118f6dfef7047ff7f68d6eecd4067d4641b77", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:4f0b36d221c0c2fb4f172e6bbe52922679d2e278930f7b42d67806e06caaada8", "content": "Spring Data JDBC requires {springdocsurl}[Spring Framework] {springVersion} and above.\n\nIn terms of databases, Spring Data JDBC requires a <<jdbc.dialects,dialect>> to abstract common SQL functionality over vendor-specific flavours.\nSpring Data JDBC includes direct support for the following databases:\n\n* DB2\n* H2\n* HSQLDB\n* MariaDB\n* Microsoft SQL Server\n* MySQL\n* Oracle\n* PostgreSQL\n\nIf you use a different database then your application won’t start up.\nThe <<jdbc.dialects,dialect>> section contains further detail on how to proceed in such case.\n\n[[jdbc.hello-world]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Requirements", "heading_level": 2, "file_order": 9, "section_index": 1, "content_hash": "4f0b36d221c0c2fb4f172e6bbe52922679d2e278930f7b42d67806e06caaada8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:e3e3a15d8c26a1ff73972b7ee8f811e92d882126fc84b2bc0be5149f3661f749", "content": "To create a Spring project in STS:\n\n. Go to File -> New -> Spring Template Project -> Simple Spring Utility Project, and press Yes when prompted.\nThen enter a project and a package name, such as `org.spring.jdbc.example`.\n. Add the following to the `pom.xml` file `dependencies` element:\n+\n[source,xml,subs=\"+attributes\"]\n----\n<dependencies>\n\n <!-- other dependency elements omitted -->\n\n <dependency>\n <groupId>org.springframework.data</groupId>\n <artifactId>spring-data-jdbc</artifactId>\n <version>{version}</version>\n </dependency>\n\n</dependencies>\n----\n\n. Change the version of Spring in the pom.xml to be\n+\n[source,xml,subs=\"+attributes\"]\n----\n<spring.version>{springVersion}</spring.version>\n----\n\n. Add the following location of the Spring Milestone repository for Maven to your `pom.xml` such that it is at the same level as your `<dependencies/>` element:\n+\n[source,xml]\n----\n<repositories>\n <repository>\n <id>spring-milestone</id>\n <name>Spring Maven MILESTONE Repository</name>\n <url>https://repo.spring.io/milestone</url>\n </repository>\n</repositories>\n----\n\nThe repository is also https://repo.spring.io/milestone/org/springframework/data/[browseable here].\n\n[[jdbc.logging]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Hello World", "heading_level": 2, "file_order": 9, "section_index": 2, "content_hash": "e3e3a15d8c26a1ff73972b7ee8f811e92d882126fc84b2bc0be5149f3661f749", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:fab45b95ae601cbf0cedb7056f240ad9750fc8e01ffcd0e3b49ecdc2c7a7ed1b", "content": "Spring Data JDBC does little to no logging on its own.\nInstead, the mechanics of `JdbcTemplate` to issue SQL statements provide logging.\nThus, if you want to inspect what SQL statements are run, activate logging for Spring's {spring-framework-docs}/data-access/jdbc/core.html#jdbc-NamedParameterJdbcTemplate[`NamedParameterJdbcTemplate`] or https://www.mybatis.org/mybatis-3/logging.html[MyBatis].\n\nYou may also want to set the logging level to `DEBUG` to see some additional information.\nTo do so, edit the `application.properties` file to have the following content:\n\n[source]\n----\nlogging.level.org.springframework.jdbc=DEBUG\n----\n\n[[jdbc.examples-repo]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Logging", "heading_level": 3, "file_order": 9, "section_index": 3, "content_hash": "fab45b95ae601cbf0cedb7056f240ad9750fc8e01ffcd0e3b49ecdc2c7a7ed1b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:2096fac0e0fcd099d3562a453623355ce6d48475674b778c713c123715013e64", "content": "There is a https://github.com/spring-projects/spring-data-examples[GitHub repository with several examples] that you can download and play around with to get a feel for how the library works.\n\n[[jdbc.java-config]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Examples Repository", "heading_level": 2, "file_order": 9, "section_index": 4, "content_hash": "2096fac0e0fcd099d3562a453623355ce6d48475674b778c713c123715013e64", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:389d9a578524f540f047fc1df2e05066dd66766f30b8aa0c3f4f12955e204d70", "content": "The Spring Data JDBC repositories support can be activated by an annotation through Java configuration, as the following example shows:\n\n.Spring Data JDBC repositories using Java configuration\n[source,java]\n----\n@Configuration\n@EnableJdbcRepositories // <1>\nclass ApplicationConfig extends AbstractJdbcConfiguration { // <2>\n\n @Bean\n DataSource dataSource() { // <3>\n\n EmbeddedDatabaseBuilder builder = new EmbeddedDatabaseBuilder();\n return builder.setType(EmbeddedDatabaseType.HSQL).build();\n }\n\n @Bean\n NamedParameterJdbcOperations namedParameterJdbcOperations(DataSource dataSource) { // <4>\n return new NamedParameterJdbcTemplate(dataSource);\n }\n\n @Bean\n TransactionManager transactionManager(DataSource dataSource) { // <5>\n return new DataSourceTransactionManager(dataSource);\n }\n}\n----\n\n<1> `@EnableJdbcRepositories` creates implementations for interfaces derived from `Repository`.\n<2> javadoc:org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration[] provides various default beans required by Spring Data JDBC.\n<3> Creates a `DataSource` connecting to a database.\nThis is required by the following two bean methods.\n<4> Creates the `NamedParameterJdbcOperations` used by Spring Data JDBC to access the database.\n<5> Spring Data JDBC utilizes the transaction management provided by Spring JDBC.\n\nThe configuration class in the preceding example sets up an embedded HSQL database by using the `EmbeddedDatabaseBuilder` API of `spring-jdbc`.\nThe `DataSource` is then used to set up `NamedParameterJdbcOperations` and a `TransactionManager`.\nWe finally activate Spring Data JDBC repositories by using the `@EnableJdbcRepositories`.\nIf no base package is configured, it uses the package in which the configuration class resides.\nExtending javadoc:org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration[] ensures various beans get registered.\nOverwriting its methods can be used to customize the setup (see below).\n\nThis configuration can be further simplified by using Spring Boot.\nWith Spring Boot a `DataSource` is sufficient once the starter `spring-boot-starter-data-jdbc` is included in the dependencies.\nEverything else is done by Spring Boot.\n\nThere are a couple of things one might want to customize in this setup.\n\n[[jdbc.dialects]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Configuration", "heading_level": 2, "file_order": 9, "section_index": 5, "content_hash": "389d9a578524f540f047fc1df2e05066dd66766f30b8aa0c3f4f12955e204d70", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:63bd8627faaf55ec6bde8651d62a0e7dd78027136a098279ccd6a79fe82dbc0b", "content": "Spring Data JDBC uses implementations of the interface `JdbcDialect` to encapsulate behavior that is specific to a database or its JDBC driver.\nBy default, the javadoc:org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration[] attempts to determine the dialect from the database configuration by obtaining a connection and registering the correct `JdbcDialect`.\nYou override `AbstractJdbcConfiguration.jdbcDialect(NamedParameterJdbcOperations)` to customize dialect selection.\n\nIf you use a database for which no dialect is available, then your application won’t start up.\nIn that case, you’ll have to ask your vendor to provide a `JdbcDialect` implementation.\nAlternatively, you can implement your own `JdbcDialect`.\n\n[TIP]\n====\nDialects are resolved by javadoc:org.springframework.data.jdbc.core.dialect.DialectResolver[] from a `JdbcOperations` instance, typically by inspecting `Connection.getMetaData()`. +\nYou can let Spring auto-discover your javadoc:org.springframework.data.jdbc.core.dialect.JdbcDialect[] by registering a class that implements `org.springframework.data.jdbc.core.dialect.DialectResolver$JdbcDialectProvider` through `META-INF/spring.factories`.\n`DialectResolver` discovers dialect provider implementations from the class path using Spring's `SpringFactoriesLoader`.\nTo do so:\n\n. Implement your own `JdbcDialect`.\n. Implement a `JdbcDialectProvider` returning the `JdbcDialect`.\n. Register the provider by creating a `spring.factories` resource under `META-INF` and perform the registration by adding a line +\n`org.springframework.data.jdbc.core.dialect.DialectResolver$JdbcDialectProvider`=<fully qualified name of your JdbcDialectProvider>`.\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/getting-started.adoc", "title": "getting-started", "heading": "Dialects", "heading_level": 2, "file_order": 9, "section_index": 6, "content_hash": "63bd8627faaf55ec6bde8651d62a0e7dd78027136a098279ccd6a79fe82dbc0b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/getting-started.adoc"}}
{"id": "sha256:b78b5a688f6f8fc62b7679e9672c02f8ccf55c30d16e6c6ff330978181f9430d", "content": "[[mapping]]\n\nRich mapping support is provided by the `MappingJdbcConverter`. `MappingJdbcConverter` has a rich metadata model that allows mapping domain objects to a data row.\nThe mapping metadata model is populated by using annotations on your domain objects.\nHowever, the infrastructure is not limited to using annotations as the only source of metadata information.\nThe `MappingJdbcConverter` also lets you map objects to rows without providing any additional metadata, by following a set of conventions.\n\nThis section describes the features of the `MappingJdbcConverter`, including how to use conventions for mapping objects to rows and how to override those conventions with annotation-based mapping metadata.\n\nRead on the basics about xref:object-mapping.adoc[] before continuing with this chapter.\n\n[[mapping.conventions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "mapping", "heading_level": 1, "file_order": 10, "section_index": 0, "content_hash": "b78b5a688f6f8fc62b7679e9672c02f8ccf55c30d16e6c6ff330978181f9430d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:0a78b64f0cc4396b585618b004a2016abb6a1d32406ec0d0d652140ea542a4a2", "content": "`MappingJdbcConverter` has a few conventions for mapping objects to rows when no additional mapping metadata is provided.\nThe conventions are:\n\n* The short Java class name is mapped to the table name in the following manner.\nThe `com.bigbank.SavingsAccount` class maps to the `SAVINGS_ACCOUNT` table name.\nThe same name mapping is applied for mapping fields to column names.\nFor example, the `firstName` field maps to the `FIRST_NAME` column.\nYou can control this mapping by providing a custom `NamingStrategy`.\nSee <<mapping.configuration,Mapping Configuration>> for more detail.\nTable and column names that are derived from property or class names are used in SQL statements without quotes by default.\nYou can control this behavior by setting `RelationalMappingContext.setForceQuote(true)`.\n\n* The converter uses any Spring Converters registered with `CustomConversions` to override the default mapping of object properties to row columns and values.\n\n* The fields of an object are used to convert to and from columns in the row.\nPublic `JavaBean` properties are not used.\n\n* If you have a single non-zero-argument constructor whose constructor argument names match top-level column names of the row, that constructor is used.\nOtherwise, the zero-argument constructor is used.\nIf there is more than one non-zero-argument constructor, an exception is thrown.\nRefer to xref:object-mapping.adoc#mapping.object-creation[Object Creation] for further details.\n\n[[jdbc.entity-persistence.types]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Convention-based Mapping", "heading_level": 2, "file_order": 10, "section_index": 1, "content_hash": "0a78b64f0cc4396b585618b004a2016abb6a1d32406ec0d0d652140ea542a4a2", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:ec63af627f0496c0de2160b45dea8409fcba8b37e5b95bce405fed461376ef20", "content": "The properties of the following types are currently supported:\n\n* All primitive types and their boxed types (`int`, `float`, `Integer`, `Float`, and so on)\n\n* Enums get mapped to their names.\n\n* `String`\n\n* `java.util.Date`, `java.time.LocalDate`, `java.time.LocalDateTime`, and `java.time.LocalTime`\n\n* Arrays and Collections of the types mentioned above can be mapped to columns of array type if your database supports that.\n\n* Anything your database driver accepts.\n\n* References to other entities.\nThey are considered a one-to-one relationship, or an embedded type.\nIt is optional for one-to-one relationship entities to have an `id` attribute.\nThe table of the referenced entity is expected to have an additional column with a name based on the referencing entity see <<jdbc.entity-persistence.types.backrefs>>.\nEmbedded entities do not need an `id`.\nIf one is present it gets mapped as a normal attribute without any special meaning.\n\n* `Set<some entity>` is considered a one-to-many relationship.\nThe table of the referenced entity is expected to have an additional column with a name based on the referencing entity see <<jdbc.entity-persistence.types.backrefs>>.\n\n* `Map<simple type, some entity>` is considered a qualified one-to-many relationship.\nThe table of the referenced entity is expected to have two additional columns: One named based on the referencing entity for the foreign key (see <<jdbc.entity-persistence.types.backrefs>>) and one with the same name and an additional `_key` suffix for the map key.\n\n* `List<some entity>` is mapped as a `Map<Integer, some entity>`.\nThe same additional columns are expected and the names used can be customized in the same way.\n+\nFor `List`, `Set`, and `Map` naming of the back reference can be controlled by implementing `NamingStrategy.getReverseColumnName(RelationalPersistentEntity<?> owner)` and `NamingStrategy.getKeyColumn(RelationalPersistentProperty property)`, respectively.\nAlternatively you may annotate the attribute with `@MappedCollection(idColumn=\"your_column_name\", keyColumn=\"your_key_column_name\")`.\nSpecifying a key column for a `Set` has no effect.\n\n* Types for which you registered suitable xref:#mapping.explicit.converters[custom converters].\n\n[[mapping.usage.annotations]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Supported Types in Your Entity", "heading_level": 2, "file_order": 10, "section_index": 2, "content_hash": "ec63af627f0496c0de2160b45dea8409fcba8b37e5b95bce405fed461376ef20", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:346a960c9841a188a5952a068ab65ce97546867d625bab0e00ba92f856aa0607", "content": "The `RelationalConverter` can use metadata to drive the mapping of objects to rows.\nThe following annotations are available:\n\n* `@Embedded`: a property with this annotation will be mapped to the table of the parent entity, instead of a separate table.\nAllows to specify if the resulting columns should have a common prefix.\nIf all columns resulting from such an entity are `null` either the annotated entity will be `null` or _empty_, i.e. all of its properties will be `null`, depending on the value of `@Embedded.onEmpty()`\nMay be combined with `@Id` to form a composite id.\n* `@Id`: Applied at the field level to mark the primary key.\nIt may be combined with `@Embedded` to form a composite id.\n* `@InsertOnlyProperty`: Marks a property as only to be written during insert.\nSuch a property on an aggregate root will only be written once and never updated.\nNote that on a nested entity, all save operations result in an insert therefore this annotation has no effect on properties of nested entities.\n* `@MappedCollection`: Allows for configuration how a collection, or a single nested entity gets mapped. `idColumn` specifies the column used for referencing the parent entities primary key. `keyColumn` specifies the column used to store the index of a `List` or the key of a `Map`.\n* `@Sequence`: specify a database sequence for generating values for the annotated property.\n* `@Table`: Applied at the class level to indicate this class is a candidate for mapping to the database.\nYou can specify the name of the table where the database is stored.\n* `@Transient`: By default, all fields are mapped to the row.\nThis annotation excludes the field where it is applied from being stored in the database.\nTransient properties cannot be used within a persistence constructor as the converter cannot materialize a value for the constructor argument.\n* `@PersistenceCreator`: Marks a given constructor or static factory method -- even a package protected one -- to use when instantiating the object from the database.\nConstructor arguments are mapped by name to the values in the retrieved row.\n* `@Value`: This annotation is part of the Spring Framework.\nWithin the mapping framework it can be applied to constructor arguments.\nThis lets you use a Spring Expression Language statement to transform a key’s value retrieved in the database before it is used to construct a domain object.\nIn order to reference a column of a given row one has to use expressions like: `@Value(\"#root.myProperty\")` where root refers to the root of the given `Row`.\n* `@Column`: Applied at the field level to describe the name of the column as it is represented in the row, letting the name be different from the field name of the class.\nNames specified with a `@Column` annotation are always quoted when used in SQL statements.\nFor most databases, this means that these names are case-sensitive.\nIt also means that you can use special characters in these names.\nHowever, this is not recommended, since it may cause problems with other tools.\n* `@Version`: Applied at field level is used for optimistic locking and checked for modification on save operations.\nThe value is `null` (`zero` for primitive types) is considered as marker for entities to be new.\nThe initially stored value is `zero` (`one` for primitive types).\nThe version gets incremented automatically on every update.\n\nSee xref:jdbc/entity-persistence.adoc#jdbc.entity-persistence.optimistic-locking[Optimistic Locking] for further reference.\n\nThe mapping metadata infrastructure is defined in the separate `spring-data-commons` project that is technology-agnostic.\nSpecific subclasses are used in the JDBC support to support annotation based metadata.\nOther strategies can also be put in place (if there is demand).\n\n[[jdbc.entity-persistence.types.referenced-entities]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Mapping Annotation Overview", "heading_level": 3, "file_order": 10, "section_index": 3, "content_hash": "346a960c9841a188a5952a068ab65ce97546867d625bab0e00ba92f856aa0607", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:2153372e5b5da5f736df7f6f6c2afbd2e3f192167142f0a052bc9625385a1401", "content": "The handling of referenced entities is limited.\nThis is based on the idea of aggregate roots as described above.\nIf you reference another entity, that entity is, by definition, part of your aggregate.\nSo, if you remove the reference, the previously referenced entity gets deleted.\nThis also means references are 1-1 or 1-n, but not n-1 or n-m.\n\nIf you have n-1 or n-m references, you are, by definition, dealing with two separate aggregates.\nReferences between those may be encoded as simple `id` values, which map properly with Spring Data JDBC.\nA better way to encode these, is to make them instances of `AggregateReference`.\nAn `AggregateReference` is a wrapper around an id value which marks that value as a reference to a different aggregate.\nAlso, the type of that aggregate is encoded in a type parameter.\n\n[[jdbc.entity-persistence.types.backrefs]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Referenced Entities", "heading_level": 3, "file_order": 10, "section_index": 4, "content_hash": "2153372e5b5da5f736df7f6f6c2afbd2e3f192167142f0a052bc9625385a1401", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:1b7f137accb35ff8cbc3b41bf9147c352835f403c2c1ba79d90be798ed00d625", "content": "All references in an aggregate result in a foreign key relationship in the opposite direction in the database.\nBy default, the name of the foreign key column is the table name of the referencing entity.\n\nIf the referenced id is an `@Embedded` id, the back reference consists of multiple columns, each named by a concatenation of <table-name> + `_` + <column-name>.\nE.g. the back reference to a `Person` entity, with a composite id with the properties `firstName` and `lastName` will consist of the two columns `PERSON_FIRST_NAME` and `PERSON_LAST_NAME`.\n\nAlternatively you may choose to have them named by the entity name of the referencing entity ignoring `@Table` annotations.\nYou activate this behaviour by calling `setForeignKeyNaming(ForeignKeyNaming.IGNORE_RENAMING)` on the `RelationalMappingContext`.\n\nFor `List` and `Map` references an additional column is required for holding the list index or map key.\nIt is based on the foreign key column with an additional `_KEY` suffix.\n\nIf you want a completely different way of naming these back references you may implement `NamingStrategy.getReverseColumnName(RelationalPersistentEntity<?> owner)` in a way that fits your needs.\n\n.Declaring and setting an `AggregateReference`\n[source,java]\n----\nclass Person {\n @Id long id;\n AggregateReference<Person, Long> bestFriend;\n}\n\nPerson p1, p2 = // some initialization\n\np1.bestFriend = AggregateReference.to(p2.id);\n\n----\n\nYou should not include attributes in your entities to hold the actual value of a back reference, nor of the key column of maps or lists.\nIf you want these values to be available in your domain model we recommend to do this in an `AfterConvertCallback` and store the values in transient values.\n\n[[entity-persistence.naming-strategy]]\n== Naming Strategy\n\nBy convention, Spring Data applies a `NamingStrategy` to determine table, column, and schema names defaulting to https://en.wikipedia.org/wiki/Snake_case[snake case].\nAn object property named `firstName` becomes `first_name`.\nYou can tweak that by providing a javadoc:org.springframework.data.relational.core.mapping.NamingStrategy[] in your application context.\n\n[[entity-persistence.custom-table-name]]\n== Override table names\n\nWhen the table naming strategy does not match your database table names, you can override the table name with the javadoc:org.springframework.data.relational.core.mapping.Table[] annotation.\nThe element `value` of this annotation provides the custom table name.\nThe following example maps the `MyEntity` class to the `CUSTOM_TABLE_NAME` table in the database:\n\n[source,java]\n----\n@Table(\"CUSTOM_TABLE_NAME\")\nclass MyEntity {\n    @Id\n    Integer id;\n\n    String name;\n}\n----\n\nYou may use xref:value-expressions.adoc[Spring Data's SpEL support] to dynamically create the table name.\nOnce generated the table name will be cached, so it is dynamic per mapping context only.\n\n[[entity-persistence.custom-column-name]]\n== Override column names\n\nWhen the column naming strategy does not match your database table names, you can override the table name with the javadoc:org.springframework.data.relational.core.mapping.Column[] annotation.\nThe element `value` of this annotation provides the custom column name.\nThe following example maps the `name` property of the `MyEntity` class to the `CUSTOM_COLUMN_NAME` column in the database:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @Column(\"CUSTOM_COLUMN_NAME\")\n    String name;\n}\n----\n\nifdef::mapped-collection[]\n\nThe javadoc:org.springframework.data.relational.core.mapping.MappedCollection[]\nannotation can be used on a reference type (one-to-one relationship) or on Sets, Lists, and Maps (one-to-many relationship).\n`idColumn` element of the annotation provides a custom name for the foreign key column referencing the id column in the other table.\nIn the following example the corresponding table for the `MySubEntity` class has a `NAME` column, and the `CUSTOM_MY_ENTITY_ID_COLUMN_NAME` column of the `MyEntity` id for relationship reasons:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @MappedCollection(idColumn = \"CUSTOM_MY_ENTITY_ID_COLUMN_NAME\")\n    Set<MySubEntity> subEntities;\n}\n\nclass MySubEntity {\n    String name;\n}\n----\n\nWhen using `List` and `Map` you must have an additional column for the position of a dataset in the `List` or the key value of the entity in the `Map`.\nThis additional column name may be customized with the `keyColumn` Element of the javadoc:org.springframework.data.relational.core.mapping.MappedCollection[] annotation:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @MappedCollection(idColumn = \"CUSTOM_COLUMN_NAME\", keyColumn = \"CUSTOM_KEY_COLUMN_NAME\")\n    List<MySubEntity> name;\n}\n\nclass MySubEntity {\n    String name;\n}\n----\nendif::[]\n\nYou may use xref:value-expressions.adoc[Spring Data's SpEL support] to dynamically create column names.\nOnce generated the names will be cached, so it is dynamic per mapping context only.\n\nifdef::embedded-entities[]\n\n[[entity-persistence.embedded-entities]]\n== Embedded entities\n\nEmbedded entities are used to have value objects in your java data model, even if there is only one table in your database.\nIn the following example you see, that `MyEntity` is mapped with the `@Embedded` annotation.\nThe consequence of this is, that in the database a table `my_entity` with the two columns `id` and `name` (from the `EmbeddedEntity` class) is expected.\n\nHowever, if the `name` column is actually `null` within the result set, the entire property `embeddedEntity` will be set to null according to the `onEmpty` of `@Embedded`, which ``null``s objects when all nested properties are `null`. +\nOpposite to this behavior `USE_EMPTY` tries to create a new instance using either a default constructor or one that accepts nullable parameter values from the result set.\n\n.Sample Code of embedding objects\n====\n[source,java]\n----\nclass MyEntity {\n\n    @Id\n    Integer id;\n\n    @Embedded(onEmpty = USE_NULL) <1>\n    EmbeddedEntity embeddedEntity;\n}\n\nclass EmbeddedEntity {\n    String name;\n}\n----\n\n<1> ``Null``s `embeddedEntity` if `name` in `null`.\nUse `USE_EMPTY` to instantiate `embeddedEntity` with a potential `null` value for the `name` property.\n====\n\nIf you need a value object multiple times in an entity, this can be achieved with the optional `prefix` element of the `@Embedded` annotation.\nThis element represents a prefix and is prepend for each column name in the embedded object.\n\n[TIP]\n====\nMake use of the shortcuts `@Embedded.Nullable` & `@Embedded.Empty` for `@Embedded(onEmpty = USE_NULL)` and `@Embedded(onEmpty = USE_EMPTY)` to reduce verbosity and simultaneously set JSR-305 `@javax.annotation.Nonnull` accordingly.\n\n[source,java]\n----\nclass MyEntity {\n\n    @Id\n    Integer id;\n\n    @Embedded.Nullable <1>\n    EmbeddedEntity embeddedEntity;\n}\n----\n\n<1> Shortcut for `@Embedded(onEmpty = USE_NULL)`.\n====\n\nEmbedded entities containing a `Collection` or a `Map` will always be considered non-empty since they will at least contain the empty collection or map.\nSuch an entity will therefore never be `null` even when using @Embedded(onEmpty = USE_NULL).\nendif::[]\n\n[[entity-persistence.embedded-ids]]\n=== Embedded Ids\n\nThe identifier property can be annotated with `@Embedded` allowing to use composite ids.\nThe full embedded entity is considered the id, and therefore the check for determining if an aggregate is considered a new aggregate requiring an insert or an existing one, asking for an update is based on that entity, not its elements.\nMost use cases will require a custom `BeforeConvertCallback` to set the id for new aggregate.\n\n====\n.Simple entity with composite id\n[source,java]\n----\n@Table(\"PERSON_WITH_COMPOSITE_ID\")\nrecord Person( <1>\n    @Id @Embedded.Nullable Name pk, <2>\n    String nickName,\n    Integer age\n) {\n}\n\nrecord Name(String first, String last) {\n}\n----\n\n.Matching table for simple entity with composite id\n[source,sql]\n----\nCREATE TABLE PERSON_WITH_COMPOSITE_ID (\n    FIRST VARCHAR(100),\n    LAST VARCHAR(100),\n    NICK_NAME VARCHAR(100),\n    AGE INT,\n    PRIMARY KEY (FIRST, LAST) <3>\n);\n\n\n----\n\n<1> Entities may be represented as records without any special consideration.\n<2> `pk` is marked as id and embedded\n<3> The two columns from the embedded `Name` entity make up the primary key in the database.\n\nDetails of table creation depend on the used database.\n====\n\n[[entity-persistence.read-only-properties]]\n== Read Only Properties\n\nAttributes annotated with `@ReadOnlyProperty` will not be written to the database by Spring Data, but they will be read when an entity gets loaded.\n\nSpring Data will not automatically reload an entity after writing it.\nTherefore, you have to reload it explicitly if you want to see data that was generated in the database for such columns.\n\nIf the annotated attribute is an entity or collection of entities, it is represented by one or more separate rows in separate tables.\nSpring Data will not perform any insert, delete or update for these rows.\n\n[[entity-persistence.insert-only-properties]]\n== Insert Only Properties\n\nAttributes annotated with `@InsertOnlyProperty` will only be written to the database by Spring Data during insert operations.\nFor updates these properties will be ignored.\n\n`@InsertOnlyProperty` is only supported for the aggregate root.\n\n[[mapping.custom.object.construction]]\n== Customized Object Construction\n\nThe mapping subsystem allows the customization of the object construction by annotating a constructor with the `@PersistenceConstructor` annotation.The values to be used for the constructor parameters are resolved in the following way:\n\n* If a parameter is annotated with the `@Value` annotation, the given expression is evaluated, and the result is used as the parameter value.\n* If the Java type has a property whose name matches the given field of the input row, then its property information is used to select the appropriate constructor parameter to which to pass the input field value.\nThis works only if the parameter name information is present in the Java `.class` files, which you can achieve by compiling the source with debug information or using the `-parameters` command-line switch for `javac` in Java 8.\n* Otherwise, a `MappingException` is thrown to indicate that the given constructor parameter could not be bound.\n\n[source,java]\n----\nclass OrderItem {\n\n    private @Id final String id;\n    private final int quantity;\n    private final double unitPrice;\n\n    OrderItem(String id, int quantity, double unitPrice) {\n        this.id = id;\n        this.quantity = quantity;\n        this.unitPrice = unitPrice;\n    }\n\n    // getters/setters omitted\n}\n----\n\n[[mapping.explicit.converters]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Back References", "heading_level": 3, "file_order": 10, "section_index": 5, "content_hash": "1b7f137accb35ff8cbc3b41bf9147c352835f403c2c1ba79d90be798ed00d625", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:8dea1fb0b07096f8942f890506aab7bafd7f677d371aed0667e7feb7b5065614", "content": "Spring Data allows registration of custom converters to influence how values are mapped in the database.\nCurrently, converters are only applied on property-level, i.e. you can only convert single values in your domain to single values in the database and back.\nConversion between complex objects and multiple columns isn't supported.\n\n[[custom-converters.writer]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Overriding Mapping with Explicit Converters", "heading_level": 2, "file_order": 10, "section_index": 6, "content_hash": "8dea1fb0b07096f8942f890506aab7bafd7f677d371aed0667e7feb7b5065614", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:d67993d18033bd8aee17fff362a11d7428d230df1949be41239d5a4559f9ab38", "content": "The following example shows an implementation of a `Converter` that converts from a `Boolean` object to a `String` value:\n\n[source,java]\n----\nimport org.springframework.core.convert.converter.Converter;\n\n@WritingConverter\npublic class BooleanToStringConverter implements Converter<Boolean, String> {\n\n @Override\n public String convert(Boolean source) {\n return source != null && source ? \"T\" : \"F\";\n }\n}\n----\n\nThere are a couple of things to notice here: `Boolean` and `String` are both simple types hence Spring Data requires a hint in which direction this converter should apply (reading or writing).\nBy annotating this converter with `@WritingConverter` you instruct Spring Data to write every `Boolean` property as `String` in the database.\n\n[[custom-converters.reader]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Writing a Property by Using a Registered Spring Converter", "heading_level": 3, "file_order": 10, "section_index": 7, "content_hash": "d67993d18033bd8aee17fff362a11d7428d230df1949be41239d5a4559f9ab38", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:fb52b65d8bb8975fc61023ff8752e82157dc41349f7d99c63c70724b5c20458b", "content": "The following example shows an implementation of a `Converter` that converts from a `String` to a `Boolean` value:\n\n[source,java]\n----\n@ReadingConverter\npublic class StringToBooleanConverter implements Converter<String, Boolean> {\n\n @Override\n public Boolean convert(String source) {\n return source != null && source.equalsIgnoreCase(\"T\") ? Boolean.TRUE : Boolean.FALSE;\n }\n}\n----\n\nThere are a couple of things to notice here: `String` and `Boolean` are both simple types hence Spring Data requires a hint in which direction this converter should apply (reading or writing).\nBy annotating this converter with `@ReadingConverter` you instruct Spring Data to convert every `String` value from the database that should be assigned to a `Boolean` property.\n\n[[jdbc.custom-converters.configuration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Reading by Using a Spring Converter", "heading_level": 3, "file_order": 10, "section_index": 8, "content_hash": "fb52b65d8bb8975fc61023ff8752e82157dc41349f7d99c63c70724b5c20458b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:d5ebe994341ea7b229da909652345b2fef92784609fc0b7597ca679ac5438545", "content": "[source,java]\n----\nclass MyJdbcConfiguration extends AbstractJdbcConfiguration {\n\n // …\n\n @Override\n protected List<?> userConverters() {\n return Arrays.asList(new BooleanToStringConverter(), new StringToBooleanConverter());\n }\n\n}\n----\n\nNOTE: In previous versions of Spring Data JDBC it was recommended to directly overwrite `AbstractJdbcConfiguration.jdbcCustomConversions()`.\nThis is no longer necessary or even recommended, since that method assembles conversions intended for all databases, conversions registered by the `JdbcDialect` used and conversions registered by the user.\nIf you are migrating from an older version of Spring Data JDBC and have `AbstractJdbcConfiguration.jdbcCustomConversions()` overwritten conversions from your `JdbcDialect` will not get registered.\n\n[TIP]\n====\nIf you want to rely on https://spring.io/projects/spring-boot[Spring Boot] to bootstrap Spring Data JDBC, but still want to override certain aspects of the configuration, you may want to expose beans of that type.\nFor custom conversions you may e.g. choose to register a bean of type `JdbcCustomConversions` that will be picked up by the Boot infrastructure.\nTo learn more about this please make sure to read the Spring Boot https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.jdbc[Reference Documentation].\n====\n\n[[jdbc.custom-converters.jdbc-value]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "Registering Spring Converters with the `JdbcConverter`", "heading_level": 3, "file_order": 10, "section_index": 9, "content_hash": "d5ebe994341ea7b229da909652345b2fef92784609fc0b7597ca679ac5438545", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:f1072ad39a57c834ae0a0ee89ba32be73d1d7848fb5916911637b8864c1eaeed", "content": "Value conversion uses `JdbcValue` to enrich values propagated to JDBC operations with a `java.sql.Types` type.\nRegister a custom write converter if you need to specify a JDBC-specific type instead of using type derivation.\nThis converter should convert the value to `JdbcValue` which has a field for the value and for the actual `JDBCType`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mapping.adoc", "title": "mapping", "heading": "JdbcValue", "heading_level": 3, "file_order": 10, "section_index": 10, "content_hash": "f1072ad39a57c834ae0a0ee89ba32be73d1d7848fb5916911637b8864c1eaeed", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mapping.adoc"}}
{"id": "sha256:27340d58167c43538f2261c00779bc6d557bc1021087a9efbbeeb77adb574b14", "content": "[[jdbc.mybatis]]\n\nThe CRUD operations and query methods can be delegated to MyBatis.\nThis section describes how to configure Spring Data JDBC to integrate with MyBatis and which conventions to follow to hand over the running of the queries as well as the mapping to the library.\n\n[[jdbc.mybatis.configuration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mybatis.adoc", "title": "mybatis", "heading": "mybatis", "heading_level": 1, "file_order": 11, "section_index": 0, "content_hash": "27340d58167c43538f2261c00779bc6d557bc1021087a9efbbeeb77adb574b14", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mybatis.adoc"}}
{"id": "sha256:526ec979bc59e7262ac9a49a515e8790e49859a9fc59c5f4d44326ee22bdcf76", "content": "The easiest way to properly plug MyBatis into Spring Data JDBC is by importing `MyBatisJdbcConfiguration` into you application configuration:\n\n[source,java]\n----\n@Configuration\n@EnableJdbcRepositories\n@Import(MyBatisJdbcConfiguration.class)\nclass Application {\n\n @Bean\n SqlSessionFactoryBean sqlSessionFactoryBean() {\n // Configure MyBatis here\n }\n}\n----\n\nAs you can see, all you need to declare is a `SqlSessionFactoryBean` as `MyBatisJdbcConfiguration` relies on a `SqlSession` bean to be available in the `ApplicationContext` eventually.\n\n[[jdbc.mybatis.conventions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mybatis.adoc", "title": "mybatis", "heading": "Configuration", "heading_level": 2, "file_order": 11, "section_index": 1, "content_hash": "526ec979bc59e7262ac9a49a515e8790e49859a9fc59c5f4d44326ee22bdcf76", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mybatis.adoc"}}
{"id": "sha256:aac659f3290f6856b7c3993e77b6d5086b2622389fb2783257674fbdd73f421d", "content": "For each operation in `CrudRepository`, Spring Data JDBC runs multiple statements.\nIf there is a https://github.com/mybatis/mybatis-3/blob/master/src/main/java/org/apache/ibatis/session/SqlSessionFactory.java[`SqlSessionFactory`] in the application context, Spring Data checks, for each step, whether the `SessionFactory` offers a statement.\nIf one is found, that statement (including its configured mapping to an entity) is used.\n\nThe name of the statement is constructed by concatenating the fully qualified name of the entity type with `Mapper.` and a `String` determining the kind of statement.\nFor example, if an instance of `org.example.User` is to be inserted, Spring Data JDBC looks for a statement named `org.example.UserMapper.insert`.\n\nWhen the statement is run, an instance of [`MyBatisContext`] gets passed as an argument, which makes various arguments available to the statement.\n\nThe following table describes the available MyBatis statements:\n\n[cols=\"default,default,default,asciidoc\"]\n|===\n| Name | Purpose | CrudRepository methods that might trigger this statement | Attributes available in the `MyBatisContext`\n\n| `insert` | Inserts a single entity. This also applies for entities referenced by the aggregate root. | `save`, `saveAll`. |\n`getInstance`: the instance to be saved.\n\n`getDomainType`: The type of the entity to be saved.\n\n`get(<key>)`: ID of the referencing entity, where `<key>` is the name of the back reference column provided by the `NamingStrategy`.\n\n| `update` | Updates a single entity. This also applies for entities referenced by the aggregate root. | `save`, `saveAll`.|\n`getInstance`: The instance to be saved.\n\n`getDomainType`: The type of the entity to be saved.\n\n| `delete` | Deletes a single entity. | `delete`, `deleteById`.|\n`getId`: The ID of the instance to be deleted.\n\n`getDomainType`: The type of the entity to be deleted.\n\n| `deleteAll-<propertyPath>` | Deletes all entities referenced by any aggregate root of the type used as prefix with the given property path.\nNote that the type used for prefixing the statement name is the name of the aggregate root, not the one of the entity to be deleted. | `deleteAll`.|\n\n`getDomainType`: The types of the entities to be deleted.\n\n| `deleteAll` | Deletes all aggregate roots of the type used as the prefix | `deleteAll`.|\n\n`getDomainType`: The type of the entities to be deleted.\n\n| `delete-<propertyPath>` | Deletes all entities referenced by an aggregate root with the given propertyPath | `deleteById`.|\n\n`getId`: The ID of the aggregate root for which referenced entities are to be deleted.\n\n`getDomainType`: The type of the entities to be deleted.\n\n| `findById` | Selects an aggregate root by ID | `findById`.|\n\n`getId`: The ID of the entity to load.\n\n`getDomainType`: The type of the entity to load.\n\n| `findAll` | Select all aggregate roots | `findAll`.|\n\n`getDomainType`: The type of the entity to load.\n\n| `findAllById` | Select a set of aggregate roots by ID values | `findAllById`.|\n\n`getId`: A list of ID values of the entities to load.\n\n`getDomainType`: The type of the entity to load.\n\n| `findAllByProperty-<propertyName>` | Select a set of entities that is referenced by another entity. The type of the referencing entity is used for the prefix. The referenced entities type is used as the suffix. _This method is deprecated. Use `findAllByPath` instead_ | All `find*` methods. If no query is defined for `findAllByPath`|\n\n`getId`: The ID of the entity referencing the entities to be loaded.\n\n`getDomainType`: The type of the entity to load.\n\n| `findAllByPath-<propertyPath>` | Select a set of entities that is referenced by another entity via a property path. | All `find*` methods.|\n\n`getIdentifier`: The `Identifier` holding the id of the aggregate root plus the keys and list indexes of all path elements.\n\n`getDomainType`: The type of the entity to load.\n\n| `findAllSorted` | Select all aggregate roots, sorted | `findAll(Sort)`.|\n\n`getSort`: The sorting specification.\n\n| `findAllPaged` | Select a page of aggregate roots, optionally sorted | `findAll(Page)`.|\n\n`getPageable`: The paging specification.\n\n| `count` | Count the number of aggregate root of the type used as prefix | `count` |\n\n`getDomainType`: The type of aggregate roots to count.\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/mybatis.adoc", "title": "mybatis", "heading": "Usage conventions", "heading_level": 2, "file_order": 11, "section_index": 2, "content_hash": "aac659f3290f6856b7c3993e77b6d5086b2622389fb2783257674fbdd73f421d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/mybatis.adoc"}}
{"id": "sha256:572c8ae3c4c871ed5f50ce9dcba123616b429a93131c13ec0de2e1edbd7f87b2", "content": "include::{commons}@data-commons::page$property-paths.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/property-paths.adoc", "title": "property-paths", "heading": "property-paths", "heading_level": 1, "file_order": 12, "section_index": 0, "content_hash": "572c8ae3c4c871ed5f50ce9dcba123616b429a93131c13ec0de2e1edbd7f87b2", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/property-paths.adoc"}}
{"id": "sha256:f11ff68d1cc0110e53cbc7ff02efe4ca75b7658a194b378d186fd85d604f6ea5", "content": "[[jdbc.query-methods]]\n\nThis section offers some specific information about the implementation and use of Spring Data JDBC.\n\nMost of the data access operations you usually trigger on a repository result in a query being run against the database.\nDefining such a query is a matter of declaring a method on the repository interface, as the following example shows:\n\n.PersonRepository with query methods\n[source,java]\n----\ninterface PersonRepository extends PagingAndSortingRepository<Person, String> {\n\n List<Person> findByFirstname(String firstname); <1>\n\n List<Person> findByFirstnameOrderByLastname(String firstname, Pageable pageable); <2>\n\n Slice<Person> findByLastname(String lastname, Pageable pageable); <3>\n\n Page<Person> findByLastname(String lastname, Pageable pageable); <4>\n\n Person findByFirstnameAndLastname(String firstname, String lastname); <5>\n\n Person findFirstByLastname(String lastname); <6>\n\n @Query(\"SELECT * FROM person WHERE lastname = :lastname\")\n List<Person> findByLastname(String lastname); <7>\n @Query(\"SELECT * FROM person WHERE lastname = :lastname\")\n Stream<Person> streamByLastname(String lastname); <8>\n\n @Query(\"SELECT * FROM person WHERE username = :#{ principal?.username }\")\n Person findActiveUser(); <9>\n}\n----\n<1> The method shows a query for all people with the given `firstname`.\nThe query is derived by parsing the method name for constraints that can be concatenated with `And` and `Or`.\nThus, the method name results in a query expression of `SELECT … FROM person WHERE firstname = :firstname`.\n<2> Use `Pageable` to pass offset and sorting parameters to the database.\n<3> Return a `Slice<Person>`. Selects `LIMIT+1` rows to determine whether there's more data to consume. `ResultSetExtractor` customization is not supported.\n<4> Run a paginated query returning `Page<Person>`.Selects only data within the given page bounds and potentially a count query to determine the total count. `ResultSetExtractor` customization is not supported.\n<5> Find a single entity for the given criteria.\nIt completes with `IncorrectResultSizeDataAccessException` on non-unique results.\n<6> In contrast to <3>, the first entity is always emitted even if the query yields more result documents.\n<7> The `findByLastname` method shows a query for all people with the given `lastname`.\n<8> The `streamByLastname` method returns a `Stream`, which makes values possible as soon as they are returned from the database.\n<9> You can use the Spring Expression Language to dynamically resolve parameters.\nIn the sample, Spring Security is used to resolve the username of the current user.\n\nThe following table shows the keywords that are supported for query methods:\n\n[cols=\"1,2,3\",options=\"header\",subs=\"quotes\"]\n.Supported keywords for query methods\n|===\n| Keyword\n| Sample\n| Logical result\n\n| `After`\n| `findByBirthdateAfter(Date date)`\n| `birthdate > date`\n\n| `GreaterThan`\n| `findByAgeGreaterThan(int age)`\n| `age > age`\n\n| `GreaterThanEqual`\n| `findByAgeGreaterThanEqual(int age)`\n| `age >= age`\n\n| `Before`\n| `findByBirthdateBefore(Date date)`\n| `birthdate < date`\n\n| `LessThan`\n| `findByAgeLessThan(int age)`\n| `age < age`\n\n| `LessThanEqual`\n| `findByAgeLessThanEqual(int age)`\n| `age \\<= age`\n\n| `Between`\n| `findByAgeBetween(int from, int to)`\n| `age BETWEEN from AND to`\n\n| `NotBetween`\n| `findByAgeNotBetween(int from, int to)`\n| `age NOT BETWEEN from AND to`\n\n| `In`\n| `findByAgeIn(Collection<Integer> ages)`\n| `age IN (age1, age2, ageN)`\n\n| `NotIn`\n| `findByAgeNotIn(Collection ages)`\n| `age NOT IN (age1, age2, ageN)`\n\n| `IsNotNull`, `NotNull`\n| `findByFirstnameNotNull()`\n| `firstname IS NOT NULL`\n\n| `IsNull`, `Null`\n| `findByFirstnameNull()`\n| `firstname IS NULL`\n\n| `Like`, `StartingWith`, `EndingWith`\n| `findByFirstnameLike(String name)`\n| `firstname LIKE name`\n\n| `NotLike`, `IsNotLike`\n| `findByFirstnameNotLike(String name)`\n| `firstname NOT LIKE name`\n\n| `Containing` on String\n| `findByFirstnameContaining(String name)`\n| `firstname LIKE '%' + name + '%'`\n\n| `NotContaining` on String\n| `findByFirstnameNotContaining(String name)`\n| `firstname NOT LIKE '%' + name + '%'`\n\n| `(No keyword)`\n| `findByFirstname(String name)`\n| `firstname = name`\n\n| `Not`\n| `findByFirstnameNot(String name)`\n| `firstname != name`\n\n| `IsTrue`, `True`\n| `findByActiveIsTrue()`\n| `active IS TRUE`\n\n| `IsFalse`, `False`\n| `findByActiveIsFalse()`\n| `active IS FALSE`\n|===\n\nNOTE: Query derivation is limited to properties that can be used in a `WHERE` clause without using joins.\n\n[[jdbc.query-methods.strategies]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "query-methods", "heading_level": 1, "file_order": 13, "section_index": 0, "content_hash": "f11ff68d1cc0110e53cbc7ff02efe4ca75b7658a194b378d186fd85d604f6ea5", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:63d3f70d7ed126106df9ac9a1c269a38d0347c9c9cc6a45407a6f5fac3e9d1fe", "content": "The JDBC module supports defining a query manually as a String in a `@Query` annotation or as named query in a property file.\n\nDeriving a query from the name of the method is currently limited to simple properties, that means properties present in the aggregate root directly.\nAlso, only select queries are supported by this approach.\n\n[[jdbc.query-methods.at-query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Query Lookup Strategies", "heading_level": 2, "file_order": 13, "section_index": 1, "content_hash": "63d3f70d7ed126106df9ac9a1c269a38d0347c9c9cc6a45407a6f5fac3e9d1fe", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:cb95684ddeb8d85739fd3df6cfb44360ddb4036fb73913d52a46676d8bf5a2d0", "content": "The following example shows how to use `@Query` to declare a query method:\n\n.Declare a query method by using @Query\n[source,java]\n----\ninterface UserRepository extends CrudRepository<User, Long> {\n\n @Query(\"select firstName, lastName from User u where u.emailAddress = :email\")\n User findByEmailAddress(@Param(\"email\") String email);\n}\n----\n\nFor converting the query result into entities the same `RowMapper` is used by default as for the queries Spring Data JDBC generates itself.\nThe query you provide must match the format the `RowMapper` expects.\nColumns for all properties that are used in the constructor of an entity must be provided.\nColumns for properties that get set via setter, wither or field access are optional.\nProperties that don't have a matching column in the result will not be set.\nThe query is used for populating the aggregate root, embedded entities and one-to-one relationships including arrays of primitive types which get stored and loaded as SQL-array-types.\nSeparate queries are generated for maps, lists, sets and arrays of entities.\n\nProperties one-to-one relationships must have their name prefixed by the name of the relationship plus `_`.\nFor example if the `User` from the example above has an `address` with the property `city` the column for that `city` must be labeled `address_city`.\n\nWARNING: Note that String-based queries do not support pagination nor accept `Sort`, `PageRequest`, and `Limit` as a query parameter as for these queries the query would be required to be rewritten.\nIf you want to apply limiting, please express this intent using SQL and bind the appropriate parameters to the query yourself.\n\nQueries may contain SpEL expressions.\nThere are two variants that are evaluated differently.\n\nIn the first variant a SpEL expression is prefixed with `:` and used like a bind variable.\nSuch a SpEL expression will get replaced with a bind variable and the variable gets bound to the result of the SpEL expression.\n\n.Use a SpEL in a query\n[source,java]\n----\n@Query(\"SELECT * FROM person WHERE id = :#{#person.id}\")\nPerson findWithSpEL(PersonRef person);\n----\n\nThis can be used to access members of a parameter, as demonstrated in the example above.\nFor more involved use cases an `EvaluationContextExtension` can be made available in the application context, which in turn can make any object available in the SpEL.\n\nThe other variant can be used anywhere in the query and the result of evaluating the query will replace the expression in the query string.\n\n.Use a SpEL in a query\n[source,java]\n----\n@Query(\"SELECT * FROM #{tableName} WHERE id = :id\")\nPerson findWithSpEL(PersonRef person);\n----\n\nIt is evaluated once before the first execution and uses a `StandardEvaluationContext` with the two variables `tableName` and `qualifiedTableName` added.\nThis use is most useful when table names are dynamic themselves, because they use SpEL expressions as well.\n\nNOTE: Spring fully supports Java 8’s parameter name discovery based on the `-parameters` compiler flag.\nBy using this flag in your build as an alternative to debug information, you can omit the `@Param` annotation for named parameters.\n\nNOTE: Spring Data JDBC supports only named parameters.\n\n[[jdbc.query-methods.named-query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Using `@Query`", "heading_level": 2, "file_order": 13, "section_index": 2, "content_hash": "cb95684ddeb8d85739fd3df6cfb44360ddb4036fb73913d52a46676d8bf5a2d0", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:be844e83093a8c36276ba38780433a45d02588155233242a32f761f729ef2fb8", "content": "If no query is given in an annotation as described in the previous section Spring Data JDBC will try to locate a named query.\nThere are two ways how the name of the query can be determined.\nThe default is to take the _domain class_ of the query, i.e. the aggregate root of the repository, take its simple name and append the name of the method separated by a `.`.\nAlternatively the `@Query` annotation has a `name` attribute which can be used to specify the name of a query to be looked up.\n\nNamed queries are expected to be provided in the property file `META-INF/jdbc-named-queries.properties` on the classpath.\n\nThe location of that file may be changed by setting a value to `@EnableJdbcRepositories.namedQueriesLocation`.\n\nNamed queries are handled in the same way as queries provided by annotation.\n\n[[jdbc.query-methods.customizing-query-methods]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Named Queries", "heading_level": 2, "file_order": 13, "section_index": 3, "content_hash": "be844e83093a8c36276ba38780433a45d02588155233242a32f761f729ef2fb8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:c7e4f0304dd8e445b8be682f5f72822884f4e5f4ac29deaa4cded0d156bc46d0", "content": "[[jdbc.query-methods.at-query.streaming-results]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Customizing Query Methods", "heading_level": 3, "file_order": 13, "section_index": 4, "content_hash": "c7e4f0304dd8e445b8be682f5f72822884f4e5f4ac29deaa4cded0d156bc46d0", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:8b76a0cf6daf7fcf5c44a9d21f21b79fd3bdc635bc6a49782bfb1388767345c7", "content": "When you specify Stream as the return type of a query method, Spring Data JDBC returns elements as soon as they become available.\nWhen dealing with large amounts of data this is suitable for reducing latency and memory requirements.\n\nThe stream contains an open connection to the database.\nTo avoid memory leaks, that connection needs to be closed eventually, by closing the stream.\nThe recommended way to do that is a `try-with-resource clause`.\nIt also means that, once the connection to the database is closed, the stream cannot obtain further elements and likely throws an exception.\n\n[[jdbc.query-methods.at-query.custom-rowmapper]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Streaming Results", "heading_level": 3, "file_order": 13, "section_index": 5, "content_hash": "8b76a0cf6daf7fcf5c44a9d21f21b79fd3bdc635bc6a49782bfb1388767345c7", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:e191959a8b80d33042fe22faefdaff631084f816afde6dd16a13719529af2865", "content": "The `@Query` annotation allows you to specify a custom `RowMapper` or `ResultSetExtractor` to use.\nThe attributes `rowMapperClass` and `resultSetExtractorClass` allow you to specify classes to use, which will get instantiated using a default constructor.\nAlternatively you may set `rowMapperClassRef` or `resultSetExtractorClassRef` to a bean name from your Spring application context.\n\nIf you want to use a certain `RowMapper` not just for a single method but for all methods with custom queries returning a certain type,\nyou may register a `RowMapperMap` bean and registering a `RowMapper` per method return type.\nThe following example shows how to register `DefaultQueryMappingConfiguration`:\n\n[source,java]\n----\n@Bean\nQueryMappingConfiguration rowMappers() {\n return new DefaultQueryMappingConfiguration()\n .register(Person.class, new PersonRowMapper())\n .register(Address.class, new AddressRowMapper());\n}\n----\n\nWhen determining which `RowMapper` to use for a method, the following steps are followed, based on the return type of the method:\n\n. If the type is a simple type, no `RowMapper` is used.\n+\nInstead, the query is expected to return a single row with a single column, and a conversion to the return type is applied to that value.\n. The entity classes in the `QueryMappingConfiguration` are iterated until one is found that is a superclass or interface of the return type in question.\nThe `RowMapper` registered for that class is used.\n+\nIterating happens in the order of registration, so make sure to register more general types after specific ones.\n\nIf applicable, wrapper types such as collections or `Optional` are unwrapped.\nThus, a return type of `Optional<Person>` uses the `Person` type in the preceding process.\n\nNOTE: Using a custom `RowMapper` through `QueryMappingConfiguration`, `@Query(rowMapperClass=…)`, or a custom `ResultSetExtractor` disables Entity Callbacks and Lifecycle Events as the result mapping can issue its own events/callbacks if needed.\n\n[[jdbc.query-methods.at-query.modifying]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Custom `RowMapper` or `ResultSetExtractor`", "heading_level": 3, "file_order": 13, "section_index": 6, "content_hash": "e191959a8b80d33042fe22faefdaff631084f816afde6dd16a13719529af2865", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:6d7a43b204e3ffbaa9b03e80a6e5edbba27465be0f98263e97f814189373879e", "content": "You can mark a query as being a modifying query by using the `@Modifying` on query method, as the following example shows:\n\n[source,java]\n----\n@Modifying\n@Query(\"UPDATE DUMMYENTITY SET name = :name WHERE id = :id\")\nboolean updateName(@Param(\"id\") Long id, @Param(\"name\") String name);\n----\n\nYou can specify the following return types:\n\n* `void`\n* `int` (updated record count)\n* `boolean`(whether a record was updated)\n\nModifying queries are executed directly against the database.\nNo events or callbacks get called.\nTherefore also fields with auditing annotations do not get updated if they don't get updated in the annotated query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/query-methods.adoc", "title": "query-methods", "heading": "Modifying Query", "heading_level": 3, "file_order": 13, "section_index": 7, "content_hash": "6d7a43b204e3ffbaa9b03e80a6e5edbba27465be0f98263e97f814189373879e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/query-methods.adoc"}}
{"id": "sha256:559f8e116ab6207e1cbc709570718bdb846bfeec2cc45631e5f4c2d0780a71c2", "content": "[[jdbc.schema]]\n\nWhen working with SQL databases, the schema is an essential part.\nSpring Data JDBC supports a wide range of schema options yet when starting with a domain model it can be challenging to come up with an initial domain model.\nTo assist you with a code-first approach, Spring Data JDBC ships with an integration to create database change sets using https://www.liquibase.org/[Liquibase].\n\nConsider the following domain entity:\n\n[source,java]\n----\n@Table\nclass Person {\n @Id long id;\n String firstName;\n String lastName;\n LocalDate birthday;\n boolean active;\n}\n----\n\nRendering the initial ChangeSet through the following code:\n\n[source,java]\n----\n\nRelationalMappingContext context = … // The context contains the Person entity, ideally initialized through initialEntitySet\nLiquibaseChangeSetWriter writer = new LiquibaseChangeSetWriter(context);\n\nwriter.writeChangeSet(new FileSystemResource(new File(…)));\n----\n\nyields the following change log:\n\n[source,yaml]\n----\ndatabaseChangeLog:\n- changeSet:\n id: '1685969572426'\n author: Spring Data Relational\n objectQuotingStrategy: LEGACY\n changes:\n - createTable:\n columns:\n - column:\n autoIncrement: true\n constraints:\n nullable: false\n primaryKey: true\n name: id\n type: BIGINT\n - column:\n constraints:\n nullable: true\n name: first_name\n type: VARCHAR(255 BYTE)\n - column:\n constraints:\n nullable: true\n name: last_name\n type: VARCHAR(255 BYTE)\n - column:\n constraints:\n nullable: true\n name: birthday\n type: DATE\n - column:\n constraints:\n nullable: false\n name: active\n type: TINYINT\n tableName: person\n----\n\nColumn types are computed from an object implementing the `SqlTypeMapping` strategy interface.\nNullability is inferred from the type and set to `false` if a property type uses primitive Java types.\n\nSchema support can assist you throughout the application development lifecycle.\nIn differential mode, you provide an existing Liquibase `Database` to the schema writer instance and the schema writer compares existing tables to mapped entities and derives from the difference which tables and columns to create/to drop.\nBy default, no tables and no columns are dropped unless you configure `dropTableFilter` and `dropColumnFilter`.\nBoth filter predicates provide the table name respective column name so your code can compute which tables and columns can be dropped.\n\n[source,java]\n----\nwriter.setDropTableFilter(tableName -> …);\nwriter.setDropColumnFilter((tableName, columnName) -> …);\n----\n\nNOTE: Schema support can only identify additions and removals in the sense of removing tables/columns that are not mapped or adding columns that do not exist in the database.\nColumns cannot be renamed nor data cannot be migrated because entity mapping does not provide details of how the schema has evolved.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/schema-support.adoc", "title": "schema-support", "heading": "schema-support", "heading_level": 1, "file_order": 14, "section_index": 0, "content_hash": "559f8e116ab6207e1cbc709570718bdb846bfeec2cc45631e5f4c2d0780a71c2", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/schema-support.adoc"}}
{"id": "sha256:de418d211e1d1b3f3cc0b5084d751532959e2e89e19b4008b9addec81ef0f04b", "content": "[[jdbc.sequences]]\n\nPrimary key properties (annotated with `@Id`) may also be annotated with `@Sequence`.\nThe presence of the `@Sequence` annotation indicates that the property's initial value should be obtained from a database sequence at the time when the object is saved.\nThe ability of the database to generate a sequence is <<sequences.dialects,determined by the used database dialect>>.\nIn the absence of the `@Sequence` annotation, it is assumed that the value for the corresponding column is automatically generated by the database upon row insertion.\n\nConsider the following entity:\n\n.Entity with Id generation from a Sequence\n[source,java]\n----\n@Table\nclass MyEntity {\n\n    @Id\n    @Sequence(\n        sequence = \"my_seq\",\n        schema = \"public\"\n    )\n    private Long id;\n\n    // …\n}\n----\n\nWhen persisting this entity, before the SQL `INSERT`, Spring Data will issue an additional `SELECT` statement to fetch the next value from the sequence.\nFor instance, for PostgreSQL the query issued by Spring Data would look like this:\n\n.Select for next sequence value in PostgreSQL\n[source,sql]\n----\nSELECT nextval('public.my_seq');\n----\n\nThe fetched identifier value is included in `VALUES` during the insert:\n\n.Insert statement enriched with Id value\n[source,sql]\n----\nINSERT INTO \"my_entity\"(\"id\", \"name\") VALUES(?, ?);\n----\n\nNOTE: Obtaining the value from a sequence and the actual insert statement are two separate operations.\nWe highly recommend running these operations within a surrounding transaction to ensure atomicity.\n\n[[sequences.dialects]]\n== Supported Dialects\n\nThe following dialects support Sequences:\n\n* H2\n* HSQL\n* PostgreSQL\n* DB2\n* Oracle\n* Microsoft SQL Server\n\nNote that MySQL does not support sequences.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/sequences.adoc", "title": "sequences", "heading": "sequences", "heading_level": 1, "file_order": 15, "section_index": 0, "content_hash": "de418d211e1d1b3f3cc0b5084d751532959e2e89e19b4008b9addec81ef0f04b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/sequences.adoc"}}
{"id": "sha256:0d641b5604f9043f6743ac527dbaf822b7873afa4edaf0543fe00088389e824d", "content": "[[jdbc.transactions]]\n\nThe methods of `CrudRepository` instances are transactional by default.\nFor reading operations, the transaction configuration `readOnly` flag is set to `true`.\nAll others are configured with a plain `@Transactional` annotation so that default transaction configuration applies.\nFor details, see the Javadoc of javadoc:org.springframework.data.jdbc.repository.support.SimpleJdbcRepository[].\nIf you need to tweak transaction configuration for one of the methods declared in a repository, redeclare the method in your repository interface, as follows:\n\n.Custom transaction configuration for CRUD\n[source,java]\n----\ninterface UserRepository extends CrudRepository<User, Long> {\n\n @Override\n @Transactional(timeout = 10)\n List<User> findAll();\n\n // Further query method declarations\n}\n----\n\nThe preceding causes the `findAll()` method to be run with a timeout of 10 seconds and without the `readOnly` flag.\n\nAnother way to alter transactional behavior is by using a facade or service implementation that typically covers more than one repository.\nIts purpose is to define transactional boundaries for non-CRUD operations.\nThe following example shows how to create such a facade:\n\n.Using a facade to define transactions for multiple repository calls\n[source,java]\n----\n@Service\npublic class UserManagementImpl implements UserManagement {\n\n private final UserRepository userRepository;\n private final RoleRepository roleRepository;\n\n UserManagementImpl(UserRepository userRepository,\n RoleRepository roleRepository) {\n this.userRepository = userRepository;\n this.roleRepository = roleRepository;\n }\n\n @Transactional\n public void addRoleToAllUsers(String roleName) {\n\n Role role = roleRepository.findByName(roleName);\n\n for (User user : userRepository.findAll()) {\n user.addRole(role);\n userRepository.save(user);\n }\n }\n}\n----\n\nThe preceding example causes calls to `addRoleToAllUsers(…)` to run inside a transaction (participating in an existing one or creating a new one if none are already running).\nThe transaction configuration for the repositories is neglected, as the outer transaction configuration determines the actual repository to be used.\nNote that you have to explicitly activate `<tx:annotation-driven />` or use `@EnableTransactionManagement` to get annotation-based configuration for facades working.\nNote that the preceding example assumes you use component scanning.\n\n[[jdbc.transaction.query-methods]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/transactions.adoc", "title": "transactions", "heading": "transactions", "heading_level": 1, "file_order": 16, "section_index": 0, "content_hash": "0d641b5604f9043f6743ac527dbaf822b7873afa4edaf0543fe00088389e824d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/transactions.adoc"}}
{"id": "sha256:e8ae15f5cd269087f6ab5c1d6b422d936af2e507cbd6798143de610aab2eee4e", "content": "To let your query methods be transactional, use `@Transactional` at the repository interface you define, as the following example shows:\n\n.Using @Transactional at query methods\n[source,java]\n----\n@Transactional(readOnly = true)\ninterface UserRepository extends CrudRepository<User, Long> {\n\n List<User> findByLastname(String lastname);\n\n @Modifying\n @Transactional\n @Query(\"delete from User u where u.active = false\")\n void deleteInactiveUsers();\n}\n----\n\nTypically, you want the `readOnly` flag to be set to true, because most of the query methods only read data.\nIn contrast to that, `deleteInactiveUsers()` uses the `@Modifying` annotation and overrides the transaction configuration.\nThus, the method is with the `readOnly` flag set to `false`.\n\nNOTE: It is highly recommended to make query methods transactional.\nThese methods might execute more than one query in order to populate an entity.\nWithout a common transaction Spring Data JDBC executes the queries in different connections.\nThis may put excessive strain on the connection pool and might even lead to deadlocks when multiple methods request a fresh connection while holding on to one.\n\nNOTE: It is definitely reasonable to mark read-only queries as such by setting the `readOnly` flag.\nThis does not, however, act as a check that you do not trigger a manipulating query (although some databases reject `INSERT` and `UPDATE` statements inside a read-only transaction).\nInstead, the `readOnly` flag is propagated as a hint to the underlying JDBC driver for performance optimizations.\n\n[[jdbc.locking]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/transactions.adoc", "title": "transactions", "heading": "Transactional Query Methods", "heading_level": 2, "file_order": 16, "section_index": 1, "content_hash": "e8ae15f5cd269087f6ab5c1d6b422d936af2e507cbd6798143de610aab2eee4e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/transactions.adoc"}}
{"id": "sha256:66e8153b58f3b8cada64bf5115a400a76fc4bde9995580878af030c1db5bc2bb", "content": "Spring Data JDBC supports locking on derived query methods.\nTo enable locking on a given derived query method inside a repository, you annotate it with `@Lock`.\nThe required value of type `LockMode` offers two values: `PESSIMISTIC_READ` which guarantees that the data you are reading doesn't get modified, and `PESSIMISTIC_WRITE` which obtains a lock to modify the data.\nSome databases do not make this distinction.\nIn that cases both modes are equivalent of `PESSIMISTIC_WRITE`.\n\n.Using @Lock on derived query method\n[source,java]\n----\ninterface UserRepository extends CrudRepository<User, Long> {\n\n @Lock(LockMode.PESSIMISTIC_READ)\n List<User> findByLastname(String lastname);\n}\n----\n\nAs you can see above, the method `findByLastname(String lastname)` will be executed with a pessimistic read lock.\nIf you are using a database with the MySQL Dialect this will result for example in the following query:\n\n.Resulting Sql query for MySQL dialect\n[source,sql]\n----\nSelect * from user u where u.lastname = lastname LOCK IN SHARE MODE\n----\n\nNOTE: `@Lock` is currently not supported on string-based queries.\nQuery-methods created with `@Query` will ignore the locking information provided by the `@Lock`,\nUsing `@Lock` on string-based queries will result in a warning in logs.\nFuture versions will throw an exception.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/transactions.adoc", "title": "transactions", "heading": "JDBC Locking", "heading_level": 2, "file_order": 16, "section_index": 2, "content_hash": "66e8153b58f3b8cada64bf5115a400a76fc4bde9995580878af030c1db5bc2bb", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/transactions.adoc"}}
{"id": "sha256:ca9edc2a5010ec3841d1dba10ce25f95682f45de7467278ef7829644333f24b4", "content": "[[jdbc.why]]\n\nThe main persistence API for relational databases in the Java world is certainly JPA, which has its own Spring Data module.\nWhy is there another one?\n\nJPA does a lot of things in order to help the developer.\nAmong other things, it tracks changes to entities.\nIt does lazy loading for you.\nIt lets you map a wide array of object constructs to an equally wide array of database designs.\n\nThis is great and makes a lot of things really easy.\nJust take a look at a basic JPA tutorial.\nBut it often gets really confusing as to why JPA does a certain thing.\nAlso, things that are really simple conceptually get rather difficult with JPA.\n\nSpring Data JDBC aims to be much simpler conceptually, by embracing the following design decisions:\n\n* If you load an entity, SQL statements get run.\nOnce this is done, you have a completely loaded entity.\nNo lazy loading or caching is done.\n\n* If you save an entity, it gets saved.\nIf you do not, it does not.\nThere is no dirty tracking and no session.\n\n* There is a simple model of how to map entities to tables.\nIt probably only works for rather simple cases.\nIf you do not like that, you should code your own strategy.\nSpring Data JDBC offers only very limited support for customizing the strategy with annotations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc/why.adoc", "title": "why", "heading": "why", "heading_level": 1, "file_order": 17, "section_index": 0, "content_hash": "ca9edc2a5010ec3841d1dba10ce25f95682f45de7467278ef7829644333f24b4", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc/why.adoc"}}
{"id": "sha256:ba1405904aaa6e2349ad66b674e67a026aa319dafffb49414d028c62bf5eb0a3", "content": "include::{commons}@data-commons::page$kotlin/coroutines.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin/coroutines.adoc", "title": "coroutines", "heading": "coroutines", "heading_level": 1, "file_order": 18, "section_index": 0, "content_hash": "ba1405904aaa6e2349ad66b674e67a026aa319dafffb49414d028c62bf5eb0a3", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin/coroutines.adoc"}}
{"id": "sha256:b264fcb430da2aa6e074af5f934fdf7d024fe4016542e045388a99e3386bd9d7", "content": "include::{commons}@data-commons::page$kotlin/extensions.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin/extensions.adoc", "title": "extensions", "heading": "extensions", "heading_level": 1, "file_order": 19, "section_index": 0, "content_hash": "b264fcb430da2aa6e074af5f934fdf7d024fe4016542e045388a99e3386bd9d7", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin/extensions.adoc"}}
{"id": "sha256:3890a18a8bd49eea65aed311989780538fe511ebfca5d4bdb8d8e0d6aff12dcf", "content": "include::{commons}@data-commons::page$kotlin/null-safety.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin/null-safety.adoc", "title": "null-safety", "heading": "null-safety", "heading_level": 1, "file_order": 20, "section_index": 0, "content_hash": "3890a18a8bd49eea65aed311989780538fe511ebfca5d4bdb8d8e0d6aff12dcf", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin/null-safety.adoc"}}
{"id": "sha256:ee72499ca213a700140c672a5fcd1bba0a99c05e613e5735b2529ccd54c12d17", "content": "include::{commons}@data-commons::page$kotlin/object-mapping.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin/object-mapping.adoc", "title": "object-mapping", "heading": "object-mapping", "heading_level": 1, "file_order": 21, "section_index": 0, "content_hash": "ee72499ca213a700140c672a5fcd1bba0a99c05e613e5735b2529ccd54c12d17", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin/object-mapping.adoc"}}
{"id": "sha256:1f6afc6d72333158d4bf66d1cf63e174d0e4613324cf34acbcec5e53ea8d8b24", "content": "include::{commons}@data-commons::page$kotlin/requirements.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin/requirements.adoc", "title": "requirements", "heading": "requirements", "heading_level": 1, "file_order": 22, "section_index": 0, "content_hash": "1f6afc6d72333158d4bf66d1cf63e174d0e4613324cf34acbcec5e53ea8d8b24", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin/requirements.adoc"}}
{"id": "sha256:99e6aad5491e3718f4306a2540f8d4b78b4c586e24c817df9bd0f47e697c113f", "content": "[[r2dbc.auditing]]\n\nSince Spring Data R2DBC 1.2, auditing can be enabled by annotating a configuration class with the `@EnableR2dbcAuditing` annotation, as the following example shows:\n\n.Activating auditing using JavaConfig\n[source,java]\n----\n@Configuration\n@EnableR2dbcAuditing\nclass Config {\n\n @Bean\n public ReactiveAuditorAware<AuditableUser> myAuditorProvider() {\n return new AuditorAwareImpl();\n }\n}\n----\n\nIf you expose a bean of type `ReactiveAuditorAware` to the `ApplicationContext`, the auditing infrastructure picks it up automatically and uses it to determine the current user to be set on domain types.\nIf you have multiple implementations registered in the `ApplicationContext`, you can select the one to be used by explicitly setting the `auditorAwareRef` attribute of `@EnableR2dbcAuditing`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/auditing.adoc", "title": "auditing", "heading": "auditing", "heading_level": 1, "file_order": 23, "section_index": 0, "content_hash": "99e6aad5491e3718f4306a2540f8d4b78b4c586e24c817df9bd0f47e697c113f", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/auditing.adoc"}}
{"id": "sha256:99bc91bf2400d303ddad0929b3ff1f689fc24933fac38d501dbe45d9f41124ba", "content": "[[r2dbc.entity-callbacks]]\n\nSpring Data R2DBC uses the xref:commons/entity-callbacks.adoc[`EntityCallback` API] for its auditing support and reacts on the following callbacks.\n\n.Supported Entity Callbacks\n[%header,cols=\"4\"]\n|===\n| Callback\n| Method\n| Description\n| Order\n\n| BeforeConvertCallback\n| `onBeforeConvert(T entity, SqlIdentifier table)`\n| Invoked before a domain object is converted to `OutboundRow`.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| AfterConvertCallback\n| `onAfterConvert(T entity, SqlIdentifier table)`\n| Invoked after a domain object is loaded. +\nCan modify the domain object after reading it from a row.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| AuditingEntityCallback\n| `onBeforeConvert(T entity, SqlIdentifier table)`\n| Marks an auditable entity _created_ or _modified_\n| 100\n\n| BeforeSaveCallback\n| `onBeforeSave(T entity, OutboundRow row, SqlIdentifier table)`\n| Invoked before a domain object is saved. +\nCan modify the target, to be persisted, `OutboundRow` containing all mapped entity information.\n| `Ordered.LOWEST_PRECEDENCE`\n\n| AfterSaveCallback\n| `onAfterSave(T entity, OutboundRow row, SqlIdentifier table)`\n| Invoked after a domain object is saved. +\nCan modify the domain object, to be returned after save, `OutboundRow` containing all mapped entity information.\n| `Ordered.LOWEST_PRECEDENCE`\n\n|===", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-callbacks.adoc", "title": "entity-callbacks", "heading": "entity-callbacks", "heading_level": 1, "file_order": 24, "section_index": 0, "content_hash": "99bc91bf2400d303ddad0929b3ff1f689fc24933fac38d501dbe45d9f41124ba", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-callbacks.adoc"}}
{"id": "sha256:05de5556808c7443365d13c05ac644a3b3b3333e9b589716bc7c5dfae9d649ff", "content": "[[r2dbc.entity-persistence]]\n\n`R2dbcEntityTemplate` is the central entrypoint for Spring Data R2DBC.\nIt provides direct entity-oriented methods and a more narrow, fluent interface for typical ad-hoc use-cases, such as querying, inserting, updating, and deleting data.\n\nThe entry points (`insert()`, `select()`, `update()`, and others) follow a natural naming schema based on the operation to be run.\nMoving on from the entry point, the API is designed to offer only context-dependent methods that lead to a terminating method that creates and runs a SQL statement.\nSpring Data R2DBC uses a `R2dbcDialect` abstraction to determine bind markers, pagination support and the data types natively supported by the underlying driver.\n\nNOTE: All terminal methods return always a `Publisher` type that represents the desired operation.\nThe actual statements are sent to the database upon subscription.\n\n[[r2dbc.entityoperations.save-insert]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "entity-persistence", "heading_level": 1, "file_order": 25, "section_index": 0, "content_hash": "05de5556808c7443365d13c05ac644a3b3b3333e9b589716bc7c5dfae9d649ff", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:1a5bac8de970e31932af6a0e57b4a08615ecfd33ac6458adcd05fa9c14587273", "content": "There are several convenient methods on `R2dbcEntityTemplate` for saving and inserting your objects.\nTo have more fine-grained control over the conversion process, you can register Spring converters with `R2dbcCustomConversions` -- for example `Converter<Person, OutboundRow>` and `Converter<Row, Person>`.\n\nThe simple case of using the save operation is to save a POJO.\nIn this case, the table name is determined by name (not fully qualified) of the class.\nYou may also call the save operation with a specific collection name.\nYou can use mapping metadata to override the collection in which to store the object.\n\nWhen inserting or saving, if the `Id` property is not set, the assumption is that its value will be auto-generated by the database.\nConsequently, for auto-generation the type of the `Id` property or field in your class must be a `Long`, or `Integer`.\n\nThe following example shows how to insert a row and retrieving its contents:\n\n.Inserting and retrieving entities using the `R2dbcEntityTemplate`\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\nThe following insert and update operations are available:\n\nA similar set of insert operations is also available:\n\n* `Mono<T>` *insert* `(T objectToSave)`: Insert the object to the default table.\n* `Mono<T>` *update* `(T objectToSave)`: Insert the object to the default table.\n\nTable names can be customized by using the fluent API.\n\n[[r2dbc.entityoperations.selecting]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Methods for Inserting and Updating Entities", "heading_level": 2, "file_order": 25, "section_index": 1, "content_hash": "1a5bac8de970e31932af6a0e57b4a08615ecfd33ac6458adcd05fa9c14587273", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:c373d4573538c27c9e085eab9b0b382044c0c199fad7019edb6f0b2a1ee70bae", "content": "The `select(…)` and `selectOne(…)` methods on `R2dbcEntityTemplate` are used to select data from a table.\nBoth methods take a <<r2dbc.datbaseclient.fluent-api.criteria,`Query`>> object that defines the field projection, the `WHERE` clause, the `ORDER BY` clause and limit/offset pagination.\nLimit/offset functionality is transparent to the application regardless of the underlying database.\nThis functionality is supported by the xref:r2dbc/getting-started.adoc#r2dbc.dialects[`R2dbcDialect` abstraction] to cater for differences between the individual SQL flavors.\n\n.Selecting entities using the `R2dbcEntityTemplate`\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n[[r2dbc.entityoperations.fluent-api]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Selecting Data", "heading_level": 2, "file_order": 25, "section_index": 2, "content_hash": "c373d4573538c27c9e085eab9b0b382044c0c199fad7019edb6f0b2a1ee70bae", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:f5d22bdea6d656888df001f103b013e96a2d07c15ad9c07c6dac1e1b4fef9ac8", "content": "This section explains the fluent API usage.\nConsider the following simple query:\n\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n<1> Using `Person` with the `select(…)` method maps tabular results on `Person` result objects.\n<2> Fetching `all()` rows returns a `Flux<Person>` without limiting results.\n\nThe following example declares a more complex query that specifies the table name by name, a `WHERE` condition, and an `ORDER BY` clause:\n\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n<1> Selecting from a table by name returns row results using the given domain type.\n<2> The issued query declares a `WHERE` condition on `firstname` and `lastname` columns to filter results.\n<3> Results can be ordered by individual column names, resulting in an `ORDER BY` clause.\n<4> Selecting the one result fetches only a single row.\nThis way of consuming rows expects the query to return exactly a single result.\n`Mono` emits a `IncorrectResultSizeDataAccessException` if the query yields more than a single result.\n\nTIP: You can directly apply xref:repositories/projections.adoc[Projections] to results by providing the target type via `select(Class<?>)`.\n\nYou can switch between retrieving a single entity and retrieving multiple entities through the following terminating methods:\n\n* `first()`: Consume only the first row, returning a `Mono`.\nThe returned `Mono` completes without emitting an object if the query returns no results.\n* `one()`: Consume exactly one row, returning a `Mono`.\nThe returned `Mono` completes without emitting an object if the query returns no results.\nIf the query returns more than one row, `Mono` completes exceptionally emitting `IncorrectResultSizeDataAccessException`.\n* `all()`: Consume all returned rows returning a `Flux`.\n* `count()`: Apply a count projection returning `Mono<Long>`.\n* `exists()`: Return whether the query yields any rows by returning `Mono<Boolean>`.\n\nYou can use the `select()` entry point to express your `SELECT` queries.\nThe resulting `SELECT` queries support the commonly used clauses (`WHERE` and `ORDER BY`) and support pagination.\nThe fluent API style let you chain together multiple methods while having easy-to-understand code.\nTo improve readability, you can use static imports that let you avoid using the 'new' keyword for creating `Criteria` instances.\n\n[[r2dbc.datbaseclient.fluent-api.criteria]]\n=== Methods for the Criteria Class\n\nThe `Criteria` class provides the following methods, all of which correspond to SQL operators:\n\n* `Criteria` *and* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *or* `(String column)`: Adds a chained `Criteria` with the specified `property` to the current `Criteria` and returns the newly created one.\n* `Criteria` *greaterThan* `(Object o)`: Creates a criterion by using the `>` operator.\n* `Criteria` *greaterThanOrEquals* `(Object o)`: Creates a criterion by using the `>=` operator.\n* `Criteria` *in* `(Object... o)`: Creates a criterion by using the `IN` operator for a varargs argument.\n* `Criteria` *in* `(Collection<?> collection)`: Creates a criterion by using the `IN` operator using a collection.\n* `Criteria` *is* `(Object o)`: Creates a criterion by using column matching (`property = value`).\n* `Criteria` *isNull* `()`: Creates a criterion by using the `IS NULL` operator.\n* `Criteria` *isNotNull* `()`: Creates a criterion by using the `IS NOT NULL` operator.\n* `Criteria` *lessThan* `(Object o)`: Creates a criterion by using the `<` operator.\n* `Criteria` *lessThanOrEquals* `(Object o)`: Creates a criterion by using the `<=` operator.\n* `Criteria` *like* `(Object o)`: Creates a criterion by using the `LIKE` operator without escape character processing.\n* `Criteria` *not* `(Object o)`: Creates a criterion by using the `!=` operator.\n* `Criteria` *notIn* `(Object... o)`: Creates a criterion by using the `NOT IN` operator for a varargs argument.\n* `Criteria` *notIn* `(Collection<?> collection)`: Creates a criterion by using the `NOT IN` operator using a collection.\nYou can use `Criteria` with `SELECT`, `UPDATE`, and `DELETE` queries.\n\n[[r2dbc.entityoperations.fluent-api.insert]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Fluent API", "heading_level": 2, "file_order": 25, "section_index": 3, "content_hash": "f5d22bdea6d656888df001f103b013e96a2d07c15ad9c07c6dac1e1b4fef9ac8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:624a75f5f20485da62218c6bc7781aefbed528e3d79a7c2eae44462fe630a46a", "content": "You can use the `insert()` entry point to insert data.\n\nConsider the following simple typed insert operation:\n\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n<1> Using `Person` with the `into(…)` method sets the `INTO` table, based on mapping metadata.\nIt also prepares the insert statement to accept `Person` objects for inserting.\n<2> Provide a scalar `Person` object.\nAlternatively, you can supply a `Publisher` to run a stream of `INSERT` statements.\nThis method extracts all non-`null` values and inserts them.\n\n[[r2dbc.entityoperations.fluent-api.update]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Inserting Data", "heading_level": 2, "file_order": 25, "section_index": 4, "content_hash": "624a75f5f20485da62218c6bc7781aefbed528e3d79a7c2eae44462fe630a46a", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:f39360921b87fc73bb18aab0cb20dea40209cc19f2153815d91f111b620b2409", "content": "You can use the `update()` entry point to update rows.\nUpdating data starts by specifying the table to update by accepting `Update` specifying assignments.\nIt also accepts `Query` to create a `WHERE` clause.\n\nConsider the following simple typed update operation:\n\n[source,java]\n----\nPerson modified = …\n\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n<1> Update `Person` objects and apply mapping based on mapping metadata.\n<2> Set a different table name by calling the `inTable(…)` method.\n<3> Specify a query that translates into a `WHERE` clause.\n<4> Apply the `Update` object.\nSet in this case `age` to `42` and return the number of affected rows.\n\n[[r2dbc.entityoperations.fluent-api.delete]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Updating Data", "heading_level": 2, "file_order": 25, "section_index": 5, "content_hash": "f39360921b87fc73bb18aab0cb20dea40209cc19f2153815d91f111b620b2409", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:3afbf728c3bed59ca7412c7922a7fadcffe6f708e2a048cc4fca95d56aa794a5", "content": "You can use the `delete()` entry point to delete rows.\nRemoving data starts with a specification of the table to delete from and, optionally, accepts a `Criteria` to create a `WHERE` clause.\n\nConsider the following simple insert operation:\n\n[source,java]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n\nimport static org.springframework.data.domain.Sort.by;\nimport static org.springframework.data.domain.Sort.Order.*;\nimport static org.springframework.data.relational.core.query.Criteria.*;\nimport static org.springframework.data.relational.core.query.Query.*;\nimport static org.springframework.data.relational.core.query.Update.*;\n\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\n/**\n * @author Mark Paluch\n */\n//@formatter:off\nclass R2dbcEntityTemplateSnippets {\n\n\tvoid saveAndSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::insertAndSelect[]\n\t\tPerson person = new Person(\"John\", \"Doe\");\n\n\t\tMono<Person> saved = template.insert(person);\n\t\tMono<Person> loaded = template.selectOne(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::insertAndSelect[]\n\t}\n\n\n\tvoid select(R2dbcEntityTemplate template) {\n\n\t\t// tag::select[]\n\t\tFlux<Person> loaded = template.select(query(where(\"firstname\").is(\"John\")),\n\t\t\t\tPerson.class);\n\t\t// end::select[]\n\t}\n\n\tvoid simpleSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::simpleSelect[]\n\t\tFlux<Person> people = template.select(Person.class) // <1>\n\t\t\t\t.all(); // <2>\n\t\t// end::simpleSelect[]\n\t}\n\n\tvoid fullSelect(R2dbcEntityTemplate template) {\n\n\t\t// tag::fullSelect[]\n\t\tMono<Person> first = template.select(Person.class)\t// <1>\n\t\t\t.from(\"other_person\")\n\t\t\t.matching(query(where(\"firstname\").is(\"John\")\t\t\t// <2>\n\t\t\t\t.and(\"lastname\").in(\"Doe\", \"White\"))\n\t\t\t  .sort(by(desc(\"id\"))))\t\t\t\t\t\t\t\t\t\t\t\t\t// <3>\n\t\t\t.one();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::fullSelect[]\n\t}\n\n\tvoid insert(R2dbcEntityTemplate template) {\n\n\t\t// tag::insert[]\n\t\tMono<Person> insert = template.insert(Person.class)\t// <1>\n\t\t\t\t.using(new Person(\"John\", \"Doe\")); // <2>\n\t\t// end::insert[]\n\t}\n\n\tvoid fluentUpdate(R2dbcEntityTemplate template) {\n\n\t\t// tag::update[]\n\t\tMono<Long> update = template.update(Person.class)\t// <1>\n\t\t\t\t.inTable(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.apply(update(\"age\", 42));\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::update[]\n\t}\n\n\tvoid delete(R2dbcEntityTemplate template) {\n\n\t\t// tag::delete[]\n\t\tMono<Long> delete = template.delete(Person.class)\t// <1>\n\t\t\t\t.from(\"other_table\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <2>\n\t\t\t\t.matching(query(where(\"firstname\").is(\"John\")))\t\t// <3>\n\t\t\t\t.all();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// <4>\n\t\t// end::delete[]\n\t}\n\n\tstatic class Person {\n\t\tString firstname, lastname;\n\t\tpublic Person(String firstname, String lastname) {\n\tthis.firstname = firstname;\n\tthis.lastname = lastname;\n}}\n}\n----\n\n<1> Delete `Person` objects and apply mapping based on mapping metadata.\n<2> Set a different table name by calling the `from(…)` method.\n<3> Specify a query that translates into a `WHERE` clause.\n<4> Apply the delete operation and return the number of affected rows.\n\n[[r2dbc.entity-persistence.saving]]\nUsing Repositories, saving an entity can be performed with the `ReactiveCrudRepository.save(…)` method.\nIf the entity is new, this results in an insert for the entity.\n\nIf the entity is not new, it gets updated.\nNote that whether an instance is new is part of the instance's state.\n\nNOTE: This approach has some obvious downsides.\nIf only few of the referenced entities have been actually changed, the deletion and insertion is wasteful.\nWhile this process could and probably will be improved, there are certain limitations to what Spring Data R2DBC can offer.\nIt does not know the previous state of an aggregate.\nSo any update process always has to take whatever it finds in the database and make sure it converts it to whatever is the state of the entity passed to the save method.\n\n[[entity-persistence.id-generation]]\n== ID Generation\n\nSpring Data uses identifier properties to identify entities.\nThat is, looking these up or creating statements targeting a particular row.\nThe ID of an entity must be annotated with Spring Data's {spring-data-commons-javadoc-base}/org/springframework/data/annotation/Id.html[`@Id`] annotation.\n\nWhen your database has an auto-increment column for the ID column, the generated value gets set in the entity after inserting it into the database.\n\nIf you annotate the identifier property additionally with `@Sequence` a database sequence will be used to obtain values for the id if the underlying `Dialect` supports sequences.\n\nOtherwise, Spring Data does not attempt to insert values of identifier columns when the entity is new and the identifier value defaults to its initial value.\nThat is `0` for primitive types and `null` if the identifier property uses a numeric wrapper type such as `Long`.\n\nxref:repositories/core-concepts.adoc#is-new-state-detection[Entity State Detection] explains in detail the strategies to detect whether an entity is new or whether it is expected to exist in your database.\n\nOne important constraint is that, after saving an entity, the entity must not be new anymore.\nNote that whether an entity is new is part of the entity's state.\nWith auto-increment columns, this happens automatically, because the ID gets set by Spring Data with the value from the ID column.\n\n[[r2dbc.entity-persistence.optimistic-locking]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Deleting Data", "heading_level": 2, "file_order": 25, "section_index": 6, "content_hash": "3afbf728c3bed59ca7412c7922a7fadcffe6f708e2a048cc4fca95d56aa794a5", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:695c5aed685a4798480844c19fb8eb752f7107abb757a7490177371ee2e8b6c4", "content": "Spring Data supports optimistic locking by means of a numeric attribute that is annotated with\n{spring-data-commons-javadoc-base}/org/springframework/data/annotation/Version.html[`@Version`] on the aggregate root.\nWhenever Spring Data saves an aggregate with such a version attribute two things happen:\n\n* The update statement for the aggregate root will contain a where clause checking that the version stored in the database is actually unchanged.\n* If this isn't the case an `OptimisticLockingFailureException` will be thrown.\n\nAlso, the version attribute gets increased both in the entity and in the database so a concurrent action will notice the change and throw an `OptimisticLockingFailureException` if applicable as described above.\n\nThis process also applies to inserting new aggregates, where a `null` or `0` version indicates a new instance and the increased instance afterwards marks the instance as not new anymore, making this work rather nicely with cases where the id is generated during object construction for example when UUIDs are used.\n\nDuring deletes the version check also applies but no version is increased.\n\n[source,java]\n----\n@Table\nclass Person {\n\n @Id Long id;\n String firstname;\n String lastname;\n @Version Long version;\n}\n\nR2dbcEntityTemplate template = …;\n\nMono<Person> daenerys = template.insert(new Person(\"Daenerys\")); <1>\n\nPerson other = template.select(Person.class)\n .matching(query(where(\"id\").is(daenerys.getId())))\n .first().block(); <2>\n\ndaenerys.setLastname(\"Targaryen\");\ntemplate.update(daenerys); <3>\n\ntemplate.update(other).subscribe(); // emits OptimisticLockingFailureException <4>\n----\n\n<1> Initially insert row. `version` is set to `0`.\n<2> Load the just inserted row. `version` is still `0`.\n<3> Update the row with `version = 0`.Set the `lastname` and bump `version` to `1`.\n<4> Try to update the previously loaded row that still has `version = 0`.The operation fails with an `OptimisticLockingFailureException`, as the current `version` is `1`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc", "title": "entity-persistence", "heading": "Optimistic Locking", "heading_level": 2, "file_order": 25, "section_index": 7, "content_hash": "695c5aed685a4798480844c19fb8eb752f7107abb757a7490177371ee2e8b6c4", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/entity-persistence.adoc"}}
{"id": "sha256:5f6894f90b6a0268ffdc5bab671d4a88c191540702352a73169b3f5e9ff62f01", "content": "[[r2dbc.getting-started]]\n\nAn easy way to bootstrap setting up a working environment is to create a Spring-based project in https://spring.io/tools[Spring Tools] or from https://start.spring.io[Spring Initializr].\n\nFirst, you need to set up a running database server.\nRefer to your vendor documentation on how to configure your database for R2DBC access.\n\n[[requirements]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "getting-started", "heading_level": 1, "file_order": 26, "section_index": 0, "content_hash": "5f6894f90b6a0268ffdc5bab671d4a88c191540702352a73169b3f5e9ff62f01", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:8ce5222ae071414d40fa48bfe82459cd2c0f87e783c67ad444fcf403d02f0384", "content": "Spring Data R2DBC requires {springdocsurl}[Spring Framework] {springVersion} and above.\n\nIn terms of databases, Spring Data R2DBC requires a <<r2dbc.drivers,driver>> to abstract common SQL functionality over vendor-specific flavours.\nSpring Data R2DBC includes direct support for the following databases:\n\n* https://github.com/r2dbc/r2dbc-h2[H2] (`io.r2dbc:r2dbc-h2`)\n* https://github.com/mariadb-corporation/mariadb-connector-r2dbc[MariaDB] (`org.mariadb:r2dbc-mariadb`)\n* https://github.com/r2dbc/r2dbc-mssql[Microsoft SQL Server] (`io.r2dbc:r2dbc-mssql`)\n* https://github.com/asyncer-io/r2dbc-mysql[MySQL] (`io.asyncer:r2dbc-mysql`)\n* https://github.com/jasync-sql/jasync-sql[jasync-sql MySQL] (`com.github.jasync-sql:jasync-r2dbc-mysql`)\n* https://github.com/r2dbc/r2dbc-postgresql[Postgres] (`org.postgresql:r2dbc-postgresql`)\n* https://github.com/oracle/oracle-r2dbc[Oracle] (`com.oracle.database.r2dbc:oracle-r2dbc`)\n\nIf you use a different database then your application won’t start up.\nThe <<r2dbc.dialects,dialect>> section contains further detail on how to proceed in such case.\n\n[[r2dbc.hello-world]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Requirements", "heading_level": 2, "file_order": 26, "section_index": 1, "content_hash": "8ce5222ae071414d40fa48bfe82459cd2c0f87e783c67ad444fcf403d02f0384", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:f0d521d4d569193828c107fbf363d9588c3fe07195a7577495a65e43c154c166", "content": "To create a Spring project in STS:\n\n. Go to File -> New -> Spring Template Project -> Simple Spring Utility Project, and press Yes when prompted.\nThen enter a project and a package name, such as `org.spring.r2dbc.example`.\n. Add the following to the `pom.xml` files `dependencies` element:\n+\n\n. Add the following to the pom.xml files `dependencies` element:\n+\n[source,xml,subs=\"+attributes\"]\n----\n<dependencies>\n\n <!-- other dependency elements omitted -->\n\n <dependency>\n <groupId>org.springframework.data</groupId>\n <artifactId>spring-data-r2dbc</artifactId>\n <version>{version}</version>\n </dependency>\n\n <!-- a R2DBC driver -->\n <dependency>\n <groupId>io.r2dbc</groupId>\n <artifactId>r2dbc-h2</artifactId>\n <version>x.y.z</version>\n </dependency>\n\n</dependencies>\n----\n\n. Change the version of Spring in the pom.xml to be\n+\n[source,xml,subs=\"+attributes\"]\n----\n<spring.version>{springVersion}</spring.version>\n----\n\n. Add the following location of the Spring Milestone repository for Maven to your `pom.xml` such that it is at the same level as your `<dependencies/>` element:\n+\n[source,xml]\n----\n<repositories>\n <repository>\n <id>spring-milestone</id>\n <name>Spring Maven MILESTONE Repository</name>\n <url>https://repo.spring.io/milestone</url>\n </repository>\n</repositories>\n----\n\nThe repository is also https://repo.spring.io/milestone/org/springframework/data/[browseable here].\n\nYou may also want to set the logging level to `DEBUG` to see some additional information.\nTo do so, edit the `application.properties` file to have the following content:\n\n[source]\n----\nlogging.level.org.springframework.r2dbc=DEBUG\n----\n\nThen you can, for example, create a `Person` class to persist, as follows:\n\n[source,java,indent=0]\n----\npublic class Person {\n\n\tprivate final String id;\n\tprivate final String name;\n\tprivate final int age;\n\n\tpublic Person(String id, String name, int age) {\n\t\tthis.id = id;\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t}\n\n\tpublic String getId() {\n\t\treturn id;\n\t}\n\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Person [id=\" + id + \", name=\" + name + \", age=\" + age + \"]\";\n\t}\n}\n----\n\nNext, you need to create a table structure in your database, as follows:\n\n[source,sql]\n----\nCREATE TABLE person(\n id VARCHAR(255) PRIMARY KEY,\n name VARCHAR(255),\n age INT\n);\n----\n\nYou also need a main application to run, as follows:\n\n[source,java,indent=0]\n----\n/*\n * Copyright 2023-present the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.data.r2dbc.documentation;\n// tag::class[]\n\nimport io.r2dbc.spi.ConnectionFactories;\nimport io.r2dbc.spi.ConnectionFactory;\nimport reactor.test.StepVerifier;\n\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\nimport org.springframework.data.r2dbc.core.R2dbcEntityTemplate;\n\npublic class R2dbcApp {\n\n  private static final Log log = LogFactory.getLog(R2dbcApp.class);\n\n  public static void main(String[] args) {\n\n    ConnectionFactory connectionFactory = ConnectionFactories.get(\"r2dbc:h2:mem:///test?options=DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE\");\n\n    R2dbcEntityTemplate template = new R2dbcEntityTemplate(connectionFactory);\n\n    template.getDatabaseClient().sql(\"CREATE TABLE person\" +\n        \"(id VARCHAR(255) PRIMARY KEY,\" +\n        \"name VARCHAR(255),\" +\n        \"age INT)\")\n      .fetch()\n      .rowsUpdated()\n      .as(StepVerifier::create)\n      .expectNextCount(1)\n      .verifyComplete();\n\n    template.insert(Person.class)\n      .using(new Person(\"joe\", \"Joe\", 34))\n      .as(StepVerifier::create)\n      .expectNextCount(1)\n      .verifyComplete();\n\n    template.select(Person.class)\n      .first()\n      .doOnNext(it -> log.info(it))\n      .as(StepVerifier::create)\n      .expectNextCount(1)\n      .verifyComplete();\n  }\n}\n// end::class[]\n----\n\nWhen you run the main program, the preceding examples produce output similar to the following:\n\n[source]\n----\n2018-11-28 10:47:03,893 DEBUG amework.core.r2dbc.DefaultDatabaseClient: 310 - Executing SQL statement [CREATE TABLE person(\n id VARCHAR(255) PRIMARY KEY,\n name VARCHAR(255),\n age INT\n )]\n2018-11-28 10:47:04,074 DEBUG amework.core.r2dbc.DefaultDatabaseClient: 908 - Executing SQL statement [INSERT INTO person (id, name, age) VALUES($1, $2, $3)]\n2018-11-28 10:47:04,092 DEBUG amework.core.r2dbc.DefaultDatabaseClient: 575 - Executing SQL statement [SELECT id, name, age FROM person]\n2018-11-28 10:47:04,436 INFO org.spring.r2dbc.example.R2dbcApp: 43 - Person [id='joe', name='Joe', age=34]\n----\n\nEven in this simple example, there are few things to notice:\n\n* You can create an instance of the central helper class in Spring Data R2DBC (`R2dbcEntityTemplate`) by using a standard `io.r2dbc.spi.ConnectionFactory` object.\n* The mapper works against standard POJO objects without the need for any additional metadata (though you can, optionally, provide that information -- see xref:r2dbc/mapping.adoc[here].).\n* Mapping conventions can use field access.Notice that the `Person` class has only getters.\n* If the constructor argument names match the column names of the stored row, they are used to instantiate the object.\n\n[[r2dbc.examples-repo]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Hello World", "heading_level": 2, "file_order": 26, "section_index": 2, "content_hash": "f0d521d4d569193828c107fbf363d9588c3fe07195a7577495a65e43c154c166", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:ce47d941c869b21a0cfa5ce86c18204bfafe6fc83a849ce10ff1a31d17a3345b", "content": "There is a https://github.com/spring-projects/spring-data-examples[GitHub repository with several examples] that you can download and play around with to get a feel for how the library works.\n\n[[r2dbc.connecting]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Examples Repository", "heading_level": 2, "file_order": 26, "section_index": 3, "content_hash": "ce47d941c869b21a0cfa5ce86c18204bfafe6fc83a849ce10ff1a31d17a3345b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:f57d56522530ea465c9a88fe19eadc6af04179dcf9efa026c446ea7a1af7e0df", "content": "One of the first tasks when using relational databases and Spring is to create a `io.r2dbc.spi.ConnectionFactory` object by using the IoC container.\nMake sure to use a <<requirements,supported database and driver>>.\n\n[[r2dbc.connectionfactory]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Connecting to a Relational Database with Spring", "heading_level": 2, "file_order": 26, "section_index": 4, "content_hash": "f57d56522530ea465c9a88fe19eadc6af04179dcf9efa026c446ea7a1af7e0df", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:9203e4617f6ebf668d9cae4ebbbdb7d228850874ae7e4b59d20707dc550f2382", "content": "The following example shows an example of using Java-based bean metadata to register an instance of `io.r2dbc.spi.ConnectionFactory`:\n\n.Registering a `io.r2dbc.spi.ConnectionFactory` object using Java Configuration\n[source,java]\n----\n@Configuration\npublic class ApplicationConfiguration extends AbstractR2dbcConfiguration {\n\n @Override\n @Bean\n public ConnectionFactory connectionFactory() {\n return …\n }\n}\n----\n\nThis approach lets you use the standard `io.r2dbc.spi.ConnectionFactory` instance, with the container using Spring's `AbstractR2dbcConfiguration`.As compared to registering a `ConnectionFactory` instance directly, the configuration support has the added advantage of also providing the container with an `ExceptionTranslator` implementation that translates R2DBC exceptions to exceptions in Spring's portable `DataAccessException` hierarchy for data access classes annotated with the `@Repository` annotation.This hierarchy and the use of `@Repository` is described in {spring-framework-docs}/data-access.html[Spring's DAO support features].\n\n`AbstractR2dbcConfiguration` also registers `DatabaseClient`, which is required for database interaction and for Repository implementation.\n\n[[r2dbc.dialects]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Registering a `ConnectionFactory` Instance using Java Configuration", "heading_level": 2, "file_order": 26, "section_index": 5, "content_hash": "9203e4617f6ebf668d9cae4ebbbdb7d228850874ae7e4b59d20707dc550f2382", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:c59c7b46fc563a82ee0258e0e0a451808f24d0d606fee56386095bad82173d57", "content": "Spring Data R2DBC uses a `R2dbcDialect` to encapsulate behavior that is specific to a database or its driver.\nSpring Data R2DBC reacts to database specifics by inspecting the `ConnectionFactory` and selects the appropriate database dialect accordingly.\nIf you use a database for which no dialect is available, then your application won’t start up.\nIn that case, you’ll have to ask your vendor to provide a `R2dbcDialect` implementation.\nAlternatively, you can implement your own `R2dbcDialect`.\n\n[TIP]\n====\nDialects are resolved by javadoc:org.springframework.data.r2dbc.dialect.DialectResolver[] from a `ConnectionFactory`, typically by inspecting `ConnectionFactoryMetadata`.\n+ You can let Spring auto-discover your `R2dbcDialect` by registering a class that implements `org.springframework.data.r2dbc.dialect.DialectResolver$R2dbcDialectProvider` through `META-INF/spring.factories`.\n`DialectResolver` discovers dialect provider implementations from the class path using Spring's `SpringFactoriesLoader`.\nTo do so:\n\n. Implement your own `Dialect`.\n. Implement a `R2dbcDialectProvider` returning the `Dialect`.\n. Register the provider by creating a `spring.factories` resource under `META-INF` and perform the registration by adding a line +\n`org.springframework.data.r2dbc.dialect.DialectResolver$R2dbcDialectProvider=<fully qualified name of your R2dbcDialectProvider>`\n====", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/getting-started.adoc", "title": "getting-started", "heading": "Dialects", "heading_level": 2, "file_order": 26, "section_index": 6, "content_hash": "c59c7b46fc563a82ee0258e0e0a451808f24d0d606fee56386095bad82173d57", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/getting-started.adoc"}}
{"id": "sha256:451a7e9b7c1b0459a03f4c85516d4f9ead2f18f18d92117bd5379e425c586cd4", "content": "[[kotlin]]\n\nThis part of the reference documentation explains the specific Kotlin functionality offered by Spring Data R2DBC.\nSee xref:kotlin.adoc[] for the general functionality provided by Spring Data.\n\nTo retrieve a list of `SWCharacter` objects in Java, you would normally write the following:\n\n[source,java]\n----\nFlux<SWCharacter> characters = client.select().from(SWCharacter.class).fetch().all();\n----\n\nWith Kotlin and the Spring Data extensions, you can instead write the following:\n\n[source,kotlin]\n----\nval characters = client.select().from<SWCharacter>().fetch().all()\nval characters : Flux<SWCharacter> = client.select().from().fetch().all()\n----\n\nAs in Java, `characters` in Kotlin is strongly typed, but Kotlin's clever type inference allows for shorter syntax.\n\nSpring Data R2DBC provides the following extensions:\n\n* Reified generics support for `DatabaseClient` and `Criteria`.\n* xref:kotlin/coroutines.adoc[] extensions for `DatabaseClient`.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/kotlin.adoc", "title": "kotlin", "heading": "kotlin", "heading_level": 1, "file_order": 27, "section_index": 0, "content_hash": "451a7e9b7c1b0459a03f4c85516d4f9ead2f18f18d92117bd5379e425c586cd4", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/kotlin.adoc"}}
{"id": "sha256:2ccb3ad2017835b1517c1e1b08c3cb77af9040010979fb71e57ddd2f6fba89e6", "content": "[[mapping]]\n\nRich mapping support is provided by the `MappingR2dbcConverter`. `MappingR2dbcConverter` has a rich metadata model that allows mapping domain objects to a data row.\nThe mapping metadata model is populated by using annotations on your domain objects.\nHowever, the infrastructure is not limited to using annotations as the only source of metadata information.\nThe `MappingR2dbcConverter` also lets you map objects to rows without providing any additional metadata, by following a set of conventions.\n\nThis section describes the features of the `MappingR2dbcConverter`, including how to use conventions for mapping objects to rows and how to override those conventions with annotation-based mapping metadata.\n\nRead on the basics about xref:object-mapping.adoc[] before continuing with this chapter.\n\n[[mapping.conventions]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "mapping", "heading_level": 1, "file_order": 28, "section_index": 0, "content_hash": "2ccb3ad2017835b1517c1e1b08c3cb77af9040010979fb71e57ddd2f6fba89e6", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:3f5f829d2af503b1c1d35fa49a6e96ece9499eb1990db1c27a5f026673bbddd8", "content": "`MappingR2dbcConverter` has a few conventions for mapping objects to rows when no additional mapping metadata is provided.\nThe conventions are:\n\n* The short Java class name is mapped to the table name in the following manner.\nThe `com.bigbank.SavingsAccount` class maps to the `SAVINGS_ACCOUNT` table name.\nThe same name mapping is applied for mapping fields to column names.\nFor example, the `firstName` field maps to the `FIRST_NAME` column.\nYou can control this mapping by providing a custom `NamingStrategy`.\nSee <<mapping.configuration,Mapping Configuration>> for more detail.\nTable and column names that are derived from property or class names are used in SQL statements without quotes by default.\nYou can control this behavior by setting `RelationalMappingContext.setForceQuote(true)`.\n\n* Nested objects are not supported.\n\n* The converter uses any Spring Converters registered with `CustomConversions` to override the default mapping of object properties to row columns and values.\n\n* The fields of an object are used to convert to and from columns in the row.\nPublic `JavaBean` properties are not used.\n\n* If you have a single non-zero-argument constructor whose constructor argument names match top-level column names of the row, that constructor is used.\nOtherwise, the zero-argument constructor is used.\nIf there is more than one non-zero-argument constructor, an exception is thrown.\nRefer to xref:object-mapping.adoc#mapping.object-creation[Object Creation] for further details.\n\n[[mapping.configuration]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Convention-based Mapping", "heading_level": 2, "file_order": 28, "section_index": 1, "content_hash": "3f5f829d2af503b1c1d35fa49a6e96ece9499eb1990db1c27a5f026673bbddd8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:d0cc2701f6b14668c268a11f0da0a39504cd19fe37f38a419d2cdabe25d38274", "content": "By default, (unless explicitly configured) an instance of `MappingR2dbcConverter` is created when you create a `DatabaseClient`.\nYou can create your own instance of the `MappingR2dbcConverter`.\nBy creating your own instance, you can register Spring converters to map specific classes to and from the database.\n\nYou can configure the `MappingR2dbcConverter` as well as `DatabaseClient` and `ConnectionFactory` by using Java-based metadata.\nThe following example uses Spring's Java-based configuration:\n\nIf you set `setForceQuote` of the `R2dbcMappingContext to` true, table and column names derived from classes and properties are used with database specific quotes.\nThis means that it is OK to use reserved SQL words (such as order) in these names.\nYou can do so by overriding `r2dbcMappingContext(Optional<NamingStrategy>)` of `AbstractR2dbcConfiguration`.\nSpring Data converts the letter casing of such a name to that form which is also used by the configured database when no quoting is used.\nTherefore, you can use unquoted names when creating tables, as long as you do not use keywords or special characters in your names.\nFor databases that adhere to the SQL standard, this means that names are converted to upper case.\nThe quoting character and the way names get capitalized is controlled by the used `R2dbcDialect`.\nSee xref:r2dbc/getting-started.adoc#r2dbc.dialects[R2DBC Drivers] for how to configure custom dialects.\n\n.@Configuration class to configure R2DBC mapping support\n[source,java]\n----\n@Configuration\npublic class MyAppConfig extends AbstractR2dbcConfiguration {\n\n public ConnectionFactory connectionFactory() {\n return ConnectionFactories.get(\"r2dbc:…\");\n }\n\n // the following are optional\n\n @Override\n protected List<Object> getCustomConverters() {\n return List.of(new PersonReadConverter(), new PersonWriteConverter());\n }\n}\n----\n\n`AbstractR2dbcConfiguration` requires you to implement a method that defines a `ConnectionFactory`.\n\nYou can add additional converters to the converter by overriding the `r2dbcCustomConversions` method.\n\nYou can configure a custom `NamingStrategy` by registering it as a bean.\nThe `NamingStrategy` controls how the names of classes and properties get converted to the names of tables and columns.\n\nNOTE: `AbstractR2dbcConfiguration` creates a `DatabaseClient` instance and registers it with the container under the name of `databaseClient`.\n\n[[mapping.usage]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Mapping Configuration", "heading_level": 2, "file_order": 28, "section_index": 2, "content_hash": "d0cc2701f6b14668c268a11f0da0a39504cd19fe37f38a419d2cdabe25d38274", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:5ac5c73f81f21443c23f5aeae2a7b53f8db8a5d9046c69f9b36646af1e2c22a6", "content": "To take full advantage of the object mapping functionality inside the Spring Data R2DBC support, you should annotate your mapped objects with the `@Table` annotation.\nAlthough it is not necessary for the mapping framework to have this annotation (your POJOs are mapped correctly, even without any annotations), it lets the classpath scanner find and pre-process your domain objects to extract the necessary metadata.\nIf you do not use this annotation, your application takes a slight performance hit the first time you store a domain object, because the mapping framework needs to build up its internal metadata model so that it knows about the properties of your domain object and how to persist them.\nThe following example shows a domain object:\n\n.Example domain object\n[source,java]\n----\npackage com.mycompany.domain;\n\n@Table\npublic class Person {\n\n @Id\n private Long id;\n\n private Integer ssn;\n\n private String firstName;\n\n private String lastName;\n}\n----\n\nIMPORTANT: The `@Id` annotation tells the mapper which property you want to use as the primary key.\n\n[[mapping.types]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Metadata-based Mapping", "heading_level": 2, "file_order": 28, "section_index": 3, "content_hash": "5ac5c73f81f21443c23f5aeae2a7b53f8db8a5d9046c69f9b36646af1e2c22a6", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:98dd8b2f77eb2384dd565fd6e4b7eae7e049030eab79c41197a9a74caaa7a519", "content": "The following table explains how property types of an entity affect mapping:\n\n|===\n|Source Type | Target Type | Remarks\n\n|Primitive types and wrapper types\n|Passthru\n|Can be customized using <<mapping.explicit.converters,Explicit Converters>>.\n\n|JSR-310 Date/Time types\n|Passthru\n|Can be customized using <<mapping.explicit.converters,Explicit Converters>>.\n\n|`String`, `BigInteger`, `BigDecimal`, and `UUID`\n|Passthru\n|Can be customized using <<mapping.explicit.converters,Explicit Converters>>.\n\n|`Enum`\n|String\n|Can be customized by registering <<mapping.explicit.converters,Explicit Converters>>.\n\n|`Blob` and `Clob`\n|Passthru\n|Can be customized using <<mapping.explicit.converters,Explicit Converters>>.\n\n|`byte[]`, `ByteBuffer`\n|Passthru\n|Considered a binary payload.\n\n|`Collection<T>`\n|Array of `T`\n|Conversion to Array type if supported by the configured xref:r2dbc/getting-started.adoc#requirements[driver], not supported otherwise.\n\n|Arrays of primitive types, wrapper types and `String`\n|Array of wrapper type (e.g. `int[]` -> `Integer[]`)\n|Conversion to Array type if supported by the configured xref:r2dbc/getting-started.adoc#requirements[driver], not supported otherwise.\n\n|Driver-specific types\n|Passthru\n|Contributed as a simple type by the used `R2dbcDialect`.\n\n|Complex objects\n|Target type depends on registered `Converter`.\n|Requires a <<mapping.explicit.converters,Explicit Converters>>, not supported otherwise.\n\n|===\n\nNOTE: The native data type for a column depends on the R2DBC driver type mapping.\nDrivers can contribute additional simple types such as Geometry types.\n\n[[mapping.usage.annotations]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Default Type Mapping", "heading_level": 3, "file_order": 28, "section_index": 4, "content_hash": "98dd8b2f77eb2384dd565fd6e4b7eae7e049030eab79c41197a9a74caaa7a519", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:dfc7d2e6b4c48b76bc6368d2da0bc8b1ae8e2fd4c5f83ff1e84ecbfbb61c68d1", "content": "The `RelationalConverter` can use metadata to drive the mapping of objects to rows.\nThe following annotations are available:\n\n* `@Embedded`: a property with this annotation will be mapped to the table of the parent entity, instead of a separate table.\nAllows to specify if the resulting columns should have a common prefix.\nIf all columns resulting from such an entity are `null` either the annotated entity will be `null` or _empty_, i.e. all of its properties will be `null`, depending on the value of `@Embedded.onEmpty()`\nMay be combined with `@Id` to form a composite id.\n* `@Id`: Applied at the field level to mark the primary key.\nIt may be combined with `@Embedded` to form a composite id.\n* `@InsertOnlyProperty`: Marks a property as only to be written during insert.\nSuch a property on an aggregate root will only be written once and never updated.\nNote that on a nested entity, all save operations result in an insert therefore this annotation has no effect on properties of nested entities.\n* `@MappedCollection`: Allows for configuration how a collection, or a single nested entity gets mapped. `idColumn` specifies the column used for referencing the parent entities primary key. `keyColumn` specifies the column used to store the index of a `List` or the key of a `Map`.\n* `@Sequence`: specify a database sequence for generating values for the annotated property.\n* `@Table`: Applied at the class level to indicate this class is a candidate for mapping to the database.\nYou can specify the name of the table where the database is stored.\n* `@Transient`: By default, all fields are mapped to the row.\nThis annotation excludes the field where it is applied from being stored in the database.\nTransient properties cannot be used within a persistence constructor as the converter cannot materialize a value for the constructor argument.\n* `@PersistenceCreator`: Marks a given constructor or static factory method -- even a package protected one -- to use when instantiating the object from the database.\nConstructor arguments are mapped by name to the values in the retrieved row.\n* `@Value`: This annotation is part of the Spring Framework.\nWithin the mapping framework it can be applied to constructor arguments.\nThis lets you use a Spring Expression Language statement to transform a key’s value retrieved in the database before it is used to construct a domain object.\nIn order to reference a column of a given row one has to use expressions like: `@Value(\"#root.myProperty\")` where root refers to the root of the given `Row`.\n* `@Column`: Applied at the field level to describe the name of the column as it is represented in the row, letting the name be different from the field name of the class.\nNames specified with a `@Column` annotation are always quoted when used in SQL statements.\nFor most databases, this means that these names are case-sensitive.\nIt also means that you can use special characters in these names.\nHowever, this is not recommended, since it may cause problems with other tools.\n* `@Version`: Applied at field level is used for optimistic locking and checked for modification on save operations.\nThe value is `null` (`zero` for primitive types) is considered as marker for entities to be new.\nThe initially stored value is `zero` (`one` for primitive types).\nThe version gets incremented automatically on every update.\nSee xref:r2dbc/entity-persistence.adoc#r2dbc.entity-persistence.optimistic-locking[Optimistic Locking] for further reference.\n\nThe mapping metadata infrastructure is defined in the separate `spring-data-commons` project that is technology-agnostic.\nSpecific subclasses are used in the R2DBC support to support annotation based metadata.\nOther strategies can also be put in place (if there is demand).\n\n[[entity-persistence.naming-strategy]]\n== Naming Strategy\n\nBy convention, Spring Data applies a `NamingStrategy` to determine table, column, and schema names defaulting to https://en.wikipedia.org/wiki/Snake_case[snake case].\nAn object property named `firstName` becomes `first_name`.\nYou can tweak that by providing a javadoc:org.springframework.data.relational.core.mapping.NamingStrategy[] in your application context.\n\n[[entity-persistence.custom-table-name]]\n== Override table names\n\nWhen the table naming strategy does not match your database table names, you can override the table name with the javadoc:org.springframework.data.relational.core.mapping.Table[] annotation.\nThe element `value` of this annotation provides the custom table name.\nThe following example maps the `MyEntity` class to the `CUSTOM_TABLE_NAME` table in the database:\n\n[source,java]\n----\n@Table(\"CUSTOM_TABLE_NAME\")\nclass MyEntity {\n    @Id\n    Integer id;\n\n    String name;\n}\n----\n\nYou may use xref:value-expressions.adoc[Spring Data's SpEL support] to dynamically create the table name.\nOnce generated the table name will be cached, so it is dynamic per mapping context only.\n\n[[entity-persistence.custom-column-name]]\n== Override column names\n\nWhen the column naming strategy does not match your database table names, you can override the table name with the javadoc:org.springframework.data.relational.core.mapping.Column[] annotation.\nThe element `value` of this annotation provides the custom column name.\nThe following example maps the `name` property of the `MyEntity` class to the `CUSTOM_COLUMN_NAME` column in the database:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @Column(\"CUSTOM_COLUMN_NAME\")\n    String name;\n}\n----\n\nifdef::mapped-collection[]\n\nThe javadoc:org.springframework.data.relational.core.mapping.MappedCollection[]\nannotation can be used on a reference type (one-to-one relationship) or on Sets, Lists, and Maps (one-to-many relationship).\n`idColumn` element of the annotation provides a custom name for the foreign key column referencing the id column in the other table.\nIn the following example the corresponding table for the `MySubEntity` class has a `NAME` column, and the `CUSTOM_MY_ENTITY_ID_COLUMN_NAME` column of the `MyEntity` id for relationship reasons:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @MappedCollection(idColumn = \"CUSTOM_MY_ENTITY_ID_COLUMN_NAME\")\n    Set<MySubEntity> subEntities;\n}\n\nclass MySubEntity {\n    String name;\n}\n----\n\nWhen using `List` and `Map` you must have an additional column for the position of a dataset in the `List` or the key value of the entity in the `Map`.\nThis additional column name may be customized with the `keyColumn` Element of the javadoc:org.springframework.data.relational.core.mapping.MappedCollection[] annotation:\n\n[source,java]\n----\nclass MyEntity {\n    @Id\n    Integer id;\n\n    @MappedCollection(idColumn = \"CUSTOM_COLUMN_NAME\", keyColumn = \"CUSTOM_KEY_COLUMN_NAME\")\n    List<MySubEntity> name;\n}\n\nclass MySubEntity {\n    String name;\n}\n----\nendif::[]\n\nYou may use xref:value-expressions.adoc[Spring Data's SpEL support] to dynamically create column names.\nOnce generated the names will be cached, so it is dynamic per mapping context only.\n\nifdef::embedded-entities[]\n\n[[entity-persistence.embedded-entities]]\n== Embedded entities\n\nEmbedded entities are used to have value objects in your java data model, even if there is only one table in your database.\nIn the following example you see, that `MyEntity` is mapped with the `@Embedded` annotation.\nThe consequence of this is, that in the database a table `my_entity` with the two columns `id` and `name` (from the `EmbeddedEntity` class) is expected.\n\nHowever, if the `name` column is actually `null` within the result set, the entire property `embeddedEntity` will be set to null according to the `onEmpty` of `@Embedded`, which ``null``s objects when all nested properties are `null`. +\nOpposite to this behavior `USE_EMPTY` tries to create a new instance using either a default constructor or one that accepts nullable parameter values from the result set.\n\n.Sample Code of embedding objects\n====\n[source,java]\n----\nclass MyEntity {\n\n    @Id\n    Integer id;\n\n    @Embedded(onEmpty = USE_NULL) <1>\n    EmbeddedEntity embeddedEntity;\n}\n\nclass EmbeddedEntity {\n    String name;\n}\n----\n\n<1> ``Null``s `embeddedEntity` if `name` in `null`.\nUse `USE_EMPTY` to instantiate `embeddedEntity` with a potential `null` value for the `name` property.\n====\n\nIf you need a value object multiple times in an entity, this can be achieved with the optional `prefix` element of the `@Embedded` annotation.\nThis element represents a prefix and is prepend for each column name in the embedded object.\n\n[TIP]\n====\nMake use of the shortcuts `@Embedded.Nullable` & `@Embedded.Empty` for `@Embedded(onEmpty = USE_NULL)` and `@Embedded(onEmpty = USE_EMPTY)` to reduce verbosity and simultaneously set JSR-305 `@javax.annotation.Nonnull` accordingly.\n\n[source,java]\n----\nclass MyEntity {\n\n    @Id\n    Integer id;\n\n    @Embedded.Nullable <1>\n    EmbeddedEntity embeddedEntity;\n}\n----\n\n<1> Shortcut for `@Embedded(onEmpty = USE_NULL)`.\n====\n\nEmbedded entities containing a `Collection` or a `Map` will always be considered non-empty since they will at least contain the empty collection or map.\nSuch an entity will therefore never be `null` even when using @Embedded(onEmpty = USE_NULL).\nendif::[]\n\n[[entity-persistence.embedded-ids]]\n=== Embedded Ids\n\nThe identifier property can be annotated with `@Embedded` allowing to use composite ids.\nThe full embedded entity is considered the id, and therefore the check for determining if an aggregate is considered a new aggregate requiring an insert or an existing one, asking for an update is based on that entity, not its elements.\nMost use cases will require a custom `BeforeConvertCallback` to set the id for new aggregate.\n\n====\n.Simple entity with composite id\n[source,java]\n----\n@Table(\"PERSON_WITH_COMPOSITE_ID\")\nrecord Person( <1>\n    @Id @Embedded.Nullable Name pk, <2>\n    String nickName,\n    Integer age\n) {\n}\n\nrecord Name(String first, String last) {\n}\n----\n\n.Matching table for simple entity with composite id\n[source,sql]\n----\nCREATE TABLE PERSON_WITH_COMPOSITE_ID (\n    FIRST VARCHAR(100),\n    LAST VARCHAR(100),\n    NICK_NAME VARCHAR(100),\n    AGE INT,\n    PRIMARY KEY (FIRST, LAST) <3>\n);\n\n\n----\n\n<1> Entities may be represented as records without any special consideration.\n<2> `pk` is marked as id and embedded\n<3> The two columns from the embedded `Name` entity make up the primary key in the database.\n\nDetails of table creation depend on the used database.\n====\n\n[[entity-persistence.read-only-properties]]\n== Read Only Properties\n\nAttributes annotated with `@ReadOnlyProperty` will not be written to the database by Spring Data, but they will be read when an entity gets loaded.\n\nSpring Data will not automatically reload an entity after writing it.\nTherefore, you have to reload it explicitly if you want to see data that was generated in the database for such columns.\n\nIf the annotated attribute is an entity or collection of entities, it is represented by one or more separate rows in separate tables.\nSpring Data will not perform any insert, delete or update for these rows.\n\n[[entity-persistence.insert-only-properties]]\n== Insert Only Properties\n\nAttributes annotated with `@InsertOnlyProperty` will only be written to the database by Spring Data during insert operations.\nFor updates these properties will be ignored.\n\n`@InsertOnlyProperty` is only supported for the aggregate root.\n\n[[mapping.custom.object.construction]]\n== Customized Object Construction\n\nThe mapping subsystem allows the customization of the object construction by annotating a constructor with the `@PersistenceConstructor` annotation.The values to be used for the constructor parameters are resolved in the following way:\n\n* If a parameter is annotated with the `@Value` annotation, the given expression is evaluated, and the result is used as the parameter value.\n* If the Java type has a property whose name matches the given field of the input row, then its property information is used to select the appropriate constructor parameter to which to pass the input field value.\nThis works only if the parameter name information is present in the Java `.class` files, which you can achieve by compiling the source with debug information or using the `-parameters` command-line switch for `javac` in Java 8.\n* Otherwise, a `MappingException` is thrown to indicate that the given constructor parameter could not be bound.\n\n[source,java]\n----\nclass OrderItem {\n\n    private @Id final String id;\n    private final int quantity;\n    private final double unitPrice;\n\n    OrderItem(String id, int quantity, double unitPrice) {\n        this.id = id;\n        this.quantity = quantity;\n        this.unitPrice = unitPrice;\n    }\n\n    // getters/setters omitted\n}\n----\n\n[[mapping.explicit.converters]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Mapping Annotation Overview", "heading_level": 3, "file_order": 28, "section_index": 5, "content_hash": "dfc7d2e6b4c48b76bc6368d2da0bc8b1ae8e2fd4c5f83ff1e84ecbfbb61c68d1", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:10e923807cc4f715884014ad00b2385957374c1ff830379e56a4f7aeede2020a", "content": "When storing and querying your objects, it is often convenient to have a `R2dbcConverter` instance to handle the mapping of all Java types to `OutboundRow` instances.\nHowever, you may sometimes want the `R2dbcConverter` instances to do most of the work but let you selectively handle the conversion for a particular type -- perhaps to optimize performance.\n\nTo selectively handle the conversion yourself, register one or more one or more `org.springframework.core.convert.converter.Converter` instances with the `R2dbcConverter`.\n\nYou can use the `r2dbcCustomConversions` method in `AbstractR2dbcConfiguration` to configure converters.\nThe examples xref:r2dbc/mapping.adoc#mapping.configuration[at the beginning of this chapter] show how to perform the configuration with Java.\n\nNOTE: Custom top-level entity conversion requires asymmetric types for conversion.\nInbound data is extracted from R2DBC's `Row`.\nOutbound data (to be used with `INSERT`/`UPDATE` statements) is represented as `OutboundRow` and later assembled to a statement.\n\nThe following example of a Spring Converter implementation converts from a `Row` to a `Person` POJO:\n\n[source,java]\n----\n@ReadingConverter\npublic class PersonReadConverter implements Converter<Row, Person> {\n\n public Person convert(Row source) {\n Person p = new Person(source.get(\"id\", String.class),source.get(\"name\", String.class));\n p.setAge(source.get(\"age\", Integer.class));\n return p;\n }\n}\n----\n\nPlease note that converters get applied on singular properties.\nCollection properties (e.g. `Collection<Person>`) are iterated and converted element-wise.\nCollection converters (e.g. `Converter<List<Person>>, OutboundRow`) are not supported.\n\nNOTE: R2DBC uses boxed primitives (`Integer.class` instead of `int.class`) to return primitive values.\n\nThe following example converts from a `Person` to a `OutboundRow`:\n\n[source,java]\n----\n@WritingConverter\npublic class PersonWriteConverter implements Converter<Person, OutboundRow> {\n\n public OutboundRow convert(Person source) {\n OutboundRow row = new OutboundRow();\n row.put(\"id\", Parameter.from(source.getId()));\n row.put(\"name\", Parameter.from(source.getFirstName()));\n row.put(\"age\", Parameter.from(source.getAge()));\n return row;\n }\n}\n----\n\n[[mapping.explicit.enum.converters]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Overriding Mapping with Explicit Converters", "heading_level": 2, "file_order": 28, "section_index": 6, "content_hash": "10e923807cc4f715884014ad00b2385957374c1ff830379e56a4f7aeede2020a", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:9fee60a96c16757c0b9a0489943fe82d36d7370ee7710b6970c5ff1dd91f2677", "content": "Some databases, such as https://github.com/pgjdbc/r2dbc-postgresql#postgres-enum-types[Postgres], can natively write enum values using their database-specific enumerated column type.\nSpring Data converts `Enum` values by default to `String` values for maximum portability.\nTo retain the actual enum value, register a `@Writing` converter whose source and target types use the actual enum type to avoid using `Enum.name()` conversion.\nAdditionally, you need to configure the enum type on the driver level so that the driver is aware how to represent the enum type.\n\nThe following example shows the involved components to read and write `Color` enum values natively:\n\n[source,java]\n----\nenum Color {\n Grey, Blue\n}\n\nclass ColorConverter extends EnumWriteSupport<Color> {\n\n}\n\nclass Product {\n @Id long id;\n Color color;\n\n // …\n}\n----", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/mapping.adoc", "title": "mapping", "heading": "Overriding Enum Mapping with Explicit Converters", "heading_level": 3, "file_order": 28, "section_index": 7, "content_hash": "9fee60a96c16757c0b9a0489943fe82d36d7370ee7710b6970c5ff1dd91f2677", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/mapping.adoc"}}
{"id": "sha256:7917a627ab430b1708fdddc0e7c99d1c7dbb7a0543343be1f77dfba75ee04ef2", "content": "[[migration-guide]]\n\nThe following sections explain how to migrate to a newer version of Spring Data R2DBC.\n\n[[upgrading.1.1-1.2]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "migration-guide", "heading_level": 1, "file_order": 29, "section_index": 0, "content_hash": "7917a627ab430b1708fdddc0e7c99d1c7dbb7a0543343be1f77dfba75ee04ef2", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:aa531a84254cf300964a217230f23cd83904c54cf28dbff2b258b91d49ffab8e", "content": "Spring Data R2DBC was developed with the intent to evaluate how well R2DBC can integrate with Spring applications.\nOne of the main aspects was to move core support into Spring Framework once R2DBC support has proven useful.\nSpring Framework 5.3 ships with a new module: Spring R2DBC (`spring-r2dbc`).\n\n`spring-r2dbc` ships core R2DBC functionality (a slim variant of `DatabaseClient`, Transaction Manager, Connection Factory initialization, Exception translation) that was initially provided by Spring Data R2DBC.\nThe 1.2.0 release aligns with what's provided in Spring R2DBC by making several changes outlined in the following sections.\n\nSpring R2DBC's `DatabaseClient` is a more lightweight implementation that encapsulates a pure SQL-oriented interface.\nYou will notice that the method to run SQL statements changed from `DatabaseClient.execute(…)` to `DatabaseClient.sql(…)`.\nThe fluent API for CRUD operations has moved into `R2dbcEntityTemplate`.\n\nIf you use logging of SQL statements through the logger prefix `org.springframework.data.r2dbc`, make sure to update it to `org.springframework.r2dbc` (that is removing `.data`) to point to Spring R2DBC components.\n\n[[upgrading.1.1-1.2.deprecation]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "Upgrading from 1.1.x to 1.2.x", "heading_level": 2, "file_order": 29, "section_index": 1, "content_hash": "aa531a84254cf300964a217230f23cd83904c54cf28dbff2b258b91d49ffab8e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:fabc64db392aed169d6312db46cb442bad062f9e032b50a9c9cb63e41afbaf3d", "content": "* Deprecation of `o.s.d.r2dbc.core.DatabaseClient` and its support classes `ConnectionAccessor`, `FetchSpec`, `SqlProvider` and a few more.\nNamed parameter support classes such as `NamedParameterExpander` are encapsulated by Spring R2DBC's `DatabaseClient` implementation hence we're not providing replacements as this was internal API in the first place.\nUse `o.s.r2dbc.core.DatabaseClient` and their Spring R2DBC replacements available from `org.springframework.r2dbc.core`.\nEntity-based methods (`select`/`insert`/`update`/`delete`) methods are available through `R2dbcEntityTemplate` which was introduced with version 1.1.\n* Deprecation of `o.s.d.r2dbc.connectionfactory`, `o.s.d.r2dbc.connectionfactory.init`, and `o.s.d.r2dbc.connectionfactory.lookup` packages.\nUse Spring R2DBC's variant which you can find at `o.s.r2dbc.connection`.\n* Deprecation of `o.s.d.r2dbc.convert.ColumnMapRowMapper`.\nUse `o.s.r2dbc.core.ColumnMapRowMapper` instead.\n* Deprecation of binding support classes `o.s.d.r2dbc.dialect.Bindings`, `BindMarker`, `BindMarkers`, `BindMarkersFactory` and related types.\nUse replacements from `org.springframework.r2dbc.core.binding`.\n* Deprecation of `BadSqlGrammarException`, `UncategorizedR2dbcException` and exception translation at `o.s.d.r2dbc.support`.\nSpring R2DBC provides a slim exception translation variant without an SPI for now available through `o.s.r2dbc.connection.ConnectionFactoryUtils#convertR2dbcException`.\n\n[[upgrading.1.1-1.2.replacements]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "Deprecations", "heading_level": 3, "file_order": 29, "section_index": 2, "content_hash": "fabc64db392aed169d6312db46cb442bad062f9e032b50a9c9cb63e41afbaf3d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:4811a668e9579381191c1de2c54ccfbba3ccde917e8ddc15bcc87d3a270168e6", "content": "To ease migration, several deprecated types are now subtypes of their replacements provided by Spring R2DBC.\nSpring Data R2DBC has changes several methods or introduced new methods accepting Spring R2DBC types.\nSpecifically the following classes are changed:\n\n* `R2dbcEntityTemplate`\n* `R2dbcDialect`\n* Types in `org.springframework.data.r2dbc.query`\n\nWe recommend that you review and update your imports if you work with these types directly.\n\n[[breaking-changes]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "Usage of replacements provided by Spring R2DBC", "heading_level": 3, "file_order": 29, "section_index": 3, "content_hash": "4811a668e9579381191c1de2c54ccfbba3ccde917e8ddc15bcc87d3a270168e6", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:107b3691b6bdd4d3e5e49ad250e72a09a89c4efc8af9f92181813931221b64ff", "content": "* `OutboundRow` and statement mappers switched from using `SettableValue` to `Parameter`\n* Repository factory support requires `o.s.r2dbc.core.DatabaseClient` instead of `o.s.data.r2dbc.core.DatabaseClient`.\n\n[[upgrading.1.1-1.2.dependencies]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "Breaking Changes", "heading_level": 3, "file_order": 29, "section_index": 4, "content_hash": "107b3691b6bdd4d3e5e49ad250e72a09a89c4efc8af9f92181813931221b64ff", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:c673cd228223bba78ca474bad37a1707be4549e3dd4c3f24c890c6d7822e2538", "content": "To make use of Spring R2DBC, make sure to include the following dependency:\n\n* `org.springframework:spring-r2dbc`", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/migration-guide.adoc", "title": "migration-guide", "heading": "Dependency Changes", "heading_level": 3, "file_order": 29, "section_index": 5, "content_hash": "c673cd228223bba78ca474bad37a1707be4549e3dd4c3f24c890c6d7822e2538", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/migration-guide.adoc"}}
{"id": "sha256:5c18f047ba635ede931006781a340bdd54d04917afbee35212986edeb69d78f6", "content": "include::{commons}@data-commons::page$property-paths.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/property-paths.adoc", "title": "property-paths", "heading": "property-paths", "heading_level": 1, "file_order": 30, "section_index": 0, "content_hash": "5c18f047ba635ede931006781a340bdd54d04917afbee35212986edeb69d78f6", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/property-paths.adoc"}}
{"id": "sha256:0678d15f8a44cfaf37fdbc98abe2c6981b781d5f1ecf13b9ae896c11a3163377", "content": "[[r2dbc.repositories.queries]]\n\nMost of the data access operations you usually trigger on a repository result in a query being run against the databases.\nDefining such a query is a matter of declaring a method on the repository interface, as the following example shows:\n\n.PersonRepository with query methods\n====\n[source,java]\n----\ninterface ReactivePersonRepository extends ReactiveSortingRepository<Person, Long> {\n\n Flux<Person> findByFirstname(String firstname); <1>\n\n Flux<Person> findByFirstname(Publisher<String> firstname); <2>\n\n Flux<Person> findByFirstnameOrderByLastname(String firstname, Pageable pageable); <3>\n\n Mono<Person> findByFirstnameAndLastname(String firstname, String lastname); <4>\n\n Mono<Person> findFirstByLastname(String lastname); <5>\n\n @Query(\"SELECT * FROM person WHERE lastname = :lastname\")\n Flux<Person> findByLastname(String lastname); <6>\n\n @Query(\"SELECT firstname, lastname FROM person WHERE lastname = $1\")\n Mono<Person> findFirstByLastname(String lastname); <7>\n}\n----\n\n<1> The method shows a query for all people with the given `firstname`.\nThe query is derived by parsing the method name for constraints that can be concatenated with `And` and `Or`.\nThus, the method name results in a query expression of `SELECT … FROM person WHERE firstname = :firstname`.\n<2> The method shows a query for all people with the given `firstname` once the `firstname` is emitted by the given `Publisher`.\n<3> Use `Pageable` to pass offset and sorting parameters to the database.\n<4> Find a single entity for the given criteria.\nIt completes with `IncorrectResultSizeDataAccessException` on non-unique results.\n<5> Unless <4>, the first entity is always emitted even if the query yields more result rows.\n<6> The `findByLastname` method shows a query for all people with the given last name.\n<7> A query for a single `Person` entity projecting only `firstname` and `lastname` columns.\nThe annotated query uses native bind markers, which are Postgres bind markers in this example.\n====\n\nNote that the columns of a select statement used in a `@Query` annotation must match the names generated by the `NamingStrategy` for the respective property.\nIf a select statement does not include a matching column, that property is not set.\nIf that property is required by the persistence constructor, either null or (for primitive types) the default value is provided.\n\nThe following table shows the keywords that are supported for query methods:\n\n[cols=\"1,2,3\",options=\"header\",subs=\"quotes\"]\n.Supported keywords for query methods\n|===\n| Keyword\n| Sample\n| Logical result\n\n| `After`\n| `findByBirthdateAfter(Date date)`\n| `birthdate > date`\n\n| `GreaterThan`\n| `findByAgeGreaterThan(int age)`\n| `age > age`\n\n| `GreaterThanEqual`\n| `findByAgeGreaterThanEqual(int age)`\n| `age >= age`\n\n| `Before`\n| `findByBirthdateBefore(Date date)`\n| `birthdate < date`\n\n| `LessThan`\n| `findByAgeLessThan(int age)`\n| `age < age`\n\n| `LessThanEqual`\n| `findByAgeLessThanEqual(int age)`\n| `age \\<= age`\n\n| `Between`\n| `findByAgeBetween(int from, int to)`\n| `age BETWEEN from AND to`\n\n| `NotBetween`\n| `findByAgeNotBetween(int from, int to)`\n| `age NOT BETWEEN from AND to`\n\n| `In`\n| `findByAgeIn(Collection<Integer> ages)`\n| `age IN (age1, age2, ageN)`\n\n| `NotIn`\n| `findByAgeNotIn(Collection ages)`\n| `age NOT IN (age1, age2, ageN)`\n\n| `IsNotNull`, `NotNull`\n| `findByFirstnameNotNull()`\n| `firstname IS NOT NULL`\n\n| `IsNull`, `Null`\n| `findByFirstnameNull()`\n| `firstname IS NULL`\n\n| `Like`, `StartingWith`, `EndingWith`\n| `findByFirstnameLike(String name)`\n| `firstname LIKE name`\n\n| `NotLike`, `IsNotLike`\n| `findByFirstnameNotLike(String name)`\n| `firstname NOT LIKE name`\n\n| `Containing` on String\n| `findByFirstnameContaining(String name)`\n| `firstname LIKE '%' + name +'%'`\n\n| `NotContaining` on String\n| `findByFirstnameNotContaining(String name)`\n| `firstname NOT LIKE '%' + name +'%'`\n\n| `(No keyword)`\n| `findByFirstname(String name)`\n| `firstname = name`\n\n| `Not`\n| `findByFirstnameNot(String name)`\n| `firstname != name`\n\n| `IsTrue`, `True`\n| `findByActiveIsTrue()`\n| `active IS TRUE`\n\n| `IsFalse`, `False`\n| `findByActiveIsFalse()`\n| `active IS FALSE`\n|===\n\n[[r2dbc.repositories.modifying]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/query-methods.adoc", "title": "query-methods", "heading": "query-methods", "heading_level": 1, "file_order": 31, "section_index": 0, "content_hash": "0678d15f8a44cfaf37fdbc98abe2c6981b781d5f1ecf13b9ae896c11a3163377", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/query-methods.adoc"}}
{"id": "sha256:9f1f1aa39b8bf7ea952000f1c2f906ca759fcf2f05fa6af5553b388aa24d77dd", "content": "The previous sections describe how to declare queries to access a given entity or collection of entities.\nUsing keywords from the preceding table can be used in conjunction with `delete…By` or `remove…By` to create derived queries that delete matching rows.\n\n.`Delete…By` Query\n====\n[source,java]\n----\ninterface ReactivePersonRepository extends ReactiveSortingRepository<Person, String> {\n\n Mono<Integer> deleteByLastname(String lastname); <1>\n\n Mono<Void> deletePersonByLastname(String lastname); <2>\n\n Mono<Boolean> deletePersonByLastname(String lastname); <3>\n}\n----\n\n<1> Using a return type of `Mono<Integer>` returns the number of affected rows.\n<2> Using `Void` just reports whether the rows were successfully deleted without emitting a result value.\n<3> Using `Boolean` reports whether at least one row was removed.\n====\n\nAs this approach is feasible for comprehensive custom functionality, you can modify queries that only need parameter binding by annotating the query method with `@Modifying`, as shown in the following example:\n\n[source,java,indent=0]\n----\n\t@Modifying\n\t@Query(\"UPDATE person SET firstname = :firstname where lastname = :lastname\")\n\tMono<Integer> setFixedFirstnameFor(String firstname, String lastname);\n----\n\nThe result of a modifying query can be:\n\n* `Void` (or Kotlin `Unit`) to discard update count and await completion.\n* `Integer` or another numeric type emitting the affected rows count.\n* `Boolean` to emit whether at least one row was updated.\n\nThe `@Modifying` annotation is only relevant in combination with the `@Query` annotation.\nDerived custom methods do not require this annotation.\n\nModifying queries are executed directly against the database.\nNo events or callbacks get called.\nTherefore also fields with auditing annotations do not get updated if they don't get updated in the annotated query.\n\nAlternatively, you can add custom modifying behavior by using the facilities described in xref:repositories/custom-implementations.adoc[Custom Implementations for Spring Data Repositories].\n\n[[r2dbc.query-methods.at-query]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/query-methods.adoc", "title": "query-methods", "heading": "Modifying Queries", "heading_level": 2, "file_order": 31, "section_index": 1, "content_hash": "9f1f1aa39b8bf7ea952000f1c2f906ca759fcf2f05fa6af5553b388aa24d77dd", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/query-methods.adoc"}}
{"id": "sha256:2525a4fa6d79020a951b6e57b37022b3cddef04322213b7764fbabcd94d796d3", "content": "The following example shows how to use `@Query` to declare a query method:\n\n.Declare a query method by using @Query\n[source,java]\n----\ninterface UserRepository extends ReactiveCrudRepository<User, Long> {\n\n @Query(\"select firstName, lastName from User u where u.emailAddress = :email\")\n Flux<User> findByEmailAddress(@Param(\"email\") String email);\n}\n----\n\nWARNING: Note that String-based queries do not support pagination nor accept `Sort`, `PageRequest`, and `Limit` as a query parameter as for these queries the query would be required to be rewritten.\nIf you want to apply limiting, please express this intent using SQL and bind the appropriate parameters to the query yourself.\n\nNOTE: Spring fully supports Java 8’s parameter name discovery based on the `-parameters` compiler flag.\nBy using this flag in your build as an alternative to debug information, you can omit the `@Param` annotation for named parameters.\n\n[[r2dbc.repositories.queries.spel]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/query-methods.adoc", "title": "query-methods", "heading": "Using `@Query`", "heading_level": 2, "file_order": 31, "section_index": 2, "content_hash": "2525a4fa6d79020a951b6e57b37022b3cddef04322213b7764fbabcd94d796d3", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/query-methods.adoc"}}
{"id": "sha256:36af7413d0d09c34ec0e38f4b5966ef2001244f8ac601e4f7720b85b601fe3e8", "content": "Query string definitions can be used together with SpEL expressions to create dynamic queries at runtime.\nSpEL expressions can be used in two ways.\n\nSpEL expressions can provide predicate values which are evaluated right before running the query.\n\nExpressions expose method arguments through an array that contains all the arguments.\nThe following query uses `[0]`\nto declare the predicate value for `lastname` (which is equivalent to the `:lastname` parameter binding):\n\n[source,java,indent=0]\n----\n\t@Query(\"SELECT * FROM person WHERE lastname = :#{[0]}\")\n\tFlux<Person> findByQueryWithParameterExpression(String lastname);\n----\n\nThis Expression support is extensible through the Query SPI: `org.springframework.data.spel.spi.EvaluationContextExtension`.\nThe Query SPI can contribute properties and functions and can customize the root object.\nExtensions are retrieved from the application context at the time of SpEL evaluation when the query is built.\n\nTIP: When using SpEL expressions in combination with plain parameters, use named parameter notation instead of native bind markers to ensure a proper binding order.\n\nThe other way to use Expression is in the middle of query, independent of parameters.\nThe result of evaluating the query will replace the expression in the query string.\n\n.Use a SpEL in a query\n[source,java,indent=0]\n----\n\t@Query(\"SELECT * FROM #{#tableName} WHERE lastname = :lastname\")\n\tFlux<Person> findByQueryWithExpression(String lastname);\n----\n\nIt is evaluated once before the first execution and uses a `StandardEvaluationContext` with the two variables `tableName` and `qualifiedTableName` added.\nThis use is most useful when table names are dynamic themselves, because they use SpEL expressions as well.\n\nSpEL in query strings can be a powerful way to enhance queries.\nHowever, they can also accept a broad range of unwanted arguments.\nYou should make sure to sanitize strings before passing them to the query to avoid unwanted changes to your query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/query-methods.adoc", "title": "query-methods", "heading": "Queries with SpEL Expressions", "heading_level": 3, "file_order": 31, "section_index": 3, "content_hash": "36af7413d0d09c34ec0e38f4b5966ef2001244f8ac601e4f7720b85b601fe3e8", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/query-methods.adoc"}}
{"id": "sha256:3fb0b6dfddbf8b97607b9b65f793e14c61854c500385dbf88f9890ef0de05972", "content": "[[r2dbc.repositories]]\n\n[[r2dbc.repositories.intro]]\nThis chapter points out the specialties for repository support for R2DBC.\nThis builds on the core repository support explained in xref:repositories/introduction.adoc[Working with Spring Data Repositories].\nBefore reading this chapter, you should have a sound understanding of the basic concepts explained there.\n\n[[r2dbc.repositories.usage]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/repositories.adoc", "title": "repositories", "heading": "repositories", "heading_level": 1, "file_order": 32, "section_index": 0, "content_hash": "3fb0b6dfddbf8b97607b9b65f793e14c61854c500385dbf88f9890ef0de05972", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/repositories.adoc"}}
{"id": "sha256:691eb29b7d4ebe93707ace43e1e7ab37b1b5ffa9b07b4c62702ee0ebb973dfef", "content": "To access domain entities stored in a relational database, you can use our sophisticated repository support that eases implementation quite significantly.\nTo do so, create an interface for your repository.\nConsider the following `Person` class:\n\n.Sample Person entity\n[source,java]\n----\npublic class Person {\n\n @Id\n private Long id;\n private String firstname;\n private String lastname;\n\n // … getters and setters omitted\n}\n----\n\nThe following example shows a repository interface for the preceding `Person` class:\n\n.Basic repository interface to persist Person entities\n[source,java]\n----\npublic interface PersonRepository extends ReactiveCrudRepository<Person, Long> {\n\n // additional custom query methods go here\n}\n----\n\nTo configure R2DBC repositories, you can use the `@EnableR2dbcRepositories` annotation.\nIf no base package is configured, the infrastructure scans the package of the annotated configuration class.\nThe following example shows how to use Java configuration for a repository:\n\n.Java configuration for repositories\n[source,java]\n----\n@Configuration\n@EnableR2dbcRepositories\nclass ApplicationConfig extends AbstractR2dbcConfiguration {\n\n @Override\n public ConnectionFactory connectionFactory() {\n return …\n }\n}\n----\n\nBecause our domain repository extends `ReactiveCrudRepository`, it provides you with reactive CRUD operations to access the entities.\nOn top of `ReactiveCrudRepository`, there is also `ReactiveSortingRepository`, which adds additional sorting functionality similar to that of `PagingAndSortingRepository`.\nWorking with the repository instance is merely a matter of dependency injecting it into a client.\nConsequently, you can retrieve all `Person` objects with the following code:\n\n.Paging access to Person entities\n[source,java,indent=0]\n----\n@ExtendWith(SpringExtension.class)\n@ContextConfiguration\nclass PersonRepositoryTests {\n\n  @Autowired\n  PersonRepository repository;\n\n  @Test\n  void readsAllEntitiesCorrectly() {\n\n    repository.findAll()\n      .as(StepVerifier::create)\n      .expectNextCount(1)\n      .verifyComplete();\n  }\n\n  @Test\n  void readsEntitiesByNameCorrectly() {\n\n    repository.findByFirstname(\"Hello World\")\n      .as(StepVerifier::create)\n      .expectNextCount(1)\n      .verifyComplete();\n  }\n}\n----\n\nThe preceding example creates an application context with Spring's unit test support, which performs annotation-based dependency injection into test cases.\nInside the test method, we use the repository to query the database.\nWe use `StepVerifier` as a test aid to verify our expectations against the results.\n\n[[projections.resultmapping]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/repositories.adoc", "title": "repositories", "heading": "Usage", "heading_level": 2, "file_order": 32, "section_index": 1, "content_hash": "691eb29b7d4ebe93707ace43e1e7ab37b1b5ffa9b07b4c62702ee0ebb973dfef", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/repositories.adoc"}}
{"id": "sha256:89fe1c0a54aa5447073deb31f84e371a005cb973534781f8af4a037295173700", "content": "A query method returning an Interface- or DTO projection is backed by results produced by the actual query.\nInterface projections generally rely on mapping results onto the domain type first to consider potential `@Column` type mappings and the actual projection proxy uses a potentially partially materialized entity to expose projection data.\n\nResult mapping for DTO projections depends on the actual query type.\nDerived queries use the domain type to map results, and Spring Data creates DTO instances solely from properties available on the domain type.\nDeclaring properties in your DTO that are not available on the domain type is not supported.\n\nString-based queries use a different approach since the actual query, specifically the field projection, and result type declaration are close together.\nDTO projections used with query methods annotated with `@Query` map query results directly into the DTO type.\nField mappings on the domain type are not considered.\nUsing the DTO type directly, your query method can benefit from a more dynamic projection that isn't restricted to the domain model.\n\n[[r2dbc.multiple-databases]]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/repositories.adoc", "title": "repositories", "heading": "Result Mapping", "heading_level": 3, "file_order": 32, "section_index": 2, "content_hash": "89fe1c0a54aa5447073deb31f84e371a005cb973534781f8af4a037295173700", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/repositories.adoc"}}
{"id": "sha256:f8fafde9b8040ae99e805ffe4ac712153fa6924a275181bb649d3d1be4503664", "content": "When working with multiple, potentially different databases, your application will require a different approach to configuration.\nThe provided `AbstractR2dbcConfiguration` support class assumes a single `ConnectionFactory` from which the `Dialect` gets derived.\nThat being said, you need to define a few beans yourself to configure Spring Data R2DBC to work with multiple databases.\n\nR2DBC repositories require `R2dbcEntityOperations` to implement repositories.\nA simple configuration to scan for repositories without using `AbstractR2dbcConfiguration` looks like:\n\n[source,java]\n----\n@Configuration\n@EnableR2dbcRepositories(basePackages = \"com.acme.mysql\", entityOperationsRef = \"mysqlR2dbcEntityOperations\")\nstatic class MySQLConfiguration {\n\n @Bean\n @Qualifier(\"mysql\")\n public ConnectionFactory mysqlConnectionFactory() {\n return …\n }\n\n @Bean\n public R2dbcEntityOperations mysqlR2dbcEntityOperations(@Qualifier(\"mysql\") ConnectionFactory connectionFactory) {\n\n DatabaseClient databaseClient = DatabaseClient.create(connectionFactory);\n\n return new R2dbcEntityTemplate(databaseClient, MySqlDialect.INSTANCE);\n }\n}\n----\n\nNote that `@EnableR2dbcRepositories` allows configuration either through `databaseClientRef` or `entityOperationsRef`.\nUsing various `DatabaseClient` beans is useful when connecting to multiple databases of the same type.\nWhen using different database systems that differ in their dialect, use `@EnableR2dbcRepositories`(entityOperationsRef = …)` instead.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/repositories.adoc", "title": "repositories", "heading": "Working with multiple Databases", "heading_level": 2, "file_order": 32, "section_index": 3, "content_hash": "f8fafde9b8040ae99e805ffe4ac712153fa6924a275181bb649d3d1be4503664", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/repositories.adoc"}}
{"id": "sha256:a2ee1a88b984fd5d8a0bffa1608e5d75c3cd54a93047209f9678e819273d1d9e", "content": "[[r2dbc.sequences]]\n\nPrimary key properties (annotated with `@Id`) may also be annotated with `@Sequence`.\nThe presence of the `@Sequence` annotation indicates that the property's initial value should be obtained from a database sequence at the time when the object is saved.\nThe ability of the database to generate a sequence is <<sequences.dialects,determined by the used database dialect>>.\nIn the absence of the `@Sequence` annotation, it is assumed that the value for the corresponding column is automatically generated by the database upon row insertion.\n\nConsider the following entity:\n\n.Entity with Id generation from a Sequence\n[source,java]\n----\n@Table\nclass MyEntity {\n\n    @Id\n    @Sequence(\n        sequence = \"my_seq\",\n        schema = \"public\"\n    )\n    private Long id;\n\n    // …\n}\n----\n\nWhen persisting this entity, before the SQL `INSERT`, Spring Data will issue an additional `SELECT` statement to fetch the next value from the sequence.\nFor instance, for PostgreSQL the query issued by Spring Data would look like this:\n\n.Select for next sequence value in PostgreSQL\n[source,sql]\n----\nSELECT nextval('public.my_seq');\n----\n\nThe fetched identifier value is included in `VALUES` during the insert:\n\n.Insert statement enriched with Id value\n[source,sql]\n----\nINSERT INTO \"my_entity\"(\"id\", \"name\") VALUES(?, ?);\n----\n\nNOTE: Obtaining the value from a sequence and the actual insert statement are two separate operations.\nWe highly recommend running these operations within a surrounding transaction to ensure atomicity.\n\n[[sequences.dialects]]\n== Supported Dialects\n\nThe following dialects support Sequences:\n\n* H2\n* HSQL\n* PostgreSQL\n* DB2\n* Oracle\n* Microsoft SQL Server\n\nNote that MySQL does not support sequences.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc/sequences.adoc", "title": "sequences", "heading": "sequences", "heading_level": 1, "file_order": 33, "section_index": 0, "content_hash": "a2ee1a88b984fd5d8a0bffa1608e5d75c3cd54a93047209f9678e819273d1d9e", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc/sequences.adoc"}}
{"id": "sha256:0e66c5e8df180b510a77a5afd4207888bb352bb494ffdeb7d5e5888245ce2cde", "content": "include::{commons}@data-commons::page$auditing.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/auditing.adoc", "title": "auditing", "heading": "auditing", "heading_level": 1, "file_order": 34, "section_index": 0, "content_hash": "0e66c5e8df180b510a77a5afd4207888bb352bb494ffdeb7d5e5888245ce2cde", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/auditing.adoc"}}
{"id": "sha256:2c5a96c11902424ae3b9499662341680f826a5ec4559f768491fd1198cdac1cf", "content": "include::{commons}@data-commons::page$repositories/core-concepts.adoc[]\n\ninclude::{commons}@data-commons::page$is-new-state-detection.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/core-concepts.adoc", "title": "core-concepts", "heading": "core-concepts", "heading_level": 1, "file_order": 35, "section_index": 0, "content_hash": "2c5a96c11902424ae3b9499662341680f826a5ec4559f768491fd1198cdac1cf", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/core-concepts.adoc"}}
{"id": "sha256:81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "content": "include::{commons}@data-commons::page$repositories/core-domain-events.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/core-domain-events.adoc", "title": "core-domain-events", "heading": "core-domain-events", "heading_level": 1, "file_order": 36, "section_index": 0, "content_hash": "81e019ce75dee61eea59094a236a3871f4c9af62f0fcd3a5c7a87af4b30030f9", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/core-domain-events.adoc"}}
{"id": "sha256:64aa7d024c0d4411af2a39c72ec3db2ed9b849e1a6db2f27c6bebd29fb12b71b", "content": "include::{commons}@data-commons::page$repositories/core-extensions.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/core-extensions.adoc", "title": "core-extensions", "heading": "core-extensions", "heading_level": 1, "file_order": 37, "section_index": 0, "content_hash": "64aa7d024c0d4411af2a39c72ec3db2ed9b849e1a6db2f27c6bebd29fb12b71b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/core-extensions.adoc"}}
{"id": "sha256:bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "content": "include::{commons}@data-commons::page$repositories/create-instances.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/create-instances.adoc", "title": "create-instances", "heading": "create-instances", "heading_level": 1, "file_order": 38, "section_index": 0, "content_hash": "bac28174cb786cac49ffd811dcd631b892f0813fc0fc9743e93def55346e1e58", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/create-instances.adoc"}}
{"id": "sha256:bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "content": "include::{commons}@data-commons::page$repositories/custom-implementations.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/custom-implementations.adoc", "title": "custom-implementations", "heading": "custom-implementations", "heading_level": 1, "file_order": 39, "section_index": 0, "content_hash": "bcf8fe4d0728082fd278624d23223ff29157e4fb465061471d2d50f2f401bc0d", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/custom-implementations.adoc"}}
{"id": "sha256:661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "content": "include::{commons}@data-commons::page$repositories/definition.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/definition.adoc", "title": "definition", "heading": "definition", "heading_level": 1, "file_order": 40, "section_index": 0, "content_hash": "661a93bfb9c9780b8bb205b092562b371e697955026e3abea11cc0abb0a3fc20", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/definition.adoc"}}
{"id": "sha256:f9a958c6b3be3b755558d498b7a7e470d6bdf74fd9b4492ffc2701160279b66c", "content": "[[common.basics]]\n\nThis chapter explains the basic foundations of Spring Data repositories.\nBefore continuing to the JDBC or R2DBC specifics, make sure you have a sound understanding of the basic concepts explained here.\n\nThe goal of the Spring Data repository abstraction is to significantly reduce the amount of boilerplate code required to implement data access layers for various persistence stores.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/introduction.adoc", "title": "introduction", "heading": "introduction", "heading_level": 1, "file_order": 41, "section_index": 0, "content_hash": "f9a958c6b3be3b755558d498b7a7e470d6bdf74fd9b4492ffc2701160279b66c", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/introduction.adoc"}}
{"id": "sha256:8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "content": "include::{commons}@data-commons::page$repositories/null-handling.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/null-handling.adoc", "title": "null-handling", "heading": "null-handling", "heading_level": 1, "file_order": 42, "section_index": 0, "content_hash": "8ca895bfddcd8ee24e8f9d5197f423b2399d74f11d14249d9f906762f4b72806", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/null-handling.adoc"}}
{"id": "sha256:5888b5097d61f1f2a4d7777dacd4fdb7616cd5b89bda6f1cb4509d3f4368e1ec", "content": "[[relational.projections]]\n\ninclude::{commons}@data-commons::page$repositories/projections.adoc[leveloffset=+1]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/projections.adoc", "title": "projections", "heading": "projections", "heading_level": 1, "file_order": 43, "section_index": 0, "content_hash": "5888b5097d61f1f2a4d7777dacd4fdb7616cd5b89bda6f1cb4509d3f4368e1ec", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/projections.adoc"}}
{"id": "sha256:7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "content": "include::{commons}@data-commons::page$repositories/query-keywords-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc", "title": "query-keywords-reference", "heading": "query-keywords-reference", "heading_level": 1, "file_order": 44, "section_index": 0, "content_hash": "7e953260056fa458d00ccd6d3916965e33c635a0e5a9c1068e6d4c915b4642be", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/query-keywords-reference.adoc"}}
{"id": "sha256:2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "content": "include::{commons}@data-commons::page$repositories/query-methods-details.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/query-methods-details.adoc", "title": "query-methods-details", "heading": "query-methods-details", "heading_level": 1, "file_order": 45, "section_index": 0, "content_hash": "2931a4be98bc609c2eb349faa7f3ea7d07742930fa4e31487a2957e5874e0633", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/query-methods-details.adoc"}}
{"id": "sha256:8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "content": "include::{commons}@data-commons::page$repositories/query-return-types-reference.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc", "title": "query-return-types-reference", "heading": "query-return-types-reference", "heading_level": 1, "file_order": 46, "section_index": 0, "content_hash": "8586bea837d1b2b190fc36059384044b5c88fe73a8012f0e6782feb992f85865", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/repositories/query-return-types-reference.adoc"}}
{"id": "sha256:b05569dbc89404c0c70c8922a421f7d3631ba45d9241b292b04c3f3b11bde130", "content": "[[spring-data-jpa-reference-documentation]]\n\n_Spring Data JDBC and R2DBC provide repository support for the Java Database Connectivity (JDBC) respective Reactive Relational Database Connectivity (R2DBC) APIs.\nIt eases development of applications with a consistent programming model that need to access SQL data sources._\n\n[horizontal]\nxref:repositories/introduction.adoc[Introduction] :: Introduction to Repositories\nxref:jdbc.adoc[JDBC] :: JDBC Object Mapping and Repositories\nxref:r2dbc.adoc[R2DBC] :: R2DBC Object Mapping and Repositories\nxref:kotlin.adoc[Kotlin] :: Kotlin-specific Support\nhttps://github.com/spring-projects/spring-data-commons/wiki[Wiki] :: What's New, Upgrade Notes, Supported Versions, additional cross-version information.\n\nJens Schauder, Jay Bryant, Mark Paluch, Bastian Wilhelm\n\n(C) 2008-{copyright-year} VMware, Inc.\n\nCopies of this document may be made for your own use and for distribution to others, provided that you do not charge any fee for such copies and further provided that each copy contains this Copyright Notice, whether distributed in print or electronically.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/index.adoc", "title": "index", "heading": "index", "heading_level": 1, "file_order": 47, "section_index": 0, "content_hash": "b05569dbc89404c0c70c8922a421f7d3631ba45d9241b292b04c3f3b11bde130", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/index.adoc"}}
{"id": "sha256:8e621436f22225c6a2573acf22fed3f6601a3c31ea43d12b351a7bd4f39f70bb", "content": "[[jdbc.repositories]]\n\nThe Spring Data JDBC module applies core Spring concepts to the development of solutions that use JDBC database drivers aligned with xref:jdbc/domain-driven-design.adoc[Domain-driven design principles].\nWe provide a \"`template`\" as a high-level abstraction for storing and querying aggregates.\n\nThis document is the reference guide for Spring Data JDBC support.\nIt explains the concepts and semantics and syntax.\n\nThis chapter points out the specialties for repository support for JDBC.\nThis builds on the core repository support explained in xref:repositories/introduction.adoc[Working with Spring Data Repositories].\nYou should have a sound understanding of the basic concepts explained there.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/jdbc.adoc", "title": "jdbc", "heading": "jdbc", "heading_level": 1, "file_order": 48, "section_index": 0, "content_hash": "8e621436f22225c6a2573acf22fed3f6601a3c31ea43d12b351a7bd4f39f70bb", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/jdbc.adoc"}}
{"id": "sha256:7ea6ef941532b479cba6ee5ca2f2f8dafc3373a9e29b7a6348efb81ee0c2cde3", "content": "include::{commons}@data-commons::page$kotlin.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/kotlin.adoc", "title": "kotlin", "heading": "kotlin", "heading_level": 1, "file_order": 49, "section_index": 0, "content_hash": "7ea6ef941532b479cba6ee5ca2f2f8dafc3373a9e29b7a6348efb81ee0c2cde3", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/kotlin.adoc"}}
{"id": "sha256:19c085bddb74453d4b6889684272690e893ea296f90875d37b19c0ae674f78c0", "content": "include::{commons}@data-commons::page$object-mapping.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/object-mapping.adoc", "title": "object-mapping", "heading": "object-mapping", "heading_level": 1, "file_order": 50, "section_index": 0, "content_hash": "19c085bddb74453d4b6889684272690e893ea296f90875d37b19c0ae674f78c0", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/object-mapping.adoc"}}
{"id": "sha256:2ec3e4027993398fbfd87b8c4777eca4114e15e86dbf805478e010f5978c566b", "content": "include::{commons}@data-commons::query-by-example.adoc[]\n\nHere's an example:\n\n[source,java,indent=0]\n----\ninclude::example$r2dbc/QueryByExampleTests.java[tag=example]\n----\n\n<1> Create a domain object with the criteria (`null` fields will be ignored).\n<2> Using the domain object, create an `Example`.\n<3> Through the repository, execute query (use `findOne` for a single item).\n\nThis illustrates how to craft a simple probe using a domain object.\nIn this case, it will query based on the `Employee` object's `name` field being equal to `Frodo`.\n`null` fields are ignored.\n\n[source,java,indent=0]\n----\ninclude::example$r2dbc/QueryByExampleTests.java[tag=example-2]\n----\n\n<1> Create a custom `ExampleMatcher` that matches on ALL fields (use `matchingAny()` to match on *ANY* fields)\n<2> For the `name` field, use a wildcard that matches against the end of the field\n<3> Match columns against `null` (don't forget that `NULL` doesn't equal `NULL` in relational databases).\n<4> Ignore the `role` field when forming the query.\n<5> Plug the custom `ExampleMatcher` into the probe.\n\nIt's also possible to apply a `withTransform()` against any property, allowing you to transform a property before forming the query.\nFor example, you can apply a `toUpperCase()` to a `String` -based property before the query is created.\n\nQuery By Example really shines when you don't know all the fields needed in a query in advance.\nIf you were building a filter on a web page where the user can pick the fields, Query By Example is a great way to flexibly capture that into an efficient query.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/query-by-example.adoc", "title": "query-by-example", "heading": "query-by-example", "heading_level": 1, "file_order": 51, "section_index": 0, "content_hash": "2ec3e4027993398fbfd87b8c4777eca4114e15e86dbf805478e010f5978c566b", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/query-by-example.adoc"}}
{"id": "sha256:18cdda9b7dff7eeffaa012e3c6d00d8a3813067cfa7ad94caf8c9a89efeec6ac", "content": "[[r2dbc.repositories]]\n\nThe Spring Data R2DBC module applies core Spring concepts to the development of solutions that use R2DBC database drivers aligned with xref:jdbc/domain-driven-design.adoc[Domain-driven design principles].\nWe provide a \"`template`\" as a high-level abstraction for storing and querying aggregates.\n\nThis document is the reference guide for Spring Data R2DBC support.\nIt explains the concepts and semantics and syntax.\n\nThis chapter points out the specialties for repository support for R2DBC.\nThis builds on the core repository support explained in xref:repositories/introduction.adoc[Working with Spring Data Repositories].\nYou should have a sound understanding of the basic concepts explained there.\n\nR2DBC contains a wide range of features:\n\n* Spring configuration support with xref:r2dbc/getting-started.adoc#r2dbc.connectionfactory[Java-based `@Configuration`] classes for an R2DBC driver instance.\n* xref:r2dbc/entity-persistence.adoc[`R2dbcEntityTemplate`] as central class for entity-bound operations that increases productivity when performing common R2DBC operations with integrated object mapping between rows and POJOs.\n* Feature-rich xref:r2dbc/mapping.adoc[object mapping] integrated with Spring's Conversion Service.\n* xref:r2dbc/mapping.adoc#mapping.usage.annotations[Annotation-based mapping metadata] that is extensible to support other metadata formats.\n* xref:r2dbc/repositories.adoc[Automatic implementation of Repository interfaces], including support for xref:repositories/custom-implementations.adoc[custom query methods].\n\nFor most tasks, you should use `R2dbcEntityTemplate` or the repository support, which both use the rich mapping functionality.\n`R2dbcEntityTemplate` is the place to look for accessing functionality such as ad-hoc CRUD operations.", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/r2dbc.adoc", "title": "r2dbc", "heading": "r2dbc", "heading_level": 1, "file_order": 52, "section_index": 0, "content_hash": "18cdda9b7dff7eeffaa012e3c6d00d8a3813067cfa7ad94caf8c9a89efeec6ac", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/r2dbc.adoc"}}
{"id": "sha256:2caa91a7043a965ab45f663e3422085f5da7f5ea65b463edb0a506c7c1c990a4", "content": "include::{commons}@data-commons::page$value-expressions.adoc[]", "metadata": {"source_type": "repo_asciidoc", "project": "spring-data-relational", "path": "antora/modules/ROOT/pages/value-expressions.adoc", "title": "value-expressions", "heading": "value-expressions", "heading_level": 1, "file_order": 53, "section_index": 0, "content_hash": "2caa91a7043a965ab45f663e3422085f5da7f5ea65b463edb0a506c7c1c990a4", "source_url": "https://github.com/spring-projects/spring-data-relational/blob/9aa45556e8abdd992620ea2a01fecf276a60992a/src/main/antora/modules/ROOT/pages/value-expressions.adoc"}}
